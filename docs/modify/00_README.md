# ğŸ“š ë¯¸êµ¬í˜„ ê¸°ëŠ¥ ìƒì„¸ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-10-11
**ë¶„ì„ì**: Claude Code (ì •ì§í•œ ê²€ì¦)
**ë¶„ì„ ë²”ìœ„**: `/docs/PRD` ì „ì²´ (19ê°œ ë¬¸ì„œ) vs ì‹¤ì œ ì½”ë“œë² ì´ìŠ¤
**ì‹¤ì œ êµ¬í˜„ë¥ **: **81.5%** (12ê°œ ì™„ì „ êµ¬í˜„, 5ê°œ ë¶€ë¶„ êµ¬í˜„, 2ê°œ ë¯¸êµ¬í˜„)

---

## âš ï¸ ì¤‘ìš”: ì´ì „ ì£¼ì¥ vs ì‹¤ì œ

### âŒ ì´ì „ ì£¼ì¥ (í‹€ë¦¼)
```
âœ… êµ¬í˜„ ì™„ë£Œ: 95%+
âœ… ë°ì´í„° ì¦ê°• ì™„ë£Œ
âœ… ì¶”ë¡  ìµœì í™” ì™„ë£Œ
```

### âœ… ì‹¤ì œ ê²€ì¦ ê²°ê³¼
```
ì‹¤ì œ êµ¬í˜„ë¥ : 81.5%
âŒ ë°ì´í„° ì¦ê°•: 30% (back_translator.py, paraphraser.py ë¹ˆ íŒŒì¼)
âŒ ì¶”ë¡  ìµœì í™”: 0% (PRD ë¬¸ì„œë§Œ ì¡´ì¬, ì½”ë“œ ì—†ìŒ)
âš ï¸ ì¸ì½”ë”© ë¬¸ì œ: 2ê°œ íŒŒì¼ í•œê¸€ ê¹¨ì§
```

---

## ğŸ”´ ì¹˜ëª…ì  ë¯¸êµ¬í˜„ í•­ëª©

### 1. PRD 04: ë°ì´í„° ì¦ê°• (30% êµ¬í˜„)

#### âŒ ë¯¸êµ¬í˜„ (ë¹ˆ íŒŒì¼)
```bash
# í™•ì¸ ê²°ê³¼
$ ls -lh src/augmentation/
-rw-r--r-- 1 user user    0 Oct 11 back_translator.py    # 0 bytes âŒ
-rw-r--r-- 1 user user    0 Oct 11 paraphraser.py        # 0 bytes âŒ
-rw-r--r-- 1 user user 2.0K Oct 11 text_augmenter.py     # 68 lines âœ…
```

#### êµ¬í˜„ í•„ìš” ì‚¬í•­

**íŒŒì¼ 1: `src/augmentation/back_translator.py`**
```python
"""
ì—­ë²ˆì—­ ê¸°ë°˜ ë°ì´í„° ì¦ê°•
í•œêµ­ì–´ â†’ ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ìœ¼ë¡œ ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´
"""

from transformers import MarianMTModel, MarianTokenizer
import torch

class BackTranslator:
    """ì—­ë²ˆì—­ ì¦ê°• í´ë˜ìŠ¤"""

    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        """
        ì´ˆê¸°í™”

        í•„ìš” ëª¨ë¸:
        - Helsinki-NLP/opus-mt-ko-en (í•œâ†’ì˜)
        - Helsinki-NLP/opus-mt-en-ko (ì˜â†’í•œ)
        """
        self.device = device

        # í•œâ†’ì˜ ëª¨ë¸
        self.ko_en_model = MarianMTModel.from_pretrained(
            "Helsinki-NLP/opus-mt-ko-en"
        ).to(device)
        self.ko_en_tokenizer = MarianTokenizer.from_pretrained(
            "Helsinki-NLP/opus-mt-ko-en"
        )

        # ì˜â†’í•œ ëª¨ë¸
        self.en_ko_model = MarianMTModel.from_pretrained(
            "Helsinki-NLP/opus-mt-en-ko"
        ).to(device)
        self.en_ko_tokenizer = MarianTokenizer.from_pretrained(
            "Helsinki-NLP/opus-mt-en-ko"
        )

    def back_translate(self, text: str) -> str:
        """
        ì—­ë²ˆì—­ ìˆ˜í–‰

        Args:
            text: í•œêµ­ì–´ í…ìŠ¤íŠ¸

        Returns:
            ì—­ë²ˆì—­ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸
        """
        # 1ë‹¨ê³„: í•œêµ­ì–´ â†’ ì˜ì–´
        ko_inputs = self.ko_en_tokenizer(
            text,
            return_tensors="pt",
            padding=True
        ).to(self.device)

        en_outputs = self.ko_en_model.generate(**ko_inputs)
        en_text = self.ko_en_tokenizer.decode(
            en_outputs[0],
            skip_special_tokens=True
        )

        # 2ë‹¨ê³„: ì˜ì–´ â†’ í•œêµ­ì–´
        en_inputs = self.en_ko_tokenizer(
            en_text,
            return_tensors="pt",
            padding=True
        ).to(self.device)

        ko_outputs = self.en_ko_model.generate(**en_inputs)
        back_translated = self.en_ko_tokenizer.decode(
            ko_outputs[0],
            skip_special_tokens=True
        )

        return back_translated

    def augment(self, dialogue: str, summary: str) -> tuple:
        """
        ëŒ€í™”-ìš”ì•½ ìŒ ì¦ê°•

        Args:
            dialogue: ì›ë³¸ ëŒ€í™”
            summary: ì›ë³¸ ìš”ì•½

        Returns:
            (ì¦ê°•ëœ ëŒ€í™”, ì›ë³¸ ìš”ì•½)
        """
        aug_dialogue = self.back_translate(dialogue)
        # ìš”ì•½ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        return aug_dialogue, summary

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    augmenter = BackTranslator()

    original = "#Person1#: ì•ˆë…•í•˜ì„¸ìš” #Person2#: ë°˜ê°‘ìŠµë‹ˆë‹¤"
    summary = "ì¸ì‚¬"

    aug_dialogue, aug_summary = augmenter.augment(original, summary)
    print(f"ì›ë³¸: {original}")
    print(f"ì¦ê°•: {aug_dialogue}")
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„**: 2-3ì‹œê°„
**ë‚œì´ë„**: â˜…â˜…â˜…â˜†â˜†
**ì˜ì¡´ì„±**: `transformers`, `sentencepiece`

---

**íŒŒì¼ 2: `src/augmentation/paraphraser.py`**
```python
"""
ë¬¸ì¥ ë³€í˜•(Paraphrasing) ê¸°ë°˜ ë°ì´í„° ì¦ê°•
"""

import random
from typing import Dict, List

class Paraphraser:
    """ë¬¸ì¥ ë³€í˜• ì¦ê°• í´ë˜ìŠ¤"""

    def __init__(self, seed: int = 42):
        """ì´ˆê¸°í™”"""
        self.seed = seed
        random.seed(seed)

        # ë™ì˜ì–´ ì‚¬ì „
        self.synonym_dict = {
            # ì¸ì‚¬
            "ì•ˆë…•í•˜ì„¸ìš”": ["ì•ˆë…•", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "í™˜ì˜í•©ë‹ˆë‹¤", "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ"],
            "ê°ì‚¬í•©ë‹ˆë‹¤": ["ê³ ë§™ìŠµë‹ˆë‹¤", "ê°ì‚¬í•´ìš”", "ê³ ë§ˆì›Œìš”", "ê°ì‚¬ë“œë¦½ë‹ˆë‹¤"],
            "ì£„ì†¡í•©ë‹ˆë‹¤": ["ë¯¸ì•ˆí•©ë‹ˆë‹¤", "ì£„ì†¡í•´ìš”", "ë¯¸ì•ˆí•´ìš”", "ì†¡êµ¬í•©ë‹ˆë‹¤"],

            # ë‹µë³€
            "ë„¤": ["ì˜ˆ", "ì•Œê² ìŠµë‹ˆë‹¤", "ê·¸ë ‡ìŠµë‹ˆë‹¤", "ë§ìŠµë‹ˆë‹¤"],
            "ì•„ë‹ˆìš”": ["ì•„ë‹™ë‹ˆë‹¤", "ì•„ë‹ˆì—ìš”", "ê·¸ë ‡ì§€ ì•ŠìŠµë‹ˆë‹¤"],

            # í–‰ë™
            "ë¨¹ë‹¤": ["ì„­ì·¨í•˜ë‹¤", "ë“œì‹œë‹¤", "ì‹ì‚¬í•˜ë‹¤"],
            "ê°€ë‹¤": ["ì´ë™í•˜ë‹¤", "í–¥í•˜ë‹¤", "ì¶œë°œí•˜ë‹¤"],
            "ì˜¤ë‹¤": ["ë„ì°©í•˜ë‹¤", "ë°©ë¬¸í•˜ë‹¤", "ì°¾ì•„ì˜¤ë‹¤"],

            # í˜•ìš©ì‚¬
            "ì¢‹ë‹¤": ["í›Œë¥­í•˜ë‹¤", "ê´œì°®ë‹¤", "ë§Œì¡±ìŠ¤ëŸ½ë‹¤", "ìš°ìˆ˜í•˜ë‹¤"],
            "ë‚˜ì˜ë‹¤": ["ì•ˆì¢‹ë‹¤", "ë³„ë¡œë‹¤", "í˜•í¸ì—†ë‹¤"],
            "í¬ë‹¤": ["ê±°ëŒ€í•˜ë‹¤", "ë„“ë‹¤", "í°"],
            "ì‘ë‹¤": ["ì ë‹¤", "ë¯¸ë¯¸í•˜ë‹¤", "ì‘ì€"],

            # ëª…ì‚¬
            "ë°¥": ["ì‹ì‚¬", "ìŒì‹", "ë¼ë‹ˆ"],
            "ì§‘": ["ì§‘", "ê°€ì •", "ì£¼íƒ"],
            "ì‚¬ëŒ": ["ì¸ê°„", "ì‚¬ëŒ", "ê°œì¸"],
        }

    def paraphrase(self, text: str) -> str:
        """
        ë™ì˜ì–´ ì¹˜í™˜ìœ¼ë¡œ ë¬¸ì¥ ë³€í˜•

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸

        Returns:
            ë³€í˜•ëœ í…ìŠ¤íŠ¸
        """
        result = text

        # ë™ì˜ì–´ ì‚¬ì „ì˜ ê° ë‹¨ì–´ì— ëŒ€í•´
        for original, synonyms in self.synonym_dict.items():
            if original in result:
                # 30% í™•ë¥ ë¡œ ì¹˜í™˜
                if random.random() < 0.3:
                    synonym = random.choice(synonyms)
                    result = result.replace(original, synonym, 1)

        return result

    def augment(self, dialogue: str, summary: str) -> tuple:
        """
        ëŒ€í™”-ìš”ì•½ ìŒ ì¦ê°•

        Args:
            dialogue: ì›ë³¸ ëŒ€í™”
            summary: ì›ë³¸ ìš”ì•½

        Returns:
            (ì¦ê°•ëœ ëŒ€í™”, ì›ë³¸ ìš”ì•½)
        """
        aug_dialogue = self.paraphrase(dialogue)
        # ìš”ì•½ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        return aug_dialogue, summary

    def batch_augment(
        self,
        dialogues: List[str],
        summaries: List[str],
        n_augmentations: int = 2
    ) -> tuple:
        """
        ë°°ì¹˜ ì¦ê°•

        Args:
            dialogues: ëŒ€í™” ë¦¬ìŠ¤íŠ¸
            summaries: ìš”ì•½ ë¦¬ìŠ¤íŠ¸
            n_augmentations: ì¦ê°• íšŸìˆ˜

        Returns:
            (ì¦ê°•ëœ ëŒ€í™” ë¦¬ìŠ¤íŠ¸, ì¦ê°•ëœ ìš”ì•½ ë¦¬ìŠ¤íŠ¸)
        """
        aug_dialogues = list(dialogues)
        aug_summaries = list(summaries)

        for dialogue, summary in zip(dialogues, summaries):
            for _ in range(n_augmentations):
                aug_d, aug_s = self.augment(dialogue, summary)
                aug_dialogues.append(aug_d)
                aug_summaries.append(aug_s)

        return aug_dialogues, aug_summaries

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    augmenter = Paraphraser()

    original = "#Person1#: ì•ˆë…•í•˜ì„¸ìš” #Person2#: ê°ì‚¬í•©ë‹ˆë‹¤"
    summary = "ì¸ì‚¬"

    aug_dialogue, aug_summary = augmenter.augment(original, summary)
    print(f"ì›ë³¸: {original}")
    print(f"ì¦ê°•: {aug_dialogue}")
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„**: 1-2ì‹œê°„
**ë‚œì´ë„**: â˜…â˜…â˜†â˜†â˜†

---

**`src/augmentation/__init__.py` ì—…ë°ì´íŠ¸ í•„ìš”**
```python
"""ë°ì´í„° ì¦ê°• ëª¨ë“ˆ"""

from src.augmentation.text_augmenter import TextAugmenter
from src.augmentation.back_translator import BackTranslator
from src.augmentation.paraphraser import Paraphraser

__all__ = [
    'TextAugmenter',
    'BackTranslator',
    'Paraphraser',
]

def create_augmenter(augment_type='basic', **kwargs):
    """
    ì¦ê°•ê¸° ìƒì„± íŒ©í† ë¦¬ í•¨ìˆ˜

    Args:
        augment_type: 'basic', 'back_translation', 'paraphrase'

    Returns:
        ì¦ê°•ê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    if augment_type == 'basic':
        return TextAugmenter(**kwargs)
    elif augment_type == 'back_translation':
        return BackTranslator(**kwargs)
    elif augment_type == 'paraphrase':
        return Paraphraser(**kwargs)
    else:
        raise ValueError(f"Unknown augment_type: {augment_type}")
```

---

### 2. PRD 17: ì¶”ë¡  ìµœì í™” (0% êµ¬í˜„)

#### í˜„ì¬ ìƒíƒœ
```bash
$ find src/ -name "*onnx*" -o -name "*tensorrt*" -o -name "*quantiz*"
# ê²°ê³¼: íŒŒì¼ ì—†ìŒ âŒ
```

#### êµ¬í˜„ í•„ìš” ì‚¬í•­

**ì´ ë¶€ë¶„ì€ ì„ íƒì ì…ë‹ˆë‹¤.** PRD 17ì€ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ê³ ê¸‰ ê¸°ëŠ¥ì´ë©°, í˜„ì¬ ëŒ€íšŒ ëª©ì ìƒ í•„ìˆ˜ëŠ” ì•„ë‹™ë‹ˆë‹¤.

**ê¶Œì¥**: PRD 17ì€ ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ êµ¬í˜„í•˜ê±°ë‚˜, PRD ë¬¸ì„œì—ì„œ ì œê±°í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

---

### 3. ì¸ì½”ë”© ë¬¸ì œ (2ê°œ íŒŒì¼)

#### ë¬¸ì œ íŒŒì¼
```bash
$ file src/prompts/prompt_manager.py
src/prompts/prompt_manager.py: data  # â† 'data'ë¡œ ë‚˜ì˜´ (UTF-8 ì•„ë‹˜)

$ file src/validation/data_quality.py
src/validation/data_quality.py: data  # â† 'data'ë¡œ ë‚˜ì˜´ (UTF-8 ì•„ë‹˜)
```

#### í•´ê²° ë°©ë²•

**ë‹¨ê³„ 1: íŒŒì¼ ì¸ì½”ë”© í™•ì¸**
```bash
file -i src/prompts/prompt_manager.py
file -i src/validation/data_quality.py
```

**ë‹¨ê³„ 2: UTF-8ë¡œ ë³€í™˜**
```bash
# iconv ì‚¬ìš©
iconv -f CP949 -t UTF-8 src/prompts/prompt_manager.py > temp.py
mv temp.py src/prompts/prompt_manager.py

iconv -f CP949 -t UTF-8 src/validation/data_quality.py > temp.py
mv temp.py src/validation/data_quality.py
```

ë˜ëŠ”

**Pythonìœ¼ë¡œ ì¬ì €ì¥**
```python
# fix_encoding.py
import codecs

files = [
    'src/prompts/prompt_manager.py',
    'src/validation/data_quality.py'
]

for filepath in files:
    # CP949 ë˜ëŠ” EUC-KRë¡œ ì½ê¸° ì‹œë„
    for encoding in ['cp949', 'euc-kr', 'utf-8']:
        try:
            with open(filepath, 'r', encoding=encoding) as f:
                content = f.read()

            # UTF-8ë¡œ ì¬ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)

            print(f"âœ… {filepath} - {encoding} â†’ UTF-8 ë³€í™˜ ì™„ë£Œ")
            break
        except:
            continue
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„**: 10ë¶„
**ë‚œì´ë„**: â˜…â˜†â˜†â˜†â˜†

---

## âœ… ì™„ì „ êµ¬í˜„ëœ í•­ëª© (ê²€ì¦ ì™„ë£Œ)

### 1. Solar API (PRD 09) - 100% âœ…
- âœ… `src/api/solar_client.py` (289 lines)
- âœ… Few-shot í”„ë¡¬í”„íŠ¸ ë¹Œë”
- âœ… í† í° ì ˆì•½ ì „ì²˜ë¦¬ (70% ì ˆê°)
- âœ… ë°°ì¹˜ ì²˜ë¦¬
- âœ… MD5 ê¸°ë°˜ ìºì‹±

### 2. K-Fold êµì°¨ ê²€ì¦ (PRD 10) - 100% âœ…
- âœ… `src/validation/kfold.py` (170 lines)
- âœ… Stratified K-Fold ì§€ì›
- âœ… Fold ê²°ê³¼ ì§‘ê³„

### 3. ì•™ìƒë¸” ì‹œìŠ¤í…œ (PRD 12) - 100% âœ…
- âœ… `src/ensemble/manager.py` (160 lines)
- âœ… `src/ensemble/weighted.py` (141 lines)
- âœ… `src/ensemble/voting.py` (147 lines)

### 4. Optuna ìµœì í™” (PRD 13) - 100% âœ…
- âœ… `src/optimization/optuna_optimizer.py` (409 lines)
- âœ… TPE Sampler, Median Pruner
- âœ… ì‹œê°í™” ë° ì €ì¥ ê¸°ëŠ¥

### 5. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ (PRD 15) - 100% âœ…
- âœ… `src/prompts/prompt_manager.py` (316 lines, ì¸ì½”ë”© ë¬¸ì œë§Œ ìˆìŒ)
- âœ… `src/prompts/templates.py` (302 lines)
- âœ… 12ê°œ í…œí”Œë¦¿ êµ¬í˜„

### 6. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (PRD 16) - 100% âœ…
- âœ… `src/validation/data_quality.py` (444 lines, ì¸ì½”ë”© ë¬¸ì œë§Œ ìˆìŒ)
- âœ… 4ë‹¨ê³„ ê²€ì¦ (êµ¬ì¡°, ì˜ë¯¸, í†µê³„, ì´ìƒì¹˜)

### 7. í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ - 100% âœ…
- âœ… `src/postprocessing/text_postprocessor.py` (59 lines)

### 8. Config ì „ëµ - 100% âœ…
- âœ… `configs/strategies/data_augmentation.yaml`
- âœ… `configs/strategies/ensemble.yaml`
- âœ… `configs/strategies/optuna.yaml`
- âœ… `configs/strategies/cross_validation.yaml`

---

## ğŸ“Š ìš°ì„ ìˆœìœ„ë³„ ì‘ì—… ê³„íš

### ğŸ”´ ê¸´ê¸‰ (ì¦‰ì‹œ ì²˜ë¦¬)
1. **ì¸ì½”ë”© ë¬¸ì œ í•´ê²°** (10ë¶„)
   - `src/prompts/prompt_manager.py`
   - `src/validation/data_quality.py`

### ğŸŸ  ì¤‘ìš” (1-2ì¼)
2. **ë°ì´í„° ì¦ê°• ì™„ì„±** (3-5ì‹œê°„)
   - `back_translator.py` êµ¬í˜„ (2-3h)
   - `paraphraser.py` êµ¬í˜„ (1-2h)
   - `__init__.py` ì—…ë°ì´íŠ¸ (10ë¶„)

### ğŸŸ¢ ì„ íƒì  (ë‚˜ì¤‘ì—)
3. **ì¶”ë¡  ìµœì í™”** (8-10ì‹œê°„, ì„ íƒ)
   - ONNX, TensorRT ë“±
   - ë˜ëŠ” PRD 17 ë¬¸ì„œ ì œê±° ê³ ë ¤

---

## ğŸ¯ ìˆ˜ì •ëœ ì „ì²´ êµ¬í˜„ë¥ 

```
ì™„ì „ êµ¬í˜„ (90%+): 12ê°œ PRD (63%)
ë¶€ë¶„ êµ¬í˜„ (50-89%): 5ê°œ PRD (26%)
ë¯¸êµ¬í˜„ (<50%): 2ê°œ PRD (11%)

ì „ì²´ í‰ê· : 81.5%
```

### ê¸´ê¸‰ ìˆ˜ì • í›„ ì˜ˆìƒ êµ¬í˜„ë¥ 
```
ì¸ì½”ë”© ë¬¸ì œ í•´ê²°: 81.5% â†’ 83%
ë°ì´í„° ì¦ê°• ì™„ì„±: 83% â†’ 87%

ìµœì¢… ëª©í‘œ: 87%+ (ì¶”ë¡  ìµœì í™” ì œì™¸)
```

---

## ğŸ“ ë‹¤ìŒ ë¬¸ì„œ

- **01_PRD_êµ¬í˜„_ê°­_ë¶„ì„.md**: ìƒì„¸ PRDë³„ ë¶„ì„ (ì´ë¯¸ ì •í™•í•¨)
- **02_ì‹¤í–‰_ì˜µì…˜_ì‹œìŠ¤í…œ_êµ¬í˜„_ê°€ì´ë“œ.md**: ì„ íƒì  ê³ ê¸‰ ê¸°ëŠ¥
- **03_LLM_í†µí•©_ê°€ì´ë“œ.md**: ì„ íƒì  ê³ ê¸‰ ê¸°ëŠ¥

---

## ğŸ’¡ í•µì‹¬ ë©”ì‹œì§€

**ê±°ì§“ë§ ì—†ì´ ì •ì§í•˜ê²Œ:**
- âœ… í•µì‹¬ ê¸°ëŠ¥ì€ **ëŒ€ë¶€ë¶„ êµ¬í˜„**ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (81.5%)
- âŒ ë°ì´í„° ì¦ê°•ì€ **30%ë§Œ** êµ¬í˜„ (ë¹ˆ íŒŒì¼ 2ê°œ)
- âŒ ì¶”ë¡  ìµœì í™”ëŠ” **0%** (ë¬¸ì„œë§Œ ì¡´ì¬)
- âš ï¸ ì¸ì½”ë”© ë¬¸ì œë¡œ í•œê¸€ì´ ê¹¨ì§„ íŒŒì¼ 2ê°œ

**ë¹ ë¥´ê²Œ ìˆ˜ì • ê°€ëŠ¥:**
- ì¸ì½”ë”© ë¬¸ì œ: 10ë¶„
- ë°ì´í„° ì¦ê°•: 3-5ì‹œê°„
- ì´ ì‘ì—… ì‹œê°„: **5ì‹œê°„ ì´ë‚´**

**í˜„ì¬ ì‹œìŠ¤í…œìœ¼ë¡œ ê°€ëŠ¥í•œ ê²ƒ:**
- âœ… í•™ìŠµ ë° ì¶”ë¡  (KoBART, Llama, Qwen)
- âœ… Solar API ì‚¬ìš©
- âœ… K-Fold êµì°¨ ê²€ì¦
- âœ… ì•™ìƒë¸”
- âœ… Optuna ìµœì í™”
- âš ï¸ ê¸°ë³¸ ë°ì´í„° ì¦ê°•ë§Œ (ê³ ê¸‰ ì¦ê°• ë¯¸ì§€ì›)
