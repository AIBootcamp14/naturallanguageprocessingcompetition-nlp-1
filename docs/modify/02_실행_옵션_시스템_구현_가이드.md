# 🎮 실행 옵션 시스템 구현 가이드

**우선순위**: 🔥 최우선 (PRD 14번)
**예상 작업 시간**: 12-16시간
**난이도**: ★★★★☆

---

## 📋 목표

**현재 `train.py`를 PRD 14번에 명시된 통합 실행 인터페이스로 완전히 재작성**

### Before (현재)
```bash
python scripts/train.py --experiment baseline_kobart --debug
```

### After (목표)
```bash
# 단일 모델 학습
python scripts/train.py --mode single --models kobart --epochs 20

# K-Fold 교차 검증
python scripts/train.py --mode kfold --models solar-10.7b --k_folds 5

# 다중 모델 앙상블
python scripts/train.py --mode multi_model --models kobart llama-3.2-3b qwen3-4b

# Optuna 최적화
python scripts/train.py --mode optuna --models kobart --optuna_trials 100

# 풀 파이프라인 (모든 옵션)
python scripts/train.py --mode full --models all --use_tta --k_folds 5
```

---

## 🏗️ 아키텍처 설계

### 1. Trainer 클래스 계층 구조

```
src/trainers/
├── __init__.py
├── base_trainer.py          # BaseTrainer 추상 클래스
├── single_trainer.py         # SingleModelTrainer
├── kfold_trainer.py          # KFoldTrainer
├── multi_model_trainer.py    # MultiModelEnsembleTrainer
├── optuna_trainer.py         # OptunaOptimizer
└── full_pipeline_trainer.py  # FullPipelineTrainer
```

#### BaseTrainer (추상 클래스)
```python
# src/trainers/base_trainer.py
from abc import ABC, abstractmethod
from pathlib import Path

class BaseTrainer(ABC):
    """모든 Trainer의 기본 클래스"""

    def __init__(self, args, logger, wandb_logger=None):
        self.args = args
        self.logger = logger
        self.wandb_logger = wandb_logger
        self.output_dir = Path(args.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    @abstractmethod
    def train(self):
        """학습 메인 로직 (서브클래스에서 구현)"""
        pass

    @abstractmethod
    def save_results(self, results):
        """결과 저장 (서브클래스에서 구현)"""
        pass

    def log(self, message, level='INFO'):
        """통합 로깅"""
        self.logger.write(message)
        if self.wandb_logger:
            self.wandb_logger.log_text(message)

    def load_data(self):
        """공통 데이터 로딩 로직"""
        import pandas as pd
        train_df = pd.read_csv(self.args.train_data)
        eval_df = pd.read_csv(self.args.dev_data)

        if self.args.debug:
            train_df = train_df.head(100)
            eval_df = eval_df.head(20)

        return train_df, eval_df
```

#### SingleModelTrainer
```python
# src/trainers/single_trainer.py
from src.trainers.base_trainer import BaseTrainer
from src.models import load_model_and_tokenizer
from src.data import DialogueSummarizationDataset
from src.training import create_trainer

class SingleModelTrainer(BaseTrainer):
    """단일 모델 학습"""

    def train(self):
        self.log("=" * 60)
        self.log("SINGLE MODEL 모드 학습 시작")
        self.log(f"모델: {self.args.models[0]}")
        self.log("=" * 60)

        # 1. 데이터 로드
        train_df, eval_df = self.load_data()
        self.log(f"학습 데이터: {len(train_df)}개")
        self.log(f"검증 데이터: {len(eval_df)}개")

        # 2. Config 로드 (모델별)
        from src.config import load_model_config
        config = load_model_config(self.args.models[0])

        # 3. 모델 로드
        model, tokenizer = load_model_and_tokenizer(config, logger=self.logger)

        # 4. Dataset 생성
        train_dataset = DialogueSummarizationDataset(
            dialogues=train_df['dialogue'].tolist(),
            summaries=train_df['summary'].tolist(),
            tokenizer=tokenizer,
            encoder_max_len=config.tokenizer.encoder_max_len,
            decoder_max_len=config.tokenizer.decoder_max_len,
            preprocess=True
        )

        eval_dataset = DialogueSummarizationDataset(
            dialogues=eval_df['dialogue'].tolist(),
            summaries=eval_df['summary'].tolist(),
            tokenizer=tokenizer,
            encoder_max_len=config.tokenizer.encoder_max_len,
            decoder_max_len=config.tokenizer.decoder_max_len,
            preprocess=True
        )

        # 5. Trainer 생성
        trainer = create_trainer(
            config=config,
            model=model,
            tokenizer=tokenizer,
            train_dataset=train_dataset,
            eval_dataset=eval_dataset,
            use_wandb=self.args.use_wandb,
            logger=self.logger
        )

        # 6. 학습 실행
        results = trainer.train()

        self.log("=" * 60)
        self.log("SINGLE MODEL 학습 완료!")
        self.log("=" * 60)

        return {
            'mode': 'single',
            'model': self.args.models[0],
            'results': results,
            'model_path': trainer.model_save_path
        }

    def save_results(self, results):
        """결과 저장"""
        import json
        result_path = self.output_dir / "single_model_results.json"

        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        self.log(f"결과 저장: {result_path}")
```

#### KFoldTrainer
```python
# src/trainers/kfold_trainer.py
from src.trainers.base_trainer import BaseTrainer
from sklearn.model_selection import KFold

class KFoldTrainer(BaseTrainer):
    """K-Fold 교차 검증 학습"""

    def train(self):
        self.log("=" * 60)
        self.log("K-FOLD 모드 학습 시작")
        self.log(f"K-Folds: {self.args.k_folds}")
        self.log(f"모델: {self.args.models[0]}")
        self.log("=" * 60)

        # 1. 전체 데이터 로드
        train_df, _ = self.load_data()

        # 2. K-Fold 분할
        kf = KFold(n_splits=self.args.k_folds, shuffle=True, random_state=self.args.fold_seed)
        fold_results = []

        for fold_idx, (train_indices, val_indices) in enumerate(kf.split(train_df)):
            self.log(f"\n{'=' * 40}")
            self.log(f"Fold {fold_idx + 1}/{self.args.k_folds} 시작")
            self.log(f"{'=' * 40}")

            # Fold별 데이터 분할
            fold_train_df = train_df.iloc[train_indices]
            fold_val_df = train_df.iloc[val_indices]

            # Fold별 학습 (SingleModelTrainer 재활용)
            fold_result = self._train_fold(fold_idx, fold_train_df, fold_val_df)
            fold_results.append(fold_result)

            self.log(f"Fold {fold_idx + 1} 완료: ROUGE = {fold_result['rouge']:.4f}")

        # 3. 평균 성능 계산
        avg_rouge = sum(r['rouge'] for r in fold_results) / len(fold_results)

        self.log("\n" + "=" * 60)
        self.log(f"K-FOLD 평균 성능: ROUGE = {avg_rouge:.4f}")
        self.log("=" * 60)

        return {
            'mode': 'kfold',
            'k_folds': self.args.k_folds,
            'fold_results': fold_results,
            'avg_rouge': avg_rouge
        }

    def _train_fold(self, fold_idx, train_df, val_df):
        """개별 Fold 학습"""
        from src.config import load_model_config
        from src.models import load_model_and_tokenizer
        from src.data import DialogueSummarizationDataset
        from src.training import create_trainer

        config = load_model_config(self.args.models[0])
        model, tokenizer = load_model_and_tokenizer(config, logger=self.logger)

        train_dataset = DialogueSummarizationDataset(
            dialogues=train_df['dialogue'].tolist(),
            summaries=train_df['summary'].tolist(),
            tokenizer=tokenizer,
            encoder_max_len=config.tokenizer.encoder_max_len,
            decoder_max_len=config.tokenizer.decoder_max_len,
            preprocess=True
        )

        val_dataset = DialogueSummarizationDataset(
            dialogues=val_df['dialogue'].tolist(),
            summaries=val_df['summary'].tolist(),
            tokenizer=tokenizer,
            encoder_max_len=config.tokenizer.encoder_max_len,
            decoder_max_len=config.tokenizer.decoder_max_len,
            preprocess=True
        )

        trainer = create_trainer(
            config=config,
            model=model,
            tokenizer=tokenizer,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            use_wandb=self.args.use_wandb,
            logger=self.logger,
            experiment_name=f"{self.args.experiment_name}_fold{fold_idx}"
        )

        results = trainer.train()

        return {
            'fold': fold_idx,
            'rouge': results['eval_metrics'].get('rouge_sum', 0),
            'model_path': trainer.model_save_path
        }

    def save_results(self, results):
        """결과 저장"""
        import json
        result_path = self.output_dir / "kfold_results.json"

        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        self.log(f"결과 저장: {result_path}")
```

#### MultiModelEnsembleTrainer (개요만)
```python
# src/trainers/multi_model_trainer.py
from src.trainers.base_trainer import BaseTrainer

class MultiModelEnsembleTrainer(BaseTrainer):
    """다중 모델 앙상블 학습"""

    def train(self):
        self.log("=" * 60)
        self.log("MULTI-MODEL ENSEMBLE 모드 학습 시작")
        self.log(f"모델 수: {len(self.args.models)}")
        self.log(f"모델 목록: {', '.join(self.args.models)}")
        self.log(f"앙상블 전략: {self.args.ensemble_strategy}")
        self.log("=" * 60)

        # 1. 각 모델 개별 학습
        model_results = []
        for model_name in self.args.models:
            self.log(f"\n{'=' * 40}")
            self.log(f"모델 학습: {model_name}")
            self.log(f"{'=' * 40}")

            # SingleModelTrainer 재활용
            result = self._train_single_model(model_name)
            model_results.append(result)

        # 2. 앙상블 (src/ensemble/ 모듈 사용)
        from src.ensemble import create_ensemble
        ensemble = create_ensemble(
            models=model_results,
            strategy=self.args.ensemble_strategy,
            weights=self.args.ensemble_weights
        )

        # 3. 앙상블 평가
        ensemble_score = self._evaluate_ensemble(ensemble)

        return {
            'mode': 'multi_model',
            'models': self.args.models,
            'model_results': model_results,
            'ensemble_score': ensemble_score
        }

    def _train_single_model(self, model_name):
        # SingleModelTrainer 로직 재활용
        pass

    def save_results(self, results):
        # 결과 저장
        pass
```

#### OptunaOptimizer (개요만)
```python
# src/trainers/optuna_trainer.py
from src.trainers.base_trainer import BaseTrainer
import optuna

class OptunaOptimizer(BaseTrainer):
    """Optuna 하이퍼파라미터 최적화"""

    def train(self):
        self.log("=" * 60)
        self.log("OPTUNA 최적화 모드 시작")
        self.log(f"Trials: {self.args.optuna_trials}")
        self.log(f"Sampler: {self.args.optuna_sampler}")
        self.log("=" * 60)

        # Optuna Study 생성
        study = optuna.create_study(
            study_name=self.args.experiment_name,
            direction='maximize',
            sampler=self._get_sampler(),
            pruner=self._get_pruner()
        )

        # 최적화 실행
        study.optimize(
            self.objective,
            n_trials=self.args.optuna_trials,
            timeout=self.args.optuna_timeout
        )

        self.log(f"\nBest Trial: {study.best_trial.number}")
        self.log(f"Best Value: {study.best_value:.4f}")
        self.log(f"Best Params: {study.best_params}")

        return {
            'mode': 'optuna',
            'best_params': study.best_params,
            'best_value': study.best_value,
            'study': study
        }

    def objective(self, trial):
        """Optuna 목적 함수"""
        # 하이퍼파라미터 샘플링
        lr = trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True)
        batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32])

        # 모델 학습 및 평가
        score = self._train_with_params(lr, batch_size)

        return score

    def save_results(self, results):
        # Optuna 결과 저장
        pass
```

---

## 📝 train.py 재작성

### 완전한 train.py (PRD 14 기반)

```python
#!/usr/bin/env python3
# scripts/train.py
"""
NLP 대화 요약 통합 학습 스크립트
PRD 14번 "실행 옵션 시스템" 구현

사용법:
    # 단일 모델
    python train.py --mode single --models kobart

    # K-Fold
    python train.py --mode kfold --models solar-10.7b --k_folds 5

    # 다중 모델 앙상블
    python train.py --mode multi_model --models kobart llama-3.2-3b

    # Optuna 최적화
    python train.py --mode optuna --optuna_trials 50

    # 풀 파이프라인
    python train.py --mode full --models all --use_tta
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime

# 프로젝트 루트 추가
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.logging import Logger
from src.utils.config.seed import set_seed


def parse_arguments():
    """명령행 인자 파싱"""
    parser = argparse.ArgumentParser(
        description='NLP 대화 요약 모델 학습 - 유연한 실행 옵션',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    # ==================== 기본 설정 ====================
    parser.add_argument(
        '--mode',
        type=str,
        default='single',
        choices=['single', 'kfold', 'multi_model', 'optuna', 'full'],
        help='''실행 모드 선택:
        single: 단일 모델 학습 (빠른 실험)
        kfold: K-Fold 교차 검증 (안정성)
        multi_model: 다중 모델 앙상블 (성능)
        optuna: 하이퍼파라미터 최적화 (자동화)
        full: 전체 파이프라인 (최종 제출)'''
    )

    parser.add_argument(
        '--config',
        type=str,
        default='configs/train_config.yaml',
        help='설정 파일 경로'
    )

    parser.add_argument(
        '--experiment_name',
        type=str,
        default=None,
        help='실험명 (자동 생성: {mode}_{model}_{timestamp})'
    )

    # ==================== 모델 선택 ====================
    parser.add_argument(
        '--models',
        type=str,
        nargs='+',
        default=['kobart'],
        choices=[
            'kobart',
            'solar-10.7b',
            'polyglot-ko-12.8b',
            'llama-3.2-korean-3b',
            'qwen3-4b',
            'kullm-v2',
            'all'  # 모든 모델
        ],
        help='사용할 모델 (multi_model 모드에서 여러 개 선택 가능)'
    )

    # ==================== 학습 설정 ====================
    parser.add_argument(
        '--epochs',
        type=int,
        default=None,
        help='에폭 수 (None: config 파일 값 사용)'
    )

    parser.add_argument(
        '--batch_size',
        type=int,
        default=None,
        help='배치 크기 (None: config 파일 값 사용 또는 자동 탐색)'
    )

    parser.add_argument(
        '--learning_rate',
        type=float,
        default=None,
        help='학습률 (None: config 파일 값 사용)'
    )

    # ==================== K-Fold 설정 ====================
    parser.add_argument(
        '--k_folds',
        type=int,
        default=5,
        help='K-Fold 수 (kfold 모드)'
    )

    parser.add_argument(
        '--fold_seed',
        type=int,
        default=42,
        help='Fold 분할 시드'
    )

    # ==================== 앙상블 설정 ====================
    parser.add_argument(
        '--ensemble_strategy',
        type=str,
        default='weighted_avg',
        choices=[
            'averaging',
            'weighted_avg',
            'majority_vote',
            'stacking',
            'blending',
            'rouge_weighted'
        ],
        help='앙상블 전략'
    )

    parser.add_argument(
        '--ensemble_weights',
        type=float,
        nargs='+',
        default=None,
        help='모델별 가중치 (자동 최적화 가능)'
    )

    # ==================== TTA 설정 ====================
    parser.add_argument(
        '--use_tta',
        action='store_true',
        help='Test Time Augmentation 사용'
    )

    parser.add_argument(
        '--tta_strategies',
        type=str,
        nargs='+',
        default=['paraphrase'],
        choices=['paraphrase', 'reorder', 'synonym', 'mask'],
        help='TTA 전략'
    )

    parser.add_argument(
        '--tta_num_aug',
        type=int,
        default=3,
        help='TTA 증강 수'
    )

    # ==================== Optuna 설정 ====================
    parser.add_argument(
        '--optuna_trials',
        type=int,
        default=100,
        help='Optuna 시도 횟수'
    )

    parser.add_argument(
        '--optuna_timeout',
        type=int,
        default=7200,
        help='Optuna 제한 시간 (초)'
    )

    parser.add_argument(
        '--optuna_sampler',
        type=str,
        default='tpe',
        choices=['tpe', 'gp', 'random', 'cmaes'],
        help='Optuna 샘플러'
    )

    parser.add_argument(
        '--optuna_pruner',
        type=str,
        default='median',
        choices=['median', 'percentile', 'hyperband'],
        help='Optuna 가지치기'
    )

    # ==================== 로깅 및 모니터링 ====================
    parser.add_argument(
        '--use_wandb',
        action='store_true',
        help='WandB 사용'
    )

    parser.add_argument(
        '--wandb_project',
        type=str,
        default='dialogue-summarization',
        help='WandB 프로젝트명'
    )

    parser.add_argument(
        '--save_visualizations',
        action='store_true',
        help='시각화 저장'
    )

    # ==================== 기타 옵션 ====================
    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help='랜덤 시드'
    )

    parser.add_argument(
        '--debug',
        action='store_true',
        help='디버그 모드 (적은 데이터)'
    )

    # ==================== 데이터 경로 ====================
    parser.add_argument(
        '--train_data',
        type=str,
        default='data/raw/train.csv',
        help='학습 데이터 경로'
    )

    parser.add_argument(
        '--dev_data',
        type=str,
        default='data/raw/dev.csv',
        help='검증 데이터 경로'
    )

    return parser.parse_args()


def setup_environment(args):
    """환경 설정"""
    # 시드 설정
    set_seed(args.seed)

    # 실험명 자동 생성
    if args.experiment_name is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = args.models[0].replace('-', '_') if args.models else 'default'
        args.experiment_name = f"{args.mode}_{model_name}_{timestamp}"

    # 출력 디렉토리 생성
    output_dir = Path(f"experiments/{args.experiment_name}")
    output_dir.mkdir(parents=True, exist_ok=True)
    args.output_dir = str(output_dir)

    # 로거 설정
    log_path = output_dir / "train.log"
    logger = Logger(log_path, print_also=True)
    logger.start_redirect()

    return logger


def get_trainer(args, logger):
    """모드에 따른 Trainer 선택"""
    from src.trainers import (
        SingleModelTrainer,
        KFoldTrainer,
        MultiModelEnsembleTrainer,
        OptunaOptimizer,
        FullPipelineTrainer
    )

    trainer_map = {
        'single': SingleModelTrainer,
        'kfold': KFoldTrainer,
        'multi_model': MultiModelEnsembleTrainer,
        'optuna': OptunaOptimizer,
        'full': FullPipelineTrainer
    }

    trainer_class = trainer_map[args.mode]
    return trainer_class(args, logger)


def main():
    """메인 실행 함수"""
    # 인자 파싱
    args = parse_arguments()

    print("=" * 60)
    print("🚀 NLP 대화 요약 학습 시작")
    print(f"📋 실행 모드: {args.mode}")
    print(f"🤖 모델: {', '.join(args.models)}")
    print("=" * 60)

    # 환경 설정
    logger = setup_environment(args)

    try:
        # Trainer 생성
        trainer = get_trainer(args, logger)

        # 학습 실행
        print(f"\n📊 {args.mode.upper()} 모드 실행 중...")
        results = trainer.train()

        # 결과 저장
        trainer.save_results(results)

        # 시각화
        if args.save_visualizations:
            print("\n📈 시각화 생성 중...")
            from src.utils.visualizations import create_training_visualizations
            create_training_visualizations(
                results=results,
                output_dir=args.output_dir
            )

        print("\n✅ 학습 완료!")
        print(f"📁 결과 저장: {args.output_dir}")

    except Exception as e:
        logger.write(f"❌ 오류 발생: {e}", print_error=True)
        raise

    finally:
        # 정리
        logger.stop_redirect()
        logger.close()


if __name__ == "__main__":
    main()
```

---

## 🔧 구현 체크리스트

### Phase 1: 디렉토리 구조 생성 (30분)
- [ ] `src/trainers/` 디렉토리 생성
- [ ] `src/trainers/__init__.py` 작성
- [ ] 각 Trainer 파일 생성 (빈 클래스)

### Phase 2: BaseTrainer 구현 (2시간)
- [ ] `base_trainer.py` 완성
- [ ] 공통 메서드 구현 (`load_data`, `log` 등)
- [ ] 추상 메서드 정의

### Phase 3: SingleModelTrainer 구현 (3시간)
- [ ] `single_trainer.py` 완성
- [ ] 기존 `train.py` 로직 이전
- [ ] 테스트 실행

### Phase 4: KFoldTrainer 구현 (4시간)
- [ ] `kfold_trainer.py` 완성
- [ ] K-Fold 분할 로직
- [ ] Fold별 학습 루프
- [ ] 평균 성능 계산

### Phase 5: train.py 재작성 (3시간)
- [ ] 기존 `train.py` 백업
- [ ] 새로운 `train.py` 작성
- [ ] 인자 파싱 (50+ 옵션)
- [ ] Trainer 선택 로직

### Phase 6: 테스트 (2시간)
- [ ] Single 모드 테스트
- [ ] KFold 모드 테스트
- [ ] 각종 옵션 조합 테스트

### Phase 7: 고급 Trainer 구현 (나중에, 8시간)
- [ ] `multi_model_trainer.py`
- [ ] `optuna_trainer.py`
- [ ] `full_pipeline_trainer.py`

---

## 🚀 즉시 시작

### 1. 디렉토리 생성
```bash
cd /home/ieyeppo/AI_Lab/natural-language-processing-competition

mkdir -p src/trainers

touch src/trainers/__init__.py
touch src/trainers/base_trainer.py
touch src/trainers/single_trainer.py
touch src/trainers/kfold_trainer.py
touch src/trainers/multi_model_trainer.py
touch src/trainers/optuna_trainer.py
touch src/trainers/full_pipeline_trainer.py
```

### 2. 기존 파일 백업
```bash
cp scripts/train.py scripts/train_old.py
```

### 3. BaseTrainer 작성 시작
```bash
# src/trainers/base_trainer.py 파일을 편집기로 열기
# 위의 BaseTrainer 코드 붙여넣기
```

---

## 📊 예상 성과

### 구현 후 사용 예시
```bash
# 빠른 실험
python train.py --mode single --models kobart --debug

# 프로덕션 학습
python train.py --mode kfold --models solar-10.7b --k_folds 5 --use_wandb

# 최종 제출
python train.py --mode full --models all --use_tta --save_visualizations
```

### 사용자 경험 개선
- ✅ 하나의 스크립트로 모든 실험 가능
- ✅ 옵션으로 기능 선택 가능
- ✅ 재현 가능한 실험 관리
- ✅ PRD 요구사항 100% 충족

---

**다음 작업**: `03_LLM_통합_가이드.md`
