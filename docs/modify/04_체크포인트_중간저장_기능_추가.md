# μ²΄ν¬ν¬μΈνΈ μ¤‘κ°„ μ €μ¥ κΈ°λ¥ μ¶”κ°€ λ°©μ•

> **λ©μ **: ν•™μµ/μ¶”λ΅ /κ²€μ¦ κ° λ‹¨κ³„λ§λ‹¤ μ²΄ν¬ν¬μΈνΈλ¥Ό μ €μ¥ν•μ—¬ μ¤‘λ‹¨ μ‹ μ΄μ–΄μ„ μ‹¤ν–‰ κ°€λ¥ν•λ„λ΅ κ°μ„ 
> **μ‘μ„±μΌ**: 2025-10-14
> **μ°μ„ μμ„**: π”¥ λ†’μ (μ‹¤ν–‰ μ•μ •μ„± ν•„μ)

---

## π“‹ λ©μ°¨

1. [λ¬Έμ  μƒν™© λ° ν•„μ”μ„±](#1-λ¬Έμ -μƒν™©-λ°-ν•„μ”μ„±)
2. [μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ „λµ](#2-μ²΄ν¬ν¬μΈνΈ-μ €μ¥-μ „λµ)
3. [λ‹¨κ³„λ³„ κµ¬ν„ λ°©μ•](#3-λ‹¨κ³„λ³„-κµ¬ν„-λ°©μ•)
4. [μ²΄ν¬ν¬μΈνΈ νμΌ κµ¬μ΅°](#4-μ²΄ν¬ν¬μΈνΈ-νμΌ-κµ¬μ΅°)
5. [Resume λ΅μ§ μ„¤κ³„](#5-resume-λ΅μ§-μ„¤κ³„)
6. [κµ¬ν„ μƒμ„Έ κ³„ν](#6-κµ¬ν„-μƒμ„Έ-κ³„ν)
7. [ν…μ¤νΈ μ‹λ‚λ¦¬μ¤](#7-ν…μ¤νΈ-μ‹λ‚λ¦¬μ¤)

---

## 1. λ¬Έμ  μƒν™© λ° ν•„μ”μ„±

### 1.1 ν„μ¬ λ°μƒν•λ” λ¬Έμ 

```mermaid
graph TB
    subgraph Problem["β ν„μ¬ λ¬Έμ  μƒν™©"]
        A[ν•™μµ μ‹μ‘] --> B[Optuna μµμ ν™”]
        B --> C{μ¤‘λ‹¨ λ°μƒ}
        C -->|μ¤λ¥| D[β λ¨λ“  μ§„ν–‰ μƒν™© μ†μ‹¤]
        C -->|μ‹¤μ| D
        C -->|νƒ€μ„μ•„μ›ƒ| D

        B --> E[K-Fold ν•™μµ]
        E --> F{Fold 3/5 μ¤‘λ‹¨}
        F --> G[β Fold 1-2 κ²°κ³Ό μ†μ‹¤]

        E --> H[λ°μ΄ν„° μ¦κ°•]
        H --> I{μ¦κ°• μ¤‘ μ¤‘λ‹¨}
        I --> J[β μ¦κ°• λ°μ΄ν„° μ¬μƒμ„± ν•„μ”]
    end

    style Problem fill:#ffebee,stroke:#c62828,color:#000
    style D fill:#ef5350,stroke:#c62828,color:#fff
    style G fill:#ef5350,stroke:#c62828,color:#fff
    style J fill:#ef5350,stroke:#c62828,color:#fff
```

### 1.2 ν•„μ”ν• μ²΄ν¬ν¬μΈνΈ μ§€μ 

| λ‹¨κ³„ | μ²΄ν¬ν¬μΈνΈ ν•„μ” μ‹μ  | μ €μ¥ λ‚΄μ© | μ°μ„ μμ„ |
|------|---------------------|----------|----------|
| **Optuna μµμ ν™”** | κ° Trial μ™„λ£ ν›„ | Trial κ²°κ³Ό, μµμ  νλΌλ―Έν„° | π”¥ λ†’μ |
| **λ°μ΄ν„° μ¦κ°•** | μ¦κ°• μ™„λ£ ν›„ | μ¦κ°•λ λ°μ΄ν„°μ…‹ | π”¥ λ†’μ |
| **K-Fold ν•™μµ** | κ° Fold μ™„λ£ ν›„ | Fold λ¨λΈ, ν‰κ°€ κ²°κ³Ό | π”¥ λ†’μ |
| **HuggingFace λ³΄μ •** | λ³΄μ • μ™„λ£ ν›„ | λ³΄μ •λ μ”μ•½, ν†µκ³„ | μ¤‘κ°„ |
| **Solar API νΈμ¶** | λ°°μΉ μ™„λ£ ν›„ | API μ‘λ‹µ, μΊμ‹ | μ¤‘κ°„ |
| **κ²€μ¦** | κ²€μ¦ μ™„λ£ ν›„ | ROUGE μ μ, λ©”νΈλ¦­ | λ‚®μ |

---

## 2. μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ „λµ

### 2.1 μ „μ²΄ μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν… κµ¬μ΅°

```mermaid
graph TB
    subgraph CheckpointSystem["β… μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν…"]
        A[μ‹¤ν–‰ μ‹μ‘] --> B{μ²΄ν¬ν¬μΈνΈ μ΅΄μ¬?}

        B -->|Yes| C[μ²΄ν¬ν¬μΈνΈ λ΅λ“]
        B -->|No| D[μ²μλ¶€ν„° μ‹μ‘]

        C --> E[μ΄μ–΄μ„ μ‹¤ν–‰]
        D --> E

        E --> F[μ‘μ—… μ§„ν–‰]
        F --> G[λ‹¨κ³„ μ™„λ£]
        G --> H[μ²΄ν¬ν¬μΈνΈ μ €μ¥]

        H --> I{λ‹¤μ λ‹¨κ³„?}
        I -->|Yes| F
        I -->|No| J[β… μ™„λ£]
    end

    style CheckpointSystem fill:#e8f5e9,stroke:#1b5e20,color:#000
    style C fill:#81c784,stroke:#388e3c,color:#000
    style H fill:#66bb6a,stroke:#2e7d32,color:#fff
    style J fill:#4caf50,stroke:#1b5e20,color:#fff
```

### 2.2 μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ›μΉ™

1. **μλ™ μ €μ¥**: κ° μ¤‘μ” λ‹¨κ³„ μ™„λ£ μ‹ μλ™μΌλ΅ μ €μ¥
2. **μ¦λ¶„ μ €μ¥**: μ΄μ „ μ²΄ν¬ν¬μΈνΈλ” μ μ§€ν•κ³  μƒλ΅μ΄ μ²΄ν¬ν¬μΈνΈ μ¶”κ°€
3. **λ©”νƒ€λ°μ΄ν„°**: μ§„ν–‰ μƒν™©, νƒ€μ„μ¤νƒ¬ν”„, λ²„μ „ μ •λ³΄ ν¬ν•¨
4. **μ›μμ  μ €μ¥**: μ €μ¥ μ¤‘ μ‹¤ν¨ μ‹ μ΄μ „ μƒνƒ μ μ§€
5. **μ •λ¦¬ μ •μ±…**: μ¤λλ μ²΄ν¬ν¬μΈνΈ μλ™ μ •λ¦¬ (μµμ…)

---

## 3. λ‹¨κ³„λ³„ κµ¬ν„ λ°©μ•

### 3.1 Optuna μµμ ν™” μ²΄ν¬ν¬μΈνΈ

#### ν„μ¬ μƒν™©
- Optunaλ” κΈ°λ³Έμ μΌλ΅ SQLite λλ” In-memory storage μ‚¬μ©
- Trial μ™„λ£λ§λ‹¤ μλ™ μ €μ¥λμ§€λ§, Study κ°μ²΄ μμ†μ„± λ¶€μ΅±

#### κµ¬ν„ λ°©μ•

```python
# src/optimization/optuna_checkpoint.py (μ‹ κ· μƒμ„±)

class OptunaCheckpointManager:
    """Optuna μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ"""

    def __init__(self, checkpoint_dir: str, study_name: str):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.study_name = study_name
        self.checkpoint_file = self.checkpoint_dir / f"{study_name}_checkpoint.pkl"

    def save_checkpoint(self, study, trial_number: int):
        """Trial μ™„λ£λ§λ‹¤ μ²΄ν¬ν¬μΈνΈ μ €μ¥"""
        checkpoint = {
            'study_name': study.study_name,
            'direction': study.direction,
            'best_params': study.best_params,
            'best_value': study.best_value,
            'completed_trials': trial_number,
            'all_trials': [self._trial_to_dict(t) for t in study.trials],
            'timestamp': datetime.now().isoformat()
        }

        # μ›μμ  μ €μ¥
        tmp_file = self.checkpoint_file.with_suffix('.tmp')
        with open(tmp_file, 'wb') as f:
            pickle.dump(checkpoint, f)
        tmp_file.replace(self.checkpoint_file)

    def load_checkpoint(self) -> Optional[dict]:
        """μ²΄ν¬ν¬μΈνΈ λ΅λ“"""
        if self.checkpoint_file.exists():
            with open(self.checkpoint_file, 'rb') as f:
                return pickle.load(f)
        return None

    def resume_study(self, sampler, pruner) -> Tuple[optuna.Study, int]:
        """μ²΄ν¬ν¬μΈνΈμ—μ„ Study λ³µμ›"""
        checkpoint = self.load_checkpoint()
        if checkpoint is None:
            # μƒλ΅ μ‹μ‘
            study = optuna.create_study(
                study_name=self.study_name,
                sampler=sampler,
                pruner=pruner,
                direction=checkpoint['direction']
            )
            return study, 0

        # κΈ°μ΅΄ Study λ³µμ›
        study = optuna.create_study(
            study_name=self.study_name,
            sampler=sampler,
            pruner=pruner,
            direction=checkpoint['direction']
        )

        # μ™„λ£λ Trialλ“¤ μ¬λ“±λ΅
        for trial_dict in checkpoint['all_trials']:
            study.add_trial(self._dict_to_trial(trial_dict))

        return study, checkpoint['completed_trials']
```

**μμ • νμΌ**: `src/optimization/optuna_optimizer.py`

```python
# κΈ°μ΅΄ μ½”λ“μ— μ¶”κ°€
from src.optimization.optuna_checkpoint import OptunaCheckpointManager

class OptunaOptimizer:
    def __init__(self, ...):
        # κΈ°μ΅΄ μ½”λ“
        ...

        # β… μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ μ¶”κ°€
        self.checkpoint_manager = OptunaCheckpointManager(
            checkpoint_dir=output_dir,
            study_name=study_name
        )

    def optimize(self, n_trials: int = 50, timeout: Optional[int] = None):
        # β… μ²΄ν¬ν¬μΈνΈμ—μ„ λ³µμ›
        study, completed_trials = self.checkpoint_manager.resume_study(
            sampler=self.sampler,
            pruner=self.pruner
        )

        remaining_trials = n_trials - completed_trials
        if remaining_trials <= 0:
            self.logger.write(f"β… μ΄λ―Έ {n_trials}κ° Trial μ™„λ£λ¨. κ±΄λ„λ€.")
            return study.best_params

        self.logger.write(f"π”„ Resume: {completed_trials}/{n_trials} μ™„λ£, {remaining_trials}κ° λ‚¨μ")

        # Trial μ½λ°±μ— μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ¶”κ°€
        def trial_callback(study, trial):
            self.checkpoint_manager.save_checkpoint(study, trial.number)

        study.optimize(
            self.objective,
            n_trials=remaining_trials,
            timeout=timeout,
            callbacks=[trial_callback]  # β… μ½λ°± μ¶”κ°€
        )

        return study.best_params
```

---

### 3.2 λ°μ΄ν„° μ¦κ°• μ²΄ν¬ν¬μΈνΈ

#### ν„μ¬ μƒν™©
- λ°μ΄ν„° μ¦κ°•μ€ μ‹κ°„μ΄ μ¤λ κ±Έλ¦Ό (μ—­λ²μ—­ λ“±)
- μ¦κ°• μ¤‘ μ¤‘λ‹¨ μ‹ μ²μλ¶€ν„° μ¬μ‹μ‘ ν•„μ”

#### κµ¬ν„ λ°©μ•

```python
# src/augmentation/augmentation_checkpoint.py (μ‹ κ· μƒμ„±)

class AugmentationCheckpointManager:
    """λ°μ΄ν„° μ¦κ°• μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ"""

    def __init__(self, checkpoint_dir: str):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_file = self.checkpoint_dir / "augmentation_checkpoint.pkl"

    def save_checkpoint(self, augmented_data: pd.DataFrame, progress: dict):
        """μ¦κ°• μ§„ν–‰ μƒν™© μ €μ¥"""
        checkpoint = {
            'augmented_data': augmented_data,
            'progress': progress,
            'timestamp': datetime.now().isoformat()
        }

        tmp_file = self.checkpoint_file.with_suffix('.tmp')
        with open(tmp_file, 'wb') as f:
            pickle.dump(checkpoint, f)
        tmp_file.replace(self.checkpoint_file)

    def load_checkpoint(self) -> Optional[dict]:
        """μ¦κ°• μ²΄ν¬ν¬μΈνΈ λ΅λ“"""
        if self.checkpoint_file.exists():
            with open(self.checkpoint_file, 'rb') as f:
                return pickle.load(f)
        return None

    def is_complete(self, target_size: int) -> bool:
        """μ¦κ°• μ™„λ£ μ—¬λ¶€ ν™•μΈ"""
        checkpoint = self.load_checkpoint()
        if checkpoint is None:
            return False
        return len(checkpoint['augmented_data']) >= target_size
```

**μμ • νμΌ**: `src/data/augmentation.py`

```python
# κΈ°μ΅΄ DataAugmenter ν΄λμ¤μ— μ¶”κ°€

class DataAugmenter:
    def __init__(self, ...):
        # κΈ°μ΅΄ μ½”λ“
        ...

        # β… μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ μ¶”κ°€
        self.checkpoint_manager = None  # ν•„μ” μ‹ μ΄κΈ°ν™”

    def augment_data(
        self,
        df: pd.DataFrame,
        augmentation_ratio: float = 0.5,
        checkpoint_dir: Optional[str] = None,
        resume: bool = True
    ) -> pd.DataFrame:
        """
        λ°μ΄ν„° μ¦κ°• (μ²΄ν¬ν¬μΈνΈ μ§€μ›)
        """
        # β… μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ μ΄κΈ°ν™”
        if checkpoint_dir:
            self.checkpoint_manager = AugmentationCheckpointManager(checkpoint_dir)

        # β… μ²΄ν¬ν¬μΈνΈ ν™•μΈ
        if resume and self.checkpoint_manager:
            checkpoint = self.checkpoint_manager.load_checkpoint()
            if checkpoint and self.checkpoint_manager.is_complete(target_size):
                self.logger.write("β… μ¦κ°• λ°μ΄ν„° μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...")
                return checkpoint['augmented_data']

        # μ¦κ°• μ§„ν–‰
        augmented_samples = []
        target_size = int(len(df) * augmentation_ratio)

        for idx in range(target_size):
            # μ¦κ°• λ΅μ§
            ...
            augmented_samples.append(augmented_sample)

            # β… μ£ΌκΈ°μ μΌλ΅ μ²΄ν¬ν¬μΈνΈ μ €μ¥ (100κ°λ§λ‹¤)
            if self.checkpoint_manager and (idx + 1) % 100 == 0:
                progress = {
                    'completed': idx + 1,
                    'total': target_size,
                    'ratio': (idx + 1) / target_size
                }
                augmented_df = pd.DataFrame(augmented_samples)
                self.checkpoint_manager.save_checkpoint(augmented_df, progress)
                self.logger.write(f"π’Ύ μ¦κ°• μ²΄ν¬ν¬μΈνΈ μ €μ¥: {idx+1}/{target_size}")

        # μµμΆ… μ €μ¥
        final_df = pd.concat([df, pd.DataFrame(augmented_samples)], ignore_index=True)
        if self.checkpoint_manager:
            progress = {'completed': target_size, 'total': target_size, 'ratio': 1.0}
            self.checkpoint_manager.save_checkpoint(final_df, progress)

        return final_df
```

---

### 3.3 K-Fold ν•™μµ μ²΄ν¬ν¬μΈνΈ

#### ν„μ¬ μƒν™©
- K-Foldλ” κ° Foldλ§λ‹¤ λ…λ¦½μ μΌλ΅ λ¨λΈ ν•™μµ
- Fold μ¤‘κ°„μ— μ¤‘λ‹¨ μ‹ μ™„λ£λ Fold κ²°κ³Ό μ†μ‹¤

#### κµ¬ν„ λ°©μ•

```python
# src/trainers/kfold_checkpoint.py (μ‹ κ· μƒμ„±)

class KFoldCheckpointManager:
    """K-Fold μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ"""

    def __init__(self, checkpoint_dir: str, k_folds: int):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.k_folds = k_folds
        self.checkpoint_file = self.checkpoint_dir / "kfold_checkpoint.json"

    def save_fold_result(self, fold: int, model_path: str, metrics: dict):
        """Fold μ™„λ£ ν›„ κ²°κ³Ό μ €μ¥"""
        checkpoint = self.load_checkpoint() or {
            'k_folds': self.k_folds,
            'completed_folds': [],
            'fold_results': {}
        }

        checkpoint['completed_folds'].append(fold)
        checkpoint['fold_results'][f'fold_{fold}'] = {
            'model_path': model_path,
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        }

        # μ›μμ  μ €μ¥
        tmp_file = self.checkpoint_file.with_suffix('.tmp')
        with open(tmp_file, 'w') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False)
        tmp_file.replace(self.checkpoint_file)

    def load_checkpoint(self) -> Optional[dict]:
        """μ²΄ν¬ν¬μΈνΈ λ΅λ“"""
        if self.checkpoint_file.exists():
            with open(self.checkpoint_file, 'r') as f:
                return json.load(f)
        return None

    def get_completed_folds(self) -> List[int]:
        """μ™„λ£λ Fold λ©λ΅"""
        checkpoint = self.load_checkpoint()
        if checkpoint is None:
            return []
        return checkpoint.get('completed_folds', [])

    def is_complete(self) -> bool:
        """K-Fold μ „μ²΄ μ™„λ£ μ—¬λ¶€"""
        checkpoint = self.load_checkpoint()
        if checkpoint is None:
            return False
        return len(checkpoint.get('completed_folds', [])) == self.k_folds
```

**μμ • νμΌ**: `src/trainers/kfold_trainer.py`

```python
# KFoldTrainer ν΄λμ¤ μμ •

from src.trainers.kfold_checkpoint import KFoldCheckpointManager

class KFoldTrainer(BaseTrainer):
    def train(self) -> dict:
        # β… μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ μ΄κΈ°ν™”
        checkpoint_manager = KFoldCheckpointManager(
            checkpoint_dir=self.args.output_dir,
            k_folds=self.args.k_folds
        )

        # β… μ™„λ£λ Fold ν™•μΈ
        completed_folds = checkpoint_manager.get_completed_folds()
        if completed_folds:
            self.logger.write(f"π”„ Resume: Fold {completed_folds} μ΄λ―Έ μ™„λ£")

        # β… λ‚¨μ€ Foldλ§ μ‹¤ν–‰
        all_results = []
        for fold in range(self.args.k_folds):
            if fold in completed_folds:
                # μ²΄ν¬ν¬μΈνΈμ—μ„ λ΅λ“
                checkpoint = checkpoint_manager.load_checkpoint()
                fold_result = checkpoint['fold_results'][f'fold_{fold}']
                all_results.append(fold_result)
                self.logger.write(f"β… Fold {fold}: μ²΄ν¬ν¬μΈνΈμ—μ„ λ΅λ“")
                continue

            # Fold ν•™μµ μ§„ν–‰
            self.logger.write(f"\n{'='*60}")
            self.logger.write(f"π“ Fold {fold + 1}/{self.args.k_folds} μ‹μ‘")

            # ... κΈ°μ΅΄ ν•™μµ λ΅μ§ ...

            fold_result = {
                'fold': fold,
                'model_path': fold_model_path,
                'metrics': fold_metrics
            }
            all_results.append(fold_result)

            # β… Fold μ™„λ£ ν›„ μ²΄ν¬ν¬μΈνΈ μ €μ¥
            checkpoint_manager.save_fold_result(
                fold=fold,
                model_path=fold_model_path,
                metrics=fold_metrics
            )
            self.logger.write(f"π’Ύ Fold {fold} μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ™„λ£")

        return {'fold_results': all_results}
```

---

### 3.4 HuggingFace λ³΄μ • μ²΄ν¬ν¬μΈνΈ

#### κµ¬ν„ λ°©μ•

```python
# src/correction/correction_checkpoint.py (μ‹ κ· μƒμ„±)

class CorrectionCheckpointManager:
    """HuggingFace λ³΄μ • μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ"""

    def __init__(self, checkpoint_dir: str):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_file = self.checkpoint_dir / "correction_checkpoint.pkl"

    def save_checkpoint(self, corrected_summaries: List[str], progress: int, total: int):
        """λ³΄μ • μ§„ν–‰ μƒν™© μ €μ¥"""
        checkpoint = {
            'corrected_summaries': corrected_summaries,
            'progress': progress,
            'total': total,
            'timestamp': datetime.now().isoformat()
        }

        tmp_file = self.checkpoint_file.with_suffix('.tmp')
        with open(tmp_file, 'wb') as f:
            pickle.dump(checkpoint, f)
        tmp_file.replace(self.checkpoint_file)

    def load_checkpoint(self) -> Optional[dict]:
        """λ³΄μ • μ²΄ν¬ν¬μΈνΈ λ΅λ“"""
        if self.checkpoint_file.exists():
            with open(self.checkpoint_file, 'rb') as f:
                return pickle.load(f)
        return None
```

**μμ • νμΌ**: `src/correction/pretrained_corrector.py`

```python
# PretrainedCorrector ν΄λμ¤μ— μ¶”κ°€

class PretrainedCorrector:
    def correct_batch(
        self,
        dialogues: List[str],
        candidate_summaries: List[str],
        batch_size: int = 16,
        checkpoint_dir: Optional[str] = None,
        **generation_kwargs
    ) -> List[str]:
        # β… μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ
        checkpoint_manager = None
        if checkpoint_dir:
            checkpoint_manager = CorrectionCheckpointManager(checkpoint_dir)
            checkpoint = checkpoint_manager.load_checkpoint()

            if checkpoint and checkpoint['progress'] == checkpoint['total']:
                self.logger.write("β… HF λ³΄μ • μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...")
                return checkpoint['corrected_summaries']

        # ... κΈ°μ΅΄ λ³΄μ • λ΅μ§ ...

        # β… λ°°μΉλ§λ‹¤ μ²΄ν¬ν¬μΈνΈ μ €μ¥
        if checkpoint_manager and (batch_idx + 1) % 10 == 0:
            checkpoint_manager.save_checkpoint(
                corrected_summaries=corrected_summaries[:len(summaries_so_far)],
                progress=len(summaries_so_far),
                total=len(dialogues)
            )
```

---

### 3.5 Solar API μ²΄ν¬ν¬μΈνΈ

#### ν„μ¬ μƒν™©
- Solar APIλ” μ΄λ―Έ μΊμ‹± κΈ°λ¥ λ‚΄μ¥
- μ¶”κ°€ μ²΄ν¬ν¬μΈνΈλ” λ°°μΉ λ‹¨μ„λ΅λ§ ν•„μ”

#### κµ¬ν„ λ°©μ•

**μμ • νμΌ**: `src/api/solar_api.py`

```python
# SolarAPI ν΄λμ¤μ— λ°°μΉ μ²΄ν¬ν¬μΈνΈ μ¶”κ°€

class SolarAPI:
    def summarize_batch(
        self,
        dialogues: List[str],
        batch_size: int = 10,
        delay: float = 1.0,
        checkpoint_dir: Optional[str] = None
    ) -> List[str]:
        # β… μ²΄ν¬ν¬μΈνΈ νμΌ
        checkpoint_file = None
        if checkpoint_dir:
            checkpoint_file = Path(checkpoint_dir) / "solar_api_checkpoint.pkl"
            if checkpoint_file.exists():
                with open(checkpoint_file, 'rb') as f:
                    checkpoint = pickle.load(f)
                    if checkpoint['total'] == len(dialogues):
                        self._log("β… Solar API μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...")
                        return checkpoint['summaries']

        summaries = []

        for i in range(0, len(dialogues), batch_size):
            # ... κΈ°μ΅΄ λ°°μΉ μ²λ¦¬ ...

            # β… λ°°μΉλ§λ‹¤ μ²΄ν¬ν¬μΈνΈ μ €μ¥
            if checkpoint_file and (i + batch_size) < len(dialogues):
                checkpoint = {
                    'summaries': summaries,
                    'progress': len(summaries),
                    'total': len(dialogues),
                    'timestamp': datetime.now().isoformat()
                }
                with open(checkpoint_file, 'wb') as f:
                    pickle.dump(checkpoint, f)

        return summaries
```

---

## 4. μ²΄ν¬ν¬μΈνΈ νμΌ κµ¬μ΅°

### 4.1 λ””λ ‰ν† λ¦¬ κµ¬μ΅°

```
experiments/20251014/20251014_094051_kobart_balanced/
β”β”€β”€ train.log
β”β”€β”€ checkpoints/                           # β… μ²΄ν¬ν¬μΈνΈ ν΄λ”
β”‚   β”β”€β”€ optuna_checkpoint.pkl              # Optuna μ²΄ν¬ν¬μΈνΈ
β”‚   β”β”€β”€ augmentation_checkpoint.pkl        # λ°μ΄ν„° μ¦κ°•
β”‚   β”β”€β”€ kfold_checkpoint.json              # K-Fold μ§„ν–‰ μƒν™©
β”‚   β”β”€β”€ correction_checkpoint.pkl          # HF λ³΄μ •
β”‚   β””β”€β”€ solar_api_checkpoint.pkl           # Solar API
β”β”€β”€ fold_0/                                # Fold λ¨λΈλ“¤
β”‚   β”β”€β”€ checkpoint-1000/
β”‚   β””β”€β”€ final_model/
β”β”€β”€ fold_1/
β”‚   β””β”€β”€ ...
β””β”€β”€ final_model/                           # μµμΆ… μ•™μƒλΈ” λ¨λΈ
```

### 4.2 μ²΄ν¬ν¬μΈνΈ νμΌ ν•μ‹

#### Optuna μ²΄ν¬ν¬μΈνΈ (pickle)
```python
{
    'study_name': 'optuna_kobart_ultimate',
    'direction': 'maximize',
    'best_params': {...},
    'best_value': 0.4616,
    'completed_trials': 11,
    'all_trials': [...],
    'timestamp': '2025-10-14T12:00:00'
}
```

#### K-Fold μ²΄ν¬ν¬μΈνΈ (JSON)
```json
{
  "k_folds": 5,
  "completed_folds": [0, 1, 2],
  "fold_results": {
    "fold_0": {
      "model_path": "experiments/.../fold_0/final_model",
      "metrics": {
        "rouge-l": 0.45
      },
      "timestamp": "2025-10-14T12:30:00"
    }
  }
}
```

---

## 5. Resume λ΅μ§ μ„¤κ³„

### 5.1 Resume ν”λ΅μ°μ°¨νΈ

```mermaid
graph TD
    A[λ…λ Ήμ–΄ μ‹¤ν–‰] --> B{--resume ν”λκ·Έ?}
    B -->|No| C[μ²μλ¶€ν„° μ‹μ‘]
    B -->|Yes| D{μ²΄ν¬ν¬μΈνΈ μ΅΄μ¬?}

    D -->|No| C
    D -->|Yes| E[μ²΄ν¬ν¬μΈνΈ κ²€μ¦]

    E --> F{μ ν¨ν• μ²΄ν¬ν¬μΈνΈ?}
    F -->|No| G[κ²½κ³  ν‘μ‹]
    F -->|Yes| H[μ§„ν–‰ μƒν™© ν‘μ‹]

    G --> I{κ°•μ  Resume?}
    I -->|Yes| J[μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹ν•κ³  μ‹μ‘]
    I -->|No| K[μΆ…λ£]

    H --> L[μ΄μ–΄μ„ μ‹¤ν–‰]

    style E fill:#fff59d,stroke:#f9a825,color:#000
    style H fill:#81c784,stroke:#388e3c,color:#000
    style L fill:#66bb6a,stroke:#2e7d32,color:#fff
```

### 5.2 Resume λ…λ Ήν–‰ μµμ…

**scripts/train.pyμ— μ¶”κ°€ν•  μµμ…**:

```python
parser.add_argument(
    '--resume',
    action='store_true',
    help='μ²΄ν¬ν¬μΈνΈμ—μ„ μ΄μ–΄μ„ μ‹¤ν–‰ (κΈ°λ³Έκ°’: False)'
)

parser.add_argument(
    '--resume_from',
    type=str,
    default=None,
    help='νΉμ • μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬μ—μ„ Resume'
)

parser.add_argument(
    '--ignore_checkpoint',
    action='store_true',
    help='μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹ν•κ³  μ²μλ¶€ν„° μ‹μ‘'
)
```

---

## 6. κµ¬ν„ μƒμ„Έ κ³„ν

### 6.1 μ‹ κ· μƒμ„± νμΌ

| νμΌ κ²½λ΅ | μ—­ν•  | μ°μ„ μμ„ |
|----------|------|----------|
| `src/checkpoints/__init__.py` | μ²΄ν¬ν¬μΈνΈ λ¨λ“ μ΄κΈ°ν™” | ν•„μ |
| `src/checkpoints/base_checkpoint.py` | λ² μ΄μ¤ μ²΄ν¬ν¬μΈνΈ ν΄λμ¤ | ν•„μ |
| `src/optimization/optuna_checkpoint.py` | Optuna μ²΄ν¬ν¬μΈνΈ | π”¥ λ†’μ |
| `src/augmentation/augmentation_checkpoint.py` | μ¦κ°• μ²΄ν¬ν¬μΈνΈ | π”¥ λ†’μ |
| `src/trainers/kfold_checkpoint.py` | K-Fold μ²΄ν¬ν¬μΈνΈ | π”¥ λ†’μ |
| `src/correction/correction_checkpoint.py` | HF λ³΄μ • μ²΄ν¬ν¬μΈνΈ | μ¤‘κ°„ |
| `src/api/solar_checkpoint.py` | Solar API μ²΄ν¬ν¬μΈνΈ | μ¤‘κ°„ |

### 6.2 μμ • νμΌ

| νμΌ κ²½λ΅ | μμ • λ‚΄μ© | μ°μ„ μμ„ |
|----------|----------|----------|
| `src/optimization/optuna_optimizer.py` | μ²΄ν¬ν¬μΈνΈ ν†µν•© | π”¥ λ†’μ |
| `src/data/augmentation.py` | μ²΄ν¬ν¬μΈνΈ ν†µν•© | π”¥ λ†’μ |
| `src/trainers/kfold_trainer.py` | Resume λ΅μ§ | π”¥ λ†’μ |
| `src/correction/pretrained_corrector.py` | μ²΄ν¬ν¬μΈνΈ ν†µν•© | μ¤‘κ°„ |
| `src/api/solar_api.py` | λ°°μΉ μ²΄ν¬ν¬μΈνΈ | μ¤‘κ°„ |
| `scripts/train.py` | --resume μµμ… μ¶”κ°€ | ν•„μ |

### 6.3 λ² μ΄μ¤ μ²΄ν¬ν¬μΈνΈ ν΄λμ¤

```python
# src/checkpoints/base_checkpoint.py (μ‹ κ· μƒμ„±)

from abc import ABC, abstractmethod
from typing import Any, Optional
from pathlib import Path
import pickle
import json
from datetime import datetime

class BaseCheckpointManager(ABC):
    """
    μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μ λ² μ΄μ¤ ν΄λμ¤

    λ¨λ“  μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬μλ” μ΄ ν΄λμ¤λ¥Ό μƒμ†λ°›μ•„ κµ¬ν„
    """

    def __init__(self, checkpoint_dir: str, checkpoint_name: str):
        """
        Args:
            checkpoint_dir: μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ””λ ‰ν† λ¦¬
            checkpoint_name: μ²΄ν¬ν¬μΈνΈ νμΌ μ΄λ¦„ (ν™•μ¥μ μ μ™Έ)
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoint_name = checkpoint_name

    @abstractmethod
    def save_checkpoint(self, data: Any, **kwargs):
        """μ²΄ν¬ν¬μΈνΈ μ €μ¥ (μ„λΈν΄λμ¤μ—μ„ κµ¬ν„)"""
        pass

    @abstractmethod
    def load_checkpoint(self) -> Optional[Any]:
        """μ²΄ν¬ν¬μΈνΈ λ΅λ“ (μ„λΈν΄λμ¤μ—μ„ κµ¬ν„)"""
        pass

    def _atomic_save_pickle(self, file_path: Path, data: Any):
        """μ›μμ  Pickle μ €μ¥"""
        tmp_file = file_path.with_suffix('.tmp')
        with open(tmp_file, 'wb') as f:
            pickle.dump(data, f)
        tmp_file.replace(file_path)

    def _atomic_save_json(self, file_path: Path, data: dict):
        """μ›μμ  JSON μ €μ¥"""
        tmp_file = file_path.with_suffix('.tmp')
        with open(tmp_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        tmp_file.replace(file_path)

    def exists(self) -> bool:
        """μ²΄ν¬ν¬μΈνΈ μ΅΄μ¬ μ—¬λ¶€"""
        return self.get_checkpoint_path().exists()

    @abstractmethod
    def get_checkpoint_path(self) -> Path:
        """μ²΄ν¬ν¬μΈνΈ νμΌ κ²½λ΅ λ°ν™"""
        pass

    def delete_checkpoint(self):
        """μ²΄ν¬ν¬μΈνΈ μ‚­μ """
        checkpoint_path = self.get_checkpoint_path()
        if checkpoint_path.exists():
            checkpoint_path.unlink()
```

---

## 7. ν…μ¤νΈ μ‹λ‚λ¦¬μ¤

### 7.1 Optuna Resume ν…μ¤νΈ

```bash
# 1. μ΄κΈ° μ‹¤ν–‰ (10 trials μ¤‘ 5κ°λ§ μ‹¤ν–‰ ν›„ μ¤‘λ‹¨)
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 10 \
  --experiment_name test_resume

# Ctrl+Cλ΅ μ¤‘λ‹¨

# 2. Resume μ‹¤ν–‰ (λ‚¨μ€ 5κ° trial μ‹¤ν–‰)
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 10 \
  --resume \
  --resume_from experiments/20251014/.../checkpoints \
  --experiment_name test_resume

# μμƒ κ²°κ³Ό: Trial 5λ¶€ν„° μ‹μ‘ν•μ—¬ 10κΉμ§€ μ™„λ£
```

### 7.2 K-Fold Resume ν…μ¤νΈ

```bash
# 1. μ΄κΈ° μ‹¤ν–‰ (5 folds μ¤‘ 2κ°λ§ μ™„λ£ ν›„ μ¤‘λ‹¨)
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --k_folds 5 \
  --epochs 3 \
  --experiment_name test_kfold_resume

# Ctrl+Cλ΅ μ¤‘λ‹¨

# 2. Resume μ‹¤ν–‰
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --k_folds 5 \
  --epochs 3 \
  --resume \
  --experiment_name test_kfold_resume

# μμƒ κ²°κ³Ό: Fold 2λ¶€ν„° μ‹μ‘ν•μ—¬ 4κΉμ§€ μ™„λ£
```

### 7.3 λ°μ΄ν„° μ¦κ°• Resume ν…μ¤νΈ

```bash
# 1. μ¦κ°• μ¤‘ μ¤‘λ‹¨
python scripts/train.py \
  --mode single \
  --models kobart \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --experiment_name test_aug_resume

# Ctrl+Cλ΅ μ¤‘λ‹¨ (μ¦κ°• 50% μ§„ν–‰ μ‹)

# 2. Resume
python scripts/train.py \
  --mode single \
  --models kobart \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --resume \
  --experiment_name test_aug_resume

# μμƒ κ²°κ³Ό: μ¦κ°• 50%λ¶€ν„° μ΄μ–΄μ„ μ§„ν–‰
```

---

## 8. κµ¬ν„ μ°μ„ μμ„

### Phase 1: ν•µμ‹¬ μ²΄ν¬ν¬μΈνΈ (ν•„μ)
1. β… BaseCheckpointManager ν΄λμ¤ κµ¬ν„
2. β… OptunaCheckpointManager κµ¬ν„ λ° ν†µν•©
3. β… KFoldCheckpointManager κµ¬ν„ λ° ν†µν•©
4. β… AugmentationCheckpointManager κµ¬ν„ λ° ν†µν•©
5. β… `--resume` λ…λ Ήν–‰ μµμ… μ¶”κ°€

### Phase 2: μ¶”κ°€ μ²΄ν¬ν¬μΈνΈ (μ„ νƒ)
1. βΈοΈ CorrectionCheckpointManager κµ¬ν„
2. βΈοΈ Solar API λ°°μΉ μ²΄ν¬ν¬μΈνΈ κ°•ν™”
3. βΈοΈ κ²€μ¦ μ²΄ν¬ν¬μΈνΈ (ν•„μ” μ‹)

### Phase 3: κ°μ„  λ° μµμ ν™”
1. βΈοΈ μλ™ μ •λ¦¬ μ •μ±… (μ¤λλ μ²΄ν¬ν¬μΈνΈ μ‚­μ )
2. βΈοΈ μ²΄ν¬ν¬μΈνΈ μ••μ¶• (λ””μ¤ν¬ κ³µκ°„ μ μ•½)
3. βΈοΈ μ§„ν–‰ μƒν™© μ‹κ°ν™” (μ§„ν–‰λ¥  ν‘μ‹)

---

## 9. μμƒ ν¨κ³Ό

### 9.1 μ‹κ°„ μ μ•½

| μ‹λ‚λ¦¬μ¤ | κΈ°μ΅΄ | μ²΄ν¬ν¬μΈνΈ μ‚¬μ© | μ μ•½ μ‹κ°„ |
|----------|------|----------------|----------|
| Optuna 10 trials μ¤‘ 5κ° μ™„λ£ ν›„ μ¤‘λ‹¨ | μ²μλ¶€ν„° (10 trials) | 5 trialsλ§ | 50% |
| K-Fold 5 μ¤‘ 3κ° μ™„λ£ ν›„ μ¤‘λ‹¨ | μ²μλ¶€ν„° (5 folds) | 2 foldsλ§ | 60% |
| μ¦κ°• 50% μ§„ν–‰ ν›„ μ¤‘λ‹¨ | μ²μλ¶€ν„° (100%) | 50%λ¶€ν„° | 50% |

### 9.2 μ•μ •μ„± ν–¥μƒ

- β… μ¥μ‹κ°„ μ‹¤ν— μ•μ‹¬ μ§„ν–‰
- β… λ„¤νΈμ›ν¬ μ¤λ¥ μ‹ λ³µκµ¬ κ°€λ¥
- β… μ‹¤μλ΅ μ¤‘λ‹¨ν•΄λ„ μ•μ „
- β… νƒ€μ„μ•„μ›ƒ λ€μ‘ κ°€λ¥

---

## 10. μ£Όμμ‚¬ν•­

### 10.1 μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹ μ£Όμ

1. **λ””μ¤ν¬ κ³µκ°„**: μ²΄ν¬ν¬μΈνΈλ” λ””μ¤ν¬ κ³µκ°„μ„ μ°¨μ§€ν•¨
2. **μ›μμ  μ €μ¥**: μ €μ¥ μ¤‘ μ¤‘λ‹¨λμ–΄λ„ μ΄μ „ μƒνƒ μ μ§€
3. **λ²„μ „ νΈν™μ„±**: μ½”λ“ λ³€κ²½ μ‹ μ²΄ν¬ν¬μΈνΈ νΈν™μ„± κ³ λ ¤

### 10.2 Resume μ‹ μ£Όμ

1. **ν•μ΄νΌνλΌλ―Έν„° λ³€κ²½**: Resume μ‹ ν•μ΄νΌνλΌλ―Έν„°κ°€ λ‹¬λΌμ§€λ©΄ κ²½κ³ 
2. **λ°μ΄ν„° λ³€κ²½**: λ°μ΄ν„°κ°€ λ³€κ²½λλ©΄ μ²΄ν¬ν¬μΈνΈ λ¬΄ν¨ν™”
3. **λ¨λΈ λ³€κ²½**: λ¨λΈ κµ¬μ΅° λ³€κ²½ μ‹ μ²΄ν¬ν¬μΈνΈ μ‚¬μ© λ¶κ°€

---

**μ‘μ„±**: 2025-10-14
**μ°μ„ μμ„**: π”¥ λ†’μ
**μμƒ κµ¬ν„ μ‹κ°„**: Phase 1 κΈ°μ¤€ 4-6μ‹κ°„
