# í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ê¸°ëŠ¥ êµ¬í˜„

> **ëª©ì **: KoBART ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ í›„ ì¶”ë¡  ì‹œ, í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•œ í’ˆì§ˆ ê²€ì¦ ë° ë³´ì • ê¸°ëŠ¥ êµ¬í˜„
> **ì‘ì„±ì¼**: 2025-10-14
> **PRD ì°¸ì¡°**: PRD 04 (ì¶”ë¡  ìµœì í™”), PRD 12 (ì•™ìƒë¸” ì „ëµ)
> **ê´€ë ¨ ë¬¸ì„œ**: `docs/ëª¨ë“ˆí™”/04_02_KoBART_ë‹¨ì¼ëª¨ë¸_ìµœê°•_ì„±ëŠ¥_ì „ëµ.md` (ì„¹ì…˜ 4.2)

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [í•µì‹¬ ê°œë… ë° ì „ëµ](#2-í•µì‹¬-ê°œë…-ë°-ì „ëµ)
3. [í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì´ ë‹´ë‹¹í•  ê¸°ëŠ¥](#3-í—ˆê¹…í˜ì´ìŠ¤-ëª¨ë¸ì´-ë‹´ë‹¹í• -ê¸°ëŠ¥)
4. [íŒŒì´í”„ë¼ì¸ë³„ ì‚¬ìš© ë°©ë²•](#4-íŒŒì´í”„ë¼ì¸ë³„-ì‚¬ìš©-ë°©ë²•)
5. [ëª¨ë“ˆ êµ¬ì¡° ë° êµ¬í˜„ ë°©ë²•](#5-ëª¨ë“ˆ-êµ¬ì¡°-ë°-êµ¬í˜„-ë°©ë²•)
6. [ì½”ë“œ í†µí•© ê°€ì´ë“œ](#6-ì½”ë“œ-í†µí•©-ê°€ì´ë“œ)
7. [ì„¤ì • ë° ì‚¬ìš© ì˜ˆì‹œ](#7-ì„¤ì •-ë°-ì‚¬ìš©-ì˜ˆì‹œ)

---

## 1. ê°œìš”

### 1.1 ë°°ê²½ ë° í•„ìš”ì„±

**í˜„ì¬ ìƒí™©:**
- âœ… Solar API ì•™ìƒë¸” ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ (`src/api/solar_api.py`)
- âœ… Solar APIëŠ” ì¶”ë¡  ì‹œ LLM ê¸°ë°˜ ê³ í’ˆì§ˆ ë³´ì • ê°€ëŠ¥
- âŒ í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•œ ë³´ì • ê¸°ëŠ¥ **ë¯¸êµ¬í˜„**

**í—ˆê¹…í˜ì´ìŠ¤ ë³´ì • ê¸°ëŠ¥ì˜ ì¥ì :**
1. **ë¹„ìš© ì ˆê°**: Solar APIëŠ” ìœ ë£Œ (í† í°ë‹¹ ê³¼ê¸ˆ), í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì€ ë¬´ë£Œ
2. **ì†ë„ í–¥ìƒ**: ë¡œì»¬ GPUì—ì„œ ì§ì ‘ ì‹¤í–‰ â†’ API í˜¸ì¶œë³´ë‹¤ ë¹ ë¦„
3. **ì˜¤í”„ë¼ì¸ ì‚¬ìš©**: ì¸í„°ë„· ì—°ê²° ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥
4. **ë‹¤ì–‘í•œ ëª¨ë¸ ì¡°í•©**: ì—¬ëŸ¬ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ë™ì‹œì— í™œìš©í•˜ì—¬ ì•™ìƒë¸” íš¨ê³¼

**Solar API vs í—ˆê¹…í˜ì´ìŠ¤ ë¹„êµ:**

| êµ¬ë¶„ | Solar API | í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ |
|------|----------|----------------------|
| **ë¹„ìš©** | ìœ ë£Œ (í† í°ë‹¹ ê³¼ê¸ˆ) | ë¬´ë£Œ (GPU ìì›ë§Œ í•„ìš”) |
| **ì†ë„** | API í˜¸ì¶œ ëŒ€ê¸° + Rate Limit | ë¡œì»¬ GPU ì¶”ë¡  (ë¹ ë¦„) |
| **í’ˆì§ˆ** | ë§¤ìš° ë†’ìŒ (LLM) | ë†’ìŒ (ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸) |
| **ë„¤íŠ¸ì›Œí¬** | í•„ìˆ˜ | ë¶ˆí•„ìš” (ì˜¤í”„ë¼ì¸ ê°€ëŠ¥) |
| **ìºì‹±** | í•„ìš” | ì„ íƒì  |
| **ì‚¬ìš© ì˜ˆ** | ìµœì¢… ë³´ì •, ì†ŒëŸ‰ ë°ì´í„° | ëŒ€ëŸ‰ ë°ì´í„°, í’ˆì§ˆ ê²€ì¦ |

### 1.2 ëª©í‘œ

1. **í•™ìŠµ**: KoBART ë‹¨ì¼ ëª¨ë¸ë¡œ ë¹ ë¥¸ í•™ìŠµ (99ì´ˆ)
2. **ì¶”ë¡ **: í•™ìŠµëœ ëª¨ë¸ + í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì¡°í•©
3. **ë³´ì •**: í’ˆì§ˆ ë‚®ì€ ìš”ì•½ì„ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ê²°ê³¼ë¡œ êµì²´
4. **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ìš”ì•½ ìƒì„±

---

## 2. í•µì‹¬ ê°œë… ë° ì „ëµ

### 2.1 ë™ì‘ ì›ë¦¬

```mermaid
graph TB
    A[ì…ë ¥: ëŒ€í™”] --> B[KoBART í•™ìŠµ ëª¨ë¸]
    B --> C[ì´ˆì•ˆ ìš”ì•½ ìƒì„±]

    A --> D[í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ 1<br/>gogamza/kobart-base-v2]
    A --> E[í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ 2<br/>digit82/kobart-summarization]
    A --> F[í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ 3<br/>eenzeenee/t5-base-korean]

    D --> G[ì°¸ì¡° ìš”ì•½ 1]
    E --> H[ì°¸ì¡° ìš”ì•½ 2]
    F --> I[ì°¸ì¡° ìš”ì•½ 3]

    C --> J[í’ˆì§ˆ í‰ê°€ê¸°<br/>ROUGE/BERTScore]
    G --> J
    H --> J
    I --> J

    J --> K{í’ˆì§ˆ ì„ê³„ê°’<br/>ì´ˆê³¼?}

    K -->|Yes| L[KoBART ê²°ê³¼ ì‚¬ìš©]
    K -->|No| M[ìµœê³  í’ˆì§ˆ ì°¸ì¡° ìš”ì•½ ì„ íƒ]

    L --> N[ìµœì¢… ìš”ì•½]
    M --> N

    style B fill:#81c784,stroke:#2e7d32,color:#000
    style D fill:#64b5f6,stroke:#1976d2,color:#000
    style E fill:#64b5f6,stroke:#1976d2,color:#000
    style F fill:#64b5f6,stroke:#1976d2,color:#000
    style J fill:#ffb74d,stroke:#f57c00,color:#000
    style N fill:#66bb6a,stroke:#1b5e20,color:#fff
```

### 2.2 ë³´ì • ì „ëµ

#### ì „ëµ 1: ì„ê³„ê°’ ê¸°ë°˜ ë³´ì • (Threshold-based Correction)

**ê°œë…:**
- KoBART ê²°ê³¼ì˜ í’ˆì§ˆì„ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ê²°ê³¼ì™€ ë¹„êµ
- í’ˆì§ˆ ì ìˆ˜ê°€ ì„ê³„ê°’ ì´í•˜ë©´ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ê²°ê³¼ ì‚¬ìš©

**ì¥ì :**
- êµ¬í˜„ ê°„ë‹¨
- ëª…í™•í•œ ê¸°ì¤€

**ë‹¨ì :**
- ì„ê³„ê°’ ì„¤ì • ì–´ë ¤ì›€
- ì ˆëŒ€ì  í’ˆì§ˆ ë³´ì¥ ì–´ë ¤ì›€

#### ì „ëµ 2: íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸” (Voting-based Ensemble)

**ê°œë…:**
- KoBART + í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ Nê°œ = ì´ N+1ê°œ ëª¨ë¸
- ê° ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ ì¤‘ ë‹¤ìˆ˜ê²°ë¡œ ì„ íƒ

**ì¥ì :**
- ë¯¼ì£¼ì  ì„ íƒ
- ì´ìƒì¹˜ ì œê±° íš¨ê³¼

**ë‹¨ì :**
- í’ˆì§ˆë³´ë‹¤ ë‹¤ìˆ˜ê°€ ìš°ì„ 
- ê³„ì‚° ë¹„ìš© ì¦ê°€

#### ì „ëµ 3: ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” (Weighted Average Ensemble)

**ê°œë…:**
- ê° ëª¨ë¸ì˜ ì‹ ë¢°ë„ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ë¶€ì—¬
- ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ìš”ì•½ ìƒì„±

**ì¥ì :**
- ëª¨ë¸ë³„ ê°•ì  í™œìš©
- ë¶€ë“œëŸ¬ìš´ ë³´ì •

**ë‹¨ì :**
- ê°€ì¤‘ì¹˜ ì¡°ì • í•„ìš”
- ë¬¸ì¥ ì•™ìƒë¸” ì–´ë ¤ì›€

#### ì „ëµ 4: í’ˆì§ˆ ê¸°ë°˜ ì„ íƒ (Quality-based Selection) â­ **ì¶”ì²œ**

**ê°œë…:**
1. KoBART ì´ˆì•ˆ ìƒì„±
2. í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ë“¤ë¡œ ì°¸ì¡° ìš”ì•½ ìƒì„±
3. ê° ìš”ì•½ì˜ í’ˆì§ˆì„ ROUGE/BERTScoreë¡œ í‰ê°€
4. ê°€ì¥ ë†’ì€ í’ˆì§ˆì˜ ìš”ì•½ ì„ íƒ

**ì¥ì :**
- í•­ìƒ ìµœê³  í’ˆì§ˆ ë³´ì¥
- ëª…í™•í•œ ì„ íƒ ê¸°ì¤€

**ë‹¨ì :**
- í‰ê°€ ë¹„ìš© ë°œìƒ
- Ground truth í•„ìš” (ê²€ì¦ ë°ì´í„°)

### 2.3 í’ˆì§ˆ í‰ê°€ ë°©ë²•

| í‰ê°€ ì§€í‘œ | ì„¤ëª… | ì‚¬ìš© ì‹œì  | ì¥ì  | ë‹¨ì  |
|----------|------|----------|------|------|
| **ROUGE** | n-gram ê²¹ì¹¨ ê¸°ë°˜ | Ground truth ìˆì„ ë•Œ | ë¹ ë¦„, ì§ê´€ì  | ì˜ë¯¸ ë¬´ì‹œ |
| **BERTScore** | ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ | Ground truth ìˆì„ ë•Œ | ì˜ë¯¸ ê³ ë ¤ | ëŠë¦¼ |
| **Self-ROUGE** | ì—¬ëŸ¬ ëª¨ë¸ ê²°ê³¼ ê°„ ì¼ì¹˜ë„ | Ground truth ì—†ì„ ë•Œ | ì°¸ì¡° ë¶ˆí•„ìš” | í¸í–¥ ê°€ëŠ¥ |
| **Diversity** | ë‹¤ì–‘ì„± ì¸¡ì • | ì•™ìƒë¸” ìµœì í™” | ì´ìƒì¹˜ ë°œê²¬ | í’ˆì§ˆ ë¬´ê´€ |

---

## 3. í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì´ ë‹´ë‹¹í•  ê¸°ëŠ¥

### 3.1 ì‚¬ì „í•™ìŠµ ëª¨ë¸ í›„ë³´

#### 3.1.1 ì¶”ì²œ ëª¨ë¸ ëª©ë¡

| ëª¨ë¸ | ì„¤ëª… | íŠ¹ì§• | ì‚¬ìš© ëª©ì  |
|------|------|------|----------|
| **gogamza/kobart-base-v2** | KoBART ì‚¬ì „í•™ìŠµ | ì¼ë°˜ í•œêµ­ì–´ ìš”ì•½ | ê¸°ë³¸ ì°¸ì¡° |
| **digit82/kobart-summarization** | KoBART ìš”ì•½ íŠ¹í™” | ëŒ€í™” ìš”ì•½ fine-tuned | ë©”ì¸ ì°¸ì¡° |
| **eenzeenee/t5-base-korean** | T5 í•œêµ­ì–´ | ìƒì„± í’ˆì§ˆ ìš°ìˆ˜ | ë‹¤ì–‘ì„± í™•ë³´ |
| **psyche/KoT5-summarization** | T5 ìš”ì•½ íŠ¹í™” | ê¸´ ë¬¸ì¥ ìš”ì•½ | ë³´ì¡° ì°¸ì¡° |
| **lcw99/t5-base-korean-text-summary** | T5 ë‰´ìŠ¤ ìš”ì•½ | ê³µì‹ì  ë¬¸ì²´ | ë¬¸ì²´ ë³´ì • |

#### 3.1.2 ëª¨ë¸ ì„ íƒ ê¸°ì¤€

**í•„ìˆ˜ ì¡°ê±´:**
- âœ… í•œêµ­ì–´ ì§€ì›
- âœ… ëŒ€í™” ìš”ì•½ ë˜ëŠ” ì¼ë°˜ ìš”ì•½ íƒœìŠ¤í¬
- âœ… Seq2Seq ë˜ëŠ” Encoder-Decoder ì•„í‚¤í…ì²˜
- âœ… í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì‰½ê²Œ ë¡œë“œ ê°€ëŠ¥

**ìš°ì„ ìˆœìœ„:**
1. **KoBART ê¸°ë°˜ ëª¨ë¸** (ë„ë©”ì¸ ì¼ì¹˜)
2. **T5 ê¸°ë°˜ ëª¨ë¸** (ìƒì„± í’ˆì§ˆ)
3. **BART ê¸°ë°˜ ëª¨ë¸** (êµ¬ì¡° ìœ ì‚¬)

### 3.2 ë‹´ë‹¹ ê¸°ëŠ¥ ìƒì„¸

#### ê¸°ëŠ¥ 1: ì°¸ì¡° ìš”ì•½ ìƒì„± (Reference Summary Generation)

**ëª©ì **: KoBART ì´ˆì•ˆì— ëŒ€í•œ ë‹¤ì–‘í•œ ì°¸ì¡° ìš”ì•½ ì œê³µ

**ë™ì‘ ë°©ì‹:**
```python
# ì…ë ¥: ëŒ€í™”
dialogue = "Person1: ì•ˆë…•í•˜ì„¸ìš”. Person2: ë°˜ê°‘ìŠµë‹ˆë‹¤..."

# KoBART ì´ˆì•ˆ
kobart_summary = "Person1ê³¼ Person2ê°€ ì¸ì‚¬ë¥¼ ë‚˜ëˆ´ë‹¤."

# í—ˆê¹…í˜ì´ìŠ¤ ì°¸ì¡° ìš”ì•½
hf_model_1_summary = "ë‘ ì‚¬ëŒì´ ë§Œë‚˜ ì¸ì‚¬ë¥¼ ì£¼ê³ ë°›ì•˜ë‹¤."
hf_model_2_summary = "Person1ê³¼ Person2ì˜ ì²« ë§Œë‚¨."
hf_model_3_summary = "ì¸ì‚¬ ë‚˜ëˆ„ëŠ” ë‘ ì‚¬ëŒ."
```

**íŠ¹ì§•:**
- ê° ëª¨ë¸ì´ ë…ë¦½ì ìœ¼ë¡œ ìš”ì•½ ìƒì„±
- ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ í™•ë³´
- í¸í–¥ ê°ì†Œ

#### ê¸°ëŠ¥ 2: í’ˆì§ˆ ê²€ì¦ (Quality Validation)

**ëª©ì **: KoBART ê²°ê³¼ì˜ í’ˆì§ˆì´ ê¸°ì¤€ ë¯¸ë‹¬ì¸ì§€ íŒë‹¨

**ê²€ì¦ í•­ëª©:**
1. **ì™„ì „ì„±**: ì¤‘ìš” ì •ë³´ ëˆ„ë½ ì—¬ë¶€
2. **ì •í™•ì„±**: ì‚¬ì‹¤ ì™œê³¡ ì—¬ë¶€
3. **ì¼ê´€ì„±**: ë¬¸ë§¥ ì¼ì¹˜ ì—¬ë¶€
4. **ìœ ì°½ì„±**: ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ì—¬ë¶€

**íŒë‹¨ ë°©ë²•:**
```python
# KoBART ê²°ê³¼ì™€ í—ˆê¹…í˜ì´ìŠ¤ ê²°ê³¼ë“¤ì„ ROUGEë¡œ ë¹„êµ
kobart_vs_hf1 = rouge_score(kobart_summary, hf_model_1_summary)
kobart_vs_hf2 = rouge_score(kobart_summary, hf_model_2_summary)
kobart_vs_hf3 = rouge_score(kobart_summary, hf_model_3_summary)

avg_agreement = (kobart_vs_hf1 + kobart_vs_hf2 + kobart_vs_hf3) / 3

# ì¼ì¹˜ë„ê°€ ë‚®ìœ¼ë©´ í’ˆì§ˆ ì˜ì‹¬
if avg_agreement < threshold:
    # í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ê²°ê³¼ ì‚¬ìš©
    pass
```

#### ê¸°ëŠ¥ 3: ë³´ì • í›„ë³´ ì œê³µ (Correction Candidates)

**ëª©ì **: í’ˆì§ˆ ë‚®ì€ ìš”ì•½ì„ êµì²´í•  í›„ë³´ ì œê³µ

**ì„ íƒ ë°©ë²•:**
1. **ìµœê³  í’ˆì§ˆ ì„ íƒ**: ROUGE ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ ì„ íƒ
2. **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ ê²°ê³¼ë¥¼ íˆ¬í‘œë¡œ ê²°í•©
3. **í•˜ì´ë¸Œë¦¬ë“œ**: KoBARTì™€ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¡°í•©

#### ê¸°ëŠ¥ 4: ì‹ ë¢°ë„ ì ìˆ˜ ì œê³µ (Confidence Scoring)

**ëª©ì **: ê° ìš”ì•½ì˜ ì‹ ë¢°ë„ ì¸¡ì •

**ì‹ ë¢°ë„ ê³„ì‚°:**
```python
# ì—¬ëŸ¬ ëª¨ë¸ ê°„ í•©ì˜ë„
def compute_confidence(summaries):
    """
    ì—¬ëŸ¬ ìš”ì•½ ê°„ Self-ROUGE ê³„ì‚°

    Args:
        summaries: ê° ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ ë¦¬ìŠ¤íŠ¸

    Returns:
        í‰ê·  Self-ROUGE (í•©ì˜ë„)
    """
    scores = []
    for i in range(len(summaries)):
        for j in range(i+1, len(summaries)):
            score = rouge_score(summaries[i], summaries[j])
            scores.append(score)

    return np.mean(scores)
```

**í™œìš©:**
- ì‹ ë¢°ë„ ë†’ìŒ â†’ KoBART ê²°ê³¼ ì‚¬ìš©
- ì‹ ë¢°ë„ ë‚®ìŒ â†’ í—ˆê¹…í˜ì´ìŠ¤ ê²°ê³¼ ì‚¬ìš©

---

## 4. íŒŒì´í”„ë¼ì¸ë³„ ì‚¬ìš© ë°©ë²•

### 4.1 í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Training)

**ì‚¬ìš© ì—¬ë¶€**: âŒ **ì‚¬ìš©í•˜ì§€ ì•ŠìŒ**

**ì´ìœ :**
- í•™ìŠµì€ KoBART ë‹¨ì¼ ëª¨ë¸ë¡œë§Œ ìˆ˜í–‰
- ë¹ ë¥¸ í•™ìŠµ ì†ë„ ìœ ì§€ (99ì´ˆ)
- í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì€ ì‚¬ì „í•™ìŠµëœ ìƒíƒœë¡œ ì‚¬ìš© (ì¶”ê°€ í•™ìŠµ ë¶ˆí•„ìš”)

**ê²°ë¡ :**
```bash
# í•™ìŠµ ì‹œì—ëŠ” í—ˆê¹…í˜ì´ìŠ¤ ë³´ì • ê¸°ëŠ¥ ì‚¬ìš© ì•ˆ í•¨
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --epochs 15 \
  ...
  # âŒ --use_pretrained_correction (í•™ìŠµ ì‹œ ë¶ˆí•„ìš”)
```

### 4.2 ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (Inference) â­ **ë©”ì¸ ì‚¬ìš©**

**ì‚¬ìš© ì—¬ë¶€**: âœ… **í•µì‹¬ ì‚¬ìš© ì§€ì **

**ë™ì‘ íë¦„:**

```mermaid
sequenceDiagram
    participant User
    participant Predictor
    participant KoBART
    participant HFCorrector
    participant HFModel1
    participant HFModel2
    participant Evaluator

    User->>Predictor: predict_batch(dialogues)
    Predictor->>KoBART: generate(dialogues)
    KoBART-->>Predictor: kobart_summaries

    alt use_pretrained_correction=True
        Predictor->>HFCorrector: correct(dialogues, kobart_summaries)
        HFCorrector->>HFModel1: generate(dialogues)
        HFModel1-->>HFCorrector: hf1_summaries
        HFCorrector->>HFModel2: generate(dialogues)
        HFModel2-->>HFCorrector: hf2_summaries

        HFCorrector->>Evaluator: evaluate_quality(kobart, hf1, hf2)
        Evaluator-->>HFCorrector: quality_scores

        HFCorrector->>HFCorrector: select_best(kobart, hf1, hf2, scores)
        HFCorrector-->>Predictor: corrected_summaries
    end

    Predictor-->>User: final_summaries
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```bash
# ì¶”ë¡  ì‹œ í—ˆê¹…í˜ì´ìŠ¤ ë³´ì • í™œì„±í™”
python scripts/inference.py \
  --model experiments/.../kobart/final_model \
  --test_data data/raw/test.csv \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --max_new_tokens 100 \
  --batch_size 16 \
  --output submissions/kobart_hf_corrected.csv
```

### 4.3 ê²€ì¦ íŒŒì´í”„ë¼ì¸ (Validation)

**ì‚¬ìš© ì—¬ë¶€**: âœ… **ë³´ì¡° ì‚¬ìš©**

**ëª©ì :**
- í•™ìŠµ ì¤‘ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ í’ˆì§ˆ í™•ì¸
- í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ê°œì„  ì—¬ë¶€ íŒë‹¨

**ë™ì‘ ë°©ì‹:**
```python
# ê²€ì¦ ì‹œ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ê³¼ ë¹„êµ
kobart_rouge = evaluate(kobart_model, val_data)
hf_rouge = evaluate(hf_model, val_data)

if kobart_rouge < hf_rouge:
    logger.write("âš ï¸  KoBART ì„±ëŠ¥ì´ ì‚¬ì „í•™ìŠµ ëª¨ë¸ë³´ë‹¤ ë‚®ìŒ")
    logger.write("   â†’ ì¶”ë¡  ì‹œ ë³´ì • ê¸°ëŠ¥ ì‚¬ìš© ê¶Œì¥")
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```bash
# K-Fold ê²€ì¦ ì‹œ ì°¸ì¡° ëª¨ë¸ê³¼ ë¹„êµ
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --k_folds 5 \
  --compare_with_pretrained \
  --reference_models gogamza/kobart-base-v2 \
  ...
```

### 4.4 ì „ì²´ íŒŒì´í”„ë¼ì¸ (Full Pipeline)

**ì‚¬ìš© ì—¬ë¶€**: âœ… **ìµœì¢… ì‚¬ìš©**

**êµ¬ì„±:**
1. **í•™ìŠµ**: KoBART ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (ë¹ ë¦„)
2. **ê²€ì¦**: í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ê³¼ ë¹„êµ (í’ˆì§ˆ í™•ì¸)
3. **ì¶”ë¡ **: ë³´ì • ê¸°ëŠ¥ í™œì„±í™” (ìµœì¢… í’ˆì§ˆ)
4. **ì œì¶œ**: ìµœê³  í’ˆì§ˆ ê²°ê³¼ ì œì¶œ

**ì‚¬ìš© ì˜ˆì‹œ:**
```bash
# Full Pipelineì—ì„œ ë³´ì • ê¸°ëŠ¥ í¬í•¨
python scripts/train.py \
  --mode full \
  --models kobart \
  --use_pretrained_correction_inference \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  ...
```

---

## 5. ëª¨ë“ˆ êµ¬ì¡° ë° êµ¬í˜„ ë°©ë²•

### 5.1 ìƒˆë¡œìš´ ëª¨ë“ˆ: `src/correction/`

#### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
src/correction/
â”œâ”€â”€ __init__.py                      # ëª¨ë“ˆ ì´ˆê¸°í™”
â”œâ”€â”€ pretrained_corrector.py          # ë©”ì¸ ë³´ì • í´ë˜ìŠ¤
â”œâ”€â”€ model_loader.py                  # í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë”
â”œâ”€â”€ quality_evaluator.py             # í’ˆì§ˆ í‰ê°€ê¸°
â”œâ”€â”€ ensemble_strategies.py           # ì•™ìƒë¸” ì „ëµ
â””â”€â”€ README.md                        # ëª¨ë“ˆ ì‚¬ìš© ê°€ì´ë“œ
```

### 5.2 í•µì‹¬ í´ë˜ìŠ¤ ì„¤ê³„

#### 5.2.1 `PretrainedCorrector` í´ë˜ìŠ¤

**ëª©ì **: ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•œ ìš”ì•½ ë³´ì •

**í´ë˜ìŠ¤ êµ¬ì¡°:**
```python
class PretrainedCorrector:
    """
    í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•œ ìš”ì•½ ë³´ì •

    ì£¼ìš” ê¸°ëŠ¥:
    1. ì—¬ëŸ¬ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ ë° ê´€ë¦¬
    2. ì°¸ì¡° ìš”ì•½ ìƒì„±
    3. í’ˆì§ˆ í‰ê°€ ë° ë³´ì •
    4. ì•™ìƒë¸” ì „ëµ ì ìš©
    """

    def __init__(
        self,
        model_names: List[str],
        correction_strategy: str = "quality_based",
        quality_threshold: float = 0.3,
        device: Optional[torch.device] = None,
        logger=None
    ):
        """
        Args:
            model_names: í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
                ì˜ˆ: ["gogamza/kobart-base-v2", "digit82/kobart-summarization"]
            correction_strategy: ë³´ì • ì „ëµ
                - "threshold": ì„ê³„ê°’ ê¸°ë°˜
                - "voting": íˆ¬í‘œ ê¸°ë°˜
                - "weighted": ê°€ì¤‘ í‰ê· 
                - "quality_based": í’ˆì§ˆ ê¸°ë°˜ (ì¶”ì²œ)
            quality_threshold: í’ˆì§ˆ ì„ê³„ê°’ (0.0~1.0)
            device: ì¶”ë¡  ë””ë°”ì´ìŠ¤
            logger: Logger ì¸ìŠ¤í„´ìŠ¤
        """
        self.model_names = model_names
        self.correction_strategy = correction_strategy
        self.quality_threshold = quality_threshold
        self.device = device
        self.logger = logger

        # ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”
        from src.correction.model_loader import HuggingFaceModelLoader
        self.model_loader = HuggingFaceModelLoader(device=device, logger=logger)

        # ëª¨ë¸ ë¡œë“œ
        self.models = {}
        self.tokenizers = {}
        for model_name in model_names:
            model, tokenizer = self.model_loader.load_model(model_name)
            self.models[model_name] = model
            self.tokenizers[model_name] = tokenizer

        # í’ˆì§ˆ í‰ê°€ê¸° ì´ˆê¸°í™”
        from src.correction.quality_evaluator import QualityEvaluator
        self.evaluator = QualityEvaluator(logger=logger)

        # ì•™ìƒë¸” ì „ëµ ì´ˆê¸°í™”
        from src.correction.ensemble_strategies import get_ensemble_strategy
        self.ensemble = get_ensemble_strategy(correction_strategy)

    def correct_batch(
        self,
        dialogues: List[str],
        candidate_summaries: List[str],
        **generation_kwargs
    ) -> List[str]:
        """
        ë°°ì¹˜ ë³´ì •

        Args:
            dialogues: ì…ë ¥ ëŒ€í™” ë¦¬ìŠ¤íŠ¸
            candidate_summaries: KoBARTê°€ ìƒì„±í•œ ì´ˆì•ˆ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
            **generation_kwargs: ìƒì„± íŒŒë¼ë¯¸í„°

        Returns:
            ë³´ì •ëœ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        """
        self._log("=" * 60)
        self._log("ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì‹œì‘")
        self._log(f"  - ìƒ˜í”Œ ìˆ˜: {len(dialogues)}")
        self._log(f"  - ì°¸ì¡° ëª¨ë¸ ìˆ˜: {len(self.models)}")
        self._log(f"  - ë³´ì • ì „ëµ: {self.correction_strategy}")
        self._log("=" * 60)

        # 1. ê° í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ë¡œ ì°¸ì¡° ìš”ì•½ ìƒì„±
        reference_summaries = {}
        for model_name, model in self.models.items():
            self._log(f"\n[1/3] ì°¸ì¡° ìš”ì•½ ìƒì„± ì¤‘: {model_name}")
            tokenizer = self.tokenizers[model_name]
            summaries = self._generate_summaries(
                dialogues, model, tokenizer, **generation_kwargs
            )
            reference_summaries[model_name] = summaries
            self._log(f"  âœ… ì™„ë£Œ: {len(summaries)}ê°œ ìš”ì•½ ìƒì„±")

        # 2. í’ˆì§ˆ í‰ê°€
        self._log(f"\n[2/3] í’ˆì§ˆ í‰ê°€ ì¤‘...")
        quality_scores = self.evaluator.evaluate_all(
            candidate_summaries=candidate_summaries,
            reference_summaries=reference_summaries,
            dialogues=dialogues
        )
        self._log(f"  âœ… í‰ê°€ ì™„ë£Œ")

        # 3. ë³´ì • ì „ëµ ì ìš©
        self._log(f"\n[3/3] ë³´ì • ì „ëµ ì ìš© ì¤‘: {self.correction_strategy}")
        corrected_summaries = self.ensemble.select(
            candidate_summaries=candidate_summaries,
            reference_summaries=reference_summaries,
            quality_scores=quality_scores,
            threshold=self.quality_threshold
        )
        self._log(f"  âœ… ë³´ì • ì™„ë£Œ")

        # í†µê³„ ì¶œë ¥
        num_corrected = sum([
            1 for orig, corr in zip(candidate_summaries, corrected_summaries)
            if orig != corr
        ])
        self._log(f"\nğŸ“Š ë³´ì • í†µê³„:")
        self._log(f"  - ì „ì²´: {len(dialogues)}ê°œ")
        self._log(f"  - ë³´ì •ë¨: {num_corrected}ê°œ ({num_corrected/len(dialogues)*100:.1f}%)")
        self._log(f"  - ìœ ì§€ë¨: {len(dialogues)-num_corrected}ê°œ")
        self._log("=" * 60)

        return corrected_summaries

    def _generate_summaries(
        self,
        dialogues: List[str],
        model,
        tokenizer,
        batch_size: int = 16,
        **generation_kwargs
    ) -> List[str]:
        """
        ë‹¨ì¼ ëª¨ë¸ë¡œ ë°°ì¹˜ ìš”ì•½ ìƒì„±

        Args:
            dialogues: ëŒ€í™” ë¦¬ìŠ¤íŠ¸
            model: ëª¨ë¸
            tokenizer: í† í¬ë‚˜ì´ì €
            batch_size: ë°°ì¹˜ í¬ê¸°
            **generation_kwargs: ìƒì„± íŒŒë¼ë¯¸í„°

        Returns:
            ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        """
        from src.inference import create_predictor

        # Predictor ìƒì„± (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)
        predictor = create_predictor(
            model=model,
            tokenizer=tokenizer,
            device=self.device,
            logger=None  # ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€
        )

        # ë°°ì¹˜ ì˜ˆì¸¡
        summaries = predictor.predict_batch(
            dialogues=dialogues,
            batch_size=batch_size,
            show_progress=False,
            **generation_kwargs
        )

        return summaries

    def _log(self, msg: str):
        """ë¡œê¹… í—¬í¼"""
        if self.logger:
            self.logger.write(msg)
        else:
            print(msg)
```

#### 5.2.2 `HuggingFaceModelLoader` í´ë˜ìŠ¤

**ëª©ì **: í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ë° ê´€ë¦¬

**í´ë˜ìŠ¤ êµ¬ì¡°:**
```python
class HuggingFaceModelLoader:
    """
    í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë”

    ì§€ì› ëª¨ë¸:
    - KoBART ê¸°ë°˜
    - T5 ê¸°ë°˜
    - BART ê¸°ë°˜
    """

    def __init__(self, device=None, logger=None):
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.logger = logger
        self.cache = {}  # ëª¨ë¸ ìºì‹œ

    def load_model(
        self,
        model_name: str,
        use_cache: bool = True
    ) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:
        """
        ëª¨ë¸ ë¡œë“œ

        Args:
            model_name: í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ì´ë¦„
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€

        Returns:
            (model, tokenizer) íŠœí”Œ
        """
        # ìºì‹œ í™•ì¸
        if use_cache and model_name in self.cache:
            self._log(f"ìºì‹œì—ì„œ ë¡œë“œ: {model_name}")
            return self.cache[model_name]

        self._log(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")

        try:
            from transformers import (
                AutoConfig,
                AutoModelForSeq2SeqLM,
                AutoTokenizer
            )

            # Config ë¡œë“œ
            config = AutoConfig.from_pretrained(model_name)

            # ëª¨ë¸ ë¡œë“œ (Seq2Seq ì „ìš©)
            model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
            model = model.to(self.device)
            model.eval()

            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            tokenizer = AutoTokenizer.from_pretrained(model_name)

            # ìºì‹œ ì €ì¥
            if use_cache:
                self.cache[model_name] = (model, tokenizer)

            self._log(f"  âœ… ë¡œë“œ ì™„ë£Œ: {model_name}")
            return model, tokenizer

        except Exception as e:
            self._log(f"  âŒ ë¡œë“œ ì‹¤íŒ¨: {model_name}")
            self._log(f"     ì—ëŸ¬: {str(e)}")
            raise

    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache.clear()
        torch.cuda.empty_cache()

    def _log(self, msg: str):
        if self.logger:
            self.logger.write(msg)
        else:
            print(msg)
```

#### 5.2.3 `QualityEvaluator` í´ë˜ìŠ¤

**ëª©ì **: ìš”ì•½ í’ˆì§ˆ í‰ê°€

**í´ë˜ìŠ¤ êµ¬ì¡°:**
```python
class QualityEvaluator:
    """
    ìš”ì•½ í’ˆì§ˆ í‰ê°€ê¸°

    ì§€ì› ë©”íŠ¸ë¦­:
    - ROUGE (F1)
    - Self-ROUGE (ì—¬ëŸ¬ ìš”ì•½ ê°„ ì¼ì¹˜ë„)
    - Length Ratio (ê¸¸ì´ ì ì ˆì„±)
    """

    def __init__(self, logger=None):
        self.logger = logger
        from rouge import Rouge
        self.rouge = Rouge()

    def evaluate_all(
        self,
        candidate_summaries: List[str],
        reference_summaries: Dict[str, List[str]],
        dialogues: Optional[List[str]] = None
    ) -> Dict[str, List[float]]:
        """
        ì „ì²´ í‰ê°€

        Args:
            candidate_summaries: KoBART ê²°ê³¼
            reference_summaries: ê° ëª¨ë¸ë³„ ì°¸ì¡° ìš”ì•½
                ì˜ˆ: {"model1": ["ìš”ì•½1", ...], "model2": [...]}
            dialogues: ì›ë³¸ ëŒ€í™” (ì„ íƒ)

        Returns:
            í’ˆì§ˆ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
                {
                    "candidate_quality": [0.5, 0.7, ...],
                    "model1_quality": [0.6, 0.8, ...],
                    "model2_quality": [...],
                    "candidate_agreement": [0.4, 0.6, ...],  # Self-ROUGE
                }
        """
        self._log("í’ˆì§ˆ í‰ê°€ ì‹œì‘...")

        quality_scores = {}

        # 1. Self-ROUGE: ì—¬ëŸ¬ ìš”ì•½ ê°„ ì¼ì¹˜ë„ ê³„ì‚°
        self._log("  [1/3] Self-ROUGE ê³„ì‚° ì¤‘...")
        all_summaries = [candidate_summaries]
        for model_name, summaries in reference_summaries.items():
            all_summaries.append(summaries)

        agreement_scores = []
        for i in range(len(candidate_summaries)):
            # ië²ˆì§¸ ìƒ˜í”Œì˜ ëª¨ë“  ìš”ì•½ë“¤
            sample_summaries = [summaries[i] for summaries in all_summaries]
            agreement = self._compute_self_rouge(sample_summaries)
            agreement_scores.append(agreement)

        quality_scores["candidate_agreement"] = agreement_scores

        # 2. ê° ëª¨ë¸ì˜ í‰ê·  í’ˆì§ˆ (ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ì˜ ROUGE)
        self._log("  [2/3] ëª¨ë¸ë³„ í’ˆì§ˆ ê³„ì‚° ì¤‘...")
        for model_name, summaries in reference_summaries.items():
            model_quality = []
            for i in range(len(summaries)):
                # ì´ ëª¨ë¸ ì œì™¸í•œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ë¹„êµ
                other_summaries = [
                    s[i] for name, s in reference_summaries.items()
                    if name != model_name
                ] + [candidate_summaries[i]]

                avg_rouge = np.mean([
                    self._compute_rouge_f1(summaries[i], other)
                    for other in other_summaries
                ])
                model_quality.append(avg_rouge)

            quality_scores[f"{model_name}_quality"] = model_quality

        # 3. Candidate í’ˆì§ˆ ê³„ì‚°
        self._log("  [3/3] Candidate í’ˆì§ˆ ê³„ì‚° ì¤‘...")
        candidate_quality = []
        for i in range(len(candidate_summaries)):
            ref_list = [
                ref[i] for ref in reference_summaries.values()
            ]
            avg_rouge = np.mean([
                self._compute_rouge_f1(candidate_summaries[i], ref)
                for ref in ref_list
            ])
            candidate_quality.append(avg_rouge)

        quality_scores["candidate_quality"] = candidate_quality

        self._log("  âœ… í‰ê°€ ì™„ë£Œ")
        return quality_scores

    def _compute_rouge_f1(self, hypothesis: str, reference: str) -> float:
        """ROUGE-L F1 ê³„ì‚°"""
        try:
            scores = self.rouge.get_scores(hypothesis, reference)[0]
            return scores['rouge-l']['f']
        except:
            return 0.0

    def _compute_self_rouge(self, summaries: List[str]) -> float:
        """Self-ROUGE: ì—¬ëŸ¬ ìš”ì•½ ê°„ í‰ê·  ROUGE"""
        if len(summaries) < 2:
            return 1.0

        scores = []
        for i in range(len(summaries)):
            for j in range(i+1, len(summaries)):
                score = self._compute_rouge_f1(summaries[i], summaries[j])
                scores.append(score)

        return np.mean(scores) if scores else 0.0

    def _log(self, msg: str):
        if self.logger:
            self.logger.write(msg)
```

#### 5.2.4 `EnsembleStrategy` í´ë˜ìŠ¤

**ëª©ì **: ì•™ìƒë¸” ì „ëµ êµ¬í˜„

**í´ë˜ìŠ¤ êµ¬ì¡°:**
```python
from abc import ABC, abstractmethod

class EnsembleStrategy(ABC):
    """ì•™ìƒë¸” ì „ëµ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    @abstractmethod
    def select(
        self,
        candidate_summaries: List[str],
        reference_summaries: Dict[str, List[str]],
        quality_scores: Dict[str, List[float]],
        threshold: float
    ) -> List[str]:
        """
        ìµœì¢… ìš”ì•½ ì„ íƒ

        Args:
            candidate_summaries: KoBART ê²°ê³¼
            reference_summaries: ì°¸ì¡° ìš”ì•½ë“¤
            quality_scores: í’ˆì§ˆ ì ìˆ˜ë“¤
            threshold: ì„ê³„ê°’

        Returns:
            ìµœì¢… ì„ íƒëœ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        """
        pass


class QualityBasedStrategy(EnsembleStrategy):
    """í’ˆì§ˆ ê¸°ë°˜ ì„ íƒ ì „ëµ (ì¶”ì²œ)"""

    def select(self, candidate_summaries, reference_summaries, quality_scores, threshold):
        """
        í’ˆì§ˆì´ ê°€ì¥ ë†’ì€ ìš”ì•½ ì„ íƒ

        ë¡œì§:
        1. candidate_qualityê°€ threshold ì´ìƒì´ë©´ KoBART ì‚¬ìš©
        2. ì•„ë‹ˆë©´ ê°€ì¥ í’ˆì§ˆ ë†’ì€ ì°¸ì¡° ëª¨ë¸ ì‚¬ìš©
        """
        final_summaries = []

        for i in range(len(candidate_summaries)):
            candidate_quality = quality_scores["candidate_quality"][i]

            # KoBART í’ˆì§ˆì´ ì¶©ë¶„íˆ ë†’ìœ¼ë©´ ì‚¬ìš©
            if candidate_quality >= threshold:
                final_summaries.append(candidate_summaries[i])
                continue

            # ì•„ë‹ˆë©´ ê°€ì¥ í’ˆì§ˆ ë†’ì€ ì°¸ì¡° ì„ íƒ
            best_model = None
            best_quality = -1

            for model_name in reference_summaries.keys():
                quality = quality_scores[f"{model_name}_quality"][i]
                if quality > best_quality:
                    best_quality = quality
                    best_model = model_name

            if best_model:
                final_summaries.append(reference_summaries[best_model][i])
            else:
                # í´ë°±: KoBART ì‚¬ìš©
                final_summaries.append(candidate_summaries[i])

        return final_summaries


class ThresholdStrategy(EnsembleStrategy):
    """ì„ê³„ê°’ ê¸°ë°˜ ì „ëµ"""

    def select(self, candidate_summaries, reference_summaries, quality_scores, threshold):
        """
        ì„ê³„ê°’ ê¸°ë°˜ ì„ íƒ

        ë¡œì§:
        - candidate_agreementê°€ threshold ì´í•˜ë©´ ì²« ë²ˆì§¸ ì°¸ì¡° ëª¨ë¸ ì‚¬ìš©
        - ì•„ë‹ˆë©´ KoBART ì‚¬ìš©
        """
        final_summaries = []
        first_ref_model = list(reference_summaries.keys())[0]

        for i in range(len(candidate_summaries)):
            agreement = quality_scores["candidate_agreement"][i]

            if agreement <= threshold:
                # í•©ì˜ë„ ë‚®ìŒ â†’ ì°¸ì¡° ëª¨ë¸ ì‚¬ìš©
                final_summaries.append(reference_summaries[first_ref_model][i])
            else:
                # í•©ì˜ë„ ë†’ìŒ â†’ KoBART ì‚¬ìš©
                final_summaries.append(candidate_summaries[i])

        return final_summaries


class VotingStrategy(EnsembleStrategy):
    """íˆ¬í‘œ ê¸°ë°˜ ì „ëµ"""

    def select(self, candidate_summaries, reference_summaries, quality_scores, threshold):
        """
        íˆ¬í‘œë¡œ ì„ íƒ

        ë¡œì§:
        - ëª¨ë“  ìš”ì•½ ì¤‘ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ìš”ì•½ ì„ íƒ
        - (ì‹¤ì œë¡œëŠ” ê°€ì¥ ìœ ì‚¬í•œ ìš”ì•½ë“¤ì„ ê·¸ë£¹í•‘í•˜ì—¬ ì„ íƒ)
        """
        from collections import Counter
        final_summaries = []

        for i in range(len(candidate_summaries)):
            # ië²ˆì§¸ ìƒ˜í”Œì˜ ëª¨ë“  ìš”ì•½
            all_summaries = [candidate_summaries[i]]
            for ref in reference_summaries.values():
                all_summaries.append(ref[i])

            # ê°€ì¥ ìœ ì‚¬í•œ ìš”ì•½ë“¤ ì°¾ê¸° (ê°„ë‹¨í•˜ê²Œ ì²« ë²ˆì§¸ ì„ íƒ)
            # TODO: ì‹¤ì œë¡œëŠ” í´ëŸ¬ìŠ¤í„°ë§ í•„ìš”
            final_summaries.append(all_summaries[0])

        return final_summaries


def get_ensemble_strategy(strategy_name: str) -> EnsembleStrategy:
    """ì „ëµ íŒ©í† ë¦¬"""
    strategies = {
        "quality_based": QualityBasedStrategy,
        "threshold": ThresholdStrategy,
        "voting": VotingStrategy,
    }

    if strategy_name not in strategies:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì „ëµ: {strategy_name}")

    return strategies[strategy_name]()
```

---

## 6. ì½”ë“œ í†µí•© ê°€ì´ë“œ

### 6.1 `Predictor` í´ë˜ìŠ¤ ìˆ˜ì •

**íŒŒì¼**: `src/inference/predictor.py`

**ìˆ˜ì • ìœ„ì¹˜**: `predict_batch` ë©”ì„œë“œ

**ìˆ˜ì • ë‚´ìš©:**
```python
# ==================== ê¸°ì¡´ ì½”ë“œ (predictor.py:278) ==================== #
def predict_batch(
    self,
    dialogues: List[str],
    batch_size: int = 32,
    show_progress: bool = True,
    use_pretrained_correction: bool = False,  # âœ… ìƒˆ íŒŒë¼ë¯¸í„°
    correction_models: Optional[List[str]] = None,  # âœ… ìƒˆ íŒŒë¼ë¯¸í„°
    correction_strategy: str = "quality_based",  # âœ… ìƒˆ íŒŒë¼ë¯¸í„°
    correction_threshold: float = 0.3,  # âœ… ìƒˆ íŒŒë¼ë¯¸í„°
    **generation_kwargs
) -> List[str]:
    """
    ë°°ì¹˜ ëŒ€í™” ìš”ì•½ ì˜ˆì¸¡

    Args:
        dialogues: ëŒ€í™” ë¦¬ìŠ¤íŠ¸
        batch_size: ë°°ì¹˜ í¬ê¸°
        show_progress: ì§„í–‰ í‘œì‹œ ì—¬ë¶€
        use_pretrained_correction: ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì‚¬ìš© ì—¬ë¶€ âœ… ì¶”ê°€
        correction_models: ë³´ì •ì— ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ âœ… ì¶”ê°€
        correction_strategy: ë³´ì • ì „ëµ âœ… ì¶”ê°€
        correction_threshold: í’ˆì§ˆ ì„ê³„ê°’ âœ… ì¶”ê°€
        **generation_kwargs: ìƒì„± íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ

    Returns:
        List[str]: ì˜ˆì¸¡ëœ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
    """
    # -------------- ê¸°ì¡´ ë°ì´í„°ì…‹ ìƒì„± ì½”ë“œ -------------- #
    # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)

    # -------------- ê¸°ì¡´ ë°°ì¹˜ ì¶”ë¡  ì½”ë“œ -------------- #
    summaries = []
    pbar = tqdm(dataloader, desc="Predicting") if show_progress else dataloader

    for batch_idx, batch in enumerate(pbar, 1):
        inputs = {
            k: v.to(self.device)
            for k, v in batch.items()
            if k in ['input_ids', 'attention_mask']
        }

        with torch.no_grad():
            outputs = self.model.generate(**inputs, **gen_config)

        batch_summaries = self.tokenizer.batch_decode(
            outputs,
            skip_special_tokens=True
        )

        # í›„ì²˜ë¦¬ ì ìš©
        summaries.extend([postprocess_summary(s) for s in batch_summaries])

    # âœ… ==================== ìƒˆë¡œìš´ ë³´ì • ë¡œì§ ì¶”ê°€ ==================== #
    if use_pretrained_correction and correction_models:
        if self.logger:
            self.logger.write("\n" + "=" * 60)
            self.logger.write("ğŸ”§ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì‹œì‘")

        # PretrainedCorrector ì´ˆê¸°í™”
        from src.correction import create_pretrained_corrector

        corrector = create_pretrained_corrector(
            model_names=correction_models,
            correction_strategy=correction_strategy,
            quality_threshold=correction_threshold,
            device=self.device,
            logger=self.logger
        )

        # ë³´ì • ìˆ˜í–‰
        summaries = corrector.correct_batch(
            dialogues=dialogues,
            candidate_summaries=summaries,
            **generation_kwargs
        )

        if self.logger:
            self.logger.write("âœ… ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì™„ë£Œ")
            self.logger.write("=" * 60 + "\n")

    return summaries
```

### 6.2 ëª…ë ¹í–‰ ì¸ì ì¶”ê°€

**íŒŒì¼**: `scripts/train.py` ë˜ëŠ” `scripts/inference.py`

**ì¶”ê°€ ë‚´ìš©:**
```python
# ==================== scripts/train.py ==================== #
parser.add_argument(
    '--use_pretrained_correction',
    action='store_true',
    help='ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì‚¬ìš© (ì¶”ë¡  ì‹œ)'
)

parser.add_argument(
    '--correction_models',
    nargs='+',
    default=['gogamza/kobart-base-v2', 'digit82/kobart-summarization'],
    help='ë³´ì •ì— ì‚¬ìš©í•  í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸'
)

parser.add_argument(
    '--correction_strategy',
    type=str,
    default='quality_based',
    choices=['quality_based', 'threshold', 'voting', 'weighted'],
    help='ë³´ì • ì „ëµ'
)

parser.add_argument(
    '--correction_threshold',
    type=float,
    default=0.3,
    help='í’ˆì§ˆ ì„ê³„ê°’ (0.0~1.0)'
)
```

### 6.3 Config íŒŒì¼ ìˆ˜ì •

**íŒŒì¼**: `configs/*.yaml`

**ì¶”ê°€ ë‚´ìš©:**
```yaml
# ==================== configs/kobart.yaml ==================== #
inference:
  # ... ê¸°ì¡´ ì„¤ì • ...

  # âœ… ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì„¤ì • ì¶”ê°€
  pretrained_correction:
    enabled: false  # ê¸°ë³¸ê°’ì€ false (ì˜µì…˜)
    models:
      - "gogamza/kobart-base-v2"
      - "digit82/kobart-summarization"
    strategy: "quality_based"  # quality_based, threshold, voting, weighted
    threshold: 0.3  # í’ˆì§ˆ ì„ê³„ê°’
```

### 6.4 `__init__.py` ìˆ˜ì •

**íŒŒì¼**: `src/correction/__init__.py`

**ë‚´ìš©:**
```python
"""
ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ëª¨ë“ˆ

PRD 04, 12: ì¶”ë¡  ìµœì í™” ë° ì•™ìƒë¸” ì „ëµ êµ¬í˜„
"""

from src.correction.pretrained_corrector import PretrainedCorrector
from src.correction.model_loader import HuggingFaceModelLoader
from src.correction.quality_evaluator import QualityEvaluator
from src.correction.ensemble_strategies import (
    EnsembleStrategy,
    QualityBasedStrategy,
    ThresholdStrategy,
    VotingStrategy,
    get_ensemble_strategy
)

__all__ = [
    "PretrainedCorrector",
    "HuggingFaceModelLoader",
    "QualityEvaluator",
    "EnsembleStrategy",
    "QualityBasedStrategy",
    "ThresholdStrategy",
    "VotingStrategy",
    "get_ensemble_strategy",
    "create_pretrained_corrector",
]


def create_pretrained_corrector(
    model_names,
    correction_strategy="quality_based",
    quality_threshold=0.3,
    device=None,
    logger=None
):
    """
    í¸ì˜ í•¨ìˆ˜: PretrainedCorrector ìƒì„±

    Args:
        model_names: í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        correction_strategy: ë³´ì • ì „ëµ
        quality_threshold: í’ˆì§ˆ ì„ê³„ê°’
        device: ë””ë°”ì´ìŠ¤
        logger: Logger

    Returns:
        PretrainedCorrector ì¸ìŠ¤í„´ìŠ¤
    """
    return PretrainedCorrector(
        model_names=model_names,
        correction_strategy=correction_strategy,
        quality_threshold=quality_threshold,
        device=device,
        logger=logger
    )
```

---

## 7. ì„¤ì • ë° ì‚¬ìš© ì˜ˆì‹œ

### 7.1 ê¸°ë³¸ ì‚¬ìš© ì˜ˆì‹œ

#### ì˜ˆì‹œ 1: ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©

```bash
# ==================== ê¸°ë³¸ ë³´ì • (2ê°œ ëª¨ë¸) ==================== #
python scripts/inference.py \
  --model experiments/20251014_120000_kobart/final_model \
  --test_data data/raw/test.csv \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --max_new_tokens 100 \
  --repetition_penalty 1.5 \
  --batch_size 16 \
  --output submissions/kobart_hf_corrected.csv

# ì˜ˆìƒ ì‹œê°„: +30-40ë¶„ (ì°¸ì¡° ëª¨ë¸ ì¶”ë¡ )
# ì˜ˆìƒ ê°œì„ : ROUGE Sum +0.03~0.05
```

#### ì˜ˆì‹œ 2: ì „ì²´ íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©

```bash
# ==================== Full Pipeline + ë³´ì • ==================== #
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 15 \
  --k_folds 5 \
  --gradient_accumulation_steps 10 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --use_pretrained_correction_inference \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization eenzeenee/t5-base-korean \
  --correction_strategy quality_based \
  --correction_threshold 0.35 \
  --experiment_name kobart_full_hf_corrected

# í•™ìŠµ: 5-7ì‹œê°„
# ì¶”ë¡  + ë³´ì •: +1-2ì‹œê°„
# ì´ ì‹œê°„: 6-9ì‹œê°„
```

#### ì˜ˆì‹œ 3: ë‹¤ì–‘í•œ ë³´ì • ì „ëµ ì‹¤í—˜

```bash
# ì „ëµ 1: í’ˆì§ˆ ê¸°ë°˜ (ì¶”ì²œ)
python scripts/inference.py \
  --use_pretrained_correction \
  --correction_strategy quality_based \
  --correction_threshold 0.3

# ì „ëµ 2: ì„ê³„ê°’ ê¸°ë°˜
python scripts/inference.py \
  --use_pretrained_correction \
  --correction_strategy threshold \
  --correction_threshold 0.5

# ì „ëµ 3: íˆ¬í‘œ ê¸°ë°˜
python scripts/inference.py \
  --use_pretrained_correction \
  --correction_strategy voting
```

### 7.2 Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from src.inference import create_predictor
from src.models import load_model_and_tokenizer
from src.correction import create_pretrained_corrector

# 1. KoBART ëª¨ë¸ ë¡œë“œ
model, tokenizer = load_model_and_tokenizer(
    config=kobart_config,
    logger=logger
)

# 2. Predictor ìƒì„±
predictor = create_predictor(
    model=model,
    tokenizer=tokenizer,
    device=device,
    logger=logger
)

# 3. ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë³´ì • ì‚¬ìš©
dialogues = ["ëŒ€í™”1", "ëŒ€í™”2", ...]

summaries = predictor.predict_batch(
    dialogues=dialogues,
    batch_size=16,
    use_pretrained_correction=True,
    correction_models=[
        "gogamza/kobart-base-v2",
        "digit82/kobart-summarization"
    ],
    correction_strategy="quality_based",
    correction_threshold=0.3,
    max_new_tokens=100,
    repetition_penalty=1.5
)
```

### 7.3 Solar API + í—ˆê¹…í˜ì´ìŠ¤ í•¨ê»˜ ì‚¬ìš©

```python
# ==================== í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ==================== #
# 1ë‹¨ê³„: KoBARTë¡œ ì´ˆì•ˆ ìƒì„±
kobart_summaries = predictor.predict_batch(dialogues, batch_size=16)

# 2ë‹¨ê³„: í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ë¡œ ë³´ì • (ëŒ€ëŸ‰, ë¹ ë¦„)
hf_corrected = predictor.predict_batch(
    dialogues,
    use_pretrained_correction=True,
    correction_models=["gogamza/kobart-base-v2"],
    correction_threshold=0.4
)

# 3ë‹¨ê³„: Solar APIë¡œ ìµœì¢… ë³´ì • (ì†ŒëŸ‰, ë†’ì€ í’ˆì§ˆ)
from src.api import create_solar_api

solar_api = create_solar_api(logger=logger)

# í’ˆì§ˆ ë‚®ì€ ìƒ˜í”Œë§Œ Solar API ì‚¬ìš©
final_summaries = []
for i, (dialogue, summary) in enumerate(zip(dialogues, hf_corrected)):
    # í’ˆì§ˆ í‰ê°€ (ì˜ˆ: Self-ROUGE)
    if quality_low(summary):
        # Solar API ì‚¬ìš©
        solar_summary = solar_api.summarize(dialogue)
        final_summaries.append(solar_summary)
    else:
        # í—ˆê¹…í˜ì´ìŠ¤ ê²°ê³¼ ìœ ì§€
        final_summaries.append(summary)
```

### 7.4 ì„±ëŠ¥ ì˜ˆì¸¡

| êµ¬ì„± | ì‹œê°„ (ì¶”ê°€) | ROUGE Sum ê°œì„  | ë¹„ìš© |
|------|-----------|--------------|------|
| **KoBART ë‹¨ë…** | ê¸°ì¤€ | 1.048 | 0ì› |
| **+ HF 1ê°œ ëª¨ë¸** | +15ë¶„ | +0.02~0.03 | 0ì› |
| **+ HF 2ê°œ ëª¨ë¸** | +30ë¶„ | +0.03~0.05 | 0ì› |
| **+ HF 3ê°œ ëª¨ë¸** | +45ë¶„ | +0.04~0.06 | 0ì› |
| **+ Solar API** | +2ì‹œê°„ | +0.05~0.10 | ìœ ë£Œ |
| **HF + Solar** | +2.5ì‹œê°„ | +0.06~0.12 | ìœ ë£Œ |

**ê¶Œì¥ êµ¬ì„±:**
- **ì‹œê°„ ì—¬ìœ **: HF 3ê°œ ëª¨ë¸ (gogamza + digit82 + eenzeenee)
- **ê· í˜•**: HF 2ê°œ ëª¨ë¸ (gogamza + digit82)
- **ë¹ ë¥¸ ì‹¤í–‰**: HF 1ê°œ ëª¨ë¸ (digit82)
- **ìµœê³  í’ˆì§ˆ**: HF 2ê°œ + Solar API (ì†ŒëŸ‰)

---

## 8. êµ¬í˜„ ìš°ì„ ìˆœìœ„ ë° ë‹¨ê³„

### 8.1 Phase 1: í•µì‹¬ ê¸°ëŠ¥ (í•„ìˆ˜)

**ëª©í‘œ**: ê¸°ë³¸ ë³´ì • ê¸°ëŠ¥ ë™ì‘

**êµ¬í˜„ í•­ëª©:**
1. âœ… `HuggingFaceModelLoader` í´ë˜ìŠ¤
2. âœ… `PretrainedCorrector` í´ë˜ìŠ¤ (ê¸°ë³¸ ê¸°ëŠ¥)
3. âœ… `QualityEvaluator` í´ë˜ìŠ¤ (ROUGEë§Œ)
4. âœ… `QualityBasedStrategy` ì „ëµ
5. âœ… `Predictor` í†µí•©
6. âœ… ëª…ë ¹í–‰ ì¸ì ì¶”ê°€

**ê²€ì¦ ë°©ë²•:**
```bash
python scripts/inference.py \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 \
  --correction_strategy quality_based
```

### 8.2 Phase 2: ê³ ê¸‰ ê¸°ëŠ¥ (ê¶Œì¥)

**ëª©í‘œ**: ë‹¤ì–‘í•œ ì „ëµ ë° í‰ê°€ ì§€í‘œ

**êµ¬í˜„ í•­ëª©:**
1. âœ… `ThresholdStrategy` ì „ëµ
2. âœ… `VotingStrategy` ì „ëµ
3. âœ… BERTScore í‰ê°€ ì¶”ê°€
4. âœ… Config íŒŒì¼ í†µí•©
5. âœ… ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### 8.3 Phase 3: ìµœì í™” (ì„ íƒ)

**ëª©í‘œ**: ì†ë„ ë° ë©”ëª¨ë¦¬ ìµœì í™”

**êµ¬í˜„ í•­ëª©:**
1. âœ… ëª¨ë¸ ìºì‹± ê°•í™”
2. âœ… ë°°ì¹˜ ìµœì í™”
3. âœ… GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
4. âœ… ë³‘ë ¬ ì²˜ë¦¬
5. âœ… ì‹œê°í™” ì¶”ê°€

---

## 9. ì˜ˆìƒ ë¬¸ì œ ë° í•´ê²° ë°©ì•ˆ

### ë¬¸ì œ 1: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì›ì¸**: ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ ë¡œë“œ

**í•´ê²°:**
```python
# ìˆœì°¨ ë¡œë“œ + ìºì‹œ í•´ì œ
for model_name in model_names:
    model, tokenizer = load_model(model_name)
    summaries = generate(model, tokenizer, dialogues)
    reference_summaries[model_name] = summaries

    # ë©”ëª¨ë¦¬ í•´ì œ
    del model
    torch.cuda.empty_cache()
```

### ë¬¸ì œ 2: ì¶”ë¡  ì‹œê°„ ë„ˆë¬´ ê¸¸ì–´ì§

**ì›ì¸**: ì—¬ëŸ¬ ëª¨ë¸ ì¶”ë¡ 

**í•´ê²°:**
```python
# ìƒ˜í”Œë§ìœ¼ë¡œ ë¹ ë¥¸ ê²€ì¦
sample_size = 100  # ì „ì²´ ë°ì´í„°ì˜ ì¼ë¶€ë§Œ ì‚¬ìš©
sample_indices = np.random.choice(len(dialogues), sample_size)
sample_dialogues = [dialogues[i] for i in sample_indices]

# ìƒ˜í”Œì—ë§Œ ë³´ì • ì ìš©
```

### ë¬¸ì œ 3: í’ˆì§ˆì´ ì˜¤íˆë ¤ ì €í•˜ë¨

**ì›ì¸**: ì„ê³„ê°’ ì„¤ì • ë¬¸ì œ

**í•´ê²°:**
```python
# Grid searchë¡œ ìµœì  ì„ê³„ê°’ íƒìƒ‰
thresholds = [0.2, 0.3, 0.4, 0.5]
best_threshold = None
best_rouge = -1

for threshold in thresholds:
    summaries = correct_with_threshold(threshold)
    rouge = evaluate(summaries, references)

    if rouge > best_rouge:
        best_rouge = rouge
        best_threshold = threshold
```

---

## 10. ìš”ì•½ ë° ê²°ë¡ 

### 10.1 í•µì‹¬ ìš”ì•½

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ëª©ì ** | KoBART ì¶”ë¡  í’ˆì§ˆ í–¥ìƒ (í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ í™œìš©) |
| **ì‚¬ìš© ì‹œì ** | ì¶”ë¡ /ê²€ì¦ íŒŒì´í”„ë¼ì¸ (í•™ìŠµ ì‹œ ë¯¸ì‚¬ìš©) |
| **êµ¬í˜„ ìœ„ì¹˜** | `src/correction/` ìƒˆ ëª¨ë“ˆ |
| **í†µí•© ì§€ì ** | `src/inference/predictor.py:predict_batch()` |
| **ì¶”ì²œ ì „ëµ** | Quality-based Selection |
| **ì¶”ì²œ ëª¨ë¸** | gogamza/kobart-base-v2, digit82/kobart-summarization |
| **ì˜ˆìƒ ê°œì„ ** | ROUGE Sum +0.03~0.06 |
| **ì¶”ê°€ ì‹œê°„** | +30ë¶„~1ì‹œê°„ |

### 10.2 Solar APIì™€ì˜ ì°¨ì´

| êµ¬ë¶„ | Solar API | í—ˆê¹…í˜ì´ìŠ¤ |
|------|----------|-----------|
| **ìš©ë„** | ìµœì¢… ê³ í’ˆì§ˆ ë³´ì • | ëŒ€ëŸ‰ í’ˆì§ˆ ê²€ì¦ |
| **ë¹„ìš©** | ìœ ë£Œ | ë¬´ë£Œ |
| **ì†ë„** | ëŠë¦¼ (API í˜¸ì¶œ) | ë¹ ë¦„ (ë¡œì»¬ GPU) |
| **í’ˆì§ˆ** | ìµœê³  | ë†’ìŒ |
| **ì¶”ì²œ ì‚¬ìš©** | ì†ŒëŸ‰ ë°ì´í„° | ëŒ€ëŸ‰ ë°ì´í„° |

### 10.3 êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `src/correction/` ë””ë ‰í† ë¦¬ ìƒì„±
- [ ] `pretrained_corrector.py` êµ¬í˜„
- [ ] `model_loader.py` êµ¬í˜„
- [ ] `quality_evaluator.py` êµ¬í˜„
- [ ] `ensemble_strategies.py` êµ¬í˜„
- [ ] `src/correction/__init__.py` ì‘ì„±
- [ ] `src/inference/predictor.py` ìˆ˜ì •
- [ ] ëª…ë ¹í–‰ ì¸ì ì¶”ê°€ (`scripts/train.py`, `scripts/inference.py`)
- [ ] Config íŒŒì¼ ìˆ˜ì • (`configs/*.yaml`)
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± (`src/tests/test_correction.py`)
- [ ] ë¬¸ì„œ ì‘ì„± (`src/correction/README.md`)

---

**ì‘ì„±**: 2025-10-14
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-14
**ë²„ì „**: 1.0
**ìƒíƒœ**: êµ¬í˜„ ëŒ€ê¸°
