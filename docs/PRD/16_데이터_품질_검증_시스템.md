# ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ

## ğŸ“Š ì‹œìŠ¤í…œ ê°œìš”

### ëª©ì 
- í•™ìŠµ ë°ì´í„°ì˜ í’ˆì§ˆ ë³´ì¥
- ë¼ë²¨ë§ ì¼ê´€ì„± ê²€ì¦
- ì´ìƒì¹˜ ë° ë…¸ì´ì¦ˆ íƒì§€
- ë°ì´í„° ì¦ê°• í’ˆì§ˆ ê´€ë¦¬
- ì‹¤í—˜ ì¬í˜„ì„± í™•ë³´

## ğŸ—ï¸ í’ˆì§ˆ ê²€ì¦ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    subgraph "ì›ë³¸ ë°ì´í„°"
        A[Train.csv<br/>12,457ê°œ] --> B[í’ˆì§ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸]
    end

    subgraph "ê²€ì¦ ë‹¨ê³„"
        B --> C[êµ¬ì¡°ì  ê²€ì¦]
        B --> D[ì˜ë¯¸ì  ê²€ì¦]
        B --> E[í†µê³„ì  ê²€ì¦]
        B --> F[ë¼ë²¨ ê²€ì¦]
    end

    subgraph "ê²€ì¦ í•­ëª©"
        C --> G[í•„ë“œ ì™„ì „ì„±<br/>í¬ë§· ì¼ê´€ì„±]
        D --> H[ëŒ€í™”-ìš”ì•½ ì¼ì¹˜ë„<br/>ì •ë³´ ì†ì‹¤ë„]
        E --> I[ê¸¸ì´ ë¶„í¬<br/>ì´ìƒì¹˜ íƒì§€]
        F --> J[ë¼ë²¨ ì¼ê´€ì„±<br/>Cross-validation]
    end

    subgraph "í’ˆì§ˆ ì ìˆ˜"
        G --> K[êµ¬ì¡° ì ìˆ˜]
        H --> L[ì˜ë¯¸ ì ìˆ˜]
        I --> M[í†µê³„ ì ìˆ˜]
        J --> N[ë¼ë²¨ ì ìˆ˜]
    end

    subgraph "ìµœì¢… ê²°ê³¼"
        K --> O[ì¢…í•© í’ˆì§ˆ ì ìˆ˜]
        L --> O
        M --> O
        N --> O
        O --> P[í’ˆì§ˆ ë¦¬í¬íŠ¸]
        O --> Q[ë¬¸ì œ ë°ì´í„° í”Œë˜ê¹…]
    end

    style B fill:#f9f,stroke:#333,stroke-width:4px
    style O fill:#9ff,stroke:#333,stroke-width:4px
```

## ğŸ“‹ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1. êµ¬ì¡°ì  ê²€ì¦
```python
class StructuralValidator:
    def __init__(self):
        self.required_fields = ['fname', 'dialogue', 'summary', 'topic']
        self.errors = []

    def validate_structure(self, df):
        """ë°ì´í„° êµ¬ì¡° ê²€ì¦"""
        checks = {
            'missing_fields': self.check_fields(df),
            'null_values': self.check_nulls(df),
            'data_types': self.check_types(df),
            'id_uniqueness': self.check_unique_ids(df),
            'encoding_issues': self.check_encoding(df)
        }
        return checks

    def check_fields(self, df):
        """í•„ìˆ˜ í•„ë“œ í™•ì¸"""
        missing = set(self.required_fields) - set(df.columns)
        if missing:
            self.errors.append(f"Missing fields: {missing}")
        return len(missing) == 0

    def check_nulls(self, df):
        """ë„ ê°’ ì²´í¬"""
        null_counts = df[self.required_fields].isnull().sum()
        problematic = null_counts[null_counts > 0]

        if not problematic.empty:
            self.errors.append(f"Null values found: {problematic.to_dict()}")
        return problematic.empty

    def check_encoding(self, df):
        """ì¸ì½”ë”© ë¬¸ì œ ì²´í¬"""
        encoding_errors = []

        for col in ['dialogue', 'summary']:
            for idx, text in df[col].items():
                if self.has_encoding_issue(text):
                    encoding_errors.append({
                        'index': idx,
                        'column': col,
                        'sample': text[:50]
                    })

        return encoding_errors
```

### 2. ì˜ë¯¸ì  ê²€ì¦
```python
class SemanticValidator:
    def __init__(self):
        self.min_compression_ratio = 0.1
        self.max_compression_ratio = 0.5

    def validate_semantic(self, df):
        """ëŒ€í™”-ìš”ì•½ ê°„ ì˜ë¯¸ì  ì¼ì¹˜ë„ ê²€ì¦"""

        results = []
        for idx, row in df.iterrows():
            score = self.calculate_alignment(
                row['dialogue'],
                row['summary']
            )
            results.append({
                'index': idx,
                'alignment_score': score['alignment'],
                'compression_ratio': score['compression'],
                'key_info_preserved': score['key_info'],
                'issues': score['issues']
            })

        return pd.DataFrame(results)

    def calculate_alignment(self, dialogue, summary):
        """ëŒ€í™”-ìš”ì•½ ì •ë ¬ë„ ê³„ì‚°"""

        # ì••ì¶•ë¥  ê³„ì‚°
        compression = len(summary.split()) / len(dialogue.split())

        # í•µì‹¬ ì •ë³´ ë³´ì¡´ë„
        dialogue_entities = self.extract_entities(dialogue)
        summary_entities = self.extract_entities(summary)
        preservation = len(summary_entities & dialogue_entities) / len(dialogue_entities)

        # ì˜ë¯¸ì  ìœ ì‚¬ë„ (ì„ë² ë”© ê¸°ë°˜)
        semantic_sim = self.calculate_semantic_similarity(dialogue, summary)

        issues = []
        if compression < self.min_compression_ratio:
            issues.append("ê³¼ë„í•œ ì••ì¶•")
        if compression > self.max_compression_ratio:
            issues.append("ì••ì¶• ë¶€ì¡±")
        if preservation < 0.5:
            issues.append("í•µì‹¬ ì •ë³´ ëˆ„ë½")

        return {
            'alignment': semantic_sim,
            'compression': compression,
            'key_info': preservation,
            'issues': issues
        }

    def extract_entities(self, text):
        """ì¤‘ìš” ì—”í‹°í‹° ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ ì˜ˆì‹œ - ì‹¤ì œë¡œëŠ” NER ëª¨ë¸ ì‚¬ìš©
        import re

        # ìˆ«ì, ë‚ ì§œ, ê³ ìœ ëª…ì‚¬ ë“± ì¶”ì¶œ
        entities = set()

        # ìˆ«ì
        entities.update(re.findall(r'\d+', text))

        # ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë‹¨ì–´ (ê³ ìœ ëª…ì‚¬ ì¶”ì •)
        entities.update(re.findall(r'\b[A-Z][a-z]+\b', text))

        return entities
```

### 3. í†µê³„ì  ê²€ì¦
```python
class StatisticalValidator:
    def __init__(self):
        self.outlier_threshold = 3  # í‘œì¤€í¸ì°¨

    def validate_statistics(self, df):
        """í†µê³„ì  ì´ìƒì¹˜ íƒì§€"""

        stats = {
            'dialogue_length': self.analyze_lengths(df['dialogue']),
            'summary_length': self.analyze_lengths(df['summary']),
            'compression_ratio': self.analyze_compression(df),
            'speaker_distribution': self.analyze_speakers(df),
            'topic_distribution': self.analyze_topics(df)
        }

        outliers = self.detect_outliers(df, stats)

        return {
            'statistics': stats,
            'outliers': outliers,
            'quality_scores': self.calculate_quality_scores(stats)
        }

    def analyze_lengths(self, texts):
        """í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„"""
        lengths = texts.str.split().str.len()

        return {
            'mean': lengths.mean(),
            'std': lengths.std(),
            'min': lengths.min(),
            'max': lengths.max(),
            'q25': lengths.quantile(0.25),
            'q50': lengths.quantile(0.50),
            'q75': lengths.quantile(0.75)
        }

    def detect_outliers(self, df, stats):
        """ì´ìƒì¹˜ íƒì§€"""
        outliers = []

        # ê¸¸ì´ ê¸°ë°˜ ì´ìƒì¹˜
        dialogue_lengths = df['dialogue'].str.split().str.len()
        mean_len = stats['dialogue_length']['mean']
        std_len = stats['dialogue_length']['std']

        for idx, length in dialogue_lengths.items():
            z_score = abs((length - mean_len) / std_len)
            if z_score > self.outlier_threshold:
                outliers.append({
                    'index': idx,
                    'type': 'dialogue_length',
                    'value': length,
                    'z_score': z_score
                })

        return outliers
```

### 4. ë¼ë²¨ ì¼ê´€ì„± ê²€ì¦
```python
class LabelConsistencyValidator:
    def __init__(self):
        self.consistency_threshold = 0.7

    def validate_labels(self, df):
        """ë¼ë²¨(ìš”ì•½) ì¼ê´€ì„± ê²€ì¦"""

        # ìœ ì‚¬í•œ ëŒ€í™”ì— ëŒ€í•œ ìš”ì•½ ì¼ê´€ì„± ì²´í¬
        consistency_scores = []

        for idx, row in df.iterrows():
            similar_dialogues = self.find_similar_dialogues(
                row['dialogue'], df, top_k=5
            )

            if similar_dialogues:
                score = self.calculate_label_consistency(
                    row['summary'],
                    [df.loc[i, 'summary'] for i in similar_dialogues]
                )
                consistency_scores.append({
                    'index': idx,
                    'consistency': score,
                    'similar_indices': similar_dialogues
                })

        return pd.DataFrame(consistency_scores)

    def find_similar_dialogues(self, dialogue, df, top_k=5):
        """ìœ ì‚¬í•œ ëŒ€í™” ì°¾ê¸°"""
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity

        vectorizer = TfidfVectorizer(max_features=100)
        tfidf_matrix = vectorizer.fit_transform(df['dialogue'])
        query_vec = vectorizer.transform([dialogue])

        similarities = cosine_similarity(query_vec, tfidf_matrix)[0]
        top_indices = similarities.argsort()[-top_k-1:-1][::-1]

        return top_indices.tolist()

    def calculate_label_consistency(self, summary, similar_summaries):
        """ìš”ì•½ ì¼ê´€ì„± ê³„ì‚°"""
        from rouge import Rouge

        rouge = Rouge()
        scores = []

        for similar in similar_summaries:
            try:
                score = rouge.get_scores(summary, similar)[0]
                scores.append(score['rouge-l']['f'])
            except:
                continue

        return np.mean(scores) if scores else 0
```

## ğŸ” ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜

### 1. ë‹¤ì°¨ì› ì´ìƒì¹˜ íƒì§€
```python
class AnomalyDetector:
    def __init__(self):
        self.methods = {
            'isolation_forest': IsolationForest(contamination=0.05),
            'local_outlier_factor': LocalOutlierFactor(contamination=0.05),
            'one_class_svm': OneClassSVM(gamma='auto', nu=0.05)
        }

    def detect_anomalies(self, df):
        """ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€"""

        # íŠ¹ì§• ì¶”ì¶œ
        features = self.extract_features(df)

        # ê° ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
        results = {}
        for method_name, detector in self.methods.items():
            if method_name == 'local_outlier_factor':
                predictions = detector.fit_predict(features)
            else:
                predictions = detector.fit_predict(features)

            anomaly_indices = np.where(predictions == -1)[0]
            results[method_name] = anomaly_indices.tolist()

        # ì•™ìƒë¸”: 2ê°œ ì´ìƒ ë°©ë²•ì—ì„œ ì´ìƒì¹˜ë¡œ íŒì •
        ensemble_anomalies = self.ensemble_detection(results)

        return {
            'individual_results': results,
            'ensemble_anomalies': ensemble_anomalies,
            'anomaly_samples': df.iloc[ensemble_anomalies]
        }

    def extract_features(self, df):
        """ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        features = pd.DataFrame()

        features['dialogue_length'] = df['dialogue'].str.len()
        features['summary_length'] = df['summary'].str.len()
        features['compression_ratio'] = features['summary_length'] / features['dialogue_length']
        features['num_speakers'] = df['dialogue'].str.count('#Person')
        features['num_turns'] = df['dialogue'].str.count('\n')

        return features

    def ensemble_detection(self, results, min_votes=2):
        """ì•™ìƒë¸” ê¸°ë°˜ ì´ìƒì¹˜ íŒì •"""
        from collections import Counter

        all_anomalies = []
        for anomalies in results.values():
            all_anomalies.extend(anomalies)

        counter = Counter(all_anomalies)
        ensemble = [idx for idx, count in counter.items() if count >= min_votes]

        return ensemble
```

### 2. ë…¸ì´ì¦ˆ íŒ¨í„´ ìë™ íƒì§€
```python
class NoisePatternDetector:
    def __init__(self):
        self.noise_patterns = {
            'escaped_newline': r'\\n',
            'html_tags': r'<[^>]+>',
            'multiple_spaces': r'\s{2,}',
            'special_chars': r'[^\w\sê°€-í£.,!?]',
            'repeated_chars': r'(.)\1{3,}',
            'broken_encoding': r'[ï¿½\ufffd]'
        }

    def detect_noise(self, df):
        """ë…¸ì´ì¦ˆ íŒ¨í„´ íƒì§€"""
        noise_report = []

        for col in ['dialogue', 'summary']:
            for pattern_name, pattern in self.noise_patterns.items():
                matches = df[col].str.contains(pattern, regex=True)
                if matches.any():
                    affected_indices = df[matches].index.tolist()
                    noise_report.append({
                        'column': col,
                        'pattern': pattern_name,
                        'count': len(affected_indices),
                        'percentage': len(affected_indices) / len(df) * 100,
                        'sample_indices': affected_indices[:5]
                    })

        return pd.DataFrame(noise_report)

    def auto_clean(self, text):
        """ìë™ ë…¸ì´ì¦ˆ ì œê±°"""
        cleaned = text

        # íŒ¨í„´ë³„ ì •ì œ
        cleaned = re.sub(r'\\n', '\n', cleaned)
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
        cleaned = re.sub(r'\s{2,}', ' ', cleaned)
        cleaned = re.sub(r'(.)\1{3,}', r'\1\1', cleaned)

        return cleaned.strip()
```

## ğŸ“ˆ í’ˆì§ˆ ì ìˆ˜ ì‹œìŠ¤í…œ

### 1. ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
```python
class QualityScorer:
    def __init__(self):
        self.weights = {
            'structural': 0.2,
            'semantic': 0.35,
            'statistical': 0.25,
            'consistency': 0.2
        }

    def calculate_quality_score(self, validation_results):
        """ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""

        scores = {
            'structural': self.structural_score(validation_results['structural']),
            'semantic': self.semantic_score(validation_results['semantic']),
            'statistical': self.statistical_score(validation_results['statistical']),
            'consistency': self.consistency_score(validation_results['consistency'])
        }

        # ê°€ì¤‘ í‰ê· 
        total_score = sum(
            score * self.weights[category]
            for category, score in scores.items()
        )

        return {
            'total_score': total_score,
            'category_scores': scores,
            'grade': self.get_grade(total_score),
            'recommendations': self.get_recommendations(scores)
        }

    def get_grade(self, score):
        """ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰"""
        if score >= 0.9:
            return 'A+ (Excellent)'
        elif score >= 0.8:
            return 'A (Very Good)'
        elif score >= 0.7:
            return 'B (Good)'
        elif score >= 0.6:
            return 'C (Acceptable)'
        else:
            return 'D (Needs Improvement)'

    def get_recommendations(self, scores):
        """ê°œì„  ê¶Œì¥ì‚¬í•­"""
        recommendations = []

        if scores['structural'] < 0.8:
            recommendations.append("êµ¬ì¡°ì  ë¬¸ì œ í•´ê²° í•„ìš” (ëˆ„ë½ ë°ì´í„°, ì¸ì½”ë”©)")

        if scores['semantic'] < 0.7:
            recommendations.append("ëŒ€í™”-ìš”ì•½ ì •ë ¬ë„ ê°œì„  í•„ìš”")

        if scores['statistical'] < 0.7:
            recommendations.append("ì´ìƒì¹˜ ì œê±° ë° ë¶„í¬ ì •ê·œí™” í•„ìš”")

        if scores['consistency'] < 0.7:
            recommendations.append("ë¼ë²¨ ì¼ê´€ì„± ê²€í†  ë° ì¬ë¼ë²¨ë§ ê³ ë ¤")

        return recommendations
```

### 2. í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±
```python
class QualityReporter:
    def __init__(self):
        self.report_template = """
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸

        ## ğŸ“Š ì¢…í•© ì ìˆ˜: {total_score:.2f} ({grade})

        ## ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜
        - êµ¬ì¡°ì  í’ˆì§ˆ: {structural:.2%}
        - ì˜ë¯¸ì  í’ˆì§ˆ: {semantic:.2%}
        - í†µê³„ì  í’ˆì§ˆ: {statistical:.2%}
        - ë¼ë²¨ ì¼ê´€ì„±: {consistency:.2%}

        ## ì£¼ìš” ë°œê²¬ì‚¬í•­
        {findings}

        ## ì´ìƒì¹˜ ë° ë¬¸ì œ ë°ì´í„°
        - ì´ìƒì¹˜ ê°œìˆ˜: {num_outliers}
        - ë…¸ì´ì¦ˆ íŒ¨í„´: {noise_patterns}
        - ê¶Œì¥ ì œê±°: {recommended_removal}

        ## ê°œì„  ê¶Œì¥ì‚¬í•­
        {recommendations}

        ## ìƒì„¸ í†µê³„
        {detailed_stats}
        """

    def generate_report(self, validation_results, output_path):
        """ìƒì„¸ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""

        report = self.report_template.format(
            total_score=validation_results['total_score'],
            grade=validation_results['grade'],
            structural=validation_results['scores']['structural'],
            semantic=validation_results['scores']['semantic'],
            statistical=validation_results['scores']['statistical'],
            consistency=validation_results['scores']['consistency'],
            findings=self.format_findings(validation_results['findings']),
            num_outliers=len(validation_results['outliers']),
            noise_patterns=validation_results['noise_summary'],
            recommended_removal=validation_results['remove_indices'],
            recommendations=self.format_recommendations(
                validation_results['recommendations']
            ),
            detailed_stats=self.format_statistics(validation_results['stats'])
        )

        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)

        # ì‹œê°í™” ìƒì„±
        self.create_visualizations(validation_results)

        return report
```

## ğŸ”„ ë°ì´í„° ì¦ê°• í’ˆì§ˆ ê´€ë¦¬

### 1. ì¦ê°• ë°ì´í„° ê²€ì¦
```python
class AugmentationValidator:
    def __init__(self):
        self.min_similarity = 0.7
        self.max_similarity = 0.95

    def validate_augmented(self, original_df, augmented_df):
        """ì¦ê°• ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""

        validation_results = []

        for idx, aug_row in augmented_df.iterrows():
            original_idx = aug_row['original_idx']
            original_row = original_df.loc[original_idx]

            # ìœ ì‚¬ë„ ì²´í¬
            similarity = self.calculate_similarity(
                original_row['summary'],
                aug_row['summary']
            )

            # ì˜ë¯¸ ë³´ì¡´ë„ ì²´í¬
            preservation = self.check_semantic_preservation(
                original_row['dialogue'],
                aug_row['dialogue']
            )

            # ë‹¤ì–‘ì„± ì²´í¬
            diversity = self.check_diversity(
                original_row['summary'],
                aug_row['summary']
            )

            validation_results.append({
                'augmented_idx': idx,
                'original_idx': original_idx,
                'similarity': similarity,
                'preservation': preservation,
                'diversity': diversity,
                'quality': self.judge_quality(similarity, preservation, diversity)
            })

        return pd.DataFrame(validation_results)

    def judge_quality(self, similarity, preservation, diversity):
        """ì¦ê°• í’ˆì§ˆ íŒì •"""
        if similarity < self.min_similarity:
            return "ê³¼ë„í•œ ë³€í˜•"
        elif similarity > self.max_similarity:
            return "ë¶ˆì¶©ë¶„í•œ ë³€í˜•"
        elif preservation < 0.8:
            return "ì˜ë¯¸ ì†ì‹¤"
        elif diversity < 0.3:
            return "ë‹¤ì–‘ì„± ë¶€ì¡±"
        else:
            return "ì ì ˆ"
```

## ğŸš€ ì‹¤í–‰ ê³„íš

### Phase 1: ê¸°ì´ˆ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] êµ¬ì¡°ì  ê²€ì¦ ëª¨ë“ˆ êµ¬í˜„
- [ ] ê¸°ë³¸ í†µê³„ ë¶„ì„ ë„êµ¬ êµ¬ì¶•
- [ ] ë…¸ì´ì¦ˆ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•

### Phase 2: ê³ ê¸‰ ê²€ì¦ ê¸°ëŠ¥
- [ ] ì˜ë¯¸ì  ê²€ì¦ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- [ ] ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ë¼ë²¨ ì¼ê´€ì„± ê²€ì‚¬ê¸° ê°œë°œ

### Phase 3: ìë™í™” ë° ë¦¬í¬íŒ…
- [ ] ìë™ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
- [ ] ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ
- [ ] ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸

## ğŸ¯ ì˜ˆìƒ íš¨ê³¼

| ê²€ì¦ ë‹¨ê³„ | ë¬¸ì œ ë°œê²¬ìœ¨ | ì„±ëŠ¥ ê°œì„  |
|----------|-----------|----------|
| êµ¬ì¡°ì  ê²€ì¦ | 5-10% | +2-3 ROUGE |
| ì˜ë¯¸ì  ê²€ì¦ | 10-15% | +3-5 ROUGE |
| í†µê³„ì  ê²€ì¦ | 8-12% | +2-4 ROUGE |
| ë¼ë²¨ ì¼ê´€ì„± | 15-20% | +4-6 ROUGE |
| **ì¢…í•©** | **30-40%** | **+10-15 ROUGE** |