# ğŸ”§ ê¸°ìˆ  ìš”êµ¬ì‚¬í•­

## ğŸ’» ê°œë°œ í™˜ê²½

### Python í™˜ê²½
- **Python ë²„ì „**: 3.11.9
- **ê°€ìƒí™˜ê²½**: pyenv + virtualenv
- **í™˜ê²½ ì´ë¦„**: nlp_py3_11_9

### GPU í™˜ê²½
- **GPU ì„œë²„**: AI Stages ì œê³µ ì„œë²„
- **ìš´ì˜ ê¸°ê°„**: 2025.09.26 ~ 2025.11.13
- **CUDA**: 11.8 ì´ìƒ
- **GPU ë©”ëª¨ë¦¬**: ìµœì†Œ 16GB ê¶Œì¥

## ğŸ“¦ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬

### í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
```python
# ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
torch>=2.0.0
transformers>=4.30.0
pytorch-lightning>=2.0.0
accelerate>=0.20.0
peft>=0.4.0  # LoRA/QLoRAìš©

# í•œêµ­ì–´ NLP
konlpy>=0.6.0
soynlp>=0.0.493
kss>=4.0.0

# í‰ê°€ ì§€í‘œ
rouge>=1.0.1
nltk>=3.8
sacrebleu>=2.3.0

# ë°ì´í„° ì²˜ë¦¬
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0

# ì‹œê°í™”
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.14.0
wordcloud>=1.9.0

# ì‹¤í—˜ ê´€ë¦¬
wandb>=0.15.0
mlflow>=2.3.0
optuna>=3.1.0

# API
openai>=1.0.0  # Solar APIìš©
requests>=2.31.0

# ìœ í‹¸ë¦¬í‹°
tqdm>=4.65.0
pyyaml>=6.0
python-dotenv>=1.0.0
jupyterlab>=4.0.0
argparse  # ì‹¤í–‰ ì˜µì…˜ ì‹œìŠ¤í…œìš©
```

### ëª¨ë¸ë³„ ì¶”ê°€ ìš”êµ¬ì‚¬í•­

#### SOLAR-10.7B (ìµœìš°ì„  ì¶”ì²œ)
```python
# Hugging Face ëª¨ë¸
from transformers import AutoModelForCausalLM, AutoTokenizer
model = AutoModelForCausalLM.from_pretrained("upstage/SOLAR-10.7B-Instruct-v1.0")
```

#### Polyglot-Ko-12.8B
```python
# Hugging Face ëª¨ë¸
model = AutoModelForCausalLM.from_pretrained("EleutherAI/polyglot-ko-12.8b")
```

#### KULLM-v2
```python
model = AutoModelForCausalLM.from_pretrained("nlpai-lab/kullm-v2")
```

#### Solar API
```python
pip install openai
# API Key: up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT
```

## ğŸ—‚ï¸ ë°ì´í„° ìš”êµ¬ì‚¬í•­

### ì €ì¥ ê³µê°„
- **ì›ë³¸ ë°ì´í„°**: ~50MB
- **ì „ì²˜ë¦¬ ë°ì´í„°**: ~100MB
- **ì¦ê°• ë°ì´í„°**: ~500MB
- **ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸**: ~5GB per model
- **ì´ ê¶Œì¥ ê³µê°„**: 50GB ì´ìƒ

### ë°ì´í„° í˜•ì‹
- **ì…ë ¥**: CSV (fname, dialogue, summary, topic)
- **ì¶œë ¥**: CSV (fname, summary)
- **ì¸ì½”ë”©**: UTF-8
- **êµ¬ë¶„ì**: ì‰¼í‘œ(,)

## âš™ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘
- **CPU**: 8 cores
- **RAM**: 32GB
- **GPU**: RTX 3090 (24GB)
- **Storage**: 100GB SSD

### ê¶Œì¥ ì‚¬ì–‘
- **CPU**: 16+ cores
- **RAM**: 64GB+
- **GPU**: A100 (40GB+) ë˜ëŠ” RTX 4090 (24GB)
- **Storage**: 500GB+ NVMe SSD

### ëª¨ë¸ë³„ GPU ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­
| ëª¨ë¸ | ê¸°ë³¸ | LoRA | QLoRA (4bit) |
|------|------|------|--------------|
| SOLAR-10.7B | 24GB | 16GB | 8GB |
| Polyglot-Ko-12.8B | 26GB | 18GB | 10GB |
| KULLM-v2 (7B) | 16GB | 12GB | 6GB |
| 5-ëª¨ë¸ ì•™ìƒë¸” | 48GB+ | 32GB | 20GB |

## ğŸ” ë³´ì•ˆ ìš”êµ¬ì‚¬í•­

### API í‚¤ ê´€ë¦¬
```python
# .env íŒŒì¼ ì‚¬ìš©
UPSTAGE_API_KEY=up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT
WANDB_API_KEY=your_wandb_key
```

### Git ì„¤ì •
```bash
# .gitignore
*.csv
*.pkl
*.pth
*.bin
.env
__pycache__/
wandb/
mlruns/
```

## ğŸ“ ì½”ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

### Python ìŠ¤íƒ€ì¼
- **PEP 8** ì¤€ìˆ˜
- **Type Hints** ì‚¬ìš©
- **Docstring** ì‘ì„± (Google Style)

### ì˜ˆì‹œ
```python
from typing import List, Dict, Tuple

def preprocess_dialogue(
    dialogue: str,
    max_length: int = 512
) -> Tuple[str, Dict[str, int]]:
    """
    ëŒ€í™”ë¬¸ì„ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        dialogue: ì›ë³¸ ëŒ€í™”ë¬¸
        max_length: ìµœëŒ€ í† í° ê¸¸ì´

    Returns:
        ì „ì²˜ë¦¬ëœ ëŒ€í™”ë¬¸ê³¼ í†µê³„ ì •ë³´
    """
    # êµ¬í˜„ ë‚´ìš©
    pass
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/test_preprocessing.py
import pytest

def test_remove_noise():
    input_text = "ì•ˆë…•\\ní•˜ì„¸ìš”"
    expected = "ì•ˆë…•\ní•˜ì„¸ìš”"
    assert remove_noise(input_text) == expected
```

### í†µí•© í…ŒìŠ¤íŠ¸
- ë°ì´í„° ë¡œë”© â†’ ì „ì²˜ë¦¬ â†’ ëª¨ë¸ â†’ í‰ê°€
- End-to-End íŒŒì´í”„ë¼ì¸ ê²€ì¦

## ğŸ“Š ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

### í•™ìŠµ ì†ë„
- **Batch ì²˜ë¦¬**: < 1ì´ˆ/batch
- **Epoch ì‹œê°„**: < 30ë¶„
- **ì „ì²´ í•™ìŠµ**: < 10ì‹œê°„

### ì¶”ë¡  ì†ë„
- **ë‹¨ì¼ ìƒ˜í”Œ**: < 100ms
- **ë°°ì¹˜ (32)**: < 2ì´ˆ
- **ì „ì²´ í…ŒìŠ¤íŠ¸ì…‹ (250)**: < 5ë¶„

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **í•™ìŠµ ì‹œ**: < 20GB GPU Memory
- **ì¶”ë¡  ì‹œ**: < 8GB GPU Memory

## ğŸ”„ ë°°í¬ ìš”êµ¬ì‚¬í•­

### Docker í™˜ê²½
```dockerfile
FROM pytorch/pytorch:2.0.0-cuda11.8-cudnn8-runtime

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "main.py"]
```

### ì œì¶œ í˜•ì‹
```bash
# ìµœì¢… ì œì¶œ íŒŒì¼ êµ¬ì¡°
submission/
â”œâ”€â”€ output.csv        # ì˜ˆì¸¡ ê²°ê³¼
â”œâ”€â”€ code/            # ì‹¤í–‰ ì½”ë“œ
â”œâ”€â”€ model/           # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â””â”€â”€ README.md        # ì‹¤í–‰ ë°©ë²•
```