# ğŸ“‚ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    subgraph "ë°ì´í„° ê³„ì¸µ"
        A[data/raw] --> B[CSV íŒŒì¼ë“¤<br/>train/dev/test]
        C[data/processed] --> D[ì „ì²˜ë¦¬ ë°ì´í„°]
        E[data/augmented] --> F[ì¦ê°• ë°ì´í„°]
    end

    subgraph "ëª¨ë¸ ê³„ì¸µ"
        G[src/models] --> H[LLM íŒŒì¸íŠœë‹<br/>LoRA/QLoRA]
        G --> I[Solar API<br/>í† í° ìµœì í™”]
        G --> J[êµì°¨ ê²€ì¦<br/>ë“€ì–¼ ìƒì„±]
    end

    subgraph "ìœ í‹¸ë¦¬í‹° ê³„ì¸µ"
        K[src/logging] --> L[í†µí•© ë¡œê±°<br/>WandB/íŒŒì¼]
        M[src/utils] --> N[GPU ìµœì í™”<br/>ìë™ ë°°ì¹˜]
        M --> O[ì‹œê°í™”<br/>7ì¢… ì°¨íŠ¸]
        M --> P[ì„¤ì • ê´€ë¦¬<br/>ì‹œë“œ/ë‚ ì§œ]
    end

    subgraph "ì‹¤í—˜ ê´€ë¦¬"
        Q[notebooks] --> R[EDA ë¶„ì„]
        Q --> S[ëª¨ë¸ ì‹¤í—˜]
        Q --> T[í‰ê°€/ì œì¶œ]
        U[outputs] --> V[ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸]
        U --> W[ì‹¤í—˜ ë¡œê·¸]
        U --> X[ì„±ëŠ¥ ì‹œê°í™”]
    end

    B --> D
    D --> F
    F --> H
    F --> I
    H --> J
    I --> J
    J --> V
    L --> W
    O --> X
    N --> H
```

## ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„¸ êµ¬ì¡°

```
natural-language-processing-competition/
â”‚
â”œâ”€â”€ ğŸ“ configs/                    # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config.yaml               # ê¸°ë³¸ ì„¤ì •
â”‚   â”œâ”€â”€ train_config.yaml         # í•™ìŠµ ì„¤ì •
â”‚   â””â”€â”€ inference_config.yaml     # ì¶”ë¡  ì„¤ì •
â”‚
â”œâ”€â”€ ğŸ“ data/                       # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ raw/                      # ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ train.csv             # í•™ìŠµ ë°ì´í„° (12,457ê°œ)
â”‚   â”‚   â”œâ”€â”€ dev.csv               # ê²€ì¦ ë°ì´í„° (499ê°œ)
â”‚   â”‚   â”œâ”€â”€ test.csv              # í…ŒìŠ¤íŠ¸ ë°ì´í„° (250ê°œ)
â”‚   â”‚   â””â”€â”€ sample_submission.csv # ì œì¶œ ìƒ˜í”Œ
â”‚   â”œâ”€â”€ processed/                 # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ train_cleaned.csv     # ë…¸ì´ì¦ˆ ì œê±°
â”‚   â”‚   â”œâ”€â”€ train_tokenized.pkl   # í† í°í™” ë°ì´í„°
â”‚   â”‚   â””â”€â”€ vocab.json            # ì–´íœ˜ ì‚¬ì „
â”‚   â””â”€â”€ augmented/                 # ì¦ê°• ë°ì´í„°
â”‚       â”œâ”€â”€ backtranslated/       # ì—­ë²ˆì—­ ë°ì´í„°
â”‚       â””â”€â”€ paraphrased/          # íŒ¨ëŸ¬í”„ë ˆì´ì§•
â”‚
â”œâ”€â”€ ğŸ“ docs/                       # ë¬¸ì„œ
â”‚   â”œâ”€â”€ ëŒ€íšŒ ì†Œê°œ ë° ê·œì¹™/        # ëŒ€íšŒ PDF ë¬¸ì„œ
â”‚   â””â”€â”€ PRD/                      # í”„ë¡œì íŠ¸ ê³„íš ë¬¸ì„œ
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ 01_í”„ë¡œì íŠ¸_ê°œìš”.md
â”‚       â”œâ”€â”€ 02_í”„ë¡œì íŠ¸_êµ¬ì¡°.md   # (í˜„ì¬ ë¬¸ì„œ)
â”‚       â”œâ”€â”€ 03_ë¸Œëœì¹˜_ì „ëµ.md
â”‚       â”œâ”€â”€ 04_ì„±ëŠ¥_ê°œì„ _ì „ëµ.md
â”‚       â”œâ”€â”€ 05_ì‹¤í—˜_ì¶”ì _ê´€ë¦¬.md
â”‚       â”œâ”€â”€ 06_ê¸°ìˆ _ìš”êµ¬ì‚¬í•­.md
â”‚       â”œâ”€â”€ 07_ë¦¬ìŠ¤í¬_ê´€ë¦¬.md
â”‚       â”œâ”€â”€ 08_LLM_íŒŒì¸íŠœë‹_ì „ëµ.md
â”‚       â”œâ”€â”€ 09_Solar_API_ìµœì í™”.md
â”‚       â”œâ”€â”€ 10_êµì°¨_ê²€ì¦_ì‹œìŠ¤í…œ.md
â”‚       â””â”€â”€ 11_ë¡œê¹…_ë°_ëª¨ë‹ˆí„°ë§_ì‹œìŠ¤í…œ.md
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                  # ì‹¤í—˜ ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ base/                     # ë² ì´ìŠ¤ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ baseline.ipynb        # BART ë² ì´ìŠ¤ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ solar_api.ipynb       # Solar API í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ models/               # ëª¨ë¸ ì €ì¥
â”‚   â”‚   â””â”€â”€ submissions/          # ì œì¶œ íŒŒì¼
â”‚   â””â”€â”€ experiments/              # ì‹¤í—˜ ë…¸íŠ¸ë¶
â”‚       â”œâ”€â”€ 01_eda/               # íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
â”‚       â”œâ”€â”€ 02_preprocessing/     # ì „ì²˜ë¦¬ ì‹¤í—˜
â”‚       â”œâ”€â”€ 03_llm_finetuning/    # LLM íŒŒì¸íŠœë‹
â”‚       â”œâ”€â”€ 04_solar_optimization/ # API ìµœì í™”
â”‚       â”œâ”€â”€ 05_cross_validation/  # êµì°¨ ê²€ì¦
â”‚       â””â”€â”€ 06_ensemble/          # ì•™ìƒë¸”
â”‚
â”œâ”€â”€ ğŸ“ src/                        # ì†ŒìŠ¤ ì½”ë“œ (ëª¨ë“ˆí™”)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ data/                  # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py             # ë°ì´í„° ë¡œë”
â”‚   â”‚   â”œâ”€â”€ preprocessor.py      # ì „ì²˜ë¦¬ê¸°
â”‚   â”‚   â”œâ”€â”€ augmentation.py      # ë°ì´í„° ì¦ê°•
â”‚   â”‚   â””â”€â”€ tokenizer.py         # í† í¬ë‚˜ì´ì €
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                # ëª¨ë¸ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_finetuning.py    # LLM íŒŒì¸íŠœë‹ (LoRA)
â”‚   â”‚   â”œâ”€â”€ solar_api.py         # Solar API ë˜í¼
â”‚   â”‚   â”œâ”€â”€ cross_validator.py   # êµì°¨ ê²€ì¦ ì‹œìŠ¤í…œ
â”‚   â”‚   â””â”€â”€ ensemble.py          # ì•™ìƒë¸” ëª¨ë¸
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ training/              # í•™ìŠµ ê´€ë ¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py           # í•™ìŠµ ë£¨í”„
â”‚   â”‚   â”œâ”€â”€ optimizer.py         # ìµœì í™”ê¸°
â”‚   â”‚   â””â”€â”€ scheduler.py         # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ evaluation/            # í‰ê°€ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py           # ROUGE, BLEU ë“±
â”‚   â”‚   â””â”€â”€ evaluator.py         # í‰ê°€ê¸°
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ logging/               # ë¡œê¹… ì‹œìŠ¤í…œ âœ¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py            # í†µí•© ë¡œê±°
â”‚   â”‚   â”œâ”€â”€ wandb_logger.py     # WandB ì—°ë™
â”‚   â”‚   â””â”€â”€ notebook_logger.py  # ë…¸íŠ¸ë¶ ì „ìš©
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                 # ìœ í‹¸ë¦¬í‹° âœ¨
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ğŸ“ config/           # ì„¤ì • ê´€ë¦¬
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ seed.py          # ì‹œë“œ ê³ ì •
â”‚       â”‚   â””â”€â”€ update_config_dates.py
â”‚       â”œâ”€â”€ ğŸ“ core/             # í•µì‹¬ ìœ í‹¸
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ common.py
â”‚       â”œâ”€â”€ ğŸ“ gpu_optimization/  # GPU ìµœì í™” âœ¨
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ team_gpu_check.py       # GPU ì²´í¬
â”‚       â”‚   â”œâ”€â”€ auto_batch_size.py      # ìë™ ë°°ì¹˜
â”‚       â”‚   â””â”€â”€ auto_batch_size_fixed.py
â”‚       â””â”€â”€ ğŸ“ visualizations/    # ì‹œê°í™” âœ¨
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ base_visualizer.py      # ê¸°ë³¸ í´ë˜ìŠ¤
â”‚           â”œâ”€â”€ training_viz.py         # í•™ìŠµ ì‹œê°í™”
â”‚           â”œâ”€â”€ inference_viz.py        # ì¶”ë¡  ì‹œê°í™”
â”‚           â”œâ”€â”€ optimization_viz.py     # ìµœì í™” ì‹œê°í™”
â”‚           â””â”€â”€ output_manager.py       # ì¶œë ¥ ê´€ë¦¬
â”‚
â”œâ”€â”€ ğŸ“ experiments/                # ì‹¤í—˜ ê´€ë¦¬
â”‚   â”œâ”€â”€ exp001_baseline/          # ë² ì´ìŠ¤ë¼ì¸
â”‚   â”œâ”€â”€ exp002_llm_lora/         # LoRA íŒŒì¸íŠœë‹
â”‚   â”œâ”€â”€ exp003_solar_optimized/  # Solar ìµœì í™”
â”‚   â”œâ”€â”€ exp004_cross_validation/ # êµì°¨ ê²€ì¦
â”‚   â””â”€â”€ exp005_final_ensemble/   # ìµœì¢… ì•™ìƒë¸”
â”‚
â”œâ”€â”€ ğŸ“ outputs/                    # ì¶œë ¥ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ models/                   # í•™ìŠµëœ ëª¨ë¸
â”‚   â”œâ”€â”€ logs/                     # ì‹¤í—˜ ë¡œê·¸
â”‚   â”œâ”€â”€ visualizations/           # ìƒì„±ëœ ì°¨íŠ¸
â”‚   â””â”€â”€ submissions/              # ì œì¶œ íŒŒì¼
â”‚
â””â”€â”€ ğŸ“ logs/                       # ë¡œê·¸ íŒŒì¼
    â”œâ”€â”€ training/                  # í•™ìŠµ ë¡œê·¸
    â”œâ”€â”€ inference/                 # ì¶”ë¡  ë¡œê·¸
    â””â”€â”€ errors/                    # ì—ëŸ¬ ë¡œê·¸
```

## ğŸ”„ ë°ì´í„° íë¦„ë„

```mermaid
graph LR
    subgraph "ì…ë ¥"
        A[ì›ë³¸ CSV]
    end

    subgraph "ì „ì²˜ë¦¬"
        B[ë…¸ì´ì¦ˆ ì œê±°]
        C[í† í°í™”]
        D[ë°ì´í„° ì¦ê°•]
    end

    subgraph "ëª¨ë¸ë§"
        E[LLM íŒŒì¸íŠœë‹]
        F[Solar API]
        G[êµì°¨ ê²€ì¦]
    end

    subgraph "ì¶œë ¥"
        H[ìš”ì•½ í…ìŠ¤íŠ¸]
        I[ì„±ëŠ¥ ë©”íŠ¸ë¦­]
        J[ì‹œê°í™”]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    D --> F
    E --> G
    F --> G
    G --> H
    G --> I
    I --> J
```

## ğŸ“‹ íŒŒì¼ ëª…ëª… ê·œì¹™

### ğŸ Python íŒŒì¼
- **ëª¨ë“ˆ**: `snake_case.py` (ì˜ˆ: `data_loader.py`)
- **í´ë˜ìŠ¤**: `PascalCase` (ì˜ˆ: `class DataLoader`)
- **í•¨ìˆ˜**: `snake_case` (ì˜ˆ: `def load_data()`)

### ğŸ““ ë…¸íŠ¸ë¶ íŒŒì¼
- **ì‹¤í—˜**: `exp{ë²ˆí˜¸}_{ì„¤ëª…}.ipynb`
- ì˜ˆ: `exp001_baseline_bart.ipynb`

### ğŸ’¾ ë°ì´í„° íŒŒì¼
- **ì „ì²˜ë¦¬**: `{ì›ë³¸ëª…}_processed.{í™•ì¥ì}`
- **ì¦ê°•**: `{ì›ë³¸ëª…}_augmented_{ë°©ë²•}.{í™•ì¥ì}`
- ì˜ˆ: `train_processed.csv`, `train_augmented_backtrans.csv`

### ğŸ“Š ì¶œë ¥ íŒŒì¼
- **ëª¨ë¸**: `model_{ì•Œê³ ë¦¬ì¦˜}_{ë‚ ì§œ}_{ë²„ì „}.pt`
- **ë¡œê·¸**: `{ì‘ì—…}_{ë‚ ì§œ}_{ì‹œê°„}.log`
- **ì œì¶œ**: `submission_{ë‚ ì§œ}_{ë²„ì „}.csv`

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### 1. í™˜ê²½ ì„¤ì •
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™
cd natural-language-processing-competition/

# GPU ì²´í¬
python src/utils/gpu_optimization/team_gpu_check.py

# ìµœì  ë°°ì¹˜ í¬ê¸° ì°¾ê¸°
python src/utils/gpu_optimization/auto_batch_size.py
```

### 2. ë°ì´í„° ì „ì²˜ë¦¬
```python
from src.data import DataLoader, Preprocessor

# ë°ì´í„° ë¡œë“œ
loader = DataLoader('data/raw/train.csv')
data = loader.load()

# ì „ì²˜ë¦¬
preprocessor = Preprocessor()
clean_data = preprocessor.clean(data)
```

### 3. ì‹¤í—˜ ì‹¤í–‰
```python
from src.logging import Logger
from src.models import LLMFineTuner

# ë¡œê±° ì´ˆê¸°í™”
logger = Logger('logs/experiment.log')
logger.start_redirect()

# ëª¨ë¸ í•™ìŠµ
model = LLMFineTuner(config)
model.train(clean_data)
```

### 4. ì‹œê°í™” ìƒì„±
```python
from src.utils.visualizations import create_training_visualizations

# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
create_training_visualizations(
    fold_results=results,
    model_name='LLM-LoRA',
    output_dir='outputs/visualizations'
)
```

## ğŸ“ ì£¼ì˜ì‚¬í•­

### âš ï¸ ì¤‘ìš” ë””ë ‰í† ë¦¬
- **data/raw/**: ì›ë³¸ ë°ì´í„° ìˆ˜ì • ê¸ˆì§€
- **docs/PRD/**: íŒ€ í•©ì˜ í›„ ìˆ˜ì •
- **experiments/**: ì‹¤í—˜ë³„ ë…ë¦½ ê´€ë¦¬

### ğŸ”’ Git ë¬´ì‹œ íŒŒì¼
- `*.log` - ë¡œê·¸ íŒŒì¼
- `*.pkl` - í”¼í´ íŒŒì¼
- `__pycache__/` - íŒŒì´ì¬ ìºì‹œ
- `.ipynb_checkpoints/` - ë…¸íŠ¸ë¶ ì²´í¬í¬ì¸íŠ¸
- `wandb/` - WandB ë¡œì»¬ íŒŒì¼

### ğŸ’¾ ëŒ€ìš©ëŸ‰ íŒŒì¼
- ëª¨ë¸ íŒŒì¼ì€ Git LFS ì‚¬ìš©
- 100MB ì´ìƒ íŒŒì¼ì€ Google Drive í™œìš©
- ì²´í¬í¬ì¸íŠ¸ëŠ” ì£¼ê¸°ì ìœ¼ë¡œ ì •ë¦¬