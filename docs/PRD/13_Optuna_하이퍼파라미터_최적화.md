# π”¬ Optuna ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” μ „λµ

## π― κ°μ”
λ² μ΄μ§€μ• μµμ ν™” κΈ°λ° Optunaλ¥Ό ν™μ©ν•μ—¬ NLP λ€ν™” μ”μ•½ λ¨λΈμ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μλ™μΌλ΅ μµμ ν™”

## π—οΈ Optuna μµμ ν™” μ‹μ¤ν… μ•„ν‚¤ν…μ²

```mermaid
graph TD
    subgraph "μ΄κΈ° μ„¤μ •"
        A[ν•μ΄νΌνλΌλ―Έν„°<br/>νƒμƒ‰ κ³µκ°„ μ •μ] --> B[λ©μ  ν•¨μ<br/>μ •μ]
        B --> C[Study μƒμ„±]
    end

    subgraph "λ² μ΄μ§€μ• μµμ ν™”"
        C --> D[Trial μƒμ„±]
        D --> E[νλΌλ―Έν„° μƒν”λ§]
        E --> F[λ¨λΈ ν•™μµ]
        F --> G[κ²€μ¦ μ„±λ¥ ν‰κ°€]
        G --> H{λ©ν‘ λ‹¬μ„±?}
    end

    subgraph "μƒν”λ§ μ „λµ"
        E --> I[TPE Sampler<br/>κ¶μ¥]
        E --> J[GP Sampler]
        E --> K[Random Sampler]
    end

    subgraph "κ°€μ§€μΉκΈ°"
        G --> L[Median Pruner]
        L --> M{μ„±λ¥ λ¶€μ΅±?}
        M -->|Yes| N[Trial μ¤‘λ‹¨]
        M -->|No| O[κ³„μ† ν•™μµ]
    end

    H -->|No| D
    H -->|Yes| P[μµμ  νλΌλ―Έν„°]

    subgraph "κ²°κ³Ό λ¶„μ„"
        P --> Q[νλΌλ―Έν„° μ¤‘μ”λ„]
        P --> R[μµμ ν™” νμ¤ν† λ¦¬]
        P --> S[νλ ν†  ν”„λ΅ νΈ]
    end

    style I fill:#f96,stroke:#333,stroke-width:4px
    style L fill:#9ff,stroke:#333,stroke-width:4px
    style P fill:#ff9,stroke:#333,stroke-width:4px
```

## π“ NLP νΉν™” ν•μ΄νΌνλΌλ―Έν„° νƒμƒ‰ κ³µκ°„

### 1. λ¨λΈ μ•„ν‚¤ν…μ² νλΌλ―Έν„°
```python
def create_model_search_space(trial):
    """NLP λ¨λΈμ© νƒμƒ‰ κ³µκ°„"""
    return {
        # λ¨λΈ μ„ νƒ
        'model_name': trial.suggest_categorical(
            'model_name',
            ['solar-10.7b', 'polyglot-ko-12.8b', 'kullm-v2', 'koalpaca']
        ),

        # LoRA νλΌλ―Έν„°
        'lora_r': trial.suggest_int('lora_r', 4, 64, step=4),
        'lora_alpha': trial.suggest_int('lora_alpha', 8, 128, step=8),
        'lora_dropout': trial.suggest_float('lora_dropout', 0.0, 0.3, step=0.05),

        # μ–‘μν™”
        'use_8bit': trial.suggest_categorical('use_8bit', [True, False]),
        'use_4bit': trial.suggest_categorical('use_4bit', [True, False]),
    }
```

### 2. ν•™μµ νλΌλ―Έν„°
```python
def create_training_search_space(trial):
    """ν•™μµμ© νƒμƒ‰ κ³µκ°„"""
    return {
        # ν•™μµλ¥  (λ΅κ·Έ μ¤μΌ€μΌ)
        'learning_rate': trial.suggest_float(
            'learning_rate', 1e-6, 1e-3, log=True
        ),

        # λ°°μΉ ν¬κΈ° (GPU λ©”λ¨λ¦¬ κ³ λ ¤)
        'batch_size': trial.suggest_categorical(
            'batch_size', [4, 8, 16, 32]
        ),

        # μ—ν­ μ
        'num_epochs': trial.suggest_int('num_epochs', 1, 10),

        # Gradient Accumulation
        'gradient_accumulation_steps': trial.suggest_categorical(
            'gradient_accumulation_steps', [1, 2, 4, 8]
        ),

        # μ¤μΌ€μ¤„λ¬
        'scheduler_type': trial.suggest_categorical(
            'scheduler_type',
            ['linear', 'cosine', 'cosine_with_restarts', 'polynomial']
        ),

        # Warmup
        'warmup_ratio': trial.suggest_float('warmup_ratio', 0.0, 0.2, step=0.05),

        # Weight Decay
        'weight_decay': trial.suggest_float('weight_decay', 0.0, 0.3, step=0.01),

        # Label Smoothing
        'label_smoothing': trial.suggest_float(
            'label_smoothing', 0.0, 0.2, step=0.05
        ),
    }
```

### 3. μƒμ„± νλΌλ―Έν„° (NLP νΉν™”)
```python
def create_generation_search_space(trial):
    """ν…μ¤νΈ μƒμ„±μ© νƒμƒ‰ κ³µκ°„"""
    return {
        # λ””μ½”λ”© μ „λµ
        'do_sample': trial.suggest_categorical('do_sample', [True, False]),

        # Temperature (μ°½μμ„±)
        'temperature': trial.suggest_float('temperature', 0.1, 1.0, step=0.1),

        # Top-p (nucleus sampling)
        'top_p': trial.suggest_float('top_p', 0.7, 0.95, step=0.05),

        # Top-k
        'top_k': trial.suggest_int('top_k', 10, 100, step=10),

        # Repetition Penalty
        'repetition_penalty': trial.suggest_float(
            'repetition_penalty', 1.0, 1.5, step=0.1
        ),

        # Length Penalty
        'length_penalty': trial.suggest_float(
            'length_penalty', 0.5, 2.0, step=0.1
        ),

        # Beam Search
        'num_beams': trial.suggest_int('num_beams', 1, 8),

        # μµλ€/μµμ† κΈΈμ΄
        'max_new_tokens': trial.suggest_int('max_new_tokens', 50, 200, step=10),
        'min_new_tokens': trial.suggest_int('min_new_tokens', 20, 80, step=10),
    }
```

### 4. λ°μ΄ν„° μ „μ²λ¦¬ νλΌλ―Έν„°
```python
def create_preprocessing_search_space(trial):
    """μ „μ²λ¦¬μ© νƒμƒ‰ κ³µκ°„"""
    return {
        # ν† ν° κΈΈμ΄
        'max_input_length': trial.suggest_categorical(
            'max_input_length', [512, 768, 1024, 1536]
        ),

        # λ°μ΄ν„° μ¦κ°•
        'use_augmentation': trial.suggest_categorical(
            'use_augmentation', [True, False]
        ),

        # μ¦κ°• μ „λµ
        'augmentation_strategy': trial.suggest_categorical(
            'augmentation_strategy',
            ['none', 'paraphrase', 'backtranslation', 'both']
        ),

        # λ…Έμ΄μ¦ μ κ±° μμ¤€
        'noise_removal_level': trial.suggest_categorical(
            'noise_removal_level',
            ['minimal', 'moderate', 'aggressive']
        ),

        # Person ν† ν° μ²λ¦¬
        'person_token_strategy': trial.suggest_categorical(
            'person_token_strategy',
            ['keep_original', 'simplify', 'abstract']
        ),
    }
```

## π― λ©μ  ν•¨μ κµ¬ν„

### 1. λ‹¨μΌ λ©μ  μµμ ν™” (ROUGE μµλ€ν™”)
```python
def objective_single(trial):
    """λ‹¨μΌ λ©μ  ν•¨μ: ROUGE-F1 μµλ€ν™”"""

    # ν•μ΄νΌνλΌλ―Έν„° μƒν”λ§
    model_params = create_model_search_space(trial)
    train_params = create_training_search_space(trial)
    gen_params = create_generation_search_space(trial)

    # λ¨λΈ μƒμ„± λ° ν•™μµ
    model = create_model(model_params)
    trainer = create_trainer(model, train_params)

    # μ΅°κΈ° μΆ…λ£ μ½λ°± (Pruning)
    pruning_callback = OptunaPruningCallback(trial, 'eval_rouge')
    trainer.add_callback(pruning_callback)

    # ν•™μµ μ‹¤ν–‰
    trainer.train()

    # κ²€μ¦ μ„ΈνΈ ν‰κ°€
    eval_results = trainer.evaluate(gen_params)

    # ROUGE-F1 λ°ν™ (μµλ€ν™”)
    return eval_results['rouge_f1']
```

### 2. λ‹¤μ¤‘ λ©μ  μµμ ν™” (μ„±λ¥ vs ν¨μ¨μ„±)
```python
def objective_multi(trial):
    """λ‹¤μ¤‘ λ©μ  ν•¨μ: ROUGEμ™€ μ†λ„ κ· ν•"""

    params = sample_all_parameters(trial)

    # λ¨λΈ ν•™μµ λ° ν‰κ°€
    model = train_model(params)
    rouge_score = evaluate_rouge(model)
    inference_time = measure_inference_time(model)
    model_size = get_model_size(model)

    # λ‹¤μ¤‘ λ©μ  λ°ν™
    return rouge_score, -inference_time, -model_size
```

### 3. μ μ•½ μ΅°κ±΄μ΄ μλ” μµμ ν™”
```python
def objective_with_constraints(trial):
    """μ μ•½ μ΅°κ±΄ ν¬ν•¨ μµμ ν™”"""

    params = sample_all_parameters(trial)

    # GPU λ©”λ¨λ¦¬ μ μ•½ μ²΄ν¬
    estimated_memory = estimate_gpu_memory(params)
    if estimated_memory > MAX_GPU_MEMORY:
        raise optuna.TrialPruned()

    # μ¶”λ΅  μ‹κ°„ μ μ•½ μ²΄ν¬
    if params['num_beams'] > 5 and params['max_new_tokens'] > 150:
        # λ„λ¬΄ λλ¦° μ„¤μ •
        raise optuna.TrialPruned()

    # μ •μƒ ν•™μµ
    rouge_score = train_and_evaluate(params)

    return rouge_score
```

## π€ Optuna Study μ‹¤ν–‰

### 1. κΈ°λ³Έ μ‹¤ν–‰
```python
import optuna
from optuna.pruners import MedianPruner
from optuna.samplers import TPESampler

# Study μƒμ„±
study = optuna.create_study(
    study_name="dialogue_summarization_optimization",
    direction="maximize",  # ROUGE μµλ€ν™”
    sampler=TPESampler(
        n_startup_trials=10,  # μ΄κΈ° λλ¤ νƒμƒ‰
        n_ei_candidates=24,    # EI ν›„λ³΄ μ
        seed=42
    ),
    pruner=MedianPruner(
        n_startup_trials=5,
        n_warmup_steps=3,
        interval_steps=1
    ),
    storage="sqlite:///optuna_study.db",  # κ²°κ³Ό μ €μ¥
    load_if_exists=True  # μ΄μ–΄μ„ μ‹¤ν–‰ κ°€λ¥
)

# μµμ ν™” μ‹¤ν–‰
study.optimize(
    objective_single,
    n_trials=100,           # μ‹λ„ νμ
    timeout=7200,           # 2μ‹κ°„ μ ν•
    n_jobs=1,               # λ³‘λ ¬ μ‹¤ν–‰
    gc_after_trial=True,    # λ©”λ¨λ¦¬ μ •λ¦¬
    show_progress_bar=True
)

# μµμ  νλΌλ―Έν„°
best_params = study.best_params
best_value = study.best_value
print(f"Best ROUGE-F1: {best_value:.4f}")
print(f"Best params: {best_params}")
```

### 2. λ³‘λ ¬ μ‹¤ν–‰ (μ—¬λ¬ GPU)
```python
def run_parallel_optimization():
    """μ—¬λ¬ GPUμ—μ„ λ³‘λ ¬ μµμ ν™”"""

    # GPUλ³„ ν”„λ΅μ„Έμ¤ μƒμ„±
    def optimize_on_gpu(gpu_id):
        import os
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)

        study = optuna.load_study(
            study_name="parallel_optimization",
            storage="mysql://user:password@localhost/optuna"
        )

        study.optimize(
            lambda trial: objective_single(trial, gpu_id=gpu_id),
            n_trials=25  # GPUλ‹Ή 25ν
        )

    # λ³‘λ ¬ μ‹¤ν–‰
    from multiprocessing import Process
    processes = []
    for gpu_id in range(4):  # 4κ° GPU
        p = Process(target=optimize_on_gpu, args=(gpu_id,))
        p.start()
        processes.append(p)

    for p in processes:
        p.join()
```

## π“ μµμ ν™” μ „λµ

### 1. λ‹¨κ³„μ  μµμ ν™” (Staged Optimization)
```python
class StagedOptimization:
    """λ‹¨κ³„λ³„ μµμ ν™” μ „λµ"""

    def __init__(self):
        self.stages = [
            ('model_selection', 20),     # 1λ‹¨κ³„: λ¨λΈ μ„ νƒ
            ('learning_rate', 30),        # 2λ‹¨κ³„: ν•™μµλ¥ 
            ('generation_params', 30),    # 3λ‹¨κ³„: μƒμ„± νλΌλ―Έν„°
            ('fine_tuning', 20)          # 4λ‹¨κ³„: λ―Έμ„Έ μ΅°μ •
        ]

    def optimize_stage(self, stage_name, n_trials):
        """κ° λ‹¨κ³„λ³„ μµμ ν™”"""
        if stage_name == 'model_selection':
            # λ¨λΈκ³Ό LoRA μ„¤μ •λ§ μµμ ν™”
            search_space = ['model_name', 'lora_r', 'lora_alpha']
        elif stage_name == 'learning_rate':
            # ν•™μµ νλΌλ―Έν„°λ§ μµμ ν™”
            search_space = ['learning_rate', 'batch_size', 'scheduler_type']
        elif stage_name == 'generation_params':
            # μƒμ„± νλΌλ―Έν„°λ§ μµμ ν™”
            search_space = ['temperature', 'top_p', 'num_beams']
        else:
            # μ „μ²΄ λ―Έμ„Έ μ΅°μ •
            search_space = 'all'

        return self.run_optimization(search_space, n_trials)

    def run_full_optimization(self):
        """μ „μ²΄ λ‹¨κ³„ μμ°¨ μ‹¤ν–‰"""
        best_params = {}
        for stage_name, n_trials in self.stages:
            stage_best = self.optimize_stage(stage_name, n_trials)
            best_params.update(stage_best)
        return best_params
```

### 2. μ μ‘μ  νƒμƒ‰ (Adaptive Search)
```python
class AdaptiveSearch:
    """μ„±λ¥μ— λ”°λΌ νƒμƒ‰ μ „λµ μ΅°μ •"""

    def __init__(self):
        self.performance_history = []
        self.search_strategy = 'exploration'

    def update_strategy(self, trial_results):
        """μµκ·Ό μ„±λ¥μ— λ”°λΌ μ „λµ λ³€κ²½"""
        self.performance_history.append(trial_results)

        if len(self.performance_history) >= 10:
            recent_improvement = self.calculate_improvement()

            if recent_improvement < 0.01:  # κ°μ„  μ •μ²΄
                self.search_strategy = 'exploitation'
                self.narrow_search_space()
            else:
                self.search_strategy = 'exploration'
                self.widen_search_space()

    def narrow_search_space(self):
        """νƒμƒ‰ κ³µκ°„ μ¶•μ† (exploitation)"""
        # μµκ³  μ„±λ¥ κ·Όμ²λ§ νƒμƒ‰
        best_params = self.get_best_params()
        return self.create_narrow_space(best_params)

    def widen_search_space(self):
        """νƒμƒ‰ κ³µκ°„ ν™•λ€ (exploration)"""
        # λ” λ„“μ€ λ²”μ„ νƒμƒ‰
        return self.create_wide_space()
```

## π“ κ²°κ³Ό λ¶„μ„ λ° μ‹κ°ν™”

### 1. μµμ ν™” νμ¤ν† λ¦¬
```python
def visualize_optimization_history(study):
    """μµμ ν™” κ³Όμ • μ‹κ°ν™”"""
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots

    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=(
            'Optimization History',
            'Parameter Importance',
            'Parallel Coordinate',
            'Slice Plot'
        )
    )

    # 1. μµμ ν™” νμ¤ν† λ¦¬
    trials = study.trials
    x = [t.number for t in trials]
    y = [t.value for t in trials if t.value is not None]

    fig.add_trace(
        go.Scatter(x=x, y=y, mode='markers+lines', name='ROUGE Score'),
        row=1, col=1
    )

    # 2. νλΌλ―Έν„° μ¤‘μ”λ„
    importance = optuna.importance.get_param_importances(study)
    fig.add_trace(
        go.Bar(x=list(importance.values()), y=list(importance.keys()),
               orientation='h', name='Importance'),
        row=1, col=2
    )

    # 3. Parallel Coordinate Plot
    fig_parallel = optuna.visualization.plot_parallel_coordinate(study)

    # 4. Slice Plot
    fig_slice = optuna.visualization.plot_slice(study)

    fig.show()
```

### 2. λ² μ¤νΈ Trial λ¶„μ„
```python
def analyze_best_trials(study, top_k=10):
    """μƒμ„ kκ° trial λ¶„μ„"""

    # μƒμ„ trials
    best_trials = sorted(
        study.trials,
        key=lambda t: t.value if t.value else -float('inf'),
        reverse=True
    )[:top_k]

    # κ³µν†µ νλΌλ―Έν„° μ¶”μ¶
    common_params = {}
    for param_name in best_trials[0].params:
        values = [t.params[param_name] for t in best_trials]

        # λ²”μ£Όν•
        if isinstance(values[0], str):
            most_common = max(set(values), key=values.count)
            frequency = values.count(most_common) / len(values)
            if frequency > 0.7:  # 70% μ΄μƒ λ™μΌν•λ©΄ κ³µν†µ
                common_params[param_name] = most_common

        # μμΉν•
        else:
            mean_val = np.mean(values)
            std_val = np.std(values)
            if std_val / mean_val < 0.2:  # CV < 20%λ©΄ κ³µν†µ
                common_params[param_name] = mean_val

    print(f"Common parameters in top {top_k} trials:")
    for param, value in common_params.items():
        print(f"  {param}: {value}")

    return common_params
```

## π® μ‹¤ν–‰ λ…λ Ήμ–΄ μμ‹

### λΉ λ¥Έ ν…μ¤νΈ (10 trials)
```bash
python train.py \
    --mode optuna \
    --optuna_trials 10 \
    --optuna_timeout 1800 \
    --optuna_sampler random
```

### ν‘μ¤€ μµμ ν™” (100 trials)
```bash
python train.py \
    --mode optuna \
    --optuna_trials 100 \
    --optuna_timeout 7200 \
    --optuna_sampler tpe \
    --optuna_pruner median
```

### λ€κ·λ¨ μµμ ν™” (500 trials, λ³‘λ ¬)
```bash
python train.py \
    --mode optuna \
    --optuna_trials 500 \
    --optuna_n_jobs 4 \
    --optuna_storage mysql://localhost/optuna \
    --optuna_study_name dialogue_optimization
```

### λ‹¨κ³„μ  μµμ ν™”
```bash
# 1λ‹¨κ³„: λ¨λΈ μ„ νƒ
python train.py --mode optuna --optuna_stage model_selection

# 2λ‹¨κ³„: ν•™μµλ¥  μµμ ν™”
python train.py --mode optuna --optuna_stage learning_rate

# 3λ‹¨κ³„: μƒμ„± νλΌλ―Έν„°
python train.py --mode optuna --optuna_stage generation

# 4λ‹¨κ³„: μ „μ²΄ λ―Έμ„Έμ΅°μ •
python train.py --mode optuna --optuna_stage fine_tuning
```

## π’΅ μµμ ν™” ν

### 1. ν¨μ¨μ μΈ νƒμƒ‰
- **μ΄κΈ° λλ¤ νƒμƒ‰**: 10-20 trialsλ” λλ¤μΌλ΅ μ‹μ‘
- **Pruning ν™μ©**: μ„±λ¥μ΄ λ‚®μ€ trial μ΅°κΈ° μ¤‘λ‹¨
- **λ³‘λ ¬ μ‹¤ν–‰**: μ—¬λ¬ GPU ν™μ©ν•μ—¬ μ‹κ°„ λ‹¨μ¶•

### 2. NLP νΉν™” μ „λµ
- **λ¨λΈ λ¨Όμ €**: λ¨λΈ μ„ νƒμ„ λ¨Όμ € μµμ ν™”
- **μƒμ„± νλΌλ―Έν„° μ¤‘μ”**: Temperature, Top-pκ°€ μ„±λ¥μ— ν° μν–¥
- **κΈ΄ μ‹ν€€μ¤ μ£Όμ**: max_length μ¦κ°€λ” λ©”λ¨λ¦¬μ™€ μ‹κ°„ κΈ‰μ¦

### 3. μ‹¤μ©μ  μ ‘κ·Ό
- **μ μ•½ μ΅°κ±΄ μ„¤μ •**: μ¶”λ΅  μ‹κ°„, λ©”λ¨λ¦¬ μ ν•
- **λ‹¨κ³„μ  μµμ ν™”**: μ „μ²΄λ³΄λ‹¤ λ‹¨κ³„λ³„μ΄ ν¨μ¨μ 
- **λ² μ¤νΈ ν”„λ™ν‹°μ¤ ν™μ©**: μ΄λ―Έ μ•λ ¤μ§„ μΆ‹μ€ λ²”μ„λ¶€ν„° μ‹μ‘

## π“ μμƒ μ„±λ¥ ν–¥μƒ

| μµμ ν™” μμ¤€ | Trials | μ‹κ°„ | ROUGE ν–¥μƒ | μ¶”μ² μƒν™© |
|------------|--------|------|-----------|-----------|
| Quick | 10 | 30λ¶„ | +1-2% | λΉ λ¥Έ μ‹¤ν— |
| Standard | 100 | 5μ‹κ°„ | +3-5% | μΌλ° μµμ ν™” |
| Thorough | 300 | 15μ‹κ°„ | +5-7% | μ¶©λ¶„ν• μ‹κ°„ |
| Extensive | 500+ | 24μ‹κ°„+ | +7-10% | μµμΆ… μ μ¶μ© |

## π† NLP λ€ν™” μ”μ•½ μ¶”μ² μ„¤μ •

### κ²€μ¦λ μµμ  μ„¤μ • (μ‹¤μ  λ°μ΄ν„° κΈ°λ°)
```python
# KoBART (Encoder-Decoder) - κ²€μ¦ μ™„λ£
kobart_optimal = {
    'model_name': 'digit82/kobart-summarization',
    'learning_rate': 5e-5,
    'batch_size': 8,
    'num_train_epochs': 20,
    'encoder_max_len': 512,
    'decoder_max_len': 100,
    'num_beams': 4,
    # Result: ROUGE Sum 94.51
}

# Llama-3.2-Korean (LLM QLoRA) - μµμ ν™” μ¤‘
llama_optimal = {
    'model_name': 'Bllossom/llama-3.2-Korean-Bllossom-3B',
    'learning_rate': 2e-5,
    'batch_size': 8,
    'gradient_accumulation_steps': 8,  # effective=64
    'num_train_epochs': 3,

    # β οΈ μ¤‘μ”: Prompt Truncation λ°©μ§€
    'encoder_max_len': 1024,  # 512 β†’ 1024 (ν•„μ!)
    'decoder_max_len': 200,   # 100 β†’ 200

    # LoRA (κ²€μ¦λ κ°’)
    'lora_r': 16,
    'lora_alpha': 32,
    'lora_dropout': 0.05,
    'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj',
                       'gate_proj', 'up_proj', 'down_proj'],

    # ν•™μµ μ•μ •μ„±
    'warmup_ratio': 0.1,
    'weight_decay': 0.1,
    'lr_scheduler_type': 'cosine',
    'max_grad_norm': 1.2,

    # Mixed Precision
    'bf16': True,  # Llamaλ” bf16
    'fp16': False,

    # μƒμ„±
    'num_beams': 4,
    'max_new_tokens': 150,  # 100 β†’ 150 (μ—¬μ )
    'repetition_penalty': 1.1,
    'no_repeat_ngram_size': 3,

    # Target: ROUGE Sum 95+
}

# Qwen3-4B (LLM QLoRA) - λ€κΈ°
qwen_optimal = {
    'model_name': 'Qwen/Qwen3-4B-Instruct-2507',
    'learning_rate': 2e-5,
    'batch_size': 6,  # Qwenμ€ λ©”λ¨λ¦¬ λ” μ‚¬μ©
    'gradient_accumulation_steps': 8,
    'num_train_epochs': 3,

    'encoder_max_len': 1024,
    'decoder_max_len': 200,

    'lora_r': 16,
    'lora_alpha': 32,
    'lora_dropout': 0.05,

    # Qwenμ€ fp16
    'fp16': True,
    'bf16': False,

    'num_beams': 4,
    'max_new_tokens': 150,
}
```

### Optuna νƒμƒ‰ κ¶μ¥ λ²”μ„
```python
# μ¶”κ°€ μµμ ν™” μ‹ νƒμƒ‰ λ²”μ„
search_ranges = {
    # ν•™μµλ¥  (κ²€μ¦λ λ²”μ„ μ¤‘μ‹¬)
    'learning_rate': [1e-5, 3e-5, 5e-5],

    # λ°°μΉ ν¬κΈ° (GPU λ©”λ¨λ¦¬ κ³ λ ¤)
    'batch_size': [4, 6, 8],  # effective=32~64

    # LoRA rank (μ„±λ¥ vs μ†λ„)
    'lora_r': [8, 16, 32],
    'lora_alpha': [16, 32, 64],

    # μƒμ„± νλΌλ―Έν„°
    'num_beams': [3, 4, 5],
    'repetition_penalty': [1.0, 1.1, 1.2],
    'max_new_tokens': [100, 150, 200],

    # β οΈ κ³ μ • κ¶μ¥ (κ²€μ¦λ κ°’)
    'encoder_max_len': 1024,  # μ λ€ 512λ΅ ν•μ§€ λ§κ²ƒ!
    'warmup_ratio': 0.1,
    'lr_scheduler_type': 'cosine',
}
```
