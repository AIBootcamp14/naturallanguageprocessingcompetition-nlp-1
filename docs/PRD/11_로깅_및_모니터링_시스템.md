# ğŸ“Š ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

## ğŸ¯ ê°œìš”
í”„ë¡œì íŠ¸ ì „ë°˜ì˜ ì‹¤í—˜ ê³¼ì •, ì„±ëŠ¥ ì§€í‘œ, GPU ì‚¬ìš©ëŸ‰ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì¶”ì í•˜ê³  ì‹œê°í™”í•˜ëŠ” í†µí•© ì‹œìŠ¤í…œ

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ì‹¤í—˜ ì‹¤í–‰"
        A[ë…¸íŠ¸ë¶/ìŠ¤í¬ë¦½íŠ¸] --> B[Logger ì‹œìŠ¤í…œ]
        A --> C[WandB Logger]
        A --> D[Notebook Logger]
    end

    subgraph "ë¡œê¹… ê³„ì¸µ"
        B --> E[íŒŒì¼ ë¡œê¹…]
        C --> F[í´ë¼ìš°ë“œ ë¡œê¹…]
        D --> G[ë…¸íŠ¸ë¶ ì¶œë ¥]
    end

    subgraph "ëª¨ë‹ˆí„°ë§"
        E --> H[ë¡œì»¬ ë¡œê·¸ íŒŒì¼]
        F --> I[WandB ëŒ€ì‹œë³´ë“œ]
        G --> J[Jupyter ì¶œë ¥]
    end

    subgraph "ì‹œê°í™”"
        H --> K[Training Viz]
        I --> L[ì‹¤ì‹œê°„ ì°¨íŠ¸]
        J --> M[ì¸ë¼ì¸ í”Œë¡¯]
    end

    K --> N[ì„±ëŠ¥ ë¦¬í¬íŠ¸]
    L --> N
    M --> N
```

## ğŸ’¡ í•µì‹¬ ê¸°ëŠ¥

### 1. í†µí•© ë¡œê±° ì‹œìŠ¤í…œ (src/logging/logger.py)
```python
class Logger:
    """
    ëª¨ë“  ì¶œë ¥ì„ íŒŒì¼ê³¼ ì½˜ì†”ì— ë™ì‹œ ê¸°ë¡
    íƒ€ì„ìŠ¤íƒ¬í”„ ìë™ ì¶”ê°€
    """
    def __init__(self, log_path: str, print_also: bool = True):
        # ë¡œê·¸ íŒŒì¼ ìƒì„±
        # stdout/stderr ë¦¬ë””ë ‰ì…˜
        # tqdm í˜¸í™˜ì„± ì§€ì›
```

#### ì£¼ìš” ê¸°ëŠ¥
- âœ… **ìë™ íƒ€ì„ìŠ¤íƒ¬í”„**: ëª¨ë“  ë¡œê·¸ì— ì‹œê°„ ì •ë³´ ì¶”ê°€
- âœ… **ì´ì¤‘ ì¶œë ¥**: íŒŒì¼ê³¼ ì½˜ì†” ë™ì‹œ ì¶œë ¥
- âœ… **ì—ëŸ¬ í•˜ì´ë¼ì´íŒ…**: ì—ëŸ¬ ë©”ì‹œì§€ ë¹¨ê°„ìƒ‰ í‘œì‹œ
- âœ… **tqdm í˜¸í™˜**: í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ ë¡œê¹… ì¶©ëŒ ë°©ì§€
- âœ… **ìë™ í”ŒëŸ¬ì‹œ**: ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸ ê°€ëŠ¥

### 2. WandB í†µí•© (src/logging/wandb_logger.py)
```python
class WandBLogger:
    """
    Weights & Biases í”Œë«í¼ í†µí•©
    ì‹¤ì‹œê°„ ì‹¤í—˜ ì¶”ì  ë° ë¹„êµ
    """
    def __init__(self, project_name: str, config: dict):
        # WandB ì´ˆê¸°í™”
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        # ë©”íŠ¸ë¦­ ì¶”ì 
```

#### ì¶”ì  í•­ëª©
- ğŸ“ˆ í•™ìŠµ ì†ì‹¤ (train/val loss)
- ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ROUGE, BLEU)
- ğŸ¯ í•˜ì´í¼íŒŒë¼ë¯¸í„°
- ğŸ–¼ï¸ ì‹œê°í™” ì´ë¯¸ì§€
- ğŸ“ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸

### 3. ë…¸íŠ¸ë¶ ë¡œê±° (src/logging/notebook_logger.py)
```python
class NotebookLogger:
    """
    Jupyter ë…¸íŠ¸ë¶ ì „ìš© ë¡œê±°
    ì¸ë¼ì¸ ì‹œê°í™” ì§€ì›
    """
    def log_with_plot(self, message: str, data: dict):
        # ë©”ì‹œì§€ ì¶œë ¥
        # ì¸ë¼ì¸ ì°¨íŠ¸ ìƒì„±
        # ì§„í–‰ë¥  í‘œì‹œ
```

## ğŸ–¥ï¸ GPU ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### 1. GPU í˜¸í™˜ì„± ì²´í¬ (team_gpu_check.py)

```mermaid
graph LR
    A[GPU ì²´í¬ ì‹œì‘] --> B{CUDA ì‚¬ìš©ê°€ëŠ¥?}
    B -->|Yes| C[GPU ì •ë³´ ìˆ˜ì§‘]
    B -->|No| D[ì—ëŸ¬ ë° í•´ê²°ì±…]

    C --> E[GPU ë“±ê¸‰ ë¶„ë¥˜]
    E --> F[High-End<br/>RTX 4090/A100]
    E --> G[Mid-Range<br/>RTX 3080/4070]
    E --> H[Budget<br/>RTX 3060/2070]
    E --> I[Low-End<br/>ê¸°íƒ€]

    F --> J[ë°°ì¹˜í¬ê¸° 96-256]
    G --> K[ë°°ì¹˜í¬ê¸° 64-128]
    H --> L[ë°°ì¹˜í¬ê¸° 32-64]
    I --> M[ë°°ì¹˜í¬ê¸° 16-32]
```

### 2. ìë™ ë°°ì¹˜ í¬ê¸° ìµœì í™” (auto_batch_size.py)
```python
def find_optimal_batch_size(model, device):
    """
    OOM ì—†ì´ ìµœëŒ€ ë°°ì¹˜ í¬ê¸° ìë™ íƒìƒ‰
    """
    # Binary searchë¡œ ìµœì ê°’ íƒìƒ‰
    # 95% ì•ˆì „ ê³„ìˆ˜ ì ìš©
    # GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
```

#### ìµœì í™” ì „ëµ
| GPU ë“±ê¸‰ | ë©”ëª¨ë¦¬ | ê¶Œì¥ ë°°ì¹˜ | Gradient Acc. |
|---------|--------|----------|---------------|
| High-End | 24GB+ | 96-256 | 1 |
| Mid-Range | 12-16GB | 64-128 | 2 |
| Budget | 8-12GB | 32-64 | 3-4 |
| Low-End | 6-8GB | 16-32 | 6-8 |

## ğŸ“Š ì‹œê°í™” ì‹œìŠ¤í…œ

### 1. í•™ìŠµ ì‹œê°í™” (training_viz.py)

```mermaid
graph TD
    A[í•™ìŠµ ë°ì´í„°] --> B[7ê°€ì§€ ì‹œê°í™”]
    B --> C[í´ë“œë³„ F1 ì„±ëŠ¥]
    B --> D[í´ë“œë³„ ì •í™•ë„]
    B --> E[F1 vs ì •í™•ë„ ì‚°ì ë„]
    B --> F[ì„±ëŠ¥ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨]
    B --> G[í†µê³„ ìš”ì•½ ì°¨íŠ¸]
    B --> H[í•™ìŠµ ê³¡ì„ ]
    B --> I[ì†ì‹¤ ë¹„êµ]

    C --> J[PNG íŒŒì¼ ì €ì¥]
    D --> J
    E --> J
    F --> J
    G --> J
    H --> J
    I --> J
```

ìƒì„±ë˜ëŠ” ì°¨íŠ¸:
1. `01_fold_f1_performance.png` - í´ë“œë³„ F1 ì ìˆ˜
2. `02_fold_accuracy_comparison.png` - í´ë“œë³„ ì •í™•ë„
3. `03_f1_vs_accuracy_scatter.png` - ìƒê´€ê´€ê³„ ë¶„ì„
4. `04_performance_distribution.png` - ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
5. `05_performance_statistics.png` - í†µê³„ ìš”ì•½
6. `06_training_history.png` - í•™ìŠµ ê³¡ì„ 
7. `07_loss_comparison.png` - ê³¼ì í•© íƒì§€

### 2. ì¶”ë¡  ì‹œê°í™” (inference_viz.py)
- ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬
- ì‹ ë¢°ë„ ì ìˆ˜ ë¶„ì„
- ìƒ˜í”Œë³„ ì„±ëŠ¥ ë¹„êµ
- ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„

### 3. ìµœì í™” ì‹œê°í™” (optimization_viz.py)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜í–¥ë„
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
- ë°°ì¹˜ í¬ê¸° vs ì„±ëŠ¥
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

## ğŸ”§ í†µí•© ë°©ë²•

### 1. í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
```python
from src.logging import Logger, WandBLogger
from src.utils.gpu_optimization import team_gpu_check

# 1. GPU í™˜ê²½ ì²´í¬
team_gpu_check.check_gpu_compatibility()

# 2. ë¡œê±° ì´ˆê¸°í™”
logger = Logger('logs/train.log')
logger.start_redirect()  # stdout/stderr ë¦¬ë””ë ‰ì…˜

# 3. WandB ì´ˆê¸°í™”
wandb_logger = WandBLogger(
    project_name='dialogue-summarization',
    config=config
)
```

### 2. í•™ìŠµ ì¤‘ ë¡œê¹…
```python
# ì—í­ë³„ ë¡œê¹…
for epoch in range(num_epochs):
    # í•™ìŠµ
    train_loss = train_one_epoch()
    val_loss, val_rouge = validate()

    # ë¡œê¹…
    logger.write(f"Epoch {epoch}: train_loss={train_loss:.4f}")
    wandb_logger.log({
        'train_loss': train_loss,
        'val_loss': val_loss,
        'val_rouge': val_rouge
    })
```

### 3. ì‹œê°í™” ìƒì„±
```python
from src.utils.visualizations import create_training_visualizations

# í•™ìŠµ ì™„ë£Œ í›„
create_training_visualizations(
    fold_results=results,
    model_name='LLM-FineTuned',
    output_dir='outputs/visualizations',
    history_data=training_history
)
```

## ğŸ“‹ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë…¸íŠ¸ë¶ ì‹¤í—˜
```python
# notebooks/experiments/llm_finetuning.ipynb
from src.logging import NotebookLogger

nb_logger = NotebookLogger()
nb_logger.start_experiment('LLM íŒŒì¸íŠœë‹ ì‹¤í—˜')

# ì‹¤í—˜ ì§„í–‰...
nb_logger.log_metric('rouge_f1', 0.65)
nb_logger.create_inline_plot(losses, 'Training Loss')
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë¶„ì‚° í•™ìŠµ
```python
# ì—¬ëŸ¬ GPUì—ì„œ í•™ìŠµ
from src.utils.gpu_optimization import auto_batch_size

optimal_batch = auto_batch_size.find_optimal_batch_size(
    model, device, safe_factor=0.95
)
print(f"ìµœì  ë°°ì¹˜ í¬ê¸°: {optimal_batch}")
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì‹¤í—˜ ë¹„êµ
```python
# WandB ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤í—˜ ë¹„êµ
wandb_logger.log_summary({
    'best_rouge': best_score,
    'best_epoch': best_epoch,
    'total_time': total_time
})
```

## ğŸš€ ì˜ˆìƒ íš¨ê³¼

### ì‹¤í—˜ ê´€ë¦¬ ê°œì„ 
- âœ… ëª¨ë“  ì‹¤í—˜ ìë™ ê¸°ë¡
- âœ… ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
- âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- âœ… ì²´ê³„ì ì¸ ë¹„êµ ë¶„ì„

### GPU í™œìš©ë„ í–¥ìƒ
- âœ… ìë™ ìµœì  ë°°ì¹˜ í¬ê¸°
- âœ… OOM ì—ëŸ¬ ë°©ì§€
- âœ… GPUë³„ ë§ì¶¤ ì„¤ì •
- âœ… 95% ë©”ëª¨ë¦¬ í™œìš©

### ë””ë²„ê¹… íš¨ìœ¨í™”
- âœ… ìƒì„¸í•œ ë¡œê·¸ ê¸°ë¡
- âœ… ì—ëŸ¬ ì¶”ì  ìš©ì´
- âœ… ì„±ëŠ¥ ë³‘ëª© ë°œê²¬
- âœ… ê³¼ì í•© ì¡°ê¸° íƒì§€

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í—˜ ì‹œì‘ ì „
- [ ] GPU í˜¸í™˜ì„± ì²´í¬ ì‹¤í–‰
- [ ] ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
- [ ] WandB í”„ë¡œì íŠ¸ ì„¤ì •
- [ ] ë°°ì¹˜ í¬ê¸° ìµœì í™”

### ì‹¤í—˜ ì¤‘
- [ ] ì—í­ë³„ ë©”íŠ¸ë¦­ ë¡œê¹…
- [ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] ì¤‘ê°„ ì‹œê°í™” í™•ì¸

### ì‹¤í—˜ í›„
- [ ] ìµœì¢… ì‹œê°í™” ìƒì„±
- [ ] ë¡œê·¸ íŒŒì¼ ë°±ì—…
- [ ] WandB ë¦¬í¬íŠ¸ ì‘ì„±
- [ ] ê²°ê³¼ ë¬¸ì„œí™”

## ğŸ’¡ íŒ

### ë¡œê¹… ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
1. **êµ¬ì¡°í™”ëœ ë¡œê·¸**: JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
2. **ì ì ˆí•œ ë¡œê·¸ ë ˆë²¨**: DEBUG, INFO, WARNING, ERROR
3. **ì˜ë¯¸ìˆëŠ” ë©”ì‹œì§€**: ì»¨í…ìŠ¤íŠ¸ í¬í•¨
4. **ì£¼ê¸°ì  í”ŒëŸ¬ì‹œ**: ì‹¤ì‹œê°„ í™•ì¸

### GPU ìµœì í™” íŒ
1. **Mixed Precision**: fp16 ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ 50% ì ˆì•½
2. **Gradient Checkpointing**: ë©”ëª¨ë¦¬ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„
3. **ë°ì´í„° ë¡œë” ìµœì í™”**: num_workers, pin_memory
4. **ìºì‹± í™œìš©**: ìì£¼ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° ë©”ëª¨ë¦¬ì— ìœ ì§€