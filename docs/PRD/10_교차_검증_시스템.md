# ğŸ”„ êµì°¨ ê²€ì¦ ì‹œìŠ¤í…œ ì„¤ê³„

## ğŸ¯ í•µì‹¬ ê°œë…
**ëª¨ë¸ í•™ìŠµ ê²°ê³¼ + Solar API ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìµœì ì˜ ìš”ì•½ ì„ íƒ**

íŒ€ì›ì˜ ì•„ì´ë””ì–´: ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì˜ ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ë” ë‚˜ì€ ìš”ì•½ì„ ì„ íƒí•˜ê³ , ì´ë¥¼ í†µí•´ ì •ë‹µë¥  í–¥ìƒ

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[ì…ë ¥ ëŒ€í™”] --> B[íŒŒì¸íŠœë‹ ëª¨ë¸]
    A --> C[Solar API]
    B --> D[ìš”ì•½1]
    C --> E[ìš”ì•½2]
    D --> F[í’ˆì§ˆ í‰ê°€ê¸°]
    E --> F
    F --> G[ìµœì¢… ìš”ì•½ ì„ íƒ]
    G --> H[ì‹ ë¢°ë„ ì ìˆ˜]
```

## ğŸ’¡ êµ¬í˜„ ì „ëµ

### 1. ë“€ì–¼ ìƒì„± ì‹œìŠ¤í…œ
```python
class DualSummarizationSystem:
    def __init__(self, finetuned_model, solar_api):
        self.model = finetuned_model
        self.api = solar_api
        self.evaluator = QualityEvaluator()

    def generate_summaries(self, dialogue):
        """
        ë‘ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ìš”ì•½ ìƒì„±
        """
        # 1. íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ìƒì„±
        model_summary = self.model.generate_summary(dialogue)
        model_confidence = self.model.get_confidence_score()

        # 2. Solar APIë¡œ ìƒì„±
        api_summary = self.api.generate_summary(dialogue)
        api_confidence = 0.85  # APIëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì•ˆì •ì 

        return {
            'model': {
                'summary': model_summary,
                'confidence': model_confidence
            },
            'api': {
                'summary': api_summary,
                'confidence': api_confidence
            }
        }

    def select_best_summary(self, summaries, dialogue):
        """
        ìµœì ì˜ ìš”ì•½ ì„ íƒ
        """
        model_score = self.evaluator.evaluate(
            summaries['model']['summary'],
            dialogue
        )
        api_score = self.evaluator.evaluate(
            summaries['api']['summary'],
            dialogue
        )

        # ê°€ì¤‘ì¹˜ ì ìš©
        model_final = model_score * summaries['model']['confidence']
        api_final = api_score * summaries['api']['confidence']

        if model_final > api_final:
            return summaries['model']['summary']
        else:
            return summaries['api']['summary']
```

### 2. í’ˆì§ˆ í‰ê°€ê¸° (Quality Evaluator)
```python
class QualityEvaluator:
    def __init__(self):
        self.criteria = {
            'length_ratio': 0.2,      # ìš”ì•½ ê¸¸ì´ ì ì ˆì„±
            'keyword_coverage': 0.3,   # í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨
            'coherence': 0.25,         # ë¬¸ì¥ ì¼ê´€ì„±
            'information_density': 0.25 # ì •ë³´ ë°€ë„
        }

    def evaluate(self, summary, dialogue):
        """
        ìš”ì•½ í’ˆì§ˆ ì¢…í•© í‰ê°€
        """
        scores = {
            'length_ratio': self.check_length_ratio(summary, dialogue),
            'keyword_coverage': self.check_keyword_coverage(summary, dialogue),
            'coherence': self.check_coherence(summary),
            'information_density': self.check_information_density(summary)
        }

        # ê°€ì¤‘ í‰ê· 
        total_score = sum(
            score * self.criteria[metric]
            for metric, score in scores.items()
        )
        return total_score

    def check_length_ratio(self, summary, dialogue):
        """
        ìš”ì•½ ê¸¸ì´ ì ì ˆì„± (ì´ìƒì : ì›ë³¸ì˜ 20-30%)
        """
        ratio = len(summary) / len(dialogue)
        if 0.2 <= ratio <= 0.3:
            return 1.0
        elif 0.15 <= ratio <= 0.35:
            return 0.8
        else:
            return 0.5

    def check_keyword_coverage(self, summary, dialogue):
        """
        í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ë„
        """
        from konlpy.tag import Okt
        okt = Okt()

        # ëª…ì‚¬ ì¶”ì¶œ
        dialogue_nouns = set(okt.nouns(dialogue))
        summary_nouns = set(okt.nouns(summary))

        # ì¤‘ìš” ëª…ì‚¬ (ë¹ˆë„ ê¸°ë°˜)
        important_nouns = self.get_important_words(dialogue_nouns)

        # Coverage ê³„ì‚°
        coverage = len(summary_nouns & important_nouns) / len(important_nouns)
        return min(coverage * 1.2, 1.0)  # ìµœëŒ€ 1.0

    def check_coherence(self, summary):
        """
        ë¬¸ì¥ ì¼ê´€ì„± ì²´í¬
        """
        sentences = summary.split('.')
        if len(sentences) < 2:
            return 0.8

        # ë¬¸ì¥ ê°„ ì—°ê²°ì„± ì²´í¬
        coherence_score = 0
        for i in range(len(sentences) - 1):
            if self.has_connection(sentences[i], sentences[i+1]):
                coherence_score += 1

        return coherence_score / (len(sentences) - 1)

    def check_information_density(self, summary):
        """
        ì •ë³´ ë°€ë„ ì¸¡ì •
        """
        # ë‹¨ì–´ ìˆ˜ ëŒ€ë¹„ ê³ ìœ  ë‹¨ì–´ ë¹„ìœ¨
        words = summary.split()
        unique_words = set(words)

        density = len(unique_words) / len(words)
        return min(density * 1.5, 1.0)
```

### 3. ì•™ìƒë¸” ì „ëµ
```python
class EnsembleSummarizer:
    def __init__(self, models_list, solar_api):
        self.models = models_list  # ì—¬ëŸ¬ íŒŒì¸íŠœë‹ ëª¨ë¸
        self.api = solar_api
        self.combiner = SummaryCombiner()

    def generate_ensemble_summary(self, dialogue):
        """
        ì•™ìƒë¸” ìš”ì•½ ìƒì„±
        """
        all_summaries = []

        # 1. ëª¨ë“  ëª¨ë¸ì—ì„œ ìš”ì•½ ìƒì„±
        for model in self.models:
            summary = model.generate_summary(dialogue)
            all_summaries.append({
                'text': summary,
                'source': f'model_{model.name}',
                'confidence': model.confidence
            })

        # 2. Solar API ìš”ì•½ ì¶”ê°€
        api_summary = self.api.generate_summary(dialogue)
        all_summaries.append({
            'text': api_summary,
            'source': 'solar_api',
            'confidence': 0.9
        })

        # 3. ìµœì  ì¡°í•© ì„ íƒ
        best_combination = self.combiner.find_best_combination(
            all_summaries,
            dialogue
        )

        return best_combination

class SummaryCombiner:
    def find_best_combination(self, summaries, dialogue):
        """
        ì—¬ëŸ¬ ìš”ì•½ ì¤‘ ìµœì  ì¡°í•© ì°¾ê¸°
        """
        # ì „ëµ 1: Voting (ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‚´ìš©)
        common_sentences = self.extract_common_sentences(summaries)

        # ì „ëµ 2: ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        weighted_summary = self.weighted_combination(summaries)

        # ì „ëµ 3: ìµœê³  í’ˆì§ˆ ì„ íƒ
        best_single = self.select_best_single(summaries, dialogue)

        # ìµœì¢… ì„ íƒ
        candidates = [common_sentences, weighted_summary, best_single]
        return self.select_final(candidates, dialogue)

    def extract_common_sentences(self, summaries):
        """
        ê³µí†µ ë¬¸ì¥ ì¶”ì¶œ (Voting)
        """
        from collections import Counter

        all_sentences = []
        for s in summaries:
            sentences = s['text'].split('.')
            all_sentences.extend(sentences)

        # ê°€ì¥ ìì£¼ ë‚˜ì˜¨ ë¬¸ì¥ë“¤
        counter = Counter(all_sentences)
        common = counter.most_common(3)

        return '. '.join([sent for sent, _ in common]) + '.'

    def weighted_combination(self, summaries):
        """
        ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ ì¡°í•©
        """
        # ê° ìš”ì•½ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentence_pool = []
        for s in summaries:
            sentences = s['text'].split('.')
            for sent in sentences:
                sentence_pool.append({
                    'text': sent,
                    'confidence': s['confidence']
                })

        # ì‹ ë¢°ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_pool = sorted(
            sentence_pool,
            key=lambda x: x['confidence'],
            reverse=True
        )

        # ìƒìœ„ ë¬¸ì¥ ì„ íƒ (ì¤‘ë³µ ì œê±°)
        selected = []
        seen = set()
        for item in sorted_pool:
            if item['text'] not in seen:
                selected.append(item['text'])
                seen.add(item['text'])
                if len(selected) >= 3:
                    break

        return '. '.join(selected) + '.'
```

### 4. ì‹ ë¢°ë„ ì ìˆ˜ ì‹œìŠ¤í…œ
```python
class ConfidenceScoring:
    def __init__(self):
        self.history = []  # ê³¼ê±° ì„±ëŠ¥ ê¸°ë¡

    def calculate_model_confidence(self, model, dialogue):
        """
        ëª¨ë¸ ì‹ ë¢°ë„ ê³„ì‚°
        """
        factors = {
            'dialogue_length': self.length_factor(dialogue),
            'speaker_count': self.speaker_factor(dialogue),
            'model_perplexity': self.perplexity_factor(model),
            'historical_performance': self.history_factor(model)
        }

        # ê°€ì¤‘ í‰ê· 
        weights = {
            'dialogue_length': 0.2,
            'speaker_count': 0.2,
            'model_perplexity': 0.3,
            'historical_performance': 0.3
        }

        confidence = sum(
            factors[k] * weights[k]
            for k in factors
        )
        return confidence

    def length_factor(self, dialogue):
        """
        ëŒ€í™” ê¸¸ì´ì— ë”°ë¥¸ ì‹ ë¢°ë„
        """
        length = len(dialogue)
        if 300 <= length <= 800:  # ì´ìƒì ì¸ ê¸¸ì´
            return 1.0
        elif length < 300:  # ë„ˆë¬´ ì§§ìŒ
            return 0.8
        else:  # ë„ˆë¬´ ê¸º
            return 0.6

    def speaker_factor(self, dialogue):
        """
        í™”ì ìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„
        """
        speakers = len(set(re.findall(r'#Person\d+#', dialogue)))
        if speakers == 2:  # ì´ìƒì 
            return 1.0
        elif speakers == 3:
            return 0.9
        else:  # 4ëª… ì´ìƒ
            return 0.7

    def update_history(self, model_name, score):
        """
        ì„±ëŠ¥ ì´ë ¥ ì—…ë°ì´íŠ¸
        """
        self.history.append({
            'model': model_name,
            'score': score,
            'timestamp': time.time()
        })
```

### 5. A/B í…ŒìŠ¤íŒ… í”„ë ˆì„ì›Œí¬
```python
class ABTestingFramework:
    def __init__(self):
        self.results = {
            'model_only': [],
            'api_only': [],
            'hybrid': []
        }

    def run_test(self, test_data, model, api):
        """
        A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        """
        dual_system = DualSummarizationSystem(model, api)

        for dialogue, gold_summary in test_data:
            # ì„¸ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ìƒì„±
            model_summary = model.generate_summary(dialogue)
            api_summary = api.generate_summary(dialogue)
            hybrid_summary = dual_system.select_best_summary(
                dialogue
            )

            # ì„±ëŠ¥ í‰ê°€
            model_score = self.evaluate_rouge(model_summary, gold_summary)
            api_score = self.evaluate_rouge(api_summary, gold_summary)
            hybrid_score = self.evaluate_rouge(hybrid_summary, gold_summary)

            # ê²°ê³¼ ì €ì¥
            self.results['model_only'].append(model_score)
            self.results['api_only'].append(api_score)
            self.results['hybrid'].append(hybrid_score)

        # í†µê³„ ë¶„ì„
        return self.analyze_results()

    def analyze_results(self):
        """
        í†µê³„ì  ë¶„ì„
        """
        import numpy as np
        from scipy import stats

        analysis = {}
        for method in self.results:
            scores = self.results[method]
            analysis[method] = {
                'mean': np.mean(scores),
                'std': np.std(scores),
                'median': np.median(scores),
                'confidence_interval': stats.t.interval(
                    0.95,
                    len(scores)-1,
                    loc=np.mean(scores),
                    scale=stats.sem(scores)
                )
            }

        # ë°©ë²• ê°„ ë¹„êµ
        analysis['comparison'] = {
            'model_vs_api': stats.ttest_ind(
                self.results['model_only'],
                self.results['api_only']
            ),
            'hybrid_vs_best': self.compare_hybrid()
        }

        return analysis
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ì˜ˆìƒ

| ë°©ë²• | ROUGE-F1 | ì•ˆì •ì„± | ë¹„ìš© |
|------|----------|--------|------|
| Model Only | 55-60 | ì¤‘ê°„ | ë‚®ìŒ |
| API Only | 50-55 | ë†’ìŒ | ë†’ìŒ |
| Hybrid (êµì°¨ê²€ì¦) | 60-65 | ë†’ìŒ | ì¤‘ê°„ |
| Ensemble | 63-68 | ë§¤ìš° ë†’ìŒ | ë†’ìŒ |

## ğŸš€ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ê¸°ë³¸ ì‹œìŠ¤í…œ êµ¬ì¶•
1. ë“€ì–¼ ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„
2. í’ˆì§ˆ í‰ê°€ê¸° ê°œë°œ
3. ê¸°ë³¸ ì„ íƒ ì•Œê³ ë¦¬ì¦˜

### Phase 2: ê³ ë„í™”
1. ì‹ ë¢°ë„ ì ìˆ˜ ì‹œìŠ¤í…œ
2. ì•™ìƒë¸” ì „ëµ êµ¬í˜„
3. A/B í…ŒìŠ¤íŒ… í”„ë ˆì„ì›Œí¬

### Phase 3: ìµœì í™”
1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
2. ê°€ì¤‘ì¹˜ ìµœì í™”
3. ì‹¤ì‹œê°„ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜

## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### ì–¸ì œ ëª¨ë¸ì„ ì‹ ë¢°í• ê¹Œ?
- ì§§ê³  ëª…í™•í•œ ëŒ€í™”
- 2ì¸ ëŒ€í™”
- í•™ìŠµ ë°ì´í„°ì™€ ìœ ì‚¬í•œ íŒ¨í„´

### ì–¸ì œ APIë¥¼ ì‹ ë¢°í• ê¹Œ?
- ë³µì¡í•œ ë‹¤ì ëŒ€í™”
- ê¸´ ëŒ€í™”
- íŠ¹ìˆ˜í•œ ë„ë©”ì¸

### í•˜ì´ë¸Œë¦¬ë“œì˜ ê°•ì 
- ë‘ ë°©ë²•ì˜ ì¥ì  ê²°í•©
- ì•ˆì •ì ì¸ ì„±ëŠ¥
- ë¹„ìš© íš¨ìœ¨ì 