# âš™ï¸ Config ì„¤ì • ì „ëµ (ì´ˆê¸° ëª¨ë“ˆí™” ê°€ì´ë“œ)

## ğŸ¯ ëª©í‘œ
í”„ë¡œì íŠ¸ ëª¨ë“ˆí™” ì§„í–‰ ì‹œ config íŒŒì¼ì„ ì²´ê³„ì ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ì‹¤í—˜ ì¬í˜„ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± í™•ë³´

## ğŸ“Š Config íŒŒì¼ ë¶„ì„ ê²°ê³¼

### 1. Baseline Config (ëŒ€íšŒ ì œê³µ)
**íŒŒì¼**: `notebooks/base/configs/config.yaml`

**íŠ¹ì§•**:
- ê²€ì¦ëœ ìµœì†Œ ì„¤ì • (KoBART ê¸°ì¤€)
- ëª…í™•í•œ êµ¬ì¡° (general, tokenizer, training, inference, wandb, paths)
- í•„ìˆ˜ íŒŒë¼ë¯¸í„°ë§Œ í¬í•¨

**í•µì‹¬ ì„¤ì •ê°’**:
```yaml
training:
  learning_rate: 1.0e-05  # 1e-5 (ê²€ì¦ë¨)
  per_device_train_batch_size: 50  # í° ë°°ì¹˜
  num_train_epochs: 20

inference:
  no_repeat_ngram_size: 2  # 2ê°€ ìµœì 
  num_beams: 4
```

**ì¥ì **:
- ë‹¨ìˆœí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ì›€
- ë¹ ë¥¸ ì‹¤í—˜ ê°€ëŠ¥
- KoBART ìµœì í™”

**ë‹¨ì **:
- ê³ ê¸‰ ê¸°ëŠ¥ ì—†ìŒ (ì¦ê°•, ì•™ìƒë¸” ë“±)
- LLM íŒŒì¸íŠœë‹ ë¯¸ì§€ì›
- ë‹¨ì¼ ëª¨ë¸ë§Œ ì§€ì›

### 2. KoBART Fine-tuning Config
**íŒŒì¼**: `notebooks/team/CHH/configs/config_finetune_kobart.yaml`

**íŠ¹ì§•**:
- KoBART ì „ìš© ìƒì„¸ ì„¤ì •
- 20 epoch ì¥ê¸° í•™ìŠµ
- Early stopping í¬í•¨
- ì™„ì „í•œ í•œê¸€ ì£¼ì„

**í•µì‹¬ ì¶”ê°€ ì‚¬í•­**:
```yaml
training:
  early_stopping_patience: 3
  early_stopping_threshold: 0.001
  save_total_limit: 2
  load_best_model_at_end: true
```

**ì¥ì **:
- ë² ì´ìŠ¤ë¼ì¸ë³´ë‹¤ ì•ˆì •ì 
- Early stoppingìœ¼ë¡œ ê³¼ì í•© ë°©ì§€
- ì¬í˜„ì„± ë†’ìŒ

**ë‹¨ì **:
- ì—¬ì „íˆ KoBART ì „ìš©
- ë‹¨ì¼ ëª¨ë¸ í•œì •

### 3. Full Pipeline Config
**íŒŒì¼**: `notebooks/team/CHH/configs/config_full_pipeline.yaml`

**íŠ¹ì§•**:
- ê°€ì¥ í¬ê´„ì ì¸ ì„¤ì •
- ëª¨ë“  PRD ì „ëµ í†µí•©
- LLM + Encoder-Decoder ì§€ì›
- ë°ì´í„° ì¦ê°•, ì•™ìƒë¸”, êµì°¨ê²€ì¦, Optuna í¬í•¨

**í•µì‹¬ êµ¬ì¡°**:
```yaml
experiment:
  name: "full_pipeline"
  use_wandb: true

models:  # ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›
  - name: "kobart"
    type: "encoder_decoder"
  - name: "llama"
    type: "causal_lm"

data_augmentation:
  methods: ["backtranslation", "paraphrase"]

cross_validation:
  use_kfold: true
  n_splits: 5

ensemble:
  strategy: "weighted_average"

optuna:
  n_trials: 20
```

**ì¥ì **:
- ëª¨ë“  ì „ëµ í¬í•¨
- ê³ ë„ë¡œ ì„¤ì • ê°€ëŠ¥
- í”„ë¡œë•ì…˜ ë ˆë²¨

**ë‹¨ì **:
- ë³µì¡ë„ ë†’ìŒ
- ì´ˆê¸° í•™ìŠµ ê³¡ì„  ê°€íŒŒë¦„
- ì‹¤í—˜ ì‹œê°„ ê¸¸ì–´ì§

### 4. LLM Fine-tuning Config (ê²€ì¦ ì™„ë£Œ)
**íŒŒì¼**: `docs/ì°¸ê³ /finetune_config.yaml`

**íŠ¹ì§•**:
- QLoRA 4-bit ì–‘ìí™” ì„¤ì •
- ëª¨ë¸ë³„ ìµœì í™” íŒŒë¼ë¯¸í„°
- Chat template í† í° ìë™ ì¶”ê°€
- WandB êµ¬ì¡°í™” ë¡œê¹…

**ê²€ì¦ëœ ì„±ëŠ¥**:
```yaml
# KoBART: ROUGE Sum 94.51
# Llama-3.2-Korean-3B: ì§„í–‰ ì¤‘ (ëª©í‘œ 95+)

models:
  - model_name: "Bllossom/llama-3.2-Korean-Bllossom-3B"
    learning_rate: 2.0e-5     # ê²€ì¦ëœ LLM í•™ìŠµë¥ 
    batch_size: 8             # QLoRA 4-bit ìµœì ê°’
    lora_dropout: 0.05        # ê³¼ì í•© ë°©ì§€
    use_bf16: true            # Llama ê¶Œì¥ dtype

tokenizer:
  encoder_max_len: 1024       # Prompt truncation 0.11% (512ëŠ” 6.07%)
  decoder_max_len: 200        # ì—¬ìœ  í™•ë³´

lora:
  r: 16
  lora_alpha: 32
  target_modules:             # Attention + MLP ëª¨ë‘ í¬í•¨
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj

training:
  num_train_epochs: 3         # LLMì€ 3 epoch ì¶©ë¶„
  gradient_accumulation_steps: 8
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"
  max_grad_norm: 1.2
  weight_decay: 0.1
```

**ì¥ì **:
- ì‹¤ì „ ê²€ì¦ëœ íŒŒë¼ë¯¸í„°
- ì¹˜ëª…ì  ì´ìŠˆ í•´ê²° (Prompt truncation, Chat template ë“±)
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

## ğŸ—ï¸ ì´ˆê¸° ëª¨ë“ˆí™”ë¥¼ ìœ„í•œ Config êµ¬ì¡° ì „ëµ

### ì „ëµ 1: ê³„ì¸µì  Config ì‹œìŠ¤í…œ (ê¶Œì¥)

```
configs/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ default.yaml              # ê³µí†µ ê¸°ë³¸ ì„¤ì •
â”‚   â”œâ”€â”€ encoder_decoder.yaml      # Encoder-Decoder ê³µí†µ
â”‚   â””â”€â”€ causal_lm.yaml            # Causal LM ê³µí†µ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ kobart.yaml               # KoBART ì „ìš©
â”‚   â”œâ”€â”€ llama_3.2_3b.yaml         # Llama-3.2-3B ì „ìš©
â”‚   â”œâ”€â”€ qwen3_4b.yaml             # Qwen3-4B ì „ìš©
â”‚   â””â”€â”€ qwen2.5_7b.yaml           # Qwen2.5-7B ì „ìš©
â”œâ”€â”€ strategies/
â”‚   â”œâ”€â”€ data_augmentation.yaml    # ë°ì´í„° ì¦ê°•
â”‚   â”œâ”€â”€ ensemble.yaml             # ì•™ìƒë¸”
â”‚   â”œâ”€â”€ cross_validation.yaml     # êµì°¨ê²€ì¦
â”‚   â””â”€â”€ optuna.yaml               # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline_kobart.yaml      # ì‹¤í—˜ 1: ë² ì´ìŠ¤ë¼ì¸
â”‚   â”œâ”€â”€ llama_finetune.yaml       # ì‹¤í—˜ 2: Llama íŒŒì¸íŠœë‹
â”‚   â”œâ”€â”€ multi_model.yaml          # ì‹¤í—˜ 3: ë‹¤ì¤‘ ëª¨ë¸
â”‚   â””â”€â”€ full_pipeline.yaml        # ì‹¤í—˜ 4: ì „ì²´ íŒŒì´í”„ë¼ì¸
â””â”€â”€ inference/
    â””â”€â”€ production.yaml            # í”„ë¡œë•ì…˜ ì¶”ë¡  ì„¤ì •
```

### ì „ëµ 2: Config ë³‘í•© ë©”ì»¤ë‹ˆì¦˜

```python
# config_loader.py
from omegaconf import OmegaConf

def load_config(experiment_config_path):
    """
    ê³„ì¸µì  Config ë³‘í•©

    ì‹¤í–‰ ìˆœì„œ:
    1. base/default.yaml ë¡œë“œ
    2. base/{model_type}.yaml ë¡œë“œ ë° ë³‘í•©
    3. models/{model_name}.yaml ë¡œë“œ ë° ë³‘í•©
    4. strategies/*.yaml ë¡œë“œ ë° ë³‘í•© (í™œì„±í™”ëœ ì „ëµë§Œ)
    5. experiments/{experiment}.yaml ë¡œë“œ ë° ë³‘í•©
    """
    # 1. ê¸°ë³¸ ì„¤ì •
    base_config = OmegaConf.load("configs/base/default.yaml")

    # 2. ì‹¤í—˜ ì„¤ì •
    exp_config = OmegaConf.load(experiment_config_path)

    # 3. ëª¨ë¸ íƒ€ì…ë³„ ì„¤ì •
    model_type = exp_config.model.type
    type_config = OmegaConf.load(f"configs/base/{model_type}.yaml")

    # 4. ëª¨ë¸ë³„ ì„¤ì •
    model_name = exp_config.model.name
    model_config = OmegaConf.load(f"configs/models/{model_name}.yaml")

    # 5. ì „ëµ ì„¤ì • (í™œì„±í™”ëœ ê²ƒë§Œ)
    strategy_configs = []
    if exp_config.get('data_augmentation', {}).get('enabled', False):
        strategy_configs.append(OmegaConf.load("configs/strategies/data_augmentation.yaml"))
    if exp_config.get('ensemble', {}).get('enabled', False):
        strategy_configs.append(OmegaConf.load("configs/strategies/ensemble.yaml"))

    # 6. ë³‘í•© (ë‚˜ì¤‘ ê²ƒì´ ìš°ì„ )
    merged = OmegaConf.merge(
        base_config,
        type_config,
        model_config,
        *strategy_configs,
        exp_config
    )

    return merged
```

### ì „ëµ 3: ë‹¨ê³„ë³„ Config ë„ì… ë¡œë“œë§µ

#### Phase 1: ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ (1-3ì¼)
**ëª©í‘œ**: ëŒ€íšŒ ë² ì´ìŠ¤ë¼ì¸ ì¬í˜„

**ì‚¬ìš© Config**:
- `configs/experiments/baseline_kobart.yaml` (ë‹¨ì¼ íŒŒì¼)

**ë‚´ìš©**:
```yaml
general:
  model_name: digit82/kobart-summarization
  seed: 42

tokenizer:
  encoder_max_len: 512
  decoder_max_len: 100

training:
  learning_rate: 1.0e-05
  per_device_train_batch_size: 50
  num_train_epochs: 20

inference:
  no_repeat_ngram_size: 2
  num_beams: 4
```

**ê²€ì¦ ëª©í‘œ**: ROUGE Sum â‰¥ 94.51

#### Phase 2: ë‹¨ì¼ ëª¨ë¸ ìµœì í™” (4-7ì¼)
**ëª©í‘œ**: KoBART ì„±ëŠ¥ ê·¹ëŒ€í™” + LLM íŒŒì¸íŠœë‹ ì‹œì‘

**ì‚¬ìš© Config**:
- `configs/base/default.yaml` (ê³µí†µ)
- `configs/base/encoder_decoder.yaml` (íƒ€ì…ë³„)
- `configs/base/causal_lm.yaml` (íƒ€ì…ë³„)
- `configs/models/kobart.yaml` (ëª¨ë¸ë³„)
- `configs/models/llama_3.2_3b.yaml` (ëª¨ë¸ë³„)
- `configs/experiments/kobart_optimized.yaml` (ì‹¤í—˜)
- `configs/experiments/llama_finetune.yaml` (ì‹¤í—˜)

**ì¶”ê°€ ê¸°ëŠ¥**:
- Early stopping
- Learning rate scheduler
- Gradient accumulation
- WandB í†µí•©

**ê²€ì¦ ëª©í‘œ**: KoBART â‰¥ 95, Llama â‰¥ 95

#### Phase 3: ì „ëµ í†µí•© (8-12ì¼)
**ëª©í‘œ**: ë°ì´í„° ì¦ê°• + êµì°¨ê²€ì¦ ì ìš©

**ì¶”ê°€ Config**:
- `configs/strategies/data_augmentation.yaml`
- `configs/strategies/cross_validation.yaml`

**ê²€ì¦ ëª©í‘œ**: ROUGE Sum â‰¥ 96-97

#### Phase 4: ì•™ìƒë¸” ë° ìµœì í™” (13-15ì¼)
**ëª©í‘œ**: ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” + Optuna

**ì¶”ê°€ Config**:
- `configs/strategies/ensemble.yaml`
- `configs/strategies/optuna.yaml`
- `configs/experiments/multi_model.yaml`
- `configs/experiments/full_pipeline.yaml`

**ê²€ì¦ ëª©í‘œ**: ROUGE Sum â‰¥ 98-100

## ğŸ“‹ Config íŒŒì¼ êµ¬ì¡° í‘œì¤€

### 1. Base Config (default.yaml)
```yaml
experiment:
  name: "default"
  seed: 42
  use_wandb: false
  wandb_project: "dialogue-summarization"
  wandb_entity: null

paths:
  train_data: "data/train.csv"
  dev_data: "data/dev.csv"
  test_data: "data/test.csv"
  output_dir: "outputs"
  model_save_dir: "models"

logging:
  log_level: "INFO"
  log_dir: "logs"
  save_steps: 100
  logging_steps: 10

strategies:
  data_augmentation: false
  cross_validation: false
  ensemble: false
  optuna: false
```

### 2. Model Type Config (encoder_decoder.yaml)
```yaml
model:
  type: "encoder_decoder"
  architecture: "bart"

tokenizer:
  encoder_max_len: 512
  decoder_max_len: 100
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#Person4#'
    - '#Person5#'
    - '#Person6#'
    - '#Person7#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

training:
  learning_rate: 1.0e-05
  per_device_train_batch_size: 50
  per_device_eval_batch_size: 32
  num_train_epochs: 20
  warmup_ratio: 0.1
  weight_decay: 0.01
  lr_scheduler_type: "cosine"
  optim: "adamw_torch"
  gradient_accumulation_steps: 1
  fp16: true
  gradient_checkpointing: false
  max_grad_norm: 1.0

  early_stopping_patience: 3
  early_stopping_threshold: 0.001

  save_strategy: "epoch"
  save_total_limit: 2
  load_best_model_at_end: true
  metric_for_best_model: "rouge_sum"
  greater_is_better: true

inference:
  batch_size: 32
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  generate_max_length: 100
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

evaluation:
  strategy: "epoch"
  metric: "rouge"
```

### 3. Model Specific Config (kobart.yaml)
```yaml
model:
  name: "kobart"
  checkpoint: "digit82/kobart-summarization"
  type: "encoder_decoder"
  architecture: "bart"

training:
  per_device_train_batch_size: 50
  learning_rate: 1.0e-05

inference:
  no_repeat_ngram_size: 2
```

### 4. Model Specific Config (llama_3.2_3b.yaml)
```yaml
model:
  name: "llama_3.2_3b"
  checkpoint: "Bllossom/llama-3.2-Korean-Bllossom-3B"
  type: "causal_lm"
  architecture: "llama"

  quantization:
    load_in_4bit: true
    bnb_4bit_use_double_quant: true
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_compute_dtype: "bfloat16"

  lora:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    bias: "none"
    task_type: "CAUSAL_LM"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"

tokenizer:
  encoder_max_len: 1024
  decoder_max_len: 200
  chat_template_type: "llama"
  chat_template_tokens:
    - "<|start_header_id|>"
    - "<|end_header_id|>"
    - "<|eot_id|>"

training:
  num_train_epochs: 3
  learning_rate: 2.0e-05
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 8

  optim: "paged_adamw_32bit"
  weight_decay: 0.1
  max_grad_norm: 1.2
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"

  bf16: true
  fp16: false
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false

  early_stopping_patience: 2
  metric_for_best_model: "eval_loss"
  greater_is_better: false

generation:
  max_new_tokens: 150
  min_new_tokens: 10
  do_sample: true
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  no_repeat_ngram_size: 3
  repetition_penalty: 1.1
```

### 5. Strategy Config (data_augmentation.yaml)
```yaml
data_augmentation:
  enabled: true

  methods:
    backtranslation:
      enabled: true
      model: "Helsinki-NLP/opus-mt-ko-en"
      ratio: 0.3

    paraphrase:
      enabled: true
      model: "beomi/KcELECTRA-base-v2022"
      ratio: 0.3

    dialogue_sampling:
      enabled: true
      min_turns: 3
      max_turns: 10
      ratio: 0.2

    synonym_replacement:
      enabled: false
      ratio: 0.1

  augmentation_factor: 2.0
  preserve_original: true

  cache_augmented: true
  cache_dir: "data/augmented_cache"
```

### 6. Experiment Config (baseline_kobart.yaml)
```yaml
experiment:
  name: "baseline_kobart"
  description: "ëŒ€íšŒ ë² ì´ìŠ¤ë¼ì¸ ì¬í˜„ ì‹¤í—˜"
  seed: 42
  use_wandb: true
  wandb_project: "dialogue-summarization"
  wandb_tags: ["baseline", "kobart"]

model:
  name: "kobart"
  checkpoint: "digit82/kobart-summarization"

strategies:
  data_augmentation: false
  cross_validation: false
  ensemble: false
  optuna: false

paths:
  output_dir: "outputs/baseline_kobart"
  model_save_dir: "models/baseline_kobart"
```

## ğŸ”§ Config ë¡œë” êµ¬í˜„ ì˜ˆì œ

### 1. ê¸°ë³¸ ë¡œë”
```python
# src/config/loader.py
from omegaconf import OmegaConf
from pathlib import Path
from typing import Dict, Any

class ConfigLoader:
    """ê³„ì¸µì  Config ë¡œë”"""

    def __init__(self, config_root: str = "configs"):
        self.config_root = Path(config_root)

    def load_base(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ë¡œë“œ"""
        return OmegaConf.load(self.config_root / "base" / "default.yaml")

    def load_model_type(self, model_type: str) -> Dict[str, Any]:
        """ëª¨ë¸ íƒ€ì…ë³„ ì„¤ì • ë¡œë“œ"""
        path = self.config_root / "base" / f"{model_type}.yaml"
        if path.exists():
            return OmegaConf.load(path)
        return {}

    def load_model(self, model_name: str) -> Dict[str, Any]:
        """ëª¨ë¸ë³„ ì„¤ì • ë¡œë“œ"""
        path = self.config_root / "models" / f"{model_name}.yaml"
        if path.exists():
            return OmegaConf.load(path)
        return {}

    def load_strategy(self, strategy_name: str) -> Dict[str, Any]:
        """ì „ëµ ì„¤ì • ë¡œë“œ"""
        path = self.config_root / "strategies" / f"{strategy_name}.yaml"
        if path.exists():
            return OmegaConf.load(path)
        return {}

    def load_experiment(self, experiment_name: str) -> Dict[str, Any]:
        """ì‹¤í—˜ ì„¤ì • ë¡œë“œ"""
        path = self.config_root / "experiments" / f"{experiment_name}.yaml"
        return OmegaConf.load(path)

    def merge_configs(self, experiment_name: str) -> OmegaConf:
        """ëª¨ë“  Configë¥¼ ê³„ì¸µì ìœ¼ë¡œ ë³‘í•©"""
        exp_config = self.load_experiment(experiment_name)
        configs = [self.load_base()]

        model_type = exp_config.get('model', {}).get('type', 'encoder_decoder')
        configs.append(self.load_model_type(model_type))

        model_name = exp_config.get('model', {}).get('name', '')
        if model_name:
            configs.append(self.load_model(model_name))

        strategies = exp_config.get('strategies', {})
        for strategy_name, enabled in strategies.items():
            if enabled:
                configs.append(self.load_strategy(strategy_name))

        configs.append(exp_config)
        merged = OmegaConf.merge(*configs)

        return merged
```

### 2. CLI ì¸í„°í˜ì´ìŠ¤
```python
# train.py
import argparse
from src.config.loader import ConfigLoader

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--config',
        type=str,
        required=True,
        help='ì‹¤í—˜ config ì´ë¦„'
    )
    parser.add_argument(
        '--override',
        type=str,
        nargs='*',
        help='ì˜¤ë²„ë¼ì´ë“œ ì„¤ì •'
    )
    args = parser.parse_args()

    loader = ConfigLoader()
    config = loader.merge_configs(args.config)

    if args.override:
        overrides = OmegaConf.from_dotlist(args.override)
        config = OmegaConf.merge(config, overrides)

    trainer = Trainer(config)
    trainer.train()
```

## ğŸ’¡ Config ì„¤ê³„ Best Practices

### 1. ëª…í™•í•œ êµ¬ë¶„
```yaml
experiment:
  name: "baseline"

model:
  name: "kobart"

training:
  learning_rate: 1e-5
```

### 2. ê²€ì¦ëœ ê¸°ë³¸ê°’
```yaml
training:
  learning_rate: 1.0e-05
  per_device_train_batch_size: 50
```

### 3. ì¡°ê±´ë¶€ ì„¤ì •
```yaml
strategies:
  data_augmentation: false
  ensemble: false

data_augmentation:
  enabled: false
  methods: [...]
```

### 4. íƒ€ì… íŒíŠ¸ (ì£¼ì„)
```yaml
training:
  learning_rate: 1.0e-05
  per_device_train_batch_size: 50
  num_train_epochs: 20
```

## ğŸš€ ì‹¤í–‰ ê³„íš

### Week 1
- [x] Config íŒŒì¼ ë¶„ì„ ì™„ë£Œ
- [ ] ê³„ì¸µì  Config êµ¬ì¡° ì„¤ê³„
- [ ] `configs/base/` ì‘ì„±
- [ ] `configs/models/` ì‘ì„±
- [ ] `configs/experiments/baseline_kobart.yaml` ì‘ì„±
- [ ] ConfigLoader êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸

### Week 2
- [ ] ë² ì´ìŠ¤ë¼ì¸ ì¬í˜„
- [ ] `configs/base/causal_lm.yaml` ì‘ì„±
- [ ] `configs/models/llama_3.2_3b.yaml` ì‘ì„±
- [ ] `configs/experiments/llama_finetune.yaml` ì‘ì„±
- [ ] Llama íŒŒì¸íŠœë‹ ì‹œì‘

### Week 3
- [ ] `configs/strategies/` ì‘ì„±
- [ ] `configs/experiments/multi_model.yaml` ì‘ì„±
- [ ] `configs/experiments/full_pipeline.yaml` ì‘ì„±
- [ ] ìµœì¢… ì•™ìƒë¸” ì‹¤í—˜

## ğŸ“Š ì˜ˆìƒ íš¨ê³¼

### ì¬í˜„ì„±
ì™„ë²½í•œ ì¬í˜„ ê°€ëŠ¥

### ì‹¤í—˜ ì†ë„
Config ë³€ê²½ìœ¼ë¡œ ì¦‰ì‹œ ì‹¤í–‰

### ìœ ì§€ë³´ìˆ˜ì„±
ì¤‘ì•™ ì§‘ì¤‘ì‹ Config ê´€ë¦¬

### í˜‘ì—…
Config íŒŒì¼ë§Œ ê³µìœ 

## ğŸ”¥ í•µì‹¬ ê¶Œì¥ì‚¬í•­

1. ë‹¨ê³„ì  ë„ì…
2. ê²€ì¦ ìš°ì„ 
3. ë¬¸ì„œí™”
4. ë²„ì „ ê´€ë¦¬
5. ë„¤ì´ë° ê·œì¹™
