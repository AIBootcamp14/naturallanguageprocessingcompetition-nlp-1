# 교차 검증 시스템 상세 가이드

## 📋 목차
1. [개요](#개요)
2. [KFoldSplitter](#kfoldsplitter)
3. [사용 방법](#사용-방법)
4. [실행 명령어](#실행-명령어)

---

## 📝 개요

### 목적
- K-Fold 교차 검증으로 모델 일반화 성능 평가
- Stratified K-Fold 지원 (층화 추출)
- Fold 결과 집계 및 통계 분석

### 핵심 기능
- ✅ K-Fold 분할
- ✅ Stratified K-Fold 분할 (대화 길이/토픽 기반)
- ✅ Fold 결과 집계
- ✅ 데이터 무결성 보장

---

## 🏗️ KFoldSplitter

### 파일 위치
```
src/validation/kfold.py
```

### 클래스 구조

```python
class KFoldSplitter:
    def __init__(n_splits=5, shuffle=True, random_state=42, stratified=False)
    def split(data, stratify_column=None)
```

### 주요 기능

#### 1. 기본 K-Fold

```python
from src.validation.kfold import KFoldSplitter

splitter = KFoldSplitter(n_splits=5, shuffle=True, random_state=42)

folds = splitter.split(data)
# 결과: [(train_df1, val_df1), (train_df2, val_df2), ...]
```

**특징:**
- 데이터를 K개 fold로 균등 분할
- 각 fold에서 K-1개는 학습, 1개는 검증
- 모든 데이터가 정확히 한 번씩 검증에 사용됨

**예시 (100개 데이터, 5-Fold):**
```
Fold 1: 학습 80개, 검증 20개 (index 0-19)
Fold 2: 학습 80개, 검증 20개 (index 20-39)
Fold 3: 학습 80개, 검증 20개 (index 40-59)
Fold 4: 학습 80개, 검증 20개 (index 60-79)
Fold 5: 학습 80개, 검증 20개 (index 80-99)
```

---

#### 2. Stratified K-Fold (층화 추출)

```python
splitter = KFoldSplitter(
    n_splits=5,
    shuffle=True,
    random_state=42,
    stratified=True
)

# 대화 길이 기반 층화
folds = splitter.split(data, stratify_column='length')

# 토픽 기반 층화
folds = splitter.split(data, stratify_column='topic')
```

**층화 기준:**

1. **대화 길이 (`stratify_column='length'`)**
   - 대화 길이를 4분위로 나눔
   - 각 fold에 모든 길이 범위의 데이터 고르게 분포

2. **토픽 (`stratify_column='topic'`)**
   - 데이터에 'topic' 컬럼 존재 시
   - 각 fold에 모든 토픽이 균등하게 분포

**효과:**
- 각 fold가 전체 데이터 분포를 대표
- 검증 결과의 안정성 향상

---

## 💻 사용 방법

### 1. 편의 함수 사용 (추천)

```python
from src.validation.kfold import create_kfold_splits
import pandas as pd

# 데이터 로드
train_df = pd.read_csv("data/raw/train.csv")

# 5-Fold 분할
folds = create_kfold_splits(
    data=train_df,
    n_splits=5,
    stratified=False
)

# 각 fold로 학습 및 평가
for fold_idx, (train_fold, val_fold) in enumerate(folds):
    print(f"\n=== Fold {fold_idx + 1}/{len(folds)} ===")
    print(f"학습 데이터: {len(train_fold)}개")
    print(f"검증 데이터: {len(val_fold)}개")

    # 모델 학습
    # model.train(train_fold)

    # 모델 평가
    # metrics = model.evaluate(val_fold)
```

---

### 2. 층화 추출 사용

```python
from src.validation.kfold import create_kfold_splits

# 대화 길이 기반 층화
folds = create_kfold_splits(
    data=train_df,
    n_splits=5,
    stratified=True,
    stratify_column='length'  # 자동으로 대화 길이 4분위 계산
)
```

---

### 3. Fold 결과 집계

```python
from src.validation.kfold import aggregate_fold_results

# 각 fold 평가 결과 저장
fold_results = []

for fold_idx, (train_fold, val_fold) in enumerate(folds):
    # 모델 학습 및 평가
    metrics = {
        'rouge1': 0.85,
        'rouge2': 0.75,
        'rougeL': 0.80
    }
    fold_results.append(metrics)

# 결과 집계
aggregated = aggregate_fold_results(fold_results)

print(f"ROUGE-1: {aggregated['rouge1_mean']:.4f} (±{aggregated['rouge1_std']:.4f})")
print(f"  - Min: {aggregated['rouge1_min']:.4f}")
print(f"  - Max: {aggregated['rouge1_max']:.4f}")
```

**집계 결과:**
```
{
    'rouge1_mean': 0.8600,
    'rouge1_std': 0.0141,
    'rouge1_min': 0.8400,
    'rouge1_max': 0.8800,
    'rouge2_mean': 0.7600,
    'rouge2_std': 0.0141,
    ...
}
```

---

### 4. 전체 교차 검증 파이프라인

```python
from src.config import load_config
from src.validation.kfold import create_kfold_splits, aggregate_fold_results
from src.models.model_loader import load_model_and_tokenizer
from src.data.preprocessor import create_dataset
from src.training.trainer import create_trainer
from src.evaluation.metrics import compute_metrics
import pandas as pd

# 1. Config 로드
config = load_config("baseline_kobart")

# 2. 데이터 로드
train_df = pd.read_csv(config.data.train_path)

# 3. K-Fold 분할
folds = create_kfold_splits(
    data=train_df,
    n_splits=5,
    stratified=True,
    stratify_column='length'
)

# 4. 각 fold로 학습 및 평가
fold_results = []

for fold_idx, (train_fold, val_fold) in enumerate(folds):
    print(f"\n{'='*60}")
    print(f"Fold {fold_idx + 1}/{len(folds)}")
    print(f"{'='*60}")

    # 모델 초기화
    model, tokenizer = load_model_and_tokenizer(config)

    # Dataset 생성
    train_dataset = create_dataset(
        train_fold['dialogue'].tolist(),
        train_fold['summary'].tolist(),
        tokenizer,
        config
    )

    val_dataset = create_dataset(
        val_fold['dialogue'].tolist(),
        val_fold['summary'].tolist(),
        tokenizer,
        config
    )

    # Trainer 생성
    trainer = create_trainer(
        config,
        model,
        tokenizer,
        train_dataset,
        val_dataset
    )

    # 학습
    trainer.train()

    # 평가
    eval_results = trainer.evaluate()
    fold_results.append(eval_results)

# 5. 결과 집계
aggregated = aggregate_fold_results(fold_results)

print(f"\n{'='*60}")
print("교차 검증 최종 결과")
print(f"{'='*60}")
print(f"ROUGE-1: {aggregated['rouge1_mean']:.4f} (±{aggregated['rouge1_std']:.4f})")
print(f"ROUGE-2: {aggregated['rouge2_mean']:.4f} (±{aggregated['rouge2_std']:.4f})")
print(f"ROUGE-L: {aggregated['rougeL_mean']:.4f} (±{aggregated['rougeL_std']:.4f})")
```

---

## 🔧 실행 명령어

### Config 설정

**파일:** `configs/experiments/baseline_kobart.yaml`

```yaml
validation:
  use_kfold: true
  n_splits: 5
  stratified: true
  stratify_column: 'length'  # 대화 길이 기반 층화
```

---

### 학습 스크립트에 통합

교차 검증을 지원하는 학습 스크립트 (예시):

```bash
# K-Fold 교차 검증 실행
python scripts/train_with_cv.py --experiment baseline_kobart --n_splits 5
```

---

## 🧪 테스트

### 테스트 파일 위치
```
src/tests/test_kfold.py
```

### 테스트 실행

```bash
python src/tests/test_kfold.py
```

### 테스트 항목 (총 6개)

1. ✅ KFoldSplitter 초기화
2. ✅ 기본 K-Fold 분할
3. ✅ Stratified K-Fold 분할
4. ✅ create_kfold_splits 함수
5. ✅ aggregate_fold_results 함수
6. ✅ Fold 데이터 무결성

**결과:** 6/6 테스트 통과 (100%)

---

## 📊 교차 검증 전략

### 1. Fold 수 선택

| Fold 수 | 학습 데이터 비율 | 검증 데이터 비율 | 특징 |
|---------|------------------|------------------|------|
| 3-Fold | 66.7% | 33.3% | 빠른 실행, 낮은 안정성 |
| 5-Fold | 80% | 20% | **권장: 균형잡힌 성능** |
| 10-Fold | 90% | 10% | 느린 실행, 높은 안정성 |

**권장: 5-Fold**
- 학습 데이터 충분 (80%)
- 실행 시간 적절
- 안정적인 평가

---

### 2. 층화 추출 사용 시기

**사용 권장:**
- ✅ 데이터 분포가 불균형한 경우
- ✅ 대화 길이 편차가 큰 경우
- ✅ 토픽/카테고리가 명확한 경우

**사용 불필요:**
- ❌ 데이터가 이미 균등하게 분포된 경우
- ❌ 데이터 크기가 매우 큰 경우 (>100K)

---

### 3. 실행 시간 고려

**예상 시간 (A6000 기준, KoBART):**

| Fold 수 | 데이터 | 에포크 | 예상 시간 |
|---------|--------|--------|-----------|
| 3-Fold | 12,457개 | 10 | ~10-15시간 |
| 5-Fold | 12,457개 | 10 | **~20-30시간** |
| 10-Fold | 12,457개 | 10 | ~40-60시간 |

**최적화 전략:**
- 에포크 수 줄이기 (20 → 10)
- Early stopping 사용
- 병렬 실행 (여러 GPU)

---

## 🎯 성능 향상 효과

### 교차 검증의 장점

1. **과적합 방지**
   - 모든 데이터로 검증
   - 특정 split에 의존하지 않음

2. **신뢰도 향상**
   - 평균 및 표준편차 제공
   - 모델 안정성 평가 가능

3. **하이퍼파라미터 튜닝**
   - 여러 fold 평균으로 최적값 선택
   - Overfitting 방지

---

### 예상 성능

**단일 Split vs 5-Fold CV:**

| 방법 | ROUGE-1 | ROUGE-2 | ROUGE-L |
|------|---------|---------|---------|
| 단일 Split | 88.5 | 77.2 | 86.8 |
| 5-Fold CV | **89.2 (±0.3)** | **78.1 (±0.4)** | **87.5 (±0.3)** |

**개선 효과:**
- 평균 성능 향상: +0.7 포인트
- 표준편차 확인으로 안정성 보장

---

## 🔗 관련 파일

**소스 코드:**
- `src/validation/kfold.py` - K-Fold 시스템
- `src/validation/__init__.py` - 패키지 초기화

**테스트:**
- `src/tests/test_kfold.py` - K-Fold 테스트

**문서:**
- `docs/모듈화/00_전체_시스템_개요.md` - 시스템 개요
- `docs/모듈화/실행_명령어_총정리.md` - 실행 명령어
