# 평가 및 최적화 시스템 가이드

> **통합 문서:** 평가 시스템 + K-Fold 교차 검증 + Optuna 최적화

## 📋 목차

### Part 1: 평가 시스템
- [개요](#part-1-평가-시스템)
- [RougeCalculator 클래스](#rougecalculator-클래스)
- [사용 방법](#평가-시스템-사용-방법)
- [Multi-reference 지원](#multi-reference-지원)
- [배치 계산](#배치-계산)
- [HuggingFace Trainer 통합](#huggingface-trainer-통합)

### Part 2: K-Fold 교차 검증
- [개요](#part-2-k-fold-교차-검증)
- [KFoldSplitter](#kfoldsplitter)
- [사용 방법](#교차-검증-사용-방법)
- [실행 명령어](#교차-검증-실행-명령어)

### Part 3: Optuna 최적화
- [개요](#part-3-optuna-최적화)
- [OptunaOptimizer 클래스](#optunaoptimizer-클래스)
- [탐색 공간 정의](#탐색-공간-정의)
- [최적화 전략](#최적화-전략)
- [사용 방법](#optuna-사용-방법)
- [실행 명령어](#optuna-실행-명령어)

---

# 📌 Part 1: 평가 시스템

## 📝 개요

### 목적
- ROUGE 점수 자동 계산 (경진대회 평가 기준)
- Multi-reference 평가 지원
- 배치 계산 및 통계 정보 제공
- 학습/평가 시 자동 통합

### 핵심 기능
- ✅ ROUGE-1/2/L F1 점수 계산
- ✅ ROUGE Sum (경진대회 기준) 자동 계산
- ✅ Multi-reference 지원 (정답이 여러 개인 경우)
- ✅ 배치 계산 및 통계 (평균, 표준편차, 최소/최대)
- ✅ HuggingFace Trainer와 자동 통합

---

## 🏗️ RougeCalculator 클래스

### 파일 위치
```
src/evaluation/metrics.py
```

### 클래스 구조

```python
class RougeCalculator:
    def __init__(self, rouge_types=['rouge1', 'rouge2', 'rougeL'], use_stemmer=False):
        """ROUGE 계산기 초기화"""

    def calculate_single(self, prediction: str, reference: Union[str, List[str]]) -> Dict:
        """단일 샘플 ROUGE 계산"""

    def calculate_batch(self, predictions: List[str], references: List[str]) -> Dict:
        """배치 샘플 ROUGE 평균 계산"""

    def _empty_scores(self) -> Dict:
        """빈 입력에 대한 기본 점수 반환"""
```

---

## 💻 평가 시스템 사용 방법

### 1. 기본 사용법 (단일 샘플)

```python
from src.evaluation import RougeCalculator

# ROUGE 계산기 초기화
calculator = RougeCalculator()

# 단일 샘플 평가
prediction = "두 사람이 저녁 약속을 잡았다"
reference = "두 사람이 저녁 식사 약속을 정했다"

scores = calculator.calculate_single(prediction, reference)

print(scores)
# 출력:
# {
#     'rouge1': {'precision': 0.75, 'recall': 0.667, 'fmeasure': 0.706},
#     'rouge2': {'precision': 0.5, 'recall': 0.4, 'fmeasure': 0.444},
#     'rougeL': {'precision': 0.75, 'recall': 0.667, 'fmeasure': 0.706}
# }
```

### 2. 편의 함수 사용

```python
from src.evaluation import calculate_rouge_scores

# 단일 샘플
scores = calculate_rouge_scores(
    predictions="예측 요약",
    references="정답 요약"
)

# 배치 샘플
predictions = ["예측1", "예측2", "예측3"]
references = ["정답1", "정답2", "정답3"]

scores = calculate_rouge_scores(predictions, references)
```

### 3. 점수 포맷팅

```python
from src.evaluation import calculate_rouge_scores, format_rouge_scores

scores = calculate_rouge_scores(predictions, references)
print(format_rouge_scores(scores))

# 출력:
# ROUGE1:
#   fmeasure: 0.7060
#   std: 0.1200
#   min: 0.5500
#   max: 0.8500
#
# ROUGE2:
#   fmeasure: 0.4440
#   ...
```

---

## 🔄 Multi-reference 지원

### 개요

하나의 대화에 대해 여러 개의 정답 요약이 있을 수 있습니다. Multi-reference 평가는 각 정답에 대해 ROUGE를 계산한 후 **최대 F1 점수**를 선택합니다.

### 사용 방법

```python
from src.evaluation import RougeCalculator

calculator = RougeCalculator()

# 단일 예측, 다중 정답
prediction = "두 사람이 저녁 약속을 잡았다"
references = [
    "두 사람이 저녁 식사 약속을 정했다",
    "저녁에 만나기로 했다",
    "저녁 약속을 잡았다"
]

scores = calculator.calculate_single(prediction, references)
```

### 처리 과정

1. **각 정답에 대해 ROUGE 계산**
   ```python
   for ref in references:
       score = scorer.score(prediction, ref)
       all_scores.append(score)
   ```

2. **최대 F1 점수 선택**
   ```python
   max_score = max(all_scores, key=lambda x: x['rouge1'].fmeasure)
   ```

3. **결과 반환**
   ```python
   {
       'rouge1': {'precision': 1.0, 'recall': 1.0, 'fmeasure': 1.0},  # "저녁 약속을 잡았다"와 완전 일치
       'rouge2': {...},
       'rougeL': {...}
   }
   ```

---

## 📊 배치 계산

### 기본 사용법

```python
from src.evaluation import RougeCalculator

calculator = RougeCalculator()

predictions = [
    "두 사람이 저녁 약속을 잡았다",
    "회의 시간을 3시로 정했다",
    "내일 점심 메뉴는 김치찌개다"
]

references = [
    "두 사람이 저녁 식사 약속을 정했다",
    "회의를 오후 3시에 하기로 했다",
    "내일 점심은 김치찌개를 먹기로 했다"
]

scores = calculator.calculate_batch(predictions, references)
```

### 출력 형식

```python
{
    'rouge1': {
        'fmeasure': 0.7060,      # 평균 F1 점수
        'std': 0.1200,           # 표준편차
        'min': 0.5500,           # 최소값
        'max': 0.8500            # 최대값
    },
    'rouge2': {
        'fmeasure': 0.4440,
        'std': 0.0800,
        'min': 0.3000,
        'max': 0.6000
    },
    'rougeL': {
        'fmeasure': 0.7060,
        'std': 0.1200,
        'min': 0.5500,
        'max': 0.8500
    },
    'rouge_sum': {               # ROUGE-1 + ROUGE-2 + ROUGE-L
        'fmeasure': 1.8560,
        'std': 0.0,
        'min': 0.0,
        'max': 0.0
    }
}
```

### ROUGE Sum (경진대회 기준)

경진대회에서는 ROUGE-1, ROUGE-2, ROUGE-L의 F1 점수 합계를 최종 평가 지표로 사용합니다:

```python
rouge_sum = rouge1_f1 + rouge2_f1 + rougeL_f1
# 예: 0.706 + 0.444 + 0.706 = 1.856
```

---

## 🔗 HuggingFace Trainer 통합

### ModelTrainer에서 자동 사용

`src/training/trainer.py`의 `ModelTrainer` 클래스는 자동으로 ROUGE를 계산합니다:

```python
from src.training import create_trainer

trainer = create_trainer(
    config=config,
    model=model,
    tokenizer=tokenizer,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

# 학습 중 자동으로 ROUGE 계산
results = trainer.train()

# 평가 결과
print(results['eval_metrics'])
# {
#     'eval_rouge1': 0.706,
#     'eval_rouge2': 0.444,
#     'eval_rougeL': 0.706,
#     'eval_rouge_sum': 1.856
# }
```

### compute_metrics 함수

Trainer에서 사용하는 평가 함수:

```python
def compute_metrics(self, eval_preds) -> Dict[str, float]:
    """평가 메트릭 계산 (ROUGE)"""
    predictions, labels = eval_preds

    # -100을 패딩 토큰으로 변경
    labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)

    # 디코딩
    decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)
    decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)

    # ROUGE 계산
    scores = self.rouge_calculator.calculate_batch(
        decoded_preds,
        decoded_labels
    )

    # 결과 포맷팅
    result = {
        'rouge1': scores['rouge1']['fmeasure'],
        'rouge2': scores['rouge2']['fmeasure'],
        'rougeL': scores['rougeL']['fmeasure'],
        'rouge_sum': scores['rouge_sum']['fmeasure']
    }

    return result
```

---

# 📌 Part 2: K-Fold 교차 검증

## 📝 개요

### 목적
- K-Fold 교차 검증으로 모델 일반화 성능 평가
- Stratified K-Fold 지원 (층화 추출)
- Fold 결과 집계 및 통계 분석

### 핵심 기능
- ✅ K-Fold 분할
- ✅ Stratified K-Fold 분할 (대화 길이/토픽 기반)
- ✅ Fold 결과 집계
- ✅ 데이터 무결성 보장

---

## 🏗️ KFoldSplitter

### 파일 위치
```
src/validation/kfold.py
```

### 클래스 구조

```python
class KFoldSplitter:
    def __init__(n_splits=5, shuffle=True, random_state=42, stratified=False)
    def split(data, stratify_column=None)
```

### 주요 기능

#### 1. 기본 K-Fold

```python
from src.validation.kfold import KFoldSplitter

splitter = KFoldSplitter(n_splits=5, shuffle=True, random_state=42)

folds = splitter.split(data)
# 결과: [(train_df1, val_df1), (train_df2, val_df2), ...]
```

**특징:**
- 데이터를 K개 fold로 균등 분할
- 각 fold에서 K-1개는 학습, 1개는 검증
- 모든 데이터가 정확히 한 번씩 검증에 사용됨

**예시 (100개 데이터, 5-Fold):**
```
Fold 1: 학습 80개, 검증 20개 (index 0-19)
Fold 2: 학습 80개, 검증 20개 (index 20-39)
Fold 3: 학습 80개, 검증 20개 (index 40-59)
Fold 4: 학습 80개, 검증 20개 (index 60-79)
Fold 5: 학습 80개, 검증 20개 (index 80-99)
```

---

#### 2. Stratified K-Fold (층화 추출)

```python
splitter = KFoldSplitter(
    n_splits=5,
    shuffle=True,
    random_state=42,
    stratified=True
)

# 대화 길이 기반 층화
folds = splitter.split(data, stratify_column='length')

# 토픽 기반 층화
folds = splitter.split(data, stratify_column='topic')
```

**층화 기준:**

1. **대화 길이 (`stratify_column='length'`)**
   - 대화 길이를 4분위로 나눔
   - 각 fold에 모든 길이 범위의 데이터 고르게 분포

2. **토픽 (`stratify_column='topic'`)**
   - 데이터에 'topic' 컬럼 존재 시
   - 각 fold에 모든 토픽이 균등하게 분포

**효과:**
- 각 fold가 전체 데이터 분포를 대표
- 검증 결과의 안정성 향상

---

## 💻 교차 검증 사용 방법

### 1. 편의 함수 사용 (추천)

```python
from src.validation.kfold import create_kfold_splits
import pandas as pd

# 데이터 로드
train_df = pd.read_csv("data/raw/train.csv")

# 5-Fold 분할
folds = create_kfold_splits(
    data=train_df,
    n_splits=5,
    stratified=False
)

# 각 fold로 학습 및 평가
for fold_idx, (train_fold, val_fold) in enumerate(folds):
    print(f"\n=== Fold {fold_idx + 1}/{len(folds)} ===")
    print(f"학습 데이터: {len(train_fold)}개")
    print(f"검증 데이터: {len(val_fold)}개")

    # 모델 학습
    # model.train(train_fold)

    # 모델 평가
    # metrics = model.evaluate(val_fold)
```

---

### 2. 층화 추출 사용

```python
from src.validation.kfold import create_kfold_splits

# 대화 길이 기반 층화
folds = create_kfold_splits(
    data=train_df,
    n_splits=5,
    stratified=True,
    stratify_column='length'  # 자동으로 대화 길이 4분위 계산
)
```

---

### 3. Fold 결과 집계

```python
from src.validation.kfold import aggregate_fold_results

# 각 fold 평가 결과 저장
fold_results = []

for fold_idx, (train_fold, val_fold) in enumerate(folds):
    # 모델 학습 및 평가
    metrics = {
        'rouge1': 0.85,
        'rouge2': 0.75,
        'rougeL': 0.80
    }
    fold_results.append(metrics)

# 결과 집계
aggregated = aggregate_fold_results(fold_results)

print(f"ROUGE-1: {aggregated['rouge1_mean']:.4f} (±{aggregated['rouge1_std']:.4f})")
print(f"  - Min: {aggregated['rouge1_min']:.4f}")
print(f"  - Max: {aggregated['rouge1_max']:.4f}")
```

**집계 결과:**
```
{
    'rouge1_mean': 0.8600,
    'rouge1_std': 0.0141,
    'rouge1_min': 0.8400,
    'rouge1_max': 0.8800,
    'rouge2_mean': 0.7600,
    'rouge2_std': 0.0141,
    ...
}
```

---

### 4. 전체 교차 검증 파이프라인

```python
from src.config import load_config
from src.validation.kfold import create_kfold_splits, aggregate_fold_results
from src.models.model_loader import load_model_and_tokenizer
from src.data.preprocessor import create_dataset
from src.training.trainer import create_trainer
from src.evaluation.metrics import compute_metrics
import pandas as pd

# 1. Config 로드
config = load_config("baseline_kobart")

# 2. 데이터 로드
train_df = pd.read_csv(config.data.train_path)

# 3. K-Fold 분할
folds = create_kfold_splits(
    data=train_df,
    n_splits=5,
    stratified=True,
    stratify_column='length'
)

# 4. 각 fold로 학습 및 평가
fold_results = []

for fold_idx, (train_fold, val_fold) in enumerate(folds):
    print(f"\n{'='*60}")
    print(f"Fold {fold_idx + 1}/{len(folds)}")
    print(f"{'='*60}")

    # 모델 초기화
    model, tokenizer = load_model_and_tokenizer(config)

    # Dataset 생성
    train_dataset = create_dataset(
        train_fold['dialogue'].tolist(),
        train_fold['summary'].tolist(),
        tokenizer,
        config
    )

    val_dataset = create_dataset(
        val_fold['dialogue'].tolist(),
        val_fold['summary'].tolist(),
        tokenizer,
        config
    )

    # Trainer 생성
    trainer = create_trainer(
        config,
        model,
        tokenizer,
        train_dataset,
        val_dataset
    )

    # 학습
    trainer.train()

    # 평가
    eval_results = trainer.evaluate()
    fold_results.append(eval_results)

# 5. 결과 집계
aggregated = aggregate_fold_results(fold_results)

print(f"\n{'='*60}")
print("교차 검증 최종 결과")
print(f"{'='*60}")
print(f"ROUGE-1: {aggregated['rouge1_mean']:.4f} (±{aggregated['rouge1_std']:.4f})")
print(f"ROUGE-2: {aggregated['rouge2_mean']:.4f} (±{aggregated['rouge2_std']:.4f})")
print(f"ROUGE-L: {aggregated['rougeL_mean']:.4f} (±{aggregated['rougeL_std']:.4f})")
```

---

## 🔧 교차 검증 실행 명령어

### Config 설정

**파일:** `configs/experiments/baseline_kobart.yaml`

```yaml
validation:
  use_kfold: true
  n_splits: 5
  stratified: true
  stratify_column: 'length'  # 대화 길이 기반 층화
```

---

### 학습 스크립트에 통합

교차 검증을 지원하는 학습 스크립트 (예시):

```bash
# K-Fold 교차 검증 실행
python scripts/train_with_cv.py --experiment baseline_kobart --n_splits 5
```

---

# 📌 Part 3: Optuna 최적화

## 📝 개요

### 목적
- Bayesian Optimization을 통한 하이퍼파라미터 자동 최적화
- NLP 특화 탐색 공간 정의 (LoRA, Generation 파라미터 등)
- 조기 종료를 통한 효율적 탐색
- ROUGE 점수 기반 최적화

### 핵심 기능
- ✅ TPE (Tree-structured Parzen Estimator) Sampler
- ✅ Median Pruner를 통한 조기 종료
- ✅ 15개 하이퍼파라미터 동시 탐색
- ✅ 최적 파라미터 자동 저장
- ✅ 시각화 지원 (Plotly)

---

## 🔧 OptunaOptimizer 클래스

### 파일 위치
```
src/optimization/optuna_optimizer.py
```

### 클래스 구조

```python
class OptunaOptimizer:
    def __init__(config, train_dataset, val_dataset, n_trials, ...)
    def create_search_space(trial)
    def objective(trial)
    def optimize()
    def get_best_params()
    def get_best_value()
    def save_results(output_path)
    def plot_optimization_history(output_path)
```

### 초기화

```python
from src.optimization import OptunaOptimizer
from src.data import load_and_preprocess_data

# 데이터 로드
train_df, val_df = load_and_preprocess_data(train_path, split_ratio=0.9)

# Config 로드
from src.config import ConfigLoader
config_loader = ConfigLoader()
config = config_loader.load("baseline_kobart")

# 데이터셋 생성
from src.data import DialogueSummarizationDataset
train_dataset = DialogueSummarizationDataset(
    train_df['dialogue'].tolist(),
    train_df['summary'].tolist(),
    tokenizer,
    config
)

val_dataset = DialogueSummarizationDataset(
    val_df['dialogue'].tolist(),
    val_df['summary'].tolist(),
    tokenizer,
    config
)

# Optimizer 초기화
optimizer = OptunaOptimizer(
    config=config,
    train_dataset=train_dataset,
    val_dataset=val_dataset,
    n_trials=50,                    # 50회 시도
    timeout=None,                   # 무제한
    study_name="kobart_optuna",     # Study 이름
    direction="maximize"            # ROUGE 최대화
)
```

---

## 🔍 탐색 공간 정의

### 1. LoRA 파라미터

| 파라미터 | 탐색 범위 | 설명 |
|---------|----------|------|
| lora_r | [8, 16, 32, 64] | LoRA rank |
| lora_alpha | [16, 32, 64, 128] | LoRA scaling factor |
| lora_dropout | 0.0 ~ 0.2 | LoRA dropout rate |

**코드:**
```python
params['lora_r'] = trial.suggest_categorical('lora_r', [8, 16, 32, 64])
params['lora_alpha'] = trial.suggest_categorical('lora_alpha', [16, 32, 64, 128])
params['lora_dropout'] = trial.suggest_float('lora_dropout', 0.0, 0.2)
```

---

### 2. 학습 파라미터

| 파라미터 | 탐색 범위 | 설명 |
|---------|----------|------|
| learning_rate | 1e-6 ~ 1e-4 (log scale) | 학습률 |
| batch_size | [8, 16, 32, 64] | 배치 크기 |
| num_epochs | 3 ~ 10 | 에포크 수 |
| warmup_ratio | 0.0 ~ 0.2 | Warmup 비율 |
| weight_decay | 0.0 ~ 0.1 | Weight decay |

**코드:**
```python
params['learning_rate'] = trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True)
params['batch_size'] = trial.suggest_categorical('batch_size', [8, 16, 32, 64])
params['num_epochs'] = trial.suggest_int('num_epochs', 3, 10)
params['warmup_ratio'] = trial.suggest_float('warmup_ratio', 0.0, 0.2)
params['weight_decay'] = trial.suggest_float('weight_decay', 0.0, 0.1)
```

---

### 3. Scheduler

| 파라미터 | 탐색 범위 | 설명 |
|---------|----------|------|
| scheduler_type | [linear, cosine, cosine_with_restarts, polynomial] | Scheduler 종류 |

**코드:**
```python
params['scheduler_type'] = trial.suggest_categorical(
    'scheduler_type',
    ['linear', 'cosine', 'cosine_with_restarts', 'polynomial']
)
```

---

### 4. Generation 파라미터

| 파라미터 | 탐색 범위 | 설명 |
|---------|----------|------|
| temperature | 0.1 ~ 1.0 | 생성 온도 |
| top_p | 0.5 ~ 1.0 | Nucleus sampling |
| num_beams | [2, 4, 6, 8] | Beam search 빔 개수 |
| length_penalty | 0.5 ~ 2.0 | 길이 패널티 |

**코드:**
```python
params['temperature'] = trial.suggest_float('temperature', 0.1, 1.0)
params['top_p'] = trial.suggest_float('top_p', 0.5, 1.0)
params['num_beams'] = trial.suggest_categorical('num_beams', [2, 4, 6, 8])
params['length_penalty'] = trial.suggest_float('length_penalty', 0.5, 2.0)
```

---

### 5. Dropout 파라미터

| 파라미터 | 탐색 범위 | 설명 |
|---------|----------|------|
| hidden_dropout | 0.0 ~ 0.3 | Hidden layer dropout |
| attention_dropout | 0.0 ~ 0.3 | Attention dropout |

**코드:**
```python
if config.model.get('hidden_dropout_prob') is not None:
    params['hidden_dropout'] = trial.suggest_float('hidden_dropout', 0.0, 0.3)
    params['attention_dropout'] = trial.suggest_float('attention_dropout', 0.0, 0.3)
```

---

## ⚡ 최적화 전략

### 1. Bayesian Optimization (TPE)

**특징:**
- Tree-structured Parzen Estimator
- 이전 trial 결과를 활용하여 다음 탐색 위치 결정
- Random search보다 효율적

**설정:**
```python
from optuna.samplers import TPESampler

sampler = TPESampler(seed=42)
```

---

### 2. Median Pruner (조기 종료)

**특징:**
- 중간 결과가 median보다 낮으면 trial 종료
- 리소스 절약 (불필요한 trial 조기 중단)

**설정:**
```python
from optuna.pruners import MedianPruner

pruner = MedianPruner(
    n_startup_trials=5,   # 처음 5개는 pruning 안함
    n_warmup_steps=3,     # 3 에포크 후부터 체크
    interval_steps=1      # 매 에포크마다 체크
)
```

**동작 방식:**
```
Trial 0: [에포크1: 0.30] [에포크2: 0.32] [에포크3: 0.35] → 계속
Trial 1: [에포크1: 0.28] [에포크2: 0.29] [에포크3: 0.30] → 계속
Trial 2: [에포크1: 0.25] [에포크2: 0.26] [에포크3: 0.27] → Pruned! (median=0.32보다 낮음)
```

---

### 3. 목적 함수 (Objective Function)

**목표:** ROUGE-L F1 점수 최대화

**흐름:**
1. Trial에서 하이퍼파라미터 샘플링
2. Config 업데이트
3. 모델 로드 및 학습
4. 검증 데이터 평가
5. ROUGE-L F1 반환

**코드:**
```python
def objective(self, trial: optuna.Trial) -> float:
    # 1. 하이퍼파라미터 샘플링
    params = self.create_search_space(trial)

    # 2. Config 업데이트
    config.training.learning_rate = params['learning_rate']
    config.training.batch_size = params['batch_size']
    # ... 기타 파라미터 업데이트

    # 3. 모델 학습
    model_loader = ModelLoader(config)
    model, tokenizer = model_loader.load()

    trainer = ModelTrainer(...)
    trainer.train()

    # 4. 평가
    metrics = trainer.evaluate()
    rouge_l_f1 = metrics['rouge_l_f1']

    # 5. Pruning 체크
    trial.report(rouge_l_f1, step=config.training.num_epochs)
    if trial.should_prune():
        raise optuna.TrialPruned()

    return rouge_l_f1
```

---

## 💻 Optuna 사용 방법

### 1. 기본 최적화

```python
from src.optimization import OptunaOptimizer
from src.config import ConfigLoader
from src.data import load_and_preprocess_data, DialogueSummarizationDataset

# Config 로드
config_loader = ConfigLoader()
config = config_loader.load("baseline_kobart")

# 데이터 로드
train_df, val_df = load_and_preprocess_data("data/raw/train.csv", split_ratio=0.9)

# 토크나이저 로드
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(config.model.name)

# 데이터셋 생성
train_dataset = DialogueSummarizationDataset(
    train_df['dialogue'].tolist(),
    train_df['summary'].tolist(),
    tokenizer,
    config
)

val_dataset = DialogueSummarizationDataset(
    val_df['dialogue'].tolist(),
    val_df['summary'].tolist(),
    tokenizer,
    config
)

# Optimizer 초기화
optimizer = OptunaOptimizer(
    config=config,
    train_dataset=train_dataset,
    val_dataset=val_dataset,
    n_trials=50
)

# 최적화 실행
study = optimizer.optimize()

# 최적 파라미터 확인
best_params = optimizer.get_best_params()
best_value = optimizer.get_best_value()

print(f"최적 ROUGE-L F1: {best_value:.4f}")
print(f"최적 파라미터: {best_params}")
```

---

### 2. 결과 저장

```python
# 결과 저장
optimizer.save_results("outputs/optuna_results")

# 저장되는 파일:
# - outputs/optuna_results/best_params.json
# - outputs/optuna_results/all_trials.csv
# - outputs/optuna_results/study_stats.json
```

**best_params.json 예시:**
```json
{
  "best_params": {
    "learning_rate": 3.5e-05,
    "batch_size": 32,
    "num_epochs": 5,
    "lora_r": 16,
    "lora_alpha": 32,
    "temperature": 0.8,
    "num_beams": 6
  },
  "best_value": 0.4521,
  "n_trials": 50
}
```

---

## 🔧 Optuna 실행 명령어

### Optuna 최적화 스크립트 (예시)

**파일:** `scripts/optimize.py`

```python
import argparse
from pathlib import Path

from src.config import ConfigLoader
from src.data import load_and_preprocess_data, DialogueSummarizationDataset
from src.optimization import OptunaOptimizer
from transformers import AutoTokenizer


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--experiment", default="baseline_kobart", help="실험 config 이름")
    parser.add_argument("--n_trials", type=int, default=50, help="Trial 횟수")
    parser.add_argument("--timeout", type=int, default=None, help="최대 실행 시간 (초)")
    parser.add_argument("--output_dir", default="outputs/optuna_results", help="결과 저장 경로")
    args = parser.parse_args()

    # Config 로드
    config_loader = ConfigLoader()
    config = config_loader.load(args.experiment)

    # 데이터 로드
    train_df, val_df = load_and_preprocess_data("data/raw/train.csv", split_ratio=0.9)

    # 토크나이저 로드
    tokenizer = AutoTokenizer.from_pretrained(config.model.name)

    # 데이터셋 생성
    train_dataset = DialogueSummarizationDataset(
        train_df['dialogue'].tolist(),
        train_df['summary'].tolist(),
        tokenizer,
        config
    )

    val_dataset = DialogueSummarizationDataset(
        val_df['dialogue'].tolist(),
        val_df['summary'].tolist(),
        tokenizer,
        config
    )

    # Optimizer 초기화
    optimizer = OptunaOptimizer(
        config=config,
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        n_trials=args.n_trials,
        timeout=args.timeout,
        study_name=f"optuna_{args.experiment}"
    )

    # 최적화 실행
    study = optimizer.optimize()

    # 결과 저장
    optimizer.save_results(args.output_dir)

    # 시각화
    try:
        optimizer.plot_optimization_history(args.output_dir)
    except ImportError:
        print("plotly가 설치되지 않아 시각화를 건너뜁니다")

    print(f"\n{'='*60}")
    print(f"최적화 완료!")
    print(f"{'='*60}")
    print(f"최적 ROUGE-L F1: {optimizer.get_best_value():.4f}")
    print(f"결과 저장: {args.output_dir}")


if __name__ == "__main__":
    main()
```

**실행:**
```bash
# 기본 실행 (50 trials)
python scripts/optimize.py --experiment baseline_kobart

# Trial 횟수 조정
python scripts/optimize.py --experiment baseline_kobart --n_trials 100

# 시간 제한 (12시간 = 43200초)
python scripts/optimize.py --experiment baseline_kobart --timeout 43200

# 결과 디렉토리 지정
python scripts/optimize.py --experiment baseline_kobart --output_dir outputs/kobart_optuna
```

---

## 🔗 관련 파일

**소스 코드:**
- `src/evaluation/metrics.py` - RougeCalculator 클래스
- `src/evaluation/__init__.py` - 외부 API
- `src/validation/kfold.py` - K-Fold 시스템
- `src/validation/__init__.py` - 패키지 초기화
- `src/optimization/optuna_optimizer.py` - Optuna optimizer
- `src/optimization/__init__.py` - 패키지 초기화

**테스트:**
- `src/tests/test_metrics.py` - ROUGE 테스트
- `src/tests/test_kfold.py` - K-Fold 테스트
- `src/tests/test_optuna.py` - Optuna 테스트

**통합:**
- `src/training/trainer.py` - Trainer에서 자동 사용

**문서:**
- `docs/모듈화/00_전체_시스템_개요.md` - 시스템 개요
- `docs/모듈화/실행_명령어_총정리.md` - 실행 명령어
- `docs/PRD/13_Optuna_하이퍼파라미터_최적화.md` - PRD 문서

**Config:**
- `configs/base/default.yaml` - 기본 하이퍼파라미터
- `configs/experiments/*.yaml` - 실험별 Config
