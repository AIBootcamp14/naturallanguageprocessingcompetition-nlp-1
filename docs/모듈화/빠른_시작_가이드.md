# ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸš€ 5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source ~/.pyenv/versions/nlp_py3_11_9/bin/activate

# ë˜ëŠ”
pyenv activate nlp_py3_11_9

# íŒ¨í‚¤ì§€ í™•ì¸
pip list | grep -E "(torch|transformers|wandb)"
```

### 2. ì „ì²´ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
cd /home/ieyeppo/AI_Lab/natural-language-processing-competition

# ëª¨ë“  í…ŒìŠ¤íŠ¸ í•œ ë²ˆì— ì‹¤í–‰
python tests/test_config_loader.py && \
python tests/test_preprocessor.py && \
python tests/test_model_loader.py && \
python tests/test_metrics.py && \
python tests/test_trainer.py && \
python tests/test_predictor.py
```

---

## ğŸ“ ì£¼ìš” ëª…ë ¹ì–´

### Config ê´€ë ¨

```python
# Config ë¡œë“œ
from src.config import load_config
config = load_config("baseline_kobart")

# Config í™•ì¸
from omegaconf import OmegaConf
print(OmegaConf.to_yaml(config))
```

### ë°ì´í„° ì „ì²˜ë¦¬

```python
from src.data import DialoguePreprocessor
import pandas as pd

# ì „ì²˜ë¦¬ê¸° ìƒì„±
preprocessor = DialoguePreprocessor()

# DataFrame ì „ì²˜ë¦¬
df = pd.read_csv("data/raw/train.csv")
df_processed = preprocessor.preprocess_dataframe(df)
```

### ëª¨ë¸ ë¡œë”©

```python
from src.models import load_model_and_tokenizer
from src.config import load_config

config = load_config("baseline_kobart")
model, tokenizer = load_model_and_tokenizer(config)

print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")
```

### í•™ìŠµ ì‹¤í–‰

```python
from src.training import create_trainer
from src.data import DialogueSummarizationDataset

# Dataset ìƒì„±
train_dataset = DialogueSummarizationDataset(
    dialogues=train_df['dialogue'].tolist(),
    summaries=train_df['summary'].tolist(),
    tokenizer=tokenizer
)

# Trainer ìƒì„± ë° í•™ìŠµ
trainer = create_trainer(config, model, tokenizer, train_dataset)
results = trainer.train()
```

### ì¶”ë¡  ì‹¤í–‰

```python
from src.inference import create_predictor

# Predictor ìƒì„±
predictor = create_predictor(model, tokenizer, config)

# ë‹¨ì¼ ì˜ˆì¸¡
summary = predictor.predict_single("#Person1#: ì•ˆë…•í•˜ì„¸ìš”")

# ì œì¶œ íŒŒì¼ ìƒì„±
test_df = pd.read_csv("data/raw/test.csv")
submission = predictor.create_submission(
    test_df,
    output_path="submissions/submission.csv"
)
```

---

## ğŸ”¥ ìì£¼ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´

### íŒ¨í„´ 1: ë¹ ë¥¸ ì‹¤í—˜

```python
# 1ë‹¨ê³„: Config ë¡œë“œ
config = load_config("baseline_kobart")

# 2ë‹¨ê³„: Config ìˆ˜ì • (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
config.training.epochs = 2
config.training.batch_size = 4
config.wandb.enabled = False

# 3ë‹¨ê³„: ëª¨ë¸ ë¡œë“œ
model, tokenizer = load_model_and_tokenizer(config)

# 4ë‹¨ê³„: ì‘ì€ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
df = pd.read_csv("data/raw/train.csv").head(100)  # 100ê°œë§Œ
# ... í•™ìŠµ ì§„í–‰
```

### íŒ¨í„´ 2: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ

```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
model = AutoModelForSeq2SeqLM.from_pretrained("outputs/baseline_kobart/checkpoint-1000")
tokenizer = AutoTokenizer.from_pretrained("outputs/baseline_kobart/checkpoint-1000")

# ì¶”ë¡  ì§„í–‰
predictor = create_predictor(model, tokenizer, config)
```

### íŒ¨í„´ 3: ROUGE í‰ê°€ë§Œ ì‹¤í–‰

```python
from src.evaluation import calculate_rouge_scores

predictions = ["ì˜ˆì¸¡ ìš”ì•½1", "ì˜ˆì¸¡ ìš”ì•½2"]
references = ["ì •ë‹µ ìš”ì•½1", "ì •ë‹µ ìš”ì•½2"]

scores = calculate_rouge_scores(predictions, references)
print(scores)
```

---

## ğŸ’¡ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: CUDA out of memory

```python
# í•´ê²°ì±…: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
config.training.batch_size = 8  # ë˜ëŠ” 4, 2
config.training.gradient_accumulation_steps = 4  # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ì‚¬ìš©
```

### ë¬¸ì œ 2: í† í¬ë‚˜ì´ì € íŠ¹ìˆ˜ í† í° ê²½ê³ 

```python
# í•´ê²°ì±…: íŠ¹ìˆ˜ í† í° ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
special_tokens = ['#Person1#', '#Person2#', ...]
tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})
model.resize_token_embeddings(len(tokenizer))
```

### ë¬¸ì œ 3: WandB ë¡œê·¸ì¸ í•„ìš”

```bash
# í•´ê²°ì±…: WandB ë¡œê·¸ì¸
wandb login

# ë˜ëŠ” Configì—ì„œ ë¹„í™œì„±í™”
config.wandb.enabled = False
```

---

## ğŸ“š ë” ì•Œì•„ë³´ê¸°

| ë¬¸ì„œ | ì„¤ëª… |
|------|------|
| [00_ì „ì²´_ì‹œìŠ¤í…œ_ê°œìš”.md](./00_ì „ì²´_ì‹œìŠ¤í…œ_ê°œìš”.md) | ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ |
| [01_Config_ì‹œìŠ¤í…œ.md](./01_Config_ì‹œìŠ¤í…œ.md) | Config ìƒì„¸ ê°€ì´ë“œ |
| [02_ë°ì´í„°_ì²˜ë¦¬.md](./02_ë°ì´í„°_ì²˜ë¦¬.md) | ë°ì´í„° ì „ì²˜ë¦¬ ìƒì„¸ |

---

