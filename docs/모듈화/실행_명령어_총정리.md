# 실행 명령어 총정리

## 📋 목차
1. [환경 설정](#환경-설정)
2. [학습 실행](#학습-실행)
3. [추론 실행](#추론-실행)
4. [Full Pipeline 실행](#full-pipeline-실행)
5. [테스트 실행](#테스트-실행)
6. [결과 파일 경로](#결과-파일-경로)

---

## 🔧 환경 설정

### 가상환경 활성화

```bash
# pyenv 가상환경 활성화
source ~/.pyenv/versions/nlp_py3_11_9/bin/activate

# 또는
pyenv activate nlp_py3_11_9

# 패키지 확인
pip list | grep -E "(torch|transformers|wandb)"
```

### 프로젝트 루트로 이동

```bash
cd /home/ieyeppo/AI_Lab/natural-language-processing-competition
```

---

## 🚀 학습 실행

### 1. 기본 학습

```bash
python scripts/train.py --experiment baseline_kobart
```

**결과 파일:**
- 모델: `outputs/baseline_kobart/final_model/`
- 체크포인트: `outputs/baseline_kobart/checkpoint-{N}/`
- 로그: `logs/YYYYMMDD/train/train_baseline_kobart_YYYYMMDD_HHMMSS.log`

### 2. 디버그 모드 (빠른 테스트)

```bash
python scripts/train.py --experiment baseline_kobart --debug
```

**디버그 모드 설정:**
- 데이터: 학습 100개, 검증 20개
- 에포크: 2회
- 배치 크기: 4
- WandB: 비활성화

**결과 파일:**
- 모델: `outputs/baseline_kobart/final_model/`
- 로그: `logs/YYYYMMDD/train/train_baseline_kobart_YYYYMMDD_HHMMSS.log`

### 3. 다른 실험 Config 사용

```bash
# 다른 Config 파일이 있다면
python scripts/train.py --experiment my_custom_experiment
```

**필요 파일:**
- Config: `configs/experiments/my_custom_experiment.yaml`

### 4. LLM 파인튜닝 학습 (Llama/Qwen + QLoRA)

```bash
# Llama-3.2-3B 학습
python scripts/train_llm.py --experiment llama_3.2_3b --use_qlora
```

**결과 파일:**
- 모델: `outputs/llama_3.2_3b_qlora/final_model/`
- 로그: `logs/YYYYMMDD/train/train_llm_llama_3.2_3b_YYYYMMDD_HHMMSS.log`

### 5. LLM Instruction Tuning (데이터 5배 증강)

```bash
python scripts/train_llm.py --experiment llama_3.2_3b --use_qlora --use_instruction_augmentation
```

**효과:**
- 학습 데이터: 12,457개 → 62,285개 (5배)
- 5가지 instruction 템플릿 적용

### 6. LLM 디버그 모드

```bash
python scripts/train_llm.py --experiment llama_3.2_3b --use_qlora --debug
```

**디버그 모드 설정:**
- 데이터: 학습 50개, 검증 10개
- 에포크: 1회
- 배치 크기: 2

---

## 🔮 추론 실행

### 1. 기본 추론

```bash
python scripts/inference.py \
    --model outputs/baseline_kobart/final_model \
    --output submissions/submission.csv
```

**결과 파일:**
- 제출 파일: `submissions/submission.csv`
- 로그: `logs/YYYYMMDD/inference/inference_final_model_YYYYMMDD_HHMMSS.log`

### 2. 특정 체크포인트로 추론

```bash
python scripts/inference.py \
    --model outputs/baseline_kobart/checkpoint-1000 \
    --output submissions/checkpoint_1000.csv
```

**결과 파일:**
- 제출 파일: `submissions/checkpoint_1000.csv`
- 로그: `logs/YYYYMMDD/inference/inference_checkpoint-1000_YYYYMMDD_HHMMSS.log`

### 3. 추론 파라미터 조정

```bash
python scripts/inference.py \
    --model outputs/baseline_kobart/final_model \
    --output submissions/submission.csv \
    --batch_size 16 \
    --num_beams 8
```

**옵션:**
- `--test_data`: 테스트 데이터 경로 (기본: `data/raw/test.csv`)
- `--batch_size`: 추론 배치 크기 (기본: 32)
- `--num_beams`: Beam search 빔 개수 (기본: 4)
- `--experiment`: Config 이름 (기본: `baseline_kobart`)

**결과 파일:**
- 제출 파일: `submissions/submission.csv`
- 로그: `logs/YYYYMMDD/inference/inference_final_model_YYYYMMDD_HHMMSS.log`

---

## 🔄 Full Pipeline 실행

### 1. 학습 + 추론 한 번에

```bash
python scripts/run_pipeline.py --experiment baseline_kobart
```

**실행 흐름:**
1. 학습 실행 → `outputs/baseline_kobart/final_model/` 생성
2. 추론 실행 → `submissions/submission.csv` 생성

**결과 파일:**
- 모델: `outputs/baseline_kobart/final_model/`
- 제출 파일: `submissions/submission.csv`
- 학습 로그: `logs/YYYYMMDD/train/train_baseline_kobart_YYYYMMDD_HHMMSS.log`
- 추론 로그: `logs/YYYYMMDD/inference/inference_final_model_YYYYMMDD_HHMMSS.log`

### 2. 학습 건너뛰고 추론만

```bash
python scripts/run_pipeline.py \
    --experiment baseline_kobart \
    --skip_training \
    --model_path outputs/baseline_kobart/final_model \
    --output submissions/submission_v2.csv
```

**결과 파일:**
- 제출 파일: `submissions/submission_v2.csv`
- 추론 로그: `logs/YYYYMMDD/inference/inference_final_model_YYYYMMDD_HHMMSS.log`

---

## 🧪 테스트 실행

### 전체 테스트 한 번에

```bash
python src/tests/test_config_loader.py && \
python src/tests/test_preprocessor.py && \
python src/tests/test_model_loader.py && \
python src/tests/test_metrics.py && \
python src/tests/test_trainer.py && \
python src/tests/test_predictor.py && \
python src/tests/test_lora_loader.py && \
python src/tests/test_augmentation.py && \
python src/tests/test_kfold.py
```

### 개별 테스트

```bash
# Config Loader 테스트
python src/tests/test_config_loader.py

# 데이터 전처리 테스트
python src/tests/test_preprocessor.py

# 모델 로더 테스트
python src/tests/test_model_loader.py

# 평가 시스템 테스트
python src/tests/test_metrics.py

# 학습 시스템 테스트
python src/tests/test_trainer.py

# 추론 시스템 테스트
python src/tests/test_predictor.py

# LLM LoRA Loader 테스트
python src/tests/test_lora_loader.py

# 데이터 증강 테스트
python src/tests/test_augmentation.py

# K-Fold 교차 검증 테스트
python src/tests/test_kfold.py
```

**테스트 결과:**
- 콘솔에 출력됨
- 총 50개 테스트 (각 모듈당 4-7개)

---

## 📂 결과 파일 경로

### 디렉토리 구조

```
natural-language-processing-competition/
├── logs/                                    # 로그 파일
│   └── YYYYMMDD/                            # 날짜별
│       ├── train/                           # 학습 로그
│       │   └── train_baseline_kobart_YYYYMMDD_HHMMSS.log
│       └── inference/                       # 추론 로그
│           └── inference_final_model_YYYYMMDD_HHMMSS.log
│
├── outputs/                                 # 모델 출력
│   └── baseline_kobart/                     # 실험별
│       ├── checkpoint-500/                  # 중간 체크포인트
│       ├── checkpoint-1000/
│       ├── checkpoint-1500/
│       ├── final_model/                     # 최종 모델
│       │   ├── config.json
│       │   ├── pytorch_model.bin
│       │   ├── tokenizer_config.json
│       │   ├── special_tokens_map.json
│       │   └── vocab.txt
│       └── logs/                            # Trainer 로그
│
└── submissions/                             # 제출 파일
    ├── submission.csv
    ├── checkpoint_1000.csv
    └── submission_v2.csv
```

### 로그 파일 (`logs/`)

**경로 규칙:** `logs/YYYYMMDD/{log_type}/{filename}.log`

**예시:**
- 학습: `logs/20251011/train/train_baseline_kobart_20251011_150300.log`
- 추론: `logs/20251011/inference/inference_final_model_20251011_150500.log`

**로그 내용:**
- 실행 시작/종료 시각
- GPU 정보 (이름, 메모리, tier)
- Config 설정값
- 데이터 로드 정보
- 학습/추론 진행 상황
- 최종 평가 결과
- 에러 메시지 (있는 경우)

### 모델 파일 (`outputs/`)

**경로 규칙:** `outputs/{experiment_name}/`

**구조:**
```
outputs/baseline_kobart/
├── checkpoint-500/              # 에포크 중간 체크포인트
│   ├── config.json
│   ├── pytorch_model.bin
│   ├── trainer_state.json
│   └── training_args.bin
├── checkpoint-1000/
├── final_model/                 # 최종 저장 모델
│   ├── config.json
│   ├── pytorch_model.bin
│   ├── tokenizer_config.json
│   ├── special_tokens_map.json
│   └── vocab.txt
└── logs/                        # HuggingFace Trainer 로그
    └── events.out.tfevents.*
```

**용량:**
- KoBART 모델: 약 500MB/체크포인트
- 최대 3개 체크포인트 유지 (save_total_limit: 3)

### 제출 파일 (`submissions/`)

**경로:** `submissions/{filename}.csv`

**형식:**
```csv
fname,summary
test_001,두 사람이 저녁 약속을 잡았다
test_002,회의 시간을 3시로 정했다
test_003,내일 점심 메뉴는 김치찌개다
...
```

**샘플 수:** 2,500개 (test.csv 기준)

---

## 🎯 실전 사용 패턴

### 패턴 1: 빠른 프로토타입

```bash
# 1. 디버그 모드로 빠른 테스트
python scripts/train.py --experiment baseline_kobart --debug

# 2. 학습된 모델 확인
ls outputs/baseline_kobart/final_model/

# 3. 작은 데이터로 추론 테스트
python scripts/inference.py \
    --model outputs/baseline_kobart/final_model \
    --output submissions/debug_test.csv \
    --batch_size 4
```

### 패턴 2: 전체 학습 및 제출

```bash
# 1. Full pipeline 실행
python scripts/run_pipeline.py --experiment baseline_kobart

# 2. 결과 확인
cat submissions/submission.csv | head -5

# 3. 로그 확인
tail -100 logs/$(date +%Y%m%d)/train/train_baseline_kobart_*.log
```

### 패턴 3: 여러 체크포인트 비교

```bash
# 각 체크포인트로 추론
for checkpoint in checkpoint-500 checkpoint-1000 checkpoint-1500 final_model
do
    python scripts/inference.py \
        --model outputs/baseline_kobart/$checkpoint \
        --output submissions/${checkpoint}.csv
done

# 결과 비교
ls -lh submissions/
```

### 패턴 4: 실험 추적

```bash
# 여러 실험 순차 실행
experiments=("baseline_kobart" "experiment_v2" "experiment_v3")

for exp in "${experiments[@]}"
do
    echo "실험 시작: $exp"
    python scripts/run_pipeline.py --experiment $exp
    echo "실험 완료: $exp"
    echo "---"
done

# 모든 실험 결과 확인
ls -R outputs/
ls submissions/
```

---

## 📊 예상 실행 시간 (A6000 기준)

### 학습 (train.py)

| 모드 | 데이터 크기 | 에포크 | 배치 크기 | 예상 시간 |
|-----|-----------|--------|---------|----------|
| 디버그 | 100개 | 2 | 4 | ~2분 |
| 전체 | 12,457개 | 20 | 50 | ~4-6시간 |

### 추론 (inference.py)

| 데이터 크기 | 배치 크기 | 예상 시간 |
|-----------|---------|----------|
| 2,500개 | 32 | ~3-5분 |
| 2,500개 | 16 | ~5-7분 |

### Full Pipeline (run_pipeline.py)

| 모드 | 예상 시간 |
|-----|----------|
| 학습 + 추론 | ~4-6시간 |
| 추론만 (--skip_training) | ~3-5분 |

---

## 🐛 문제 해결

### GPU 메모리 부족

```bash
# 배치 크기 줄이기 (디버그 모드 사용)
python scripts/train.py --experiment baseline_kobart --debug
```

또는 Config 수정:
```yaml
# configs/experiments/baseline_kobart.yaml
training:
  batch_size: 16  # 50 → 16
```

### WandB 로그인 필요

```bash
# WandB 로그인
wandb login

# 또는 디버그 모드 (WandB 비활성화)
python scripts/train.py --experiment baseline_kobart --debug
```

### 모델 경로 찾을 수 없음

```bash
# 경로 확인
ls -la outputs/baseline_kobart/

# 정확한 경로 사용
python scripts/inference.py \
    --model outputs/baseline_kobart/final_model \
    --output submissions/submission.csv
```

### 로그 파일 찾기

```bash
# 오늘 날짜 로그 확인
ls logs/$(date +%Y%m%d)/

# 최신 학습 로그
ls -lt logs/$(date +%Y%m%d)/train/ | head

# 로그 내용 보기
tail -100 logs/$(date +%Y%m%d)/train/train_baseline_kobart_*.log
```

---

## 📝 Config 파일 위치

### 실험 Config

```
configs/experiments/
└── baseline_kobart.yaml         # 베이스라인 실험 설정
```

### Base Config

```
configs/base/
├── default.yaml                 # 전체 기본 설정
└── encoder_decoder.yaml         # Encoder-Decoder 공통 설정
```

### 모델 Config

```
configs/models/
└── kobart.yaml                  # KoBART 전용 설정
```

---

## 🔗 관련 문서

- [00_전체_시스템_개요.md](./00_전체_시스템_개요.md) - 시스템 아키텍처
- [스크립트_사용법.md](./스크립트_사용법.md) - 상세 사용법
- [빠른_시작_가이드.md](./빠른_시작_가이드.md) - 5분 시작 가이드
