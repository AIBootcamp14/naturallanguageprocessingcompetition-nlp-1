# 10. 베이스라인 검증 가이드

> **통합 문서:** 토크나이저 검증 + 학습률 검증 + 생성 품질 검증

## 📋 목차

- [개요](#개요)
- [BaselineChecker 클래스](#baselinechecker-클래스)
- [검증 방법](#검증-방법)
  - [1. 토크나이저 검증](#1-토크나이저-검증)
  - [2. 학습률 검증](#2-학습률-검증)
  - [3. 생성 품질 검증](#3-생성-품질-검증)
- [사용 방법](#사용-방법)
- [검증 결과 해석](#검증-결과-해석)
- [문제 해결](#문제-해결)

---

## 📝 개요

### 목적
- 학습 시작 전 기본 설정 자동 검증
- 흔한 설정 오류 사전 감지
- 생성 품질 조기 검증
- 학습 실패 위험 감소

### 핵심 기능
- ✅ 토크나이저 설정 검증 (vocab, special tokens, tokenization)
- ✅ 학습률 적정성 검증 (범위, 모델 크기 기반)
- ✅ 생성 품질 검증 (repetition, length, 정상 작동)
- ✅ 자동 요약 보고서 생성
- ✅ JSON 결과 저장

### 파일 위치
```
src/validation/baseline_checker.py
```

---

## 🔧 BaselineChecker 클래스

### 클래스 구조

```python
# ==================== BaselineChecker 클래스 구조 ==================== #

class BaselineChecker:
    # ---------------------- 초기화 메서드 ---------------------- #
    def __init__(config=None, logger=None)
        """베이스라인 검증기 초기화"""

    # ---------------------- 개별 검증 메서드 ---------------------- #
    def check_tokenization(tokenizer, sample_texts) -> Dict
        """토크나이저 설정 검증"""

    def check_learning_rate(learning_rate, model_size, batch_size) -> Dict
        """학습률 적정성 검증"""

    def check_generation_quality(model, tokenizer, sample_inputs, reference_outputs) -> Dict
        """생성 품질 검증"""

    # ---------------------- 전체 검증 메서드 ---------------------- #
    def run_all_checks(tokenizer, learning_rate, model, sample_texts) -> Dict
        """모든 검증 항목 실행"""

    # ---------------------- 결과 관리 메서드 ---------------------- #
    def save_results(output_path)
        """검증 결과 JSON 파일로 저장"""

    # ---------------------- 내부 메서드 ---------------------- #
    def _analyze_generation_quality(text) -> Dict
        """생성 텍스트 품질 분석"""

    def _create_summary() -> Dict
        """검증 결과 요약 생성"""

    def _get_default_config() -> Dict
        """기본 검증 설정 로드"""
```

---

## ✅ 검증 방법

### 1. 토크나이저 검증

#### 검증 항목

| 항목 | 검증 내용 | 통과 기준 |
|------|---------|---------|
| **Vocab Size** | 어휘 크기 | ≥ 1,000 |
| **Max Length** | 최대 시퀀스 길이 | 128 ~ 2,048 |
| **Special Tokens** | 특수 토큰 존재 | PAD, UNK, BOS, EOS |
| **Tokenization** | 샘플 텍스트 토크나이제이션 | 오류 없이 실행 |

#### 사용 예시

```python
# ==================== 토크나이저 검증 사용 예시 ==================== #

# ---------------------- 프로젝트 모듈 임포트 ---------------------- #
from src.validation import create_baseline_checker

# ---------------------- 서드파티 라이브러리 임포트 ---------------------- #
from transformers import AutoTokenizer

# ---------------------- 검증기 생성 ---------------------- #
# 기본 설정으로 베이스라인 검증기 생성
checker = create_baseline_checker()

# ---------------------- 토크나이저 로드 ---------------------- #
# KoBART 요약 모델의 토크나이저 로드
tokenizer = AutoTokenizer.from_pretrained("digit82/kobart-summarization")

# ---------------------- 샘플 텍스트 준비 ---------------------- #
# 검증용 샘플 대화 텍스트
sample_texts = [
    "#Person1#: 안녕하세요 #Person2#: 반갑습니다",
    "오늘 회의 시간을 정하려고 합니다.",
    "점심 메뉴를 김치찌개로 하자"
]

# ---------------------- 토크나이저 검증 실행 ---------------------- #
# 토크나이저 설정 및 동작 검증
result = checker.check_tokenization(
    tokenizer=tokenizer,      # 검증할 토크나이저
    sample_texts=sample_texts # 샘플 텍스트 리스트
)

# ---------------------- 검증 결과 출력 ---------------------- #
print(f"검증 결과: {'PASS' if result['passed'] else 'FAIL'}")
print(f"Errors: {len(result['errors'])}")
print(f"Warnings: {len(result['warnings'])}")
```

#### 출력 예시

```
=== 토크나이저 검증 ===
  - Vocab size: 30,000
  - Max length: 1024

  [Special Tokens 검증]
    - pad_token: <pad>
    - unk_token: <unk>
    - bos_token: <s>
    - eos_token: </s>

  [샘플 토크나이제이션]
    - Sample 1: 15 tokens
    - Sample 2: 12 tokens
    - Sample 3: 8 tokens

  토크나이저 검증: ✓ PASS
```

#### 결과 딕셔너리

```python
{
    'passed': True,
    'errors': [],
    'warnings': [],
    'info': {
        'vocab_size': 30000,
        'model_max_length': 1024,
        'special_tokens': {
            'pad_token': '<pad>',
            'unk_token': '<unk>',
            'bos_token': '<s>',
            'eos_token': '</s>'
        },
        'tokenization_samples': [
            {'text': 'Sample 1...', 'token_count': 15, 'success': True},
            {'text': 'Sample 2...', 'token_count': 12, 'success': True},
            {'text': 'Sample 3...', 'token_count': 8, 'success': True}
        ]
    }
}
```

---

### 2. 학습률 검증

#### 검증 기준

| 학습률 범위 | 상태 | 설명 |
|-----------|------|------|
| < 1e-6 | ❌ Error | 너무 작음 (수렴 불가) |
| 1e-6 ~ 1e-5 | ⚠️ Warning | 권장 범위 이하 |
| 1e-5 ~ 5e-4 | ✅ Good | **권장 범위** |
| 5e-4 ~ 1e-3 | ⚠️ Warning | 권장 범위 초과 |
| > 1e-3 | ❌ Error | 너무 큼 (발산 위험) |

#### 모델 크기별 권장 학습률

| 모델 크기 | 권장 학습률 | 예시 모델 |
|----------|-----------|---------|
| < 100M | 2e-5 ~ 5e-5 | DistilBERT |
| 100M ~ 1B | 1e-5 ~ 3e-5 | BERT, KoBART |
| > 1B | 5e-6 ~ 1e-5 | GPT-2, GPT-3 |

#### 사용 예시

```python
# ==================== 학습률 검증 사용 예시 ==================== #

# ---------------------- 서드파티 라이브러리 임포트 ---------------------- #
from transformers import AutoModelForSeq2SeqLM

# ---------------------- 모델 로드 ---------------------- #
# KoBART 요약 모델 로드
model = AutoModelForSeq2SeqLM.from_pretrained("digit82/kobart-summarization")

# ---------------------- 모델 크기 계산 ---------------------- #
# 모델의 전체 파라미터 수 계산
model_size = sum(p.numel() for p in model.parameters())
print(f"Model size: {model_size:,} parameters")

# ---------------------- 학습률 검증 실행 ---------------------- #
# 학습률의 적정성 검증
result = checker.check_learning_rate(
    learning_rate=2e-5,  # 검증할 학습률
    model_size=model_size,  # 모델 파라미터 수
    batch_size=16  # 배치 크기
)

# ---------------------- 검증 결과 출력 ---------------------- #
print(f"검증 결과: {'PASS' if result['passed'] else 'FAIL'}")
```

#### 출력 예시

```
=== 학습률 검증 ===
  - Learning rate: 2e-05
  - Model size: 139,420,672 params
  - Batch size: 16

  학습률 검증: ✓ PASS
```

#### 경고 메시지 예시

```python
# 너무 큰 학습률
learning_rate = 1e-3
# Warning: "Learning rate above recommended: 0.001 > 0.0005"

# 큰 모델에 큰 학습률
model_size = 500e6  # 500M params
learning_rate = 1e-4
# Warning: "For medium model (>100M), consider smaller LR: 2e-05"

# 작은 배치에 큰 학습률
batch_size = 4
learning_rate = 5e-4
# Warning: "Small batch size may need smaller learning rate"
```

---

### 3. 생성 품질 검증

#### 검증 항목

| 항목 | 검증 내용 | 통과 기준 |
|------|---------|---------|
| **정상 생성** | 오류 없이 생성 | 예외 없음 |
| **출력 길이** | 생성 토큰 수 | ≥ 10 tokens |
| **반복 비율** | 중복 단어 비율 | ≤ 30% |
| **빈 출력** | 내용 존재 | 길이 > 0 |

#### 사용 예시

```python
# 샘플 입력
sample_inputs = [
    "#Person1#: 안녕하세요 #Person2#: 안녕하세요 #Person1#: 오늘 점심 뭐 먹을까요? #Person2#: 김치찌개 어때요?",
    "#Person1#: 회의 시간 정해야 해요 #Person2#: 3시에 하죠 #Person1#: 좋아요",
    "#Person1#: 내일 날씨 어때요? #Person2#: 비 온대요 #Person1#: 우산 챙겨야겠네요"
]

# 생성 품질 검증
result = checker.check_generation_quality(
    model=model,
    tokenizer=tokenizer,
    sample_inputs=sample_inputs
)

print(f"검증 결과: {'PASS' if result['passed'] else 'FAIL'}")
```

#### 출력 예시

```
=== 생성 품질 검증 ===

  [Sample 1]
  Input: #Person1#: 안녕하세요 #Person2#: 안녕하세요 #Person1#: 오늘 점심 뭐 먹을까요? #Person2#: 김치찌개 어때요?
  Output: 두 사람이 점심 메뉴를 김치찌개로 정했다.

  [Sample 2]
  Input: #Person1#: 회의 시간 정해야 해요 #Person2#: 3시에 하죠 #Person1#: 좋아요
  Output: 회의 시간을 3시로 정했다.

  [Sample 3]
  Input: #Person1#: 내일 날씨 어때요? #Person2#: 비 온대요 #Person1#: 우산 챙겨야겠네요
  Output: 내일 비가 온다는 예보에 우산을 챙기기로 했다.

  생성 품질 검증: ✓ PASS
```

#### 품질 분석 결과

```python
{
    'length': 12,              # 단어 수
    'unique_words': 10,        # 고유 단어 수
    'repetition_ratio': 0.17,  # 반복 비율 (17%)
    'has_content': True        # 내용 존재 여부
}
```

#### 경고 메시지 예시

```python
# 높은 반복 비율
# Output: "점심 점심 점심을 점심으로 정했다 정했다."
# Warning: "Sample 1: High repetition ratio 45.00%"

# 너무 짧은 출력
# Output: "회의"
# Warning: "Sample 2: Output too short (1 tokens)"
```

---

## 💻 사용 방법

### 1. 기본 사용 (전체 검증)

```python
# ==================== 베이스라인 전체 검증 사용 예시 ==================== #

# ---------------------- 프로젝트 모듈 임포트 ---------------------- #
from src.validation import create_baseline_checker

# ---------------------- 서드파티 라이브러리 임포트 ---------------------- #
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

# ---------------------- 1. 모델 및 토크나이저 로드 ---------------------- #
# 학습된 모델 로드
model = AutoModelForSeq2SeqLM.from_pretrained("outputs/kobart_model")

# 토크나이저 로드
tokenizer = AutoTokenizer.from_pretrained("digit82/kobart-summarization")

# ---------------------- 2. 검증기 생성 ---------------------- #
# 기본 설정으로 베이스라인 검증기 생성
checker = create_baseline_checker()

# ---------------------- 3. 샘플 텍스트 준비 ---------------------- #
# 검증용 샘플 대화 텍스트
sample_texts = [
    "#Person1#: 안녕하세요 #Person2#: 반갑습니다",
    "#Person1#: 회의 시간은? #Person2#: 3시요",
    "#Person1#: 점심은? #Person2#: 김치찌개"
]

# ---------------------- 4. 전체 검증 실행 ---------------------- #
# 토크나이저, 학습률, 생성 품질 모두 검증
results = checker.run_all_checks(
    tokenizer=tokenizer,        # 토크나이저 객체
    learning_rate=2e-5,          # 학습률
    model=model,                 # 모델 객체
    sample_texts=sample_texts    # 샘플 텍스트 리스트
)

# ---------------------- 5. 결과 확인 ---------------------- #
# 전체 검증 결과 출력
print(f"\n전체 결과: {'PASS' if results['all_passed'] else 'FAIL'}")
print(f"  - Passed: {results['passed_count']}/{results['total_checks']}")
print(f"  - Errors: {results['total_errors']}")
print(f"  - Warnings: {results['total_warnings']}")
```

#### 출력 예시

```
============================================================
베이스라인 검증 시작
============================================================

=== 토크나이저 검증 ===
  - Vocab size: 30,000
  - Max length: 1024
  ...
  토크나이저 검증: ✓ PASS

=== 학습률 검증 ===
  - Learning rate: 2e-05
  - Model size: 139,420,672 params
  ...
  학습률 검증: ✓ PASS

=== 생성 품질 검증 ===
  [Sample 1]
  Input: #Person1#: 안녕하세요 #Person2#: 반갑습니다
  Output: 두 사람이 인사를 나누었다.
  ...
  생성 품질 검증: ✓ PASS

============================================================
검증 완료
============================================================
전체 결과: ✓ PASS
  - Passed: 3/3
  - Errors: 0
  - Warnings: 0
```

---

### 2. 개별 검증

#### 토크나이저만 검증

```python
checker = create_baseline_checker()

result = checker.check_tokenization(
    tokenizer=tokenizer,
    sample_texts=sample_texts
)

if not result['passed']:
    print("토크나이저 설정에 문제가 있습니다:")
    for error in result['errors']:
        print(f"  - {error}")
```

#### 학습률만 검증

```python
result = checker.check_learning_rate(
    learning_rate=3e-5,
    model_size=139_420_672,
    batch_size=16
)

for warning in result['warnings']:
    print(f"Warning: {warning}")
```

---

### 3. 커스텀 설정

```python
# 커스텀 검증 기준
custom_config = {
    'tokenizer': {
        'max_length_min': 256,      # 최소 길이 증가
        'vocab_size_min': 5000,     # 최소 vocab 크기 증가
    },
    'learning_rate': {
        'min': 5e-6,
        'max': 1e-4,
        'recommended_min': 1e-5,
        'recommended_max': 3e-5     # 권장 범위 축소
    },
    'generation': {
        'min_length': 15,            # 최소 길이 증가
        'max_repetition_ratio': 0.2  # 반복 허용 범위 축소
    }
}

# 커스텀 설정으로 검증기 생성
checker = create_baseline_checker(config=custom_config)

results = checker.run_all_checks(
    tokenizer=tokenizer,
    learning_rate=2e-5,
    model=model,
    sample_texts=sample_texts
)
```

---

### 4. 결과 저장

```python
# JSON으로 저장
checker.save_results("results/baseline_validation.json")
```

**저장 형식:**

```json
{
  "all_passed": true,
  "total_checks": 3,
  "passed_count": 3,
  "total_errors": 0,
  "total_warnings": 1,
  "details": {
    "tokenization": {
      "passed": true,
      "errors": [],
      "warnings": [],
      "info": {...}
    },
    "learning_rate": {
      "passed": true,
      "errors": [],
      "warnings": ["Learning rate below recommended: 1e-05 < 2e-05"],
      "info": {...}
    },
    "generation_quality": {
      "passed": true,
      "errors": [],
      "warnings": [],
      "info": {...}
    }
  }
}
```

---

## 🔍 검증 결과 해석

### 결과 상태

| 상태 | 의미 | 조치 |
|------|------|------|
| **✓ PASS (0 errors)** | 모든 검증 통과 | 학습 진행 가능 |
| **⚠️ PASS (warnings)** | 통과하지만 경고 존재 | 검토 후 진행 |
| **✗ FAIL** | 검증 실패 | **설정 수정 필수** |

---

### 흔한 오류 및 해결

#### 1. Vocab Size 오류

**오류:**
```
Error: Vocab size too small: 500 < 1000
```

**원인:** 토크나이저가 제대로 로드되지 않음

**해결:**
```python
# 올바른 토크나이저 로드
tokenizer = AutoTokenizer.from_pretrained("digit82/kobart-summarization")

# Vocab size 확인
print(f"Vocab size: {len(tokenizer)}")  # 30,000 이상이어야 함
```

---

#### 2. Special Token 누락

**경고:**
```
Warning: pad_token is not set
Warning: eos_token is not set
```

**원인:** 토크나이저에 특수 토큰 미설정

**해결:**
```python
# Special tokens 수동 설정
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# 또는 모델 config에서 로드
tokenizer = AutoTokenizer.from_pretrained(
    "digit82/kobart-summarization",
    use_fast=True
)
```

---

#### 3. 학습률 범위 초과

**오류:**
```
Error: Learning rate too large: 0.01 > 0.001
```

**원인:** 학습률이 너무 큼 (발산 위험)

**해결:**
```python
# 학습률 조정
learning_rate = 2e-5  # 0.00002

# Config 파일 수정
# configs/experiments/baseline_kobart.yaml
training:
  learning_rate: 2e-5  # 1e-3에서 수정
```

---

#### 4. 높은 반복 비율

**경고:**
```
Warning: Sample 1: High repetition ratio 45.00%
```

**원인:** 모델이 같은 단어를 반복 생성

**해결:**
```python
# 생성 파라미터 조정
outputs = model.generate(
    **inputs,
    max_length=150,
    num_beams=4,
    no_repeat_ngram_size=3,  # 추가: 3-gram 반복 방지
    repetition_penalty=1.2,  # 추가: 반복 패널티
    early_stopping=True
)
```

---

#### 5. 생성 출력이 너무 짧음

**경고:**
```
Warning: Sample 1: Output too short (3 tokens)
```

**원인:** 모델이 조기 종료

**해결:**
```python
# min_length 설정
outputs = model.generate(
    **inputs,
    min_length=15,      # 추가: 최소 길이 설정
    max_length=150,
    num_beams=4,
    early_stopping=True
)
```

---

## 📈 검증 체크리스트

### 학습 시작 전 필수 검증

```
□ 토크나이저 설정 확인
  □ Vocab size ≥ 1,000
  □ Special tokens 모두 설정
  □ 샘플 텍스트 정상 토크나이제이션

□ 학습률 적정성 확인
  □ 1e-6 ~ 1e-3 범위 내
  □ 모델 크기 고려
  □ 배치 크기 고려

□ 생성 품질 확인 (모델 있는 경우)
  □ 오류 없이 생성
  □ 출력 길이 적절
  □ 반복 비율 < 30%
```

---

## 🚀 실전 활용 예시

### 학습 스크립트에 통합

```python
# scripts/train.py

from src.validation import create_baseline_checker
from src.config import load_config
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

def main():
    # Config 로드
    config = load_config("baseline_kobart")

    # 모델 및 토크나이저 로드
    model = AutoModelForSeq2SeqLM.from_pretrained(config.model.name)
    tokenizer = AutoTokenizer.from_pretrained(config.model.name)

    # === 베이스라인 검증 ===
    print("\n" + "="*60)
    print("학습 시작 전 베이스라인 검증")
    print("="*60)

    checker = create_baseline_checker()

    # 샘플 데이터
    import pandas as pd
    train_df = pd.read_csv(config.data.train_path)
    sample_texts = train_df['dialogue'].tolist()[:5]

    # 전체 검증
    results = checker.run_all_checks(
        tokenizer=tokenizer,
        learning_rate=config.training.learning_rate,
        model=model,
        sample_texts=sample_texts
    )

    # 검증 실패 시 종료
    if not results['all_passed']:
        print("\n❌ 베이스라인 검증 실패!")
        print(f"Errors: {results['total_errors']}")
        print("\n설정을 수정한 후 다시 시도하세요.")
        return

    # 경고가 있으면 확인 요청
    if results['total_warnings'] > 0:
        print(f"\n⚠️ {results['total_warnings']}개의 경고가 있습니다.")
        response = input("계속 진행하시겠습니까? (y/n): ")
        if response.lower() != 'y':
            return

    # 검증 결과 저장
    checker.save_results("results/baseline_validation.json")

    print("\n✓ 베이스라인 검증 통과!")
    print("="*60)

    # === 학습 진행 ===
    # 학습 코드...
```

---

## 📊 팩토리 함수

### create_baseline_checker()

```python
from src.validation import create_baseline_checker

# 기본 설정
checker = create_baseline_checker()

# 커스텀 설정
custom_config = {
    'tokenizer': {...},
    'learning_rate': {...},
    'generation': {...}
}
checker = create_baseline_checker(config=custom_config)

# Logger 사용
from src.logging import WandBLogger

logger = WandBLogger(project="nlp-competition")
checker = create_baseline_checker(logger=logger)
```

---

## 🔗 관련 파일

**소스 코드:**
- `src/validation/baseline_checker.py` - BaselineChecker 클래스
- `src/validation/__init__.py` - 패키지 초기화

**테스트:**
- `src/tests/test_baseline_checker.py` - 검증 테스트

**문서:**
- `docs/모듈화/00_전체_시스템_개요.md` - 시스템 개요
- `docs/PRD/18_베이스라인_검증_전략.md` - PRD 문서

**Config:**
- `configs/validation/baseline.yaml` - 검증 설정
