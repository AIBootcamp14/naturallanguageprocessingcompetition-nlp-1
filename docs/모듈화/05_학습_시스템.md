# 학습 시스템 상세 가이드

## 📋 목차
1. [개요](#개요)
2. [ModelTrainer 클래스](#modeltrainer-클래스)
3. [사용 방법](#사용-방법)
4. [WandB 통합](#wandb-통합)
5. [체크포인트 관리](#체크포인트-관리)

---

## 📝 개요

### 목적
- HuggingFace Seq2SeqTrainer 래핑
- Config 기반 학습 자동화
- WandB 로깅 통합
- ROUGE 평가 자동 실행
- 체크포인트 자동 관리

### 핵심 기능
- ✅ Seq2SeqTrainer 자동 설정
- ✅ WandB 로깅 통합
- ✅ ROUGE 자동 평가
- ✅ Early Stopping 지원
- ✅ 최상 모델 자동 저장
- ✅ Logger 통합 지원

---

## 🏗️ ModelTrainer 클래스

### 파일 위치
```
src/training/trainer.py
```

### 클래스 구조

```python
class ModelTrainer:
    def __init__(self, config, model, tokenizer, train_dataset,
                 eval_dataset=None, use_wandb=True, logger=None):
        """학습 시스템 초기화"""

    def _create_training_args(self) -> Seq2SeqTrainingArguments:
        """HuggingFace 학습 인자 생성"""

    def compute_metrics(self, eval_preds) -> Dict[str, float]:
        """평가 메트릭 계산 (ROUGE)"""

    def _create_trainer(self) -> Seq2SeqTrainer:
        """HuggingFace Seq2SeqTrainer 생성"""

    def train(self) -> Dict[str, Any]:
        """모델 학습 실행"""

    def evaluate(self) -> Dict[str, float]:
        """모델 평가 실행"""
```

---

## 💻 사용 방법

### 1. 기본 사용법

```python
from src.config import load_config
from src.models import load_model_and_tokenizer
from src.data import DialogueSummarizationDataset
from src.training import create_trainer
import pandas as pd

# 1. Config 로드
config = load_config("baseline_kobart")

# 2. 모델 로드
model, tokenizer = load_model_and_tokenizer(config)

# 3. 데이터 로드
train_df = pd.read_csv("data/raw/train.csv")
eval_df = pd.read_csv("data/raw/dev.csv")

# 4. Dataset 생성
train_dataset = DialogueSummarizationDataset(
    dialogues=train_df['dialogue'].tolist(),
    summaries=train_df['summary'].tolist(),
    tokenizer=tokenizer,
    encoder_max_len=config.tokenizer.encoder_max_len,
    decoder_max_len=config.tokenizer.decoder_max_len
)

eval_dataset = DialogueSummarizationDataset(
    dialogues=eval_df['dialogue'].tolist(),
    summaries=eval_df['summary'].tolist(),
    tokenizer=tokenizer,
    encoder_max_len=config.tokenizer.encoder_max_len,
    decoder_max_len=config.tokenizer.decoder_max_len
)

# 5. Trainer 생성 및 학습
trainer = create_trainer(
    config=config,
    model=model,
    tokenizer=tokenizer,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    use_wandb=True
)

# 6. 학습 실행
results = trainer.train()

print(f"최종 모델 경로: {results['final_model_path']}")
print(f"ROUGE Sum: {results['eval_metrics']['eval_rouge_sum']:.4f}")
```

### 2. Logger와 함께 사용

```python
from src.logging.logger import Logger
from src.utils.core.common import create_log_path

# Logger 초기화
log_path = create_log_path("train", "train.log")
logger = Logger(log_path, print_also=True)
logger.start_redirect()

try:
    # Trainer 생성 (Logger 전달)
    trainer = create_trainer(
        config=config,
        model=model,
        tokenizer=tokenizer,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        use_wandb=True,
        logger=logger
    )

    # 학습 실행
    results = trainer.train()

finally:
    logger.stop_redirect()
    logger.close()
```

### 3. WandB 없이 학습

```python
# WandB 비활성화
trainer = create_trainer(
    config=config,
    model=model,
    tokenizer=tokenizer,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    use_wandb=False  # WandB 사용 안 함
)

results = trainer.train()
```

---

## 📊 학습 인자 (Seq2SeqTrainingArguments)

### Config에서 자동 생성

`src/training/trainer.py`의 `_create_training_args` 함수가 Config를 기반으로 학습 인자를 자동 생성합니다:

```yaml
# configs/experiments/baseline_kobart.yaml
training:
  epochs: 20
  batch_size: 50
  learning_rate: 1e-5
  weight_decay: 0.01
  warmup_steps: 500
  save_total_limit: 3
  logging_steps: 100
```

### 생성된 학습 인자

```python
Seq2SeqTrainingArguments(
    output_dir="outputs/baseline_kobart",
    overwrite_output_dir=True,

    # 학습 하이퍼파라미터
    num_train_epochs=20,
    per_device_train_batch_size=50,
    per_device_eval_batch_size=50,
    learning_rate=1e-5,
    weight_decay=0.01,
    warmup_steps=500,

    # 평가 및 저장
    eval_strategy='epoch',
    save_strategy='epoch',
    save_total_limit=3,
    load_best_model_at_end=True,
    metric_for_best_model='eval_rouge_sum',

    # 로깅
    logging_dir="outputs/baseline_kobart/logs",
    logging_steps=100,
    report_to=['wandb'] if use_wandb else [],

    # Seq2Seq 특화
    predict_with_generate=True,
    generation_max_length=100,
    generation_num_beams=4,

    # 기타
    fp16=torch.cuda.is_available(),
    dataloader_num_workers=4
)
```

---

## 🔗 WandB 통합

### WandB 설정

```yaml
# configs/experiments/baseline_kobart.yaml
wandb:
  enabled: true
  project: "nlp-competition"
  entity: "ieyeppo"

experiment:
  name: "baseline_kobart"
  tags:
    - "baseline"
    - "kobart"
```

### 자동 로깅 항목

WandB에 자동으로 로깅되는 항목:

1. **학습 메트릭**
   - train_loss
   - train_runtime
   - train_samples_per_second
   - train_steps_per_second

2. **평가 메트릭**
   - eval_rouge1
   - eval_rouge2
   - eval_rougeL
   - eval_rouge_sum
   - eval_loss

3. **Config 정보**
   - 전체 Config 파라미터
   - 실험 태그
   - 모델 체크포인트 이름

4. **시스템 정보**
   - GPU 사용률
   - 메모리 사용량
   - CPU 사용률

### WandB 초기화 및 종료

```python
# WandB Logger 초기화
if use_wandb and config.wandb.enabled:
    self.wandb_logger = WandbLogger(
        project_name=config.wandb.project,
        entity=config.wandb.entity,
        experiment_name=config.experiment.name,
        config=dict(config),
        tags=config.experiment.tags
    )

# 학습 시작 시 WandB Run 초기화
self.wandb_logger.init_run()

# 학습 종료 시 WandB Run 종료
self.wandb_logger.finish()
```

---

## 💾 체크포인트 관리

### 자동 저장

학습 중 자동으로 체크포인트가 저장됩니다:

```
outputs/baseline_kobart/
├── checkpoint-500/          # 500 스텝 체크포인트
│   ├── config.json
│   ├── pytorch_model.bin
│   └── trainer_state.json
├── checkpoint-1000/         # 1000 스텝 체크포인트
├── checkpoint-1500/         # 1500 스텝 체크포인트
└── final_model/             # 최종 모델
    ├── config.json
    ├── pytorch_model.bin
    ├── tokenizer_config.json
    └── special_tokens_map.json
```

### 최상 모델 자동 로드

```python
# Config 설정
save_strategy='epoch',
load_best_model_at_end=True,           # 최상 모델 자동 로드
metric_for_best_model='eval_rouge_sum' # ROUGE Sum 기준
```

학습 종료 후 자동으로 가장 높은 ROUGE Sum을 달성한 체크포인트가 로드됩니다.

### 체크포인트 개수 제한

```yaml
# configs/experiments/baseline_kobart.yaml
training:
  save_total_limit: 3  # 최대 3개 체크포인트만 유지
```

오래된 체크포인트는 자동으로 삭제되어 디스크 공간을 절약합니다.

---

## 🧪 테스트

### 테스트 파일 위치
```
src/tests/test_trainer.py
```

### 테스트 실행

```bash
python src/tests/test_trainer.py
```

### 테스트 항목 (총 4개)

1. ✅ Trainer 생성
2. ✅ 학습 인자 생성
3. ✅ ROUGE 평가 함수 (compute_metrics)
4. ✅ 편의 함수 (create_trainer)

---

## 🎯 실전 활용 예시

### 예시 1: 디버그 모드 학습

```python
# Config 수정
config.training.epochs = 2
config.training.batch_size = 4
config.wandb.enabled = False

# 작은 데이터셋
train_df = train_df.head(100)
eval_df = eval_df.head(20)

# 빠른 학습
trainer = create_trainer(config, model, tokenizer, train_dataset, eval_dataset, use_wandb=False)
results = trainer.train()
```

### 예시 2: Early Stopping 사용

```yaml
# configs/experiments/my_experiment.yaml
training:
  early_stopping_patience: 3  # 3 에포크 동안 개선 없으면 종료
```

### 예시 3: 학습 재개

```python
# 체크포인트에서 재개
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

# 특정 체크포인트에서 재개
trainer.train(resume_from_checkpoint="outputs/baseline_kobart/checkpoint-1000")
```

---

## 📌 주의사항

### 1. 배치 크기와 GPU 메모리

GPU 메모리 부족 시 배치 크기를 줄이세요:

```yaml
training:
  batch_size: 16  # 50 → 16
  gradient_accumulation_steps: 4  # 실질적 배치 크기: 16 * 4 = 64
```

### 2. WandB 로그인

WandB 사용 전 로그인 필요:

```bash
wandb login
```

### 3. FP16 자동 활성화

GPU가 있으면 자동으로 FP16 학습이 활성화됩니다:

```python
fp16=torch.cuda.is_available()
```

---

## 🔗 관련 파일

**소스 코드:**
- `src/training/trainer.py` - ModelTrainer 클래스
- `src/training/__init__.py` - 외부 API

**테스트:**
- `src/tests/test_trainer.py` - 단위 테스트

**Config:**
- `configs/base/default.yaml` - 기본 학습 설정
- `configs/experiments/baseline_kobart.yaml` - 실험별 설정
