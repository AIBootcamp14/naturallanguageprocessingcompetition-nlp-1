# μ²΄ν¬ν¬μΈνΈ Resume μ‚¬μ© κ°€μ΄λ“

> **λ©μ **: ν•™μµ/μ¶”λ΅ /κ²€μ¦ μ¤‘λ‹¨ μ‹ μ²΄ν¬ν¬μΈνΈμ—μ„ μ΄μ–΄μ„ μ‹¤ν–‰ν•λ” λ°©λ²• μ•λ‚΄
> **μ‘μ„±μΌ**: 2025-10-14
> **λ²„μ „**: 1.0

---

## π“‹ λ©μ°¨

1. [μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν… κ°μ”](#1-μ²΄ν¬ν¬μΈνΈ-μ‹μ¤ν…-κ°μ”)
2. [λ…λ Ήν–‰ μµμ… μƒμ„Έ μ„¤λ…](#2-λ…λ Ήν–‰-μµμ…-μƒμ„Έ-μ„¤λ…)
3. [λ‹¨κ³„λ³„ Resume λ…λ Ήμ–΄](#3-λ‹¨κ³„λ³„-resume-λ…λ Ήμ–΄)
4. [μ‹¤μ „ μ‹λ‚λ¦¬μ¤ μμ ](#4-μ‹¤μ „-μ‹λ‚λ¦¬μ¤-μμ )
5. [μ£Όμμ‚¬ν•­ λ° FAQ](#5-μ£Όμμ‚¬ν•­-λ°-faq)

---

## 1. μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν… κ°μ”

### 1.1 μ§€μ›λλ” μ²΄ν¬ν¬μΈνΈ μ ν•

| μ²΄ν¬ν¬μΈνΈ μ ν• | μ €μ¥ μ‹μ  | μ €μ¥ λ‚΄μ© | Resume μ‹ λ™μ‘ |
|----------------|----------|----------|---------------|
| **Optuna μµμ ν™”** | Trial μ™„λ£λ§λ‹¤ | Trial κ²°κ³Ό, μµμ  νλΌλ―Έν„° | μ™„λ£λ Trial κ±΄λ„λ›°κ³  μ΄μ–΄μ„ μ‹¤ν–‰ |
| **K-Fold ν•™μµ** | Fold μ™„λ£λ§λ‹¤ | Fold λ¨λΈ, ν‰κ°€ λ©”νΈλ¦­ | μ™„λ£λ Fold κ±΄λ„λ›°κ³  μ΄μ–΄μ„ μ‹¤ν–‰ |
| **λ°μ΄ν„° μ¦κ°•** | 100κ°λ§λ‹¤ | μ¦κ°•λ λ°μ΄ν„°, μ§„ν–‰λ¥  | μ™„λ£λ μ¦κ°• λ°μ΄ν„° λ΅λ“ ν›„ μ΄μ–΄μ„ μ‹¤ν–‰ |
| **HuggingFace λ³΄μ •** | λ°°μΉλ§λ‹¤ | λ³΄μ •λ μ”μ•½, μ§„ν–‰λ¥  | μ™„λ£λ λ³΄μ • λ°μ΄ν„° λ΅λ“ ν›„ μ΄μ–΄μ„ μ‹¤ν–‰ |
| **Solar API νΈμ¶** | λ°°μΉλ§λ‹¤ | API μ‘λ‹µ, ν†µκ³„ | μ™„λ£λ νΈμ¶ λ°μ΄ν„° λ΅λ“ ν›„ μ΄μ–΄μ„ μ‹¤ν–‰ |
| **κ²€μ¦** | λ°°μΉλ§λ‹¤ | μμΈ΅ κ²°κ³Ό, λ©”νΈλ¦­ | μ™„λ£λ ν‰κ°€ λ°μ΄ν„° λ΅λ“ ν›„ μ΄μ–΄μ„ μ‹¤ν–‰ |

### 1.2 μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ„μΉ

```
experiments/{λ‚ μ§}/{μ‹κ°„}_{μ‹¤ν—λ…}/
β”β”€β”€ checkpoints/                              # μ²΄ν¬ν¬μΈνΈ ν΄λ”
β”‚   β”β”€β”€ optuna_kobart_ultimate_checkpoint.pkl # Optuna μ²΄ν¬ν¬μΈνΈ
β”‚   β”β”€β”€ kfold_checkpoint.json                 # K-Fold μ²΄ν¬ν¬μΈνΈ
β”‚   β”β”€β”€ augmentation_checkpoint.pkl           # λ°μ΄ν„° μ¦κ°• μ²΄ν¬ν¬μΈνΈ
β”‚   β”β”€β”€ correction_checkpoint.pkl             # HF λ³΄μ • μ²΄ν¬ν¬μΈνΈ
β”‚   β”β”€β”€ solar_api_checkpoint.pkl              # Solar API μ²΄ν¬ν¬μΈνΈ
β”‚   β””β”€β”€ validation_checkpoint.pkl             # κ²€μ¦ μ²΄ν¬ν¬μΈνΈ
β”β”€β”€ fold_0/                                   # Fold λ¨λΈλ“¤
β”β”€β”€ fold_1/
β””β”€β”€ train.log                                 # ν•™μµ λ΅κ·Έ
```

---

## 2. λ…λ Ήν–‰ μµμ… μƒμ„Έ μ„¤λ…

### 2.1 κΈ°λ³Έ Resume μµμ…

#### `--resume`
μ²΄ν¬ν¬μΈνΈμ—μ„ μ΄μ–΄μ„ μ‹¤ν–‰

```bash
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --resume  # β… μ²΄ν¬ν¬μΈνΈμ—μ„ μ΄μ–΄μ„ μ‹¤ν–‰
```

**λ™μ‘ λ°©μ‹**:
- μ¶λ ¥ λ””λ ‰ν† λ¦¬μ—μ„ μ²΄ν¬ν¬μΈνΈ νμΌ μλ™ νƒμ§€
- μ²΄ν¬ν¬μΈνΈκ°€ μμΌλ©΄: μ™„λ£λ μ‘μ—… κ±΄λ„λ›°κ³  μ΄μ–΄μ„ μ‹¤ν–‰
- μ²΄ν¬ν¬μΈνΈκ°€ μ—†μΌλ©΄: μ²μλ¶€ν„° μ‹μ‘ (κ²½κ³  μ—†μ)

#### `--resume_from`
νΉμ • μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬μ—μ„ Resume

```bash
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --resume \
  --resume_from experiments/20251014/20251014_143000_kobart_ultimate/checkpoints
```

**λ™μ‘ λ°©μ‹**:
- μ§€μ •λ μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬μ—μ„ Resume μ‹μ‘
- `checkpoints` ν΄λ”λ¥Ό μ§€μ •ν•λ©΄ μλ™μΌλ΅ μƒμ„ ν΄λ”λ¥Ό μ‹¤ν— λ””λ ‰ν† λ¦¬λ΅ μΈμ‹
- μ‹¤ν— ν΄λ” κ²½λ΅λ¥Ό μ§μ ‘ μ§€μ •ν•΄λ„ μλ™μΌλ΅ `checkpoints/` ν•μ„ ν΄λ” νƒμƒ‰

**μ‚¬μ© μ‹λ‚λ¦¬μ¤**:
- λ‹¤λ¥Έ μ‹¤ν—μ μ²΄ν¬ν¬μΈνΈλ¥Ό μ΄μ–΄λ°›μ„ λ•
- λ…μ‹μ μΌλ΅ μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ¥Ό μ§€μ •ν•κ³  μ‹¶μ„ λ•

#### `--ignore_checkpoint`
μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹ν•κ³  μ²μλ¶€ν„° μ‹μ‘

```bash
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --ignore_checkpoint  # β… μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹
```

**μ‚¬μ© μ‹λ‚λ¦¬μ¤**:
- λ™μΌν• μ‹¤ν—λ…μΌλ΅ μƒλ΅ μ‹μ‘ν•κ³  μ‹¶μ„ λ•
- μ²΄ν¬ν¬μΈνΈκ°€ μ†μƒλμ—μ„ λ•

---

## 3. λ‹¨κ³„λ³„ Resume λ…λ Ήμ–΄

### 3.1 Optuna μµμ ν™” Resume

#### μ‹λ‚λ¦¬μ¤: Trial 11/20 μ™„λ£ ν›„ μ¤‘λ‹¨

**μ΄κΈ° μ‹¤ν–‰ (μ¤‘λ‹¨λ¨)**:
```bash
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --optuna_timeout 10800 \
  --epochs 7 \
  --batch_size 16 \
  --gradient_accumulation_steps 10 \
  --learning_rate 9.14e-5 \
  --warmup_ratio 0.00136 \
  --weight_decay 0.0995 \
  --scheduler_type cosine \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --augmentation_methods back_translation paraphrase \
  --k_folds 5 \
  --fold_seed 42 \
  --max_new_tokens 100 \
  --min_new_tokens 30 \
  --num_beams 4 \
  --repetition_penalty 1.5 \
  --length_penalty 0.938 \
  --no_repeat_ngram_size 3 \
  --use_solar_api \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --save_visualizations \
  --experiment_name kobart_ultimate \
  --seed 42

# Trial 11/20 μ™„λ£ ν›„ Ctrl+C λλ” μ¤λ¥ λ°μƒ
```

**Resume μ‹¤ν–‰ (λ‚¨μ€ Trial 9κ°λ§ μ‹¤ν–‰)**:
```bash
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --optuna_timeout 10800 \
  --epochs 7 \
  --batch_size 16 \
  --gradient_accumulation_steps 10 \
  --learning_rate 9.14e-5 \
  --warmup_ratio 0.00136 \
  --weight_decay 0.0995 \
  --scheduler_type cosine \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --augmentation_methods back_translation paraphrase \
  --k_folds 5 \
  --fold_seed 42 \
  --max_new_tokens 100 \
  --min_new_tokens 30 \
  --num_beams 4 \
  --repetition_penalty 1.5 \
  --length_penalty 0.938 \
  --no_repeat_ngram_size 3 \
  --use_solar_api \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --save_visualizations \
  --experiment_name kobart_ultimate \
  --seed 42 \
  --resume  # β… μ¶”κ°€: Resume μµμ…
```

**μμƒ λ΅κ·Έ**:
```
π”„ μ²΄ν¬ν¬μΈνΈμ—μ„ Resume: 11/20 Trial μ΄λ―Έ μ™„λ£
  - ν„μ¬ μµμ κ°’: 0.4616
  - λ§μ§€λ§‰ μ €μ¥: 2025-10-14T14:30:00
  - λ‚¨μ€ Trial: 9κ°

Trial 12/20:
  - learning_rate: 7.25e-5
  - epochs: 6
  ...
```

---

### 3.2 K-Fold ν•™μµ Resume

#### μ‹λ‚λ¦¬μ¤: Fold 2/5 μ™„λ£ ν›„ μ¤‘λ‹¨

**μ΄κΈ° μ‹¤ν–‰ (μ¤‘λ‹¨λ¨)**:
```bash
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --epochs 7 \
  --batch_size 16 \
  --gradient_accumulation_steps 10 \
  --learning_rate 9.14e-5 \
  --warmup_ratio 0.00136 \
  --weight_decay 0.0995 \
  --scheduler_type cosine \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --augmentation_methods back_translation paraphrase \
  --k_folds 5 \
  --fold_seed 42 \
  --max_new_tokens 100 \
  --min_new_tokens 30 \
  --num_beams 4 \
  --repetition_penalty 1.5 \
  --length_penalty 0.938 \
  --no_repeat_ngram_size 3 \
  --use_solar_api \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --experiment_name kobart_balanced \
  --seed 42

# Fold 2/5 μ™„λ£ ν›„ GPU μ¤λ¥ λ°μƒ
```

**Resume μ‹¤ν–‰ (λ‚¨μ€ Fold 3κ°λ§ μ‹¤ν–‰)**:
```bash
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --epochs 7 \
  --batch_size 16 \
  --gradient_accumulation_steps 10 \
  --learning_rate 9.14e-5 \
  --warmup_ratio 0.00136 \
  --weight_decay 0.0995 \
  --scheduler_type cosine \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --augmentation_methods back_translation paraphrase \
  --k_folds 5 \
  --fold_seed 42 \
  --max_new_tokens 100 \
  --min_new_tokens 30 \
  --num_beams 4 \
  --repetition_penalty 1.5 \
  --length_penalty 0.938 \
  --no_repeat_ngram_size 3 \
  --use_solar_api \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --experiment_name kobart_balanced \
  --seed 42 \
  --resume  # β… μ¶”κ°€: Resume μµμ…
```

**μμƒ λ΅κ·Έ**:
```
π”„ μ²΄ν¬ν¬μΈνΈμ—μ„ Resume: 2/5 Fold μ΄λ―Έ μ™„λ£
  μ™„λ£λ Fold: [0, 1]

β­οΈ  Fold 1/5 - μ΄λ―Έ μ™„λ£λ¨ (κ±΄λ„λ€)
β­οΈ  Fold 2/5 - μ΄λ―Έ μ™„λ£λ¨ (κ±΄λ„λ€)

========================================
π“ Fold 3/5 ν•™μµ μ‹μ‘
========================================
  ν•™μµ: 2632κ°
  κ²€μ¦: 658κ°
...
```

---

### 3.3 λ°μ΄ν„° μ¦κ°• Resume

#### μ‹λ‚λ¦¬μ¤: μ¦κ°• 50% μ§„ν–‰ ν›„ μ¤‘λ‹¨

**μ΄κΈ° μ‹¤ν–‰ (μ¤‘λ‹¨λ¨)**:
```bash
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 5 \
  --batch_size 16 \
  --gradient_accumulation_steps 10 \
  --learning_rate 9.14e-5 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --augmentation_methods back_translation paraphrase \
  --experiment_name kobart_test \
  --seed 42

# μ¦κ°• μ§„ν–‰ μ¤‘ (1500/3000) Ctrl+C
```

**Resume μ‹¤ν–‰ (50%λ¶€ν„° μ΄μ–΄μ„ μ‹¤ν–‰)**:
```bash
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 5 \
  --batch_size 16 \
  --gradient_accumulation_steps 10 \
  --learning_rate 9.14e-5 \
  --use_augmentation \
  --augmentation_ratio 0.5 \
  --augmentation_methods back_translation paraphrase \
  --experiment_name kobart_test \
  --seed 42 \
  --resume  # β… μ¶”κ°€: Resume μµμ…
```

**μμƒ λ΅κ·Έ**:
```
β… μ¦κ°• λ°μ΄ν„° μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...

λ°μ΄ν„° μ¦κ°• μ‹μ‘
  - μ›λ³Έ λ°μ΄ν„°: 3290κ°
  - μ¦κ°• λ°©λ²•: ['back_translation', 'paraphrase']
  - λ°©λ²•λ‹Ή μƒν” μ: 1
  - λ©ν‘ λ°μ΄ν„° ν¬κΈ°: 9870κ°

[λ΅λ“λ λ°μ΄ν„° μ‚¬μ©]
λ°μ΄ν„° μ¦κ°• μ™„λ£: 9870κ°
```

---

### 3.4 HuggingFace λ³΄μ • Resume

#### μ‹λ‚λ¦¬μ¤: λ³΄μ • μ§„ν–‰ μ¤‘ μ¤‘λ‹¨

**μ¶”λ΅  λ…λ Ήμ–΄ (μ¤‘λ‹¨λ¨)**:
```bash
python scripts/inference.py \
  --model experiments/20251014/20251014_143000_kobart_balanced/fold_0/final_model \
  --test_data data/raw/test.csv \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --max_new_tokens 100 \
  --min_new_tokens 30 \
  --num_beams 4 \
  --length_penalty 0.938 \
  --repetition_penalty 1.5 \
  --batch_size 16 \
  --output submissions/kobart_hf_corrected.csv

# λ³΄μ • μ§„ν–‰ μ¤‘ (500/1000) μ¤‘λ‹¨
```

**Resume μ‹¤ν–‰**:
```bash
python scripts/inference.py \
  --model experiments/20251014/20251014_143000_kobart_balanced/fold_0/final_model \
  --test_data data/raw/test.csv \
  --use_pretrained_correction \
  --correction_models gogamza/kobart-base-v2 digit82/kobart-summarization \
  --correction_strategy quality_based \
  --correction_threshold 0.3 \
  --max_new_tokens 100 \
  --min_new_tokens 30 \
  --num_beams 4 \
  --length_penalty 0.938 \
  --repetition_penalty 1.5 \
  --batch_size 16 \
  --output submissions/kobart_hf_corrected.csv \
  --resume  # β… μ¶”κ°€: Resume μµμ…
```

**μμƒ λ΅κ·Έ**:
```
π”„ HF λ³΄μ • μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...
  - μ™„λ£: 500/1000
  - μ§„ν–‰λ¥ : 50.0%

λ³΄μ • μ΄μ–΄μ„ μ§„ν–‰ μ¤‘...
[501/1000] λ³΄μ • μ¤‘...
[600/1000] λ³΄μ • μ¤‘...
...
```

---

### 3.5 Solar API Resume

#### μ‹λ‚λ¦¬μ¤: Solar API λ°°μΉ νΈμ¶ μ¤‘ μ¤‘λ‹¨

**μ¶”λ΅  λ…λ Ήμ–΄ (μ¤‘λ‹¨λ¨)**:
```bash
python scripts/inference.py \
  --model experiments/20251014/20251014_143000_kobart_balanced/fold_0/final_model \
  --test_data data/raw/test.csv \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --batch_size 10 \
  --output submissions/kobart_solar.csv

# API νΈμ¶ μ¤‘ (300/1000) νƒ€μ„μ•„μ›ƒ λ°μƒ
```

**Resume μ‹¤ν–‰**:
```bash
python scripts/inference.py \
  --model experiments/20251014/20251014_143000_kobart_balanced/fold_0/final_model \
  --test_data data/raw/test.csv \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --batch_size 10 \
  --output submissions/kobart_solar.csv \
  --resume  # β… μ¶”κ°€: Resume μµμ…
```

**μμƒ λ΅κ·Έ**:
```
π”„ Solar API μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...
  - μ™„λ£: 300/1000
  - μ§„ν–‰λ¥ : 30.0%
  - μ΄ ν† ν°: 45,000
  - ν‰κ·  μ§€μ—°μ‹κ°„: 1.2μ΄

API νΈμ¶ μ΄μ–΄μ„ μ§„ν–‰ μ¤‘...
[301/1000] API νΈμ¶ μ¤‘...
[310/1000] λ°°μΉ μ™„λ£ (μ§€μ—°μ‹κ°„: 1.1μ΄)
...
```

---

### 3.6 κ²€μ¦ Resume

#### μ‹λ‚λ¦¬μ¤: λ€κ·λ¨ κ²€μ¦ μ„ΈνΈ ν‰κ°€ μ¤‘ μ¤‘λ‹¨

**κ²€μ¦ λ…λ Ήμ–΄ (μ¤‘λ‹¨λ¨)**:
```bash
python scripts/validate.py \
  --model experiments/20251014/20251014_143000_kobart_balanced/fold_0/final_model \
  --validation_data data/raw/dev.csv \
  --batch_size 16 \
  --output_dir experiments/20251014/20251014_143000_kobart_balanced/validation

# ν‰κ°€ μ§„ν–‰ μ¤‘ (200/500) μ¤‘λ‹¨
```

**Resume μ‹¤ν–‰**:
```bash
python scripts/validate.py \
  --model experiments/20251014/20251014_143000_kobart_balanced/fold_0/final_model \
  --validation_data data/raw/dev.csv \
  --batch_size 16 \
  --output_dir experiments/20251014/20251014_143000_kobart_balanced/validation \
  --resume  # β… μ¶”κ°€: Resume μµμ…
```

**μμƒ λ΅κ·Έ**:
```
π”„ κ²€μ¦ μ²΄ν¬ν¬μΈνΈ λ°κ²¬. λ΅λ“ μ¤‘...
  - μ™„λ£: 200/500
  - μ§„ν–‰λ¥ : 40.0%
  - ν„μ¬ ROUGE-L: 0.42

κ²€μ¦ μ΄μ–΄μ„ μ§„ν–‰ μ¤‘...
[201/500] ν‰κ°€ μ¤‘...
[210/500] λ°°μΉ μ™„λ£
...
```

---

## 4. μ‹¤μ „ μ‹λ‚λ¦¬μ¤ μμ 

### 4.1 μ‹λ‚λ¦¬μ¤ 1: κΈ΄κΈ‰ μ¤‘λ‹¨ ν›„ Resume

**μƒν™©**: Optuna μµμ ν™” μ¤‘ GPU μ„λ²„ μ¬λ¶€ν… ν•„μ”

```bash
# 1λ‹¨κ³„: μ§„ν–‰ μ¤‘μΈ ν•™μµ ν™•μΈ
tail -f experiments/20251014/*/train.log
# μ¶λ ¥: Trial 8/20 μ™„λ£

# 2λ‹¨κ³„: Ctrl+Cλ΅ μ¤‘λ‹¨

# 3λ‹¨κ³„: GPU μ„λ²„ μ¬λ¶€ν…

# 4λ‹¨κ³„: λ™μΌν• λ…λ Ήμ–΄μ— --resume μ¶”κ°€ν•μ—¬ μ¬μ‹¤ν–‰
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  ... (κΈ°μ΅΄ μµμ… λ™μΌ) ... \
  --experiment_name kobart_ultimate \
  --seed 42 \
  --resume  # β… Resume μµμ… μ¶”κ°€

# κ²°κ³Ό: Trial 9λ¶€ν„° μ΄μ–΄μ„ μ‹¤ν–‰ (Trial 1-8μ€ κ±΄λ„λ€)
```

---

### 4.2 μ‹λ‚λ¦¬μ¤ 2: λ‹¤λ¥Έ μ‹¤ν—μ μ²΄ν¬ν¬μΈνΈ μ΄μ–΄λ°›κΈ°

**μƒν™©**: μ΄μ „ μ‹¤ν—μ Optuna κ²°κ³Όλ¥Ό μ΄μ–΄λ°›μ•„ μ¶”κ°€ Trial μ‹¤ν–‰

```bash
# 1λ‹¨κ³„: μ΄μ „ μ‹¤ν— μ²΄ν¬ν¬μΈνΈ μ„μΉ ν™•μΈ
ls experiments/20251014/20251014_120000_kobart_ultimate/checkpoints/
# μ¶λ ¥: optuna_kobart_ultimate_checkpoint.pkl

# 2λ‹¨κ³„: --resume_fromμΌλ΅ λ…μ‹μ μΌλ΅ μ§€μ •
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 30 \  # β… 20 β†’ 30μΌλ΅ μ¦κ°€
  ... (κΈ°μ΅΄ μµμ… λ™μΌ) ... \
  --experiment_name kobart_ultimate_extended \
  --seed 42 \
  --resume \
  --resume_from experiments/20251014/20251014_120000_kobart_ultimate/checkpoints

# κ²°κ³Ό: μ΄μ „ 20 trials + μ¶”κ°€ 10 trials = μ΄ 30 trials μ‹¤ν–‰
```

---

### 4.3 μ‹λ‚λ¦¬μ¤ 3: μ†μƒλ μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹ν•κ³  μ¬μ‹μ‘

**μƒν™©**: μ²΄ν¬ν¬μΈνΈ νμΌμ΄ μ†μƒλμ–΄ λ΅λ“ μ‹¤ν¨

```bash
# 1λ‹¨κ³„: Resume μ‹λ„ (μ‹¤ν¨)
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  ... (κΈ°μ΅΄ μµμ…) ... \
  --resume

# μ¶λ ¥: β μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ‹¤ν¨: νμΌ μ†μƒ

# 2λ‹¨κ³„: --ignore_checkpointλ΅ μ²μλ¶€ν„° μ¬μ‹μ‘
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  ... (κΈ°μ΅΄ μµμ…) ... \
  --ignore_checkpoint  # β… μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹

# κ²°κ³Ό: μ²μλ¶€ν„° μƒλ΅ μ‹μ‘ (Trial 1λ¶€ν„°)
```

---

### 4.4 μ‹λ‚λ¦¬μ¤ 4: λ³‘λ ¬ μ‹¤ν— κ΄€λ¦¬

**μƒν™©**: μ—¬λ¬ μ „λµμ„ λ™μ‹μ— μ‹¤ν—ν•λ©΄μ„ μ¤‘λ‹¨/μ¬κ°

```bash
# μ‹¤ν— A: μµκ³  μ„±λ¥ μ „λµ (Optuna)
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --experiment_name kobart_ultimate_A \
  --resume &

# μ‹¤ν— B: κ· ν• μ „λµ (K-Fold 5)
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --k_folds 5 \
  --experiment_name kobart_balanced_B \
  --resume &

# μ‹¤ν— C: λΉ λ¥Έ μ „λµ (K-Fold 3)
python scripts/train.py \
  --mode kfold \
  --models kobart \
  --k_folds 3 \
  --experiment_name kobart_fast_C \
  --resume &

# λ¨λ“  μ‹¤ν—μ΄ μ²΄ν¬ν¬μΈνΈμ—μ„ μλ™μΌλ΅ μ΄μ–΄μ„ μ‹¤ν–‰λ¨
```

---

## 5. μ£Όμμ‚¬ν•­ λ° FAQ

### 5.1 μ£Όμμ‚¬ν•­

#### β οΈ ν•μ΄νΌνλΌλ―Έν„° λ³€κ²½ κΈμ§€
```bash
# β μλ»λ μ: Resume μ‹ ν•μ΄νΌνλΌλ―Έν„° λ³€κ²½
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --epochs 10 \  # β μ›λλ” 7μ΄μ—λ”λ° λ³€κ²½
  --resume

# β… μ¬λ°”λ¥Έ μ: λ™μΌν• ν•μ΄νΌνλΌλ―Έν„° μ μ§€
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --epochs 7 \  # β… μ›λ κ°’ μ μ§€
  --resume
```

**μ΄μ **: ν•μ΄νΌνλΌλ―Έν„°κ°€ λ³€κ²½λλ©΄ μ²΄ν¬ν¬μΈνΈκ°€ λ¬΄ν¨ν™”λ  μ μμ

#### β οΈ μ‹¤ν—λ… μΌμΉ ν•„μ
```bash
# β μλ»λ μ: μ‹¤ν—λ… λ³€κ²½
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --experiment_name kobart_ultimate_v2 \  # β μ›λλ” kobart_ultimate
  --resume

# β… μ¬λ°”λ¥Έ μ: λ™μΌν• μ‹¤ν—λ… μ μ§€
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --experiment_name kobart_ultimate \  # β… μ›λ κ°’ μ μ§€
  --resume
```

**μ΄μ **: μ‹¤ν—λ…μ΄ λ³€κ²½λλ©΄ μ¶λ ¥ λ””λ ‰ν† λ¦¬κ°€ λ‹¬λΌμ Έ μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μ

#### β οΈ λ°μ΄ν„° λ³€κ²½ μ£Όμ
Resume μ‹ μ›λ³Έ λ°μ΄ν„°κ°€ λ³€κ²½λλ©΄ μΌκ΄€μ„±μ΄ κΉ¨μ§ μ μμΌλ―€λ΅ μ£Όμ

---

### 5.2 FAQ

#### Q1: μ²΄ν¬ν¬μΈνΈκ°€ μλ™μΌλ΅ μ‚­μ λλ‚μ”?
**A**: μ•„λ‹μ”, μλ™μΌλ΅ μ‚­μ λμ§€ μ•μµλ‹λ‹¤. ν•„μ” μ‹ μλ™μΌλ΅ μ‚­μ ν•κ±°λ‚ `cleanup_old_checkpoints()` λ©”μ„λ“λ¥Ό μ‚¬μ©ν•μ„Έμ”.

```python
# Python μ¤ν¬λ¦½νΈμ—μ„ μ •λ¦¬
from src.checkpoints import OptunaCheckpointManager

checkpoint_mgr = OptunaCheckpointManager("experiments/.../checkpoints", "optuna_study")
checkpoint_mgr.cleanup_old_checkpoints(keep_last_n=3)  # μµκ·Ό 3κ°λ§ μ μ§€
```

#### Q2: μ²΄ν¬ν¬μΈνΈ νμΌμ΄ λ„λ¬΄ ν½λ‹λ‹¤. μ–΄λ–»κ² ν•λ‚μ”?
**A**: μ••μ¶• κΈ°λ¥μ„ μ‚¬μ©ν•μ„Έμ”.

```python
# μ²΄ν¬ν¬μΈνΈ μ••μ¶•
checkpoint_mgr.compress_checkpoint(compression_level=6)  # λ λ²¨ 1-9

# ν•„μ” μ‹ μ••μ¶• ν•΄μ 
checkpoint_mgr.decompress_checkpoint()
```

#### Q3: Resume μ‹ μ§„ν–‰λ¥ μ„ ν™•μΈν•κ³  μ‹¶μµλ‹λ‹¤
**A**: μ²΄ν¬ν¬μΈνΈμ—μ„ μ§„ν–‰λ¥ μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

```python
# Python μ¤ν¬λ¦½νΈμ—μ„
progress = checkpoint_mgr.get_progress()
print(f"μ™„λ£: {progress['completed']}/{progress['total']}")
print(f"μ§„ν–‰λ¥ : {progress['ratio']*100:.1f}%")

# λλ” μ§„ν–‰λ¥  ν‘μ‹μ¤„
print(checkpoint_mgr.format_progress_bar(width=50))
# μ¶λ ¥: [=========================                         ] 50.0%
```

#### Q4: μ²΄ν¬ν¬μΈνΈκ°€ μ†μƒλμ—λ”μ§€ ν™•μΈν•λ” λ°©λ²•μ€?
**A**: μ²΄ν¬ν¬μΈνΈ λ΅λ“λ¥Ό μ‹λ„ν•΄λ³΄μ„Έμ”.

```python
checkpoint = checkpoint_mgr.load_checkpoint()
if checkpoint is None:
    print("β μ²΄ν¬ν¬μΈνΈ μ†μƒ λλ” μ—†μ")
else:
    print("β… μ²΄ν¬ν¬μΈνΈ μ •μƒ")
    print(f"μ €μ¥ μ‹κ°„: {checkpoint['timestamp']}")
```

#### Q5: μ—¬λ¬ λ‹¨κ³„κ°€ λ™μ‹μ— Resumeλλ‚μ”?
**A**: λ„¤, κ° λ‹¨κ³„λ³„λ΅ λ…λ¦½μ μΌλ΅ Resumeλ©λ‹λ‹¤.

```bash
# Optuna + K-Fold + λ°μ΄ν„° μ¦κ°• λ¨λ‘ Resume
python scripts/train.py \
  --mode optuna \
  --models kobart \
  --optuna_trials 20 \
  --use_augmentation \
  --k_folds 5 \
  --resume

# λ™μ‘:
# 1. λ°μ΄ν„° μ¦κ°• μ²΄ν¬ν¬μΈνΈ ν™•μΈ β†’ Resume
# 2. Optuna μ²΄ν¬ν¬μΈνΈ ν™•μΈ β†’ Resume
# 3. K-Foldλ” Optuna μ™„λ£ ν›„ λ³„λ„ μ‹¤ν–‰
```

#### Q6: Resume μ‹ μ‹λ“κ°€ λ‹¬λΌμ§€λ©΄ μ–΄λ–»κ² λλ‚μ”?
**A**: μ΄λ―Έ μ™„λ£λ μ‘μ—…μ€ κ±΄λ„λ›°κ³ , μƒλ΅μ΄ μ‘μ—…λ§ μƒ μ‹λ“λ΅ μ‹¤ν–‰λ©λ‹λ‹¤.

```bash
# μ›λ μ‹¤ν–‰ (seed=42, Trial 10/20 μ™„λ£)
python scripts/train.py --mode optuna --optuna_trials 20 --seed 42

# Resume (seed=100)
python scripts/train.py --mode optuna --optuna_trials 20 --seed 100 --resume

# κ²°κ³Ό:
# - Trial 1-10: κ·Έλ€λ΅ μ μ§€ (seed=42λ΅ μ‹¤ν–‰λ κ²°κ³Ό)
# - Trial 11-20: seed=100μΌλ΅ μ‹¤ν–‰
```

#### Q7: μ²΄ν¬ν¬μΈνΈ μ—†μ΄ Resumeν•λ©΄ μ–΄λ–»κ² λλ‚μ”?
**A**: κ²½κ³  μ—†μ΄ μ²μλ¶€ν„° μ‹μ‘ν•©λ‹λ‹¤.

```bash
python scripts/train.py --mode optuna --optuna_trials 20 --resume
# μ²΄ν¬ν¬μΈνΈκ°€ μ—†μΌλ©΄ μλ™μΌλ΅ μ²μλ¶€ν„° μ‹μ‘
```

#### Q8: νΉμ • λ‹¨κ³„μ μ²΄ν¬ν¬μΈνΈλ§ μ‚­μ ν•κ³  μ‹¶μµλ‹λ‹¤
**A**: ν•΄λ‹Ή μ²΄ν¬ν¬μΈνΈ νμΌλ§ μλ™μΌλ΅ μ‚­μ ν•μ„Έμ”.

```bash
# Optuna μ²΄ν¬ν¬μΈνΈλ§ μ‚­μ 
rm experiments/20251014/*/checkpoints/optuna_*_checkpoint.pkl

# K-Fold μ²΄ν¬ν¬μΈνΈλ§ μ‚­μ 
rm experiments/20251014/*/checkpoints/kfold_checkpoint.json
```

---

## 6. κ³ κΈ‰ κΈ°λ¥

### 6.1 μ²΄ν¬ν¬μΈνΈ μ••μ¶• μ‚¬μ©

```bash
# ν•™μµ μ™„λ£ ν›„ μ••μ¶• (λ””μ¤ν¬ κ³µκ°„ μ μ•½)
python -c "
from src.checkpoints import OptunaCheckpointManager
mgr = OptunaCheckpointManager('experiments/20251014/.../checkpoints', 'optuna_study')
mgr.compress_checkpoint(compression_level=9)  # μµλ€ μ••μ¶•
print(f'μ••μ¶• μ „: {mgr.get_checkpoint_size()//1024}KB')
"
```

### 6.2 μ¤λλ μ²΄ν¬ν¬μΈνΈ μλ™ μ •λ¦¬

```bash
# μµκ·Ό 3κ° μ²΄ν¬ν¬μΈνΈλ§ μ μ§€, 7μΌ μ΄μƒλ νμΌ μ‚­μ 
python -c "
from src.checkpoints import OptunaCheckpointManager
mgr = OptunaCheckpointManager('experiments/20251014/.../checkpoints', 'optuna_study')
mgr.cleanup_old_checkpoints(keep_last_n=3, max_age_days=7)
print('β… μ¤λλ μ²΄ν¬ν¬μΈνΈ μ •λ¦¬ μ™„λ£')
"
```

### 6.3 μ§„ν–‰λ¥  μ‹κ°ν™”

```bash
# μ§„ν–‰λ¥  ν‘μ‹μ¤„ μ¶λ ¥
python -c "
from src.checkpoints import KFoldCheckpointManager
mgr = KFoldCheckpointManager('experiments/20251014/.../checkpoints', n_folds=5)
progress = mgr.get_progress()
print(mgr.format_progress_bar(width=50))
print(f'μ™„λ£λ Fold: {progress[\"completed_folds\"]}/{progress[\"total_folds\"]}')
"
```

---

## 7. μ”μ•½

### 7.1 ν•µμ‹¬ ν¬μΈνΈ

1. β… **λ¨λ“  λ‹¨κ³„μ—μ„ μ²΄ν¬ν¬μΈνΈ μ§€μ›**: Optuna, K-Fold, λ°μ΄ν„° μ¦κ°•, HF λ³΄μ •, Solar API, κ²€μ¦
2. β… **κ°„λ‹¨ν• Resume**: κΈ°μ΅΄ λ…λ Ήμ–΄μ— `--resume` μ¶”κ°€λ§
3. β… **μλ™ μ§„ν–‰λ¥  κ΄€λ¦¬**: μ™„λ£λ μ‘μ—… μλ™ κ±΄λ„λ›°κΈ°
4. β… **μ•μ „ν• μ €μ¥**: μ›μμ  μ €μ¥μΌλ΅ νμΌ μ†μƒ λ°©μ§€
5. β… **μ μ—°ν• κ΄€λ¦¬**: μ••μ¶•, μ •λ¦¬, μ§„ν–‰λ¥  ν™•μΈ κΈ°λ¥

### 7.2 λΉ λ¥Έ μ°Έμ΅°

| λ…λ Ή | μµμ… | μ„¤λ… |
|------|------|------|
| Resume | `--resume` | μ²΄ν¬ν¬μΈνΈμ—μ„ μ΄μ–΄μ„ μ‹¤ν–‰ (μλ™ νƒμ§€) |
| νΉμ • κ²½λ΅ Resume | `--resume_from {κ²½λ΅}` | μ§€μ •λ μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬μ—μ„ Resume |
| μ²μλ¶€ν„° μ‹μ‘ | `--ignore_checkpoint` | μ²΄ν¬ν¬μΈνΈ λ¬΄μ‹ν•κ³  μƒλ΅ μ‹μ‘ |

---

**μ‘μ„±**: 2025-10-14
**λ²„μ „**: 1.0
**κ΄€λ ¨ λ¬Έμ„**:
- `docs/modify/04_μ²΄ν¬ν¬μΈνΈ_μ¤‘κ°„μ €μ¥_κΈ°λ¥_μ¶”κ°€.md`
- `docs/λ¨λ“ν™”/04_02_KoBART_λ‹¨μΌλ¨λΈ_μµκ°•_μ„±λ¥_μ „λµ.md`
