# 전체 파이프라인 실행 명령어

> **고성능 경진대회 제출용 명령어 모음** - 3시간 이내 실행 가능한 최적화된 조합

## 📋 목차

1. [전략 1: 단일 고성능 모델](#전략-1-단일-고성능-모델)
2. [전략 2: 이중 모델 앙상블](#전략-2-이중-모델-앙상블)
3. [전략 3: 삼중 모델 앙상블](#전략-3-삼중-모델-앙상블)
4. [전략 4: 전체 모델 앙상블 (고급)](#전략-4-전체-모델-앙상블-고급)
5. [전략 5: K-Fold 중심 전략](#전략-5-k-fold-중심-전략)
6. [전략 6: Solar API 활용 전략 (프리미엄)](#전략-6-solar-api-활용-전략-프리미엄)
7. [빠른 참조표](#빠른-참조표)

---

## 전략 1: 단일 고성능 모델

### 1-1. KoBART 단일 모델 (속도 최적화)

**특징**: 빠른 학습 속도, 안정적 성능, 메모리 효율적

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 8 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy1_kobart_optimized \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 30분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 2 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --temperature 0.7 \
  --top_p 0.9 \
  --repetition_penalty 1.2 \
  --save_visualizations \
  --experiment_name test_strategy1_kobart \
  --seed 42
```

---

### 1-2. Llama-3.2-Korean 단일 모델 (균형 최적화)

**특징**: 균형잡힌 속도와 성능, 한국어 특화

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.5시간**)

```bash
python scripts/train.py \
  --mode full \
  --models llama-3.2-korean-3b \
  --epochs 6 \
  --batch_size 8 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.4 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy1_llama_balanced \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 40분**)

```bash
python scripts/train.py \
  --mode full \
  --models llama-3.2-korean-3b \
  --epochs 2 \
  --batch_size 8 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy1_llama \
  --seed 42
```

---

## 전략 2: 이중 모델 앙상블

### 2-1. KoBART + Llama (속도-성능 균형)

**특징**: 빠른 모델과 성능 모델의 조합으로 최적 균형

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.5시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 6 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 3 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.35 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy2_kobart_llama \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 45분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 2 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy2_kobart_llama \
  --seed 42
```

---

### 2-2. KoBART + Qwen3 (효율성 극대화)

**특징**: 두 효율적 모델의 조합으로 빠른 학습과 좋은 성능

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.3시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart qwen3-4b \
  --epochs 7 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 3 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy blending \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy2_kobart_qwen \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 40분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart qwen3-4b \
  --epochs 2 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy blending \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy2_kobart_qwen \
  --seed 42
```

---

## 전략 3: 삼중 모델 앙상블

### 3-1. KoBART + Llama + Qwen (다양성 극대화)

**특징**: 세 가지 다른 아키텍처의 조합으로 앙상블 효과 극대화

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.8시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b \
  --epochs 5 \
  --batch_size 10 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.4 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy3_triple_stacking \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 50분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b \
  --epochs 2 \
  --batch_size 10 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 2500 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy3_triple \
  --seed 42
```

---

## 전략 4: 전체 모델 앙상블 (고급)

### 4-1. 전체 6개 모델 앙상블 (최고 성능 추구)

**특징**: 모든 모델 활용으로 최고 성능 목표, 계산 집약적

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.9시간**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 4 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.3 \
  --k_folds 4 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 2 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy4_all_models_premium \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 1시간**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.05 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 1 \
  --max_train_samples 2000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy4_all_models \
  --seed 42
```

---

## 전략 5: K-Fold 중심 전략

### 5-1. KoBART K-Fold 10 (안정성 극대화)

**특징**: 높은 K-Fold로 안정적 성능 확보, 단일 모델 최적화

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.5시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 5 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 10 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy5_kfold10_stability \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 35분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 2 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 3 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy5_kfold \
  --seed 42
```

---

## 전략 6: Solar API 활용 전략 (프리미엄)

### 6-1. KoBART + Solar API (고품질 데이터 검증)

**특징**: Solar API로 데이터 품질 향상, 대회 주최측 권장 기능 활용

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.5시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 7 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy6_kobart_solar_api \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 35분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 2 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --max_train_samples 2000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy6_solar_api \
  --seed 42
```

---

### 6-2. 이중 모델 + Solar API (균형 프리미엄)

**특징**: 앙상블 + Solar API로 품질과 성능 동시 확보

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.7시간**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 6 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 3 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.35 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy6_dual_solar_premium \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 45분**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 2 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --max_train_samples 2000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy6_dual_solar \
  --seed 42
```

---

### 6-3. 전체 모델 + Solar API (최상급 프리미엄)

**특징**: 모든 기능 총동원, 최고 성능 추구

#### 🎯 **실제 실행용 명령어** (예상 소요 시간: **약 2.9시간**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 4 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.3 \
  --k_folds 4 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-chat \
  --prompt_strategy chain_of_thought \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy6_ultimate_premium \
  --seed 42
```

#### ⚡ **빠른 테스트용 명령어** (예상 소요 시간: **약 1시간**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.05 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 1 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --max_train_samples 1500 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy6_ultimate \
  --seed 42
```

---

## 빠른 참조표

| 전략 | 모델 수 | 예상 시간 | K-Fold | 앙상블 전략 | Solar API | 특징 | 추천 대상 |
|------|---------|-----------|--------|-------------|-----------|------|-----------|
| **1-1** | 1 (KoBART) | 2시간 | 5 | weighted_avg | ❌ | 빠른 속도, 안정적 | 빠른 실험 |
| **1-2** | 1 (Llama) | 2.5시간 | 5 | weighted_avg | ❌ | 균형잡힌 성능 | 표준 제출 |
| **2-1** | 2 | 2.5시간 | 5 | weighted_avg | ❌ | 속도-성능 균형 | 실용적 선택 |
| **2-2** | 2 | 2.3시간 | 5 | blending | ❌ | 효율성 극대화 | 리소스 제한 |
| **3-1** | 3 | 2.8시간 | 5 | stacking | ❌ | 다양성 극대화 | 고성능 추구 |
| **4-1** | 6 | 2.9시간 | 4 | stacking | ❌ | 최고 성능 | 최종 제출 |
| **5-1** | 1 | 2.5시간 | 10 | weighted_avg | ❌ | 안정성 극대화 | 리더보드 안정 |
| **6-1** | 1 + API | 2.5시간 | 5 | weighted_avg | ✅ Mini | 데이터 품질 향상 | API 활용 실험 |
| **6-2** | 2 + API | 2.7시간 | 5 | weighted_avg | ✅ Mini | 균형 프리미엄 | 품질+성능 |
| **6-3** | 6 + API | 2.9시간 | 4 | stacking | ✅ Full | 최상급 프리미엄 | 최종 제출 (최고) |

---

## 💡 전략 선택 가이드

### 시간이 부족할 때 (1일 남음)
- **추천**: 전략 1-1 (KoBART 단일) 또는 전략 2-1 (KoBART + Llama)
- **이유**: 빠른 실행으로 여러 번 시도 가능

### 성능을 최대한 끌어올리고 싶을 때
- **추천**: 전략 6-3 (전체 모델 + Solar API Full)
- **이유**: 모든 기능을 총동원한 최상급 프리미엄 전략
- **대안**: 전략 4-1 (전체 6개 모델, API 미사용)

### 안정적인 점수를 원할 때
- **추천**: 전략 5-1 (K-Fold 10)
- **이유**: 높은 K-Fold로 과적합 방지

### 균형잡힌 선택을 원할 때
- **추천**: 전략 6-2 (이중 모델 + Solar API) 또는 전략 3-1 (삼중 모델)
- **이유**: 시간과 성능의 최적 균형

### Solar API를 활용하고 싶을 때
- **추천**: 전략 6-1 (단일 모델 + API) → 전략 6-2 (이중 모델 + API) → 전략 6-3 (전체 + API)
- **이유**: 대회 주최측이 권장하는 API 활용으로 데이터 품질 향상
- **비용**: 30달러 예산 내에서 충분히 실험 가능

---

## ⚙️ 공통 설정 설명

### 성능에 영향을 주는 핵심 파라미터

1. **학습 관련**
   - `--epochs`: 낮을수록 빠름 (단일: 6-8, 다중: 4-6)
   - `--batch_size`: 클수록 빠름 (GPU 메모리 허용 범위)
   - `--gradient_accumulation_steps`: 작을수록 빠름
   - `--learning_rate`: 모델 크기에 따라 조정 (작은 모델: 5e-5, 큰 모델: 1e-5)

2. **증강 관련**
   - `--augmentation_ratio`: 0.3-0.4 권장 (너무 높으면 학습 시간 증가)
   - `--augmentation_methods`: back_translation이 가장 효과적

3. **K-Fold 관련**
   - `--k_folds`: 4-5 권장 (10은 시간이 매우 오래 걸림)
   - K-Fold가 높을수록 안정적이지만 학습 시간 선형 증가

4. **TTA 관련**
   - `--tta_num_aug`: 2-3 권장 (추론 시간에 직접 영향)
   - paraphrase, reorder가 가장 효과적

5. **앙상블 전략**
   - `weighted_avg`: 빠르고 효과적
   - `blending`: 과적합 방지
   - `stacking`: 최고 성능이지만 시간 소요

6. **Solar API 관련**
   - `--use_solar_api`: Solar API 활성화
   - `--solar_model`: `solar-1-mini-chat` (빠르고 저렴) vs `solar-1-chat` (고품질)
   - `--prompt_strategy`: 프롬프트 전략 선택
     - `few_shot_standard`: 2개 예시 (기본, 권장)
     - `chain_of_thought`: 단계별 추론 (고품질)
     - `self_consistency`: 다중 생성 후 투표 (최고 안정성)
   - Solar API는 데이터 품질 검증에 사용되며, 추가 비용 발생
   - 대회에서 30달러 지원 → 충분히 활용 가능

---

## 🔍 실험 결과 확인

실행 후 다음 위치에서 결과를 확인할 수 있습니다:

1. **제출 파일**:
   - `experiments/{날짜}/{실행폴더명}/submissions/{실행폴더명}.csv`
   - `submissions/{날짜}/{실행폴더명}.csv`

2. **학습 로그**:
   - `experiments/{날짜}/{실행폴더명}/train.log`

3. **시각화**:
   - `experiments/{날짜}/{실행폴더명}/visualizations/`

---

## 📝 팁

### 일반 팁
1. **첫 실행 시**: 반드시 **빠른 테스트용 명령어**로 정상 작동 확인
2. **GPU 메모리 부족 시**: `--batch_size` 줄이고 `--gradient_accumulation_steps` 증가
3. **시간 초과 시**: `--epochs`, `--k_folds`, `--augmentation_ratio` 감소
4. **성능 향상 시**: `--epochs` 증가, `--k_folds` 증가, 더 많은 모델 사용

### Solar API 활용 팁
1. **API 키 설정**: 명령어 실행 전 반드시 환경변수 설정
   ```bash
   export SOLAR_API_KEY="your-api-key-here"
   ```
   또는 `.env` 파일에 `SOLAR_API_KEY=your-api-key` 저장

2. **모델 선택**:
   - `solar-1-mini-chat`: 빠르고 저렴, 대부분의 경우 충분
   - `solar-1-chat`: 최고 품질이 필요할 때 (비용 더 높음)

3. **프롬프트 전략**:
   - 시작: `few_shot_standard` (가장 안정적)
   - 고품질: `chain_of_thought` (더 나은 추론)
   - 최고 안정성: `self_consistency` (가장 느리지만 안정적)

4. **비용 관리**:
   - 빠른 테스트에서는 `solar-1-mini-chat` 사용
   - 최종 제출용에서만 `solar-1-chat` 고려
   - `--max_train_samples` 옵션으로 테스트 시 API 호출 횟수 제한

5. **효과 확인**:
   - Solar API 사용 전후 성능 비교
   - `--validate_data_quality`와 함께 사용하면 데이터 품질 보고서 생성

---

## 🚀 권장 실행 순서

### 기본 전략 (Solar API 미사용)

1. **1단계**: 빠른 테스트로 정상 작동 확인
   ```bash
   # 전략 2-1의 빠른 테스트 실행 (45분)
   ```

2. **2단계**: 실제 제출용 명령어 실행
   ```bash
   # 전략 2-1의 실제 실행 (2.5시간)
   ```

3. **3단계**: 다른 전략으로 추가 실험
   ```bash
   # 전략 3-1 또는 전략 4-1 실행
   ```

4. **4단계**: 최고 점수 제출 파일 선택 및 제출

### Solar API 활용 전략 (추천)

1. **1단계**: API 키 설정 및 빠른 테스트
   ```bash
   # API 키 설정
   export SOLAR_API_KEY="your-api-key"

   # 전략 6-1 빠른 테스트 (35분)
   # Solar API 정상 작동 확인
   ```

2. **2단계**: Solar API 포함 실제 실행
   ```bash
   # 전략 6-2 실제 실행 (2.7시간)
   # 이중 모델 + Solar API로 균형잡힌 성능
   ```

3. **3단계**: 최상급 프리미엄 전략 (시간 여유 있을 때)
   ```bash
   # 전략 6-3 실제 실행 (2.9시간)
   # 전체 모델 + Solar API Full + Chain-of-Thought
   ```

4. **4단계**: 결과 비교 및 최고 점수 제출
   - Solar API 사용 전후 성능 비교
   - 가장 높은 점수의 제출 파일 선택

---

**마지막 업데이트**: 2025-10-13
**작성 기준 문서**: `docs/모듈화/04_명령어_옵션_완전_가이드.md`
