# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ëª…ë ¹ì–´

> **ê³ ì„±ëŠ¥ ê²½ì§„ëŒ€íšŒ ì œì¶œìš© ëª…ë ¹ì–´ ëª¨ìŒ** - 3ì‹œê°„ ì´ë‚´ ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì í™”ëœ ì¡°í•©

## ğŸ“‹ ëª©ì°¨

1. [ì „ëµ 1: ë‹¨ì¼ ê³ ì„±ëŠ¥ ëª¨ë¸](#ì „ëµ-1-ë‹¨ì¼-ê³ ì„±ëŠ¥-ëª¨ë¸)
2. [ì „ëµ 2: ì´ì¤‘ ëª¨ë¸ ì•™ìƒë¸”](#ì „ëµ-2-ì´ì¤‘-ëª¨ë¸-ì•™ìƒë¸”)
3. [ì „ëµ 3: ì‚¼ì¤‘ ëª¨ë¸ ì•™ìƒë¸”](#ì „ëµ-3-ì‚¼ì¤‘-ëª¨ë¸-ì•™ìƒë¸”)
4. [ì „ëµ 4: ì „ì²´ ëª¨ë¸ ì•™ìƒë¸” (ê³ ê¸‰)](#ì „ëµ-4-ì „ì²´-ëª¨ë¸-ì•™ìƒë¸”-ê³ ê¸‰)
5. [ì „ëµ 5: K-Fold ì¤‘ì‹¬ ì „ëµ](#ì „ëµ-5-k-fold-ì¤‘ì‹¬-ì „ëµ)
6. [ì „ëµ 6: Solar API í™œìš© ì „ëµ (í”„ë¦¬ë¯¸ì—„)](#ì „ëµ-6-solar-api-í™œìš©-ì „ëµ-í”„ë¦¬ë¯¸ì—„)
7. [ë¹ ë¥¸ ì°¸ì¡°í‘œ](#ë¹ ë¥¸-ì°¸ì¡°í‘œ)

---

## ì „ëµ 1: ë‹¨ì¼ ê³ ì„±ëŠ¥ ëª¨ë¸

### 1-1. KoBART ë‹¨ì¼ ëª¨ë¸ (ì†ë„ ìµœì í™”)

**íŠ¹ì§•**: ë¹ ë¥¸ í•™ìŠµ ì†ë„, ì•ˆì •ì  ì„±ëŠ¥, ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 8 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy1_kobart_optimized \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 30ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 2 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --temperature 0.7 \
  --top_p 0.9 \
  --repetition_penalty 1.2 \
  --save_visualizations \
  --experiment_name test_strategy1_kobart \
  --seed 42
```

---

### 1-2. Llama-3.2-Korean ë‹¨ì¼ ëª¨ë¸ (ê· í˜• ìµœì í™”)

**íŠ¹ì§•**: ê· í˜•ì¡íŒ ì†ë„ì™€ ì„±ëŠ¥, í•œêµ­ì–´ íŠ¹í™”

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.5ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models llama-3.2-korean-3b \
  --epochs 6 \
  --batch_size 8 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.4 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy1_llama_balanced \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 40ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models llama-3.2-korean-3b \
  --epochs 2 \
  --batch_size 8 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy1_llama \
  --seed 42
```

---

## ì „ëµ 2: ì´ì¤‘ ëª¨ë¸ ì•™ìƒë¸”

### 2-1. KoBART + Llama (ì†ë„-ì„±ëŠ¥ ê· í˜•)

**íŠ¹ì§•**: ë¹ ë¥¸ ëª¨ë¸ê³¼ ì„±ëŠ¥ ëª¨ë¸ì˜ ì¡°í•©ìœ¼ë¡œ ìµœì  ê· í˜•

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.5ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 6 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 3 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.35 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy2_kobart_llama \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 45ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 2 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy2_kobart_llama \
  --seed 42
```

---

### 2-2. KoBART + Qwen3 (íš¨ìœ¨ì„± ê·¹ëŒ€í™”)

**íŠ¹ì§•**: ë‘ íš¨ìœ¨ì  ëª¨ë¸ì˜ ì¡°í•©ìœ¼ë¡œ ë¹ ë¥¸ í•™ìŠµê³¼ ì¢‹ì€ ì„±ëŠ¥

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.3ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart qwen3-4b \
  --epochs 7 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 3 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy blending \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy2_kobart_qwen \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 40ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart qwen3-4b \
  --epochs 2 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy blending \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy2_kobart_qwen \
  --seed 42
```

---

## ì „ëµ 3: ì‚¼ì¤‘ ëª¨ë¸ ì•™ìƒë¸”

### 3-1. KoBART + Llama + Qwen (ë‹¤ì–‘ì„± ê·¹ëŒ€í™”)

**íŠ¹ì§•**: ì„¸ ê°€ì§€ ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ì˜ ì¡°í•©ìœ¼ë¡œ ì•™ìƒë¸” íš¨ê³¼ ê·¹ëŒ€í™”

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.8ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b \
  --epochs 5 \
  --batch_size 10 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.4 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy3_triple_stacking \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 50ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b \
  --epochs 2 \
  --batch_size 10 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 2500 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy3_triple \
  --seed 42
```

---

## ì „ëµ 4: ì „ì²´ ëª¨ë¸ ì•™ìƒë¸” (ê³ ê¸‰)

### 4-1. ì „ì²´ 6ê°œ ëª¨ë¸ ì•™ìƒë¸” (ìµœê³  ì„±ëŠ¥ ì¶”êµ¬)

**íŠ¹ì§•**: ëª¨ë“  ëª¨ë¸ í™œìš©ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ëª©í‘œ, ê³„ì‚° ì§‘ì•½ì 

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.9ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 4 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.3 \
  --k_folds 4 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 2 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy4_all_models_premium \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 1ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.05 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 1 \
  --max_train_samples 2000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy4_all_models \
  --seed 42
```

---

## ì „ëµ 5: K-Fold ì¤‘ì‹¬ ì „ëµ

### 5-1. KoBART K-Fold 10 (ì•ˆì •ì„± ê·¹ëŒ€í™”)

**íŠ¹ì§•**: ë†’ì€ K-Foldë¡œ ì•ˆì •ì  ì„±ëŠ¥ í™•ë³´, ë‹¨ì¼ ëª¨ë¸ ìµœì í™”

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.5ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 5 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 10 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy5_kfold10_stability \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 35ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 2 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 3 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 3000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy5_kfold \
  --seed 42
```

---

## ì „ëµ 6: Solar API í™œìš© ì „ëµ (í”„ë¦¬ë¯¸ì—„)

### 6-1. KoBART + Solar API (ê³ í’ˆì§ˆ ë°ì´í„° ê²€ì¦)

**íŠ¹ì§•**: Solar APIë¡œ ë°ì´í„° í’ˆì§ˆ í–¥ìƒ, ëŒ€íšŒ ì£¼ìµœì¸¡ ê¶Œì¥ ê¸°ëŠ¥ í™œìš©

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.5ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 7 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy6_kobart_solar_api \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 35ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 2 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --max_train_samples 2000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy6_solar_api \
  --seed 42
```

---

### 6-2. ì´ì¤‘ ëª¨ë¸ + Solar API (ê· í˜• í”„ë¦¬ë¯¸ì—„)

**íŠ¹ì§•**: ì•™ìƒë¸” + Solar APIë¡œ í’ˆì§ˆê³¼ ì„±ëŠ¥ ë™ì‹œ í™•ë³´

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.7ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 6 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 3 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.35 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 3 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy6_dual_solar_premium \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 45ë¶„**)

```bash
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b \
  --epochs 2 \
  --batch_size 12 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --max_train_samples 2000 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy6_dual_solar \
  --seed 42
```

---

### 6-3. ì „ì²´ ëª¨ë¸ + Solar API (ìµœìƒê¸‰ í”„ë¦¬ë¯¸ì—„)

**íŠ¹ì§•**: ëª¨ë“  ê¸°ëŠ¥ ì´ë™ì›, ìµœê³  ì„±ëŠ¥ ì¶”êµ¬

#### ğŸ¯ **ì‹¤ì œ ì‹¤í–‰ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 2.9ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 4 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.3 \
  --k_folds 4 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-chat \
  --prompt_strategy chain_of_thought \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --save_visualizations \
  --experiment_name strategy6_ultimate_premium \
  --seed 42
```

#### âš¡ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´** (ì˜ˆìƒ ì†Œìš” ì‹œê°„: **ì•½ 1ì‹œê°„**)

```bash
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.05 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 1 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --max_train_samples 1500 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy6_ultimate \
  --seed 42
```

---

## ë¹ ë¥¸ ì°¸ì¡°í‘œ

| ì „ëµ | ëª¨ë¸ ìˆ˜ | ì˜ˆìƒ ì‹œê°„ | K-Fold | ì•™ìƒë¸” ì „ëµ | Solar API | íŠ¹ì§• | ì¶”ì²œ ëŒ€ìƒ |
|------|---------|-----------|--------|-------------|-----------|------|-----------|
| **1-1** | 1 (KoBART) | 2ì‹œê°„ | 5 | weighted_avg | âŒ | ë¹ ë¥¸ ì†ë„, ì•ˆì •ì  | ë¹ ë¥¸ ì‹¤í—˜ |
| **1-2** | 1 (Llama) | 2.5ì‹œê°„ | 5 | weighted_avg | âŒ | ê· í˜•ì¡íŒ ì„±ëŠ¥ | í‘œì¤€ ì œì¶œ |
| **2-1** | 2 | 2.5ì‹œê°„ | 5 | weighted_avg | âŒ | ì†ë„-ì„±ëŠ¥ ê· í˜• | ì‹¤ìš©ì  ì„ íƒ |
| **2-2** | 2 | 2.3ì‹œê°„ | 5 | blending | âŒ | íš¨ìœ¨ì„± ê·¹ëŒ€í™” | ë¦¬ì†ŒìŠ¤ ì œí•œ |
| **3-1** | 3 | 2.8ì‹œê°„ | 5 | stacking | âŒ | ë‹¤ì–‘ì„± ê·¹ëŒ€í™” | ê³ ì„±ëŠ¥ ì¶”êµ¬ |
| **4-1** | 6 | 2.9ì‹œê°„ | 4 | stacking | âŒ | ìµœê³  ì„±ëŠ¥ | ìµœì¢… ì œì¶œ |
| **5-1** | 1 | 2.5ì‹œê°„ | 10 | weighted_avg | âŒ | ì•ˆì •ì„± ê·¹ëŒ€í™” | ë¦¬ë”ë³´ë“œ ì•ˆì • |
| **6-1** | 1 + API | 2.5ì‹œê°„ | 5 | weighted_avg | âœ… Mini | ë°ì´í„° í’ˆì§ˆ í–¥ìƒ | API í™œìš© ì‹¤í—˜ |
| **6-2** | 2 + API | 2.7ì‹œê°„ | 5 | weighted_avg | âœ… Mini | ê· í˜• í”„ë¦¬ë¯¸ì—„ | í’ˆì§ˆ+ì„±ëŠ¥ |
| **6-3** | 6 + API | 2.9ì‹œê°„ | 4 | stacking | âœ… Full | ìµœìƒê¸‰ í”„ë¦¬ë¯¸ì—„ | ìµœì¢… ì œì¶œ (ìµœê³ ) |

---

## ğŸ’¡ ì „ëµ ì„ íƒ ê°€ì´ë“œ

### ì‹œê°„ì´ ë¶€ì¡±í•  ë•Œ (1ì¼ ë‚¨ìŒ)
- **ì¶”ì²œ**: ì „ëµ 1-1 (KoBART ë‹¨ì¼) ë˜ëŠ” ì „ëµ 2-1 (KoBART + Llama)
- **ì´ìœ **: ë¹ ë¥¸ ì‹¤í–‰ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ ì‹œë„ ê°€ëŠ¥

### ì„±ëŠ¥ì„ ìµœëŒ€í•œ ëŒì–´ì˜¬ë¦¬ê³  ì‹¶ì„ ë•Œ
- **ì¶”ì²œ**: ì „ëµ 6-3 (ì „ì²´ ëª¨ë¸ + Solar API Full)
- **ì´ìœ **: ëª¨ë“  ê¸°ëŠ¥ì„ ì´ë™ì›í•œ ìµœìƒê¸‰ í”„ë¦¬ë¯¸ì—„ ì „ëµ
- **ëŒ€ì•ˆ**: ì „ëµ 4-1 (ì „ì²´ 6ê°œ ëª¨ë¸, API ë¯¸ì‚¬ìš©)

### ì•ˆì •ì ì¸ ì ìˆ˜ë¥¼ ì›í•  ë•Œ
- **ì¶”ì²œ**: ì „ëµ 5-1 (K-Fold 10)
- **ì´ìœ **: ë†’ì€ K-Foldë¡œ ê³¼ì í•© ë°©ì§€

### ê· í˜•ì¡íŒ ì„ íƒì„ ì›í•  ë•Œ
- **ì¶”ì²œ**: ì „ëµ 6-2 (ì´ì¤‘ ëª¨ë¸ + Solar API) ë˜ëŠ” ì „ëµ 3-1 (ì‚¼ì¤‘ ëª¨ë¸)
- **ì´ìœ **: ì‹œê°„ê³¼ ì„±ëŠ¥ì˜ ìµœì  ê· í˜•

### Solar APIë¥¼ í™œìš©í•˜ê³  ì‹¶ì„ ë•Œ
- **ì¶”ì²œ**: ì „ëµ 6-1 (ë‹¨ì¼ ëª¨ë¸ + API) â†’ ì „ëµ 6-2 (ì´ì¤‘ ëª¨ë¸ + API) â†’ ì „ëµ 6-3 (ì „ì²´ + API)
- **ì´ìœ **: ëŒ€íšŒ ì£¼ìµœì¸¡ì´ ê¶Œì¥í•˜ëŠ” API í™œìš©ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
- **ë¹„ìš©**: 30ë‹¬ëŸ¬ ì˜ˆì‚° ë‚´ì—ì„œ ì¶©ë¶„íˆ ì‹¤í—˜ ê°€ëŠ¥

---

## âš™ï¸ ê³µí†µ ì„¤ì • ì„¤ëª…

### ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ëŠ” í•µì‹¬ íŒŒë¼ë¯¸í„°

1. **í•™ìŠµ ê´€ë ¨**
   - `--epochs`: ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„ (ë‹¨ì¼: 6-8, ë‹¤ì¤‘: 4-6)
   - `--batch_size`: í´ìˆ˜ë¡ ë¹ ë¦„ (GPU ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„)
   - `--gradient_accumulation_steps`: ì‘ì„ìˆ˜ë¡ ë¹ ë¦„
   - `--learning_rate`: ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì¡°ì • (ì‘ì€ ëª¨ë¸: 5e-5, í° ëª¨ë¸: 1e-5)

2. **ì¦ê°• ê´€ë ¨**
   - `--augmentation_ratio`: 0.3-0.4 ê¶Œì¥ (ë„ˆë¬´ ë†’ìœ¼ë©´ í•™ìŠµ ì‹œê°„ ì¦ê°€)
   - `--augmentation_methods`: back_translationì´ ê°€ì¥ íš¨ê³¼ì 

3. **K-Fold ê´€ë ¨**
   - `--k_folds`: 4-5 ê¶Œì¥ (10ì€ ì‹œê°„ì´ ë§¤ìš° ì˜¤ë˜ ê±¸ë¦¼)
   - K-Foldê°€ ë†’ì„ìˆ˜ë¡ ì•ˆì •ì ì´ì§€ë§Œ í•™ìŠµ ì‹œê°„ ì„ í˜• ì¦ê°€

4. **TTA ê´€ë ¨**
   - `--tta_num_aug`: 2-3 ê¶Œì¥ (ì¶”ë¡  ì‹œê°„ì— ì§ì ‘ ì˜í–¥)
   - paraphrase, reorderê°€ ê°€ì¥ íš¨ê³¼ì 

5. **ì•™ìƒë¸” ì „ëµ**
   - `weighted_avg`: ë¹ ë¥´ê³  íš¨ê³¼ì 
   - `blending`: ê³¼ì í•© ë°©ì§€
   - `stacking`: ìµœê³  ì„±ëŠ¥ì´ì§€ë§Œ ì‹œê°„ ì†Œìš”

6. **Solar API ê´€ë ¨**
   - `--use_solar_api`: Solar API í™œì„±í™”
   - `--solar_model`: `solar-1-mini-chat` (ë¹ ë¥´ê³  ì €ë ´) vs `solar-1-chat` (ê³ í’ˆì§ˆ)
   - `--prompt_strategy`: í”„ë¡¬í”„íŠ¸ ì „ëµ ì„ íƒ
     - `few_shot_standard`: 2ê°œ ì˜ˆì‹œ (ê¸°ë³¸, ê¶Œì¥)
     - `chain_of_thought`: ë‹¨ê³„ë³„ ì¶”ë¡  (ê³ í’ˆì§ˆ)
     - `self_consistency`: ë‹¤ì¤‘ ìƒì„± í›„ íˆ¬í‘œ (ìµœê³  ì•ˆì •ì„±)
   - Solar APIëŠ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ì— ì‚¬ìš©ë˜ë©°, ì¶”ê°€ ë¹„ìš© ë°œìƒ
   - ëŒ€íšŒì—ì„œ 30ë‹¬ëŸ¬ ì§€ì› â†’ ì¶©ë¶„íˆ í™œìš© ê°€ëŠ¥

---

## ğŸ” ì‹¤í—˜ ê²°ê³¼ í™•ì¸

ì‹¤í–‰ í›„ ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **ì œì¶œ íŒŒì¼**:
   - `experiments/{ë‚ ì§œ}/{ì‹¤í–‰í´ë”ëª…}/submissions/{ì‹¤í–‰í´ë”ëª…}.csv`
   - `submissions/{ë‚ ì§œ}/{ì‹¤í–‰í´ë”ëª…}.csv`

2. **í•™ìŠµ ë¡œê·¸**:
   - `experiments/{ë‚ ì§œ}/{ì‹¤í–‰í´ë”ëª…}/train.log`

3. **ì‹œê°í™”**:
   - `experiments/{ë‚ ì§œ}/{ì‹¤í–‰í´ë”ëª…}/visualizations/`

---

## ğŸ“ íŒ

### ì¼ë°˜ íŒ
1. **ì²« ì‹¤í–‰ ì‹œ**: ë°˜ë“œì‹œ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì–´**ë¡œ ì •ìƒ ì‘ë™ í™•ì¸
2. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ**: `--batch_size` ì¤„ì´ê³  `--gradient_accumulation_steps` ì¦ê°€
3. **ì‹œê°„ ì´ˆê³¼ ì‹œ**: `--epochs`, `--k_folds`, `--augmentation_ratio` ê°ì†Œ
4. **ì„±ëŠ¥ í–¥ìƒ ì‹œ**: `--epochs` ì¦ê°€, `--k_folds` ì¦ê°€, ë” ë§ì€ ëª¨ë¸ ì‚¬ìš©

### Solar API í™œìš© íŒ
1. **API í‚¤ ì„¤ì •**: ëª…ë ¹ì–´ ì‹¤í–‰ ì „ ë°˜ë“œì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
   ```bash
   export SOLAR_API_KEY="your-api-key-here"
   ```
   ë˜ëŠ” `.env` íŒŒì¼ì— `SOLAR_API_KEY=your-api-key` ì €ì¥

2. **ëª¨ë¸ ì„ íƒ**:
   - `solar-1-mini-chat`: ë¹ ë¥´ê³  ì €ë ´, ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì¶©ë¶„
   - `solar-1-chat`: ìµœê³  í’ˆì§ˆì´ í•„ìš”í•  ë•Œ (ë¹„ìš© ë” ë†’ìŒ)

3. **í”„ë¡¬í”„íŠ¸ ì „ëµ**:
   - ì‹œì‘: `few_shot_standard` (ê°€ì¥ ì•ˆì •ì )
   - ê³ í’ˆì§ˆ: `chain_of_thought` (ë” ë‚˜ì€ ì¶”ë¡ )
   - ìµœê³  ì•ˆì •ì„±: `self_consistency` (ê°€ì¥ ëŠë¦¬ì§€ë§Œ ì•ˆì •ì )

4. **ë¹„ìš© ê´€ë¦¬**:
   - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” `solar-1-mini-chat` ì‚¬ìš©
   - ìµœì¢… ì œì¶œìš©ì—ì„œë§Œ `solar-1-chat` ê³ ë ¤
   - `--max_train_samples` ì˜µì…˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì‹œ API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ

5. **íš¨ê³¼ í™•ì¸**:
   - Solar API ì‚¬ìš© ì „í›„ ì„±ëŠ¥ ë¹„êµ
   - `--validate_data_quality`ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±

---

## ğŸš€ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ

### ê¸°ë³¸ ì „ëµ (Solar API ë¯¸ì‚¬ìš©)

1. **1ë‹¨ê³„**: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¡œ ì •ìƒ ì‘ë™ í™•ì¸
   ```bash
   # ì „ëµ 2-1ì˜ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (45ë¶„)
   ```

2. **2ë‹¨ê³„**: ì‹¤ì œ ì œì¶œìš© ëª…ë ¹ì–´ ì‹¤í–‰
   ```bash
   # ì „ëµ 2-1ì˜ ì‹¤ì œ ì‹¤í–‰ (2.5ì‹œê°„)
   ```

3. **3ë‹¨ê³„**: ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ ì¶”ê°€ ì‹¤í—˜
   ```bash
   # ì „ëµ 3-1 ë˜ëŠ” ì „ëµ 4-1 ì‹¤í–‰
   ```

4. **4ë‹¨ê³„**: ìµœê³  ì ìˆ˜ ì œì¶œ íŒŒì¼ ì„ íƒ ë° ì œì¶œ

### Solar API í™œìš© ì „ëµ (ì¶”ì²œ)

1. **1ë‹¨ê³„**: API í‚¤ ì„¤ì • ë° ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
   ```bash
   # API í‚¤ ì„¤ì •
   export SOLAR_API_KEY="your-api-key"

   # ì „ëµ 6-1 ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (35ë¶„)
   # Solar API ì •ìƒ ì‘ë™ í™•ì¸
   ```

2. **2ë‹¨ê³„**: Solar API í¬í•¨ ì‹¤ì œ ì‹¤í–‰
   ```bash
   # ì „ëµ 6-2 ì‹¤ì œ ì‹¤í–‰ (2.7ì‹œê°„)
   # ì´ì¤‘ ëª¨ë¸ + Solar APIë¡œ ê· í˜•ì¡íŒ ì„±ëŠ¥
   ```

3. **3ë‹¨ê³„**: ìµœìƒê¸‰ í”„ë¦¬ë¯¸ì—„ ì „ëµ (ì‹œê°„ ì—¬ìœ  ìˆì„ ë•Œ)
   ```bash
   # ì „ëµ 6-3 ì‹¤ì œ ì‹¤í–‰ (2.9ì‹œê°„)
   # ì „ì²´ ëª¨ë¸ + Solar API Full + Chain-of-Thought
   ```

4. **4ë‹¨ê³„**: ê²°ê³¼ ë¹„êµ ë° ìµœê³  ì ìˆ˜ ì œì¶œ
   - Solar API ì‚¬ìš© ì „í›„ ì„±ëŠ¥ ë¹„êµ
   - ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì œì¶œ íŒŒì¼ ì„ íƒ

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-13
**ì‘ì„± ê¸°ì¤€ ë¬¸ì„œ**: `docs/ëª¨ë“ˆí™”/04_ëª…ë ¹ì–´_ì˜µì…˜_ì™„ì „_ê°€ì´ë“œ.md`
