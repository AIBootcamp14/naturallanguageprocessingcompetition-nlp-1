# ëª¨ë¸ ë¡œë” ì‹œìŠ¤í…œ ìƒì„¸ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ModelLoader í´ë˜ìŠ¤](#modelloader-í´ë˜ìŠ¤)
3. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
4. [ë””ë°”ì´ìŠ¤ ê´€ë¦¬](#ë””ë°”ì´ìŠ¤-ê´€ë¦¬)
5. [íŠ¹ìˆ˜ í† í° ì²˜ë¦¬](#íŠ¹ìˆ˜-í† í°-ì²˜ë¦¬)

---

## ğŸ“ ê°œìš”

### ëª©ì 
- HuggingFace ì‚¬ì „í•™ìŠµ ëª¨ë¸ ìë™ ë¡œë“œ
- í† í¬ë‚˜ì´ì € ì´ˆê¸°í™” ë° íŠ¹ìˆ˜ í† í° ì¶”ê°€
- ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ ë° ë°°ì¹˜
- ì„ë² ë”© í¬ê¸° ìë™ ì¡°ì •

### í•µì‹¬ ê¸°ëŠ¥
- âœ… Config ê¸°ë°˜ ëª¨ë¸ ë¡œë”©
- âœ… íŠ¹ìˆ˜ í† í° ìë™ ì¶”ê°€ ë° ì„ë² ë”© ë¦¬ì‚¬ì´ì¦ˆ
- âœ… GPU/CPU ìë™ ê°ì§€
- âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ì •ë³´ ì¶œë ¥
- âœ… Logger í†µí•© ì§€ì›

---

## ğŸ—ï¸ ModelLoader í´ë˜ìŠ¤

### íŒŒì¼ ìœ„ì¹˜
```
src/models/model_loader.py
```

### í´ë˜ìŠ¤ êµ¬ì¡°

```python
class ModelLoader:
    def __init__(self, config: DictConfig, logger=None):
        """ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”"""

    def _get_device(self) -> torch.device:
        """ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ê²°ì • (GPU/CPU)"""

    def load_tokenizer(self) -> PreTrainedTokenizer:
        """í† í¬ë‚˜ì´ì € ë¡œë“œ ë° íŠ¹ìˆ˜ í† í° ì¶”ê°€"""

    def load_model(self, tokenizer=None) -> PreTrainedModel:
        """ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ"""

    def load_model_and_tokenizer(self) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:
        """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ í•¨ê»˜ ë¡œë“œ"""
```

---

## ğŸ’» ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from src.config import load_config
from src.models import load_model_and_tokenizer

# Config ë¡œë“œ
config = load_config("baseline_kobart")

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model, tokenizer = load_model_and_tokenizer(config)

print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")
```

### 2. Loggerì™€ í•¨ê»˜ ì‚¬ìš©

```python
from src.logging.logger import Logger
from src.utils.core.common import create_log_path
from src.models import load_model_and_tokenizer

# Logger ì´ˆê¸°í™”
log_path = create_log_path("train", "model_load.log")
logger = Logger(log_path, print_also=True)

# Loggerë¥¼ ì „ë‹¬í•˜ì—¬ ëª¨ë¸ ë¡œë“œ
model, tokenizer = load_model_and_tokenizer(config, logger=logger)
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
============================================================
ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì‹œì‘
============================================================
í† í¬ë‚˜ì´ì € ë¡œë”©: digit82/kobart-summarization
  â†’ íŠ¹ìˆ˜ í† í° 7ê°œ ì¶”ê°€ë¨
  â†’ pad_token ì„¤ì •: </s>

ëª¨ë¸ ë¡œë”©: digit82/kobart-summarization
  â†’ ì„ë² ë”© í¬ê¸° ì¡°ì •: 51200 â†’ 51207
  â†’ ë””ë°”ì´ìŠ¤: cuda
  â†’ ì „ì²´ íŒŒë¼ë¯¸í„°: 123,859,968
  â†’ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 123,859,968
============================================================
âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ
============================================================
```

### 3. ModelLoader í´ë˜ìŠ¤ ì§ì ‘ ì‚¬ìš©

```python
from src.models.model_loader import ModelLoader

# ModelLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
loader = ModelLoader(config, logger=logger)

# ë‹¨ê³„ë³„ ë¡œë“œ
tokenizer = loader.load_tokenizer()      # 1. í† í¬ë‚˜ì´ì €ë§Œ ë¡œë“œ
model = loader.load_model(tokenizer)     # 2. ëª¨ë¸ ë¡œë“œ

# ë˜ëŠ” í•œ ë²ˆì— ë¡œë“œ
model, tokenizer = loader.load_model_and_tokenizer()
```

---

## ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤ ê´€ë¦¬

### ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€

ModelLoaderëŠ” ë‹¤ìŒ ìš°ì„ ìˆœìœ„ë¡œ ë””ë°”ì´ìŠ¤ë¥¼ ê²°ì •í•©ë‹ˆë‹¤:

1. **Config ì„¤ì • í™•ì¸**
   ```yaml
   # configs/base/default.yaml
   training:
     device: "cuda"  # ë˜ëŠ” "cpu", "cuda:0", "cuda:1" ë“±
   ```

2. **ìë™ ê°ì§€ (Config ì—†ëŠ” ê²½ìš°)**
   ```python
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   ```

### íŠ¹ì • GPU ì§€ì •

```yaml
# configs/experiments/my_experiment.yaml
training:
  device: "cuda:1"  # ë‘ ë²ˆì§¸ GPU ì‚¬ìš©
```

### ë””ë°”ì´ìŠ¤ ê´€ë ¨ ë™ì‘

```python
# 1. ë””ë°”ì´ìŠ¤ ê²°ì •
device = loader._get_device()

# 2. ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
model = model.to(device)

# 3. GPU ì‚¬ìš© ë¶ˆê°€ ì‹œ ê²½ê³ 
# CUDAê°€ ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
```

---

## ğŸ”¤ íŠ¹ìˆ˜ í† í° ì²˜ë¦¬

### íŠ¹ìˆ˜ í† í° ìë™ ì¶”ê°€

Configì—ì„œ íŠ¹ìˆ˜ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ì˜í•˜ë©´ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤:

```yaml
# configs/base/encoder_decoder.yaml
tokenizer:
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateAndTime#'
```

### ì²˜ë¦¬ ê³¼ì •

1. **í† í¬ë‚˜ì´ì € ë¡œë“œ**
   ```python
   tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True)
   ```

2. **íŠ¹ìˆ˜ í† í° ì¶”ê°€**
   ```python
   special_tokens = list(config.model.special_tokens)
   num_added = tokenizer.add_special_tokens({
       'additional_special_tokens': special_tokens
   })
   # ì¶œë ¥: "íŠ¹ìˆ˜ í† í° 7ê°œ ì¶”ê°€ë¨"
   ```

3. **íŒ¨ë”© í† í° ì„¤ì •** (BART ê³„ì—´ ëª¨ë¸)
   ```python
   if tokenizer.pad_token is None:
       tokenizer.pad_token = tokenizer.eos_token
   ```

4. **ëª¨ë¸ ì„ë² ë”© ë¦¬ì‚¬ì´ì¦ˆ**
   ```python
   vocab_size = len(tokenizer)
   model_vocab_size = model.config.vocab_size

   if vocab_size != model_vocab_size:
       model.resize_token_embeddings(vocab_size)
       # ì¶œë ¥: "ì„ë² ë”© í¬ê¸° ì¡°ì •: 51200 â†’ 51207"
   ```

### ì„ë² ë”© í¬ê¸° ì¡°ì • ì´ìœ 

íŠ¹ìˆ˜ í† í°ì„ ì¶”ê°€í•˜ë©´ í† í¬ë‚˜ì´ì € ì–´íœ˜ í¬ê¸°ê°€ ì¦ê°€í•˜ë¯€ë¡œ, ëª¨ë¸ì˜ ì„ë² ë”© ë ˆì´ì–´ í¬ê¸°ë„ í•¨ê»˜ ëŠ˜ë ¤ì•¼ í•©ë‹ˆë‹¤.

**ë³€ê²½ ì „:**
- í† í¬ë‚˜ì´ì € ì–´íœ˜: 51,200ê°œ
- ëª¨ë¸ ì„ë² ë”©: 51,200ê°œ

**ë³€ê²½ í›„:**
- í† í¬ë‚˜ì´ì € ì–´íœ˜: 51,207ê°œ (+7)
- ëª¨ë¸ ì„ë² ë”©: 51,207ê°œ (+7)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ íŒŒì¼ ìœ„ì¹˜
```
src/tests/test_model_loader.py
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source ~/.pyenv/versions/nlp_py3_11_9/bin/activate

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python src/tests/test_model_loader.py
```

### í…ŒìŠ¤íŠ¸ í•­ëª© (ì´ 5ê°œ)

1. âœ… ê¸°ë³¸ Config ë¡œë“œ
2. âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ë° íŠ¹ìˆ˜ í† í° ì¶”ê°€
3. âœ… ëª¨ë¸ ë¡œë“œ
4. âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € í•¨ê»˜ ë¡œë“œ
5. âœ… í¸ì˜ í•¨ìˆ˜ (load_model_and_tokenizer)

---

## ğŸ¯ ì‹¤ì „ í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©

```python
# scripts/train.py
from src.models import load_model_and_tokenizer
from src.logging.logger import Logger

def main():
    # Logger ì´ˆê¸°í™”
    logger = Logger(log_path, print_also=True)
    logger.start_redirect()

    try:
        # Config ë¡œë“œ
        config = load_config(args.experiment)

        # ëª¨ë¸ ë¡œë“œ (Loggerì™€ í•¨ê»˜)
        logger.write("\n[3/6] ëª¨ë¸ ë¡œë”©...")
        model, tokenizer = load_model_and_tokenizer(config, logger=logger)
        logger.write("  âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        # ... í•™ìŠµ ì§„í–‰

    finally:
        logger.stop_redirect()
        logger.close()
```

### ì˜ˆì‹œ 2: ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ

```python
from src.models.model_loader import ModelLoader
from omegaconf import DictConfig

# ì»¤ìŠ¤í…€ Config ìƒì„±
custom_config = DictConfig({
    "model": {
        "checkpoint": "facebook/bart-base",
        "special_tokens": ["<CUSTOM>", "<TOKEN>"]
    },
    "training": {
        "device": "cuda:0"
    }
})

# ëª¨ë¸ ë¡œë“œ
loader = ModelLoader(custom_config)
model, tokenizer = loader.load_model_and_tokenizer()
```

### ì˜ˆì‹œ 3: CPU ì „ìš© ë¡œë“œ

```python
# GPUê°€ ì—†ëŠ” í™˜ê²½ì—ì„œ ê°•ì œë¡œ CPU ì‚¬ìš©
config.training.device = "cpu"
model, tokenizer = load_model_and_tokenizer(config)
```

---

## ğŸ“Œ ì£¼ì˜ì‚¬í•­

### 1. ë©”ëª¨ë¦¬ ê´€ë¦¬

ëŒ€í˜• ëª¨ë¸ ë¡œë“œ ì‹œ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì£¼ì˜:
```python
# GPU ë©”ëª¨ë¦¬ í™•ì¸
import torch
print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

### 2. í† í¬ë‚˜ì´ì € ì €ì¥

í•™ìŠµ í›„ í† í¬ë‚˜ì´ì €ë„ í•¨ê»˜ ì €ì¥í•´ì•¼ ì¶”ë¡  ì‹œ ì‚¬ìš© ê°€ëŠ¥:
```python
# í•™ìŠµ í›„
model.save_pretrained("outputs/my_model")
tokenizer.save_pretrained("outputs/my_model")  # í•„ìˆ˜!

# ì¶”ë¡  ì‹œ
model = AutoModelForSeq2SeqLM.from_pretrained("outputs/my_model")
tokenizer = AutoTokenizer.from_pretrained("outputs/my_model")
```

### 3. íŠ¹ìˆ˜ í† í° ì¼ê´€ì„±

í•™ìŠµê³¼ ì¶”ë¡  ì‹œ ë™ì¼í•œ íŠ¹ìˆ˜ í† í°ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. Configë¥¼ í†µí•´ ê´€ë¦¬í•˜ë©´ ìë™ìœ¼ë¡œ ë³´ì¥ë©ë‹ˆë‹¤.

---

## ğŸ”— ê´€ë ¨ íŒŒì¼

**ì†ŒìŠ¤ ì½”ë“œ:**
- `src/models/model_loader.py` - ModelLoader í´ë˜ìŠ¤
- `src/models/__init__.py` - ì™¸ë¶€ API

**í…ŒìŠ¤íŠ¸:**
- `src/tests/test_model_loader.py` - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**Config:**
- `configs/base/default.yaml` - ë””ë°”ì´ìŠ¤ ì„¤ì •
- `configs/base/encoder_decoder.yaml` - íŠ¹ìˆ˜ í† í° ì •ì˜
- `configs/models/kobart.yaml` - KoBART ì²´í¬í¬ì¸íŠ¸
