# 평가 시스템 상세 가이드

## 📋 목차
1. [개요](#개요)
2. [RougeCalculator 클래스](#rougecalculator-클래스)
3. [사용 방법](#사용-방법)
4. [Multi-reference 지원](#multi-reference-지원)
5. [배치 계산](#배치-계산)

---

## 📝 개요

### 목적
- ROUGE 점수 자동 계산 (경진대회 평가 기준)
- Multi-reference 평가 지원
- 배치 계산 및 통계 정보 제공
- 학습/평가 시 자동 통합

### 핵심 기능
- ✅ ROUGE-1/2/L F1 점수 계산
- ✅ ROUGE Sum (경진대회 기준) 자동 계산
- ✅ Multi-reference 지원 (정답이 여러 개인 경우)
- ✅ 배치 계산 및 통계 (평균, 표준편차, 최소/최대)
- ✅ HuggingFace Trainer와 자동 통합

---

## 🏗️ RougeCalculator 클래스

### 파일 위치
```
src/evaluation/metrics.py
```

### 클래스 구조

```python
class RougeCalculator:
    def __init__(self, rouge_types=['rouge1', 'rouge2', 'rougeL'], use_stemmer=False):
        """ROUGE 계산기 초기화"""

    def calculate_single(self, prediction: str, reference: Union[str, List[str]]) -> Dict:
        """단일 샘플 ROUGE 계산"""

    def calculate_batch(self, predictions: List[str], references: List[str]) -> Dict:
        """배치 샘플 ROUGE 평균 계산"""

    def _empty_scores(self) -> Dict:
        """빈 입력에 대한 기본 점수 반환"""
```

---

## 💻 사용 방법

### 1. 기본 사용법 (단일 샘플)

```python
from src.evaluation import RougeCalculator

# ROUGE 계산기 초기화
calculator = RougeCalculator()

# 단일 샘플 평가
prediction = "두 사람이 저녁 약속을 잡았다"
reference = "두 사람이 저녁 식사 약속을 정했다"

scores = calculator.calculate_single(prediction, reference)

print(scores)
# 출력:
# {
#     'rouge1': {'precision': 0.75, 'recall': 0.667, 'fmeasure': 0.706},
#     'rouge2': {'precision': 0.5, 'recall': 0.4, 'fmeasure': 0.444},
#     'rougeL': {'precision': 0.75, 'recall': 0.667, 'fmeasure': 0.706}
# }
```

### 2. 편의 함수 사용

```python
from src.evaluation import calculate_rouge_scores

# 단일 샘플
scores = calculate_rouge_scores(
    predictions="예측 요약",
    references="정답 요약"
)

# 배치 샘플
predictions = ["예측1", "예측2", "예측3"]
references = ["정답1", "정답2", "정답3"]

scores = calculate_rouge_scores(predictions, references)
```

### 3. 점수 포맷팅

```python
from src.evaluation import calculate_rouge_scores, format_rouge_scores

scores = calculate_rouge_scores(predictions, references)
print(format_rouge_scores(scores))

# 출력:
# ROUGE1:
#   fmeasure: 0.7060
#   std: 0.1200
#   min: 0.5500
#   max: 0.8500
#
# ROUGE2:
#   fmeasure: 0.4440
#   ...
```

---

## 🔄 Multi-reference 지원

### 개요

하나의 대화에 대해 여러 개의 정답 요약이 있을 수 있습니다. Multi-reference 평가는 각 정답에 대해 ROUGE를 계산한 후 **최대 F1 점수**를 선택합니다.

### 사용 방법

```python
from src.evaluation import RougeCalculator

calculator = RougeCalculator()

# 단일 예측, 다중 정답
prediction = "두 사람이 저녁 약속을 잡았다"
references = [
    "두 사람이 저녁 식사 약속을 정했다",
    "저녁에 만나기로 했다",
    "저녁 약속을 잡았다"
]

scores = calculator.calculate_single(prediction, references)
```

### 처리 과정

1. **각 정답에 대해 ROUGE 계산**
   ```python
   for ref in references:
       score = scorer.score(prediction, ref)
       all_scores.append(score)
   ```

2. **최대 F1 점수 선택**
   ```python
   max_score = max(all_scores, key=lambda x: x['rouge1'].fmeasure)
   ```

3. **결과 반환**
   ```python
   {
       'rouge1': {'precision': 1.0, 'recall': 1.0, 'fmeasure': 1.0},  # "저녁 약속을 잡았다"와 완전 일치
       'rouge2': {...},
       'rougeL': {...}
   }
   ```

---

## 📊 배치 계산

### 기본 사용법

```python
from src.evaluation import RougeCalculator

calculator = RougeCalculator()

predictions = [
    "두 사람이 저녁 약속을 잡았다",
    "회의 시간을 3시로 정했다",
    "내일 점심 메뉴는 김치찌개다"
]

references = [
    "두 사람이 저녁 식사 약속을 정했다",
    "회의를 오후 3시에 하기로 했다",
    "내일 점심은 김치찌개를 먹기로 했다"
]

scores = calculator.calculate_batch(predictions, references)
```

### 출력 형식

```python
{
    'rouge1': {
        'fmeasure': 0.7060,      # 평균 F1 점수
        'std': 0.1200,           # 표준편차
        'min': 0.5500,           # 최소값
        'max': 0.8500            # 최대값
    },
    'rouge2': {
        'fmeasure': 0.4440,
        'std': 0.0800,
        'min': 0.3000,
        'max': 0.6000
    },
    'rougeL': {
        'fmeasure': 0.7060,
        'std': 0.1200,
        'min': 0.5500,
        'max': 0.8500
    },
    'rouge_sum': {               # ROUGE-1 + ROUGE-2 + ROUGE-L
        'fmeasure': 1.8560,
        'std': 0.0,
        'min': 0.0,
        'max': 0.0
    }
}
```

### ROUGE Sum (경진대회 기준)

경진대회에서는 ROUGE-1, ROUGE-2, ROUGE-L의 F1 점수 합계를 최종 평가 지표로 사용합니다:

```python
rouge_sum = rouge1_f1 + rouge2_f1 + rougeL_f1
# 예: 0.706 + 0.444 + 0.706 = 1.856
```

---

## 🔗 HuggingFace Trainer 통합

### ModelTrainer에서 자동 사용

`src/training/trainer.py`의 `ModelTrainer` 클래스는 자동으로 ROUGE를 계산합니다:

```python
from src.training import create_trainer

trainer = create_trainer(
    config=config,
    model=model,
    tokenizer=tokenizer,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

# 학습 중 자동으로 ROUGE 계산
results = trainer.train()

# 평가 결과
print(results['eval_metrics'])
# {
#     'eval_rouge1': 0.706,
#     'eval_rouge2': 0.444,
#     'eval_rougeL': 0.706,
#     'eval_rouge_sum': 1.856
# }
```

### compute_metrics 함수

Trainer에서 사용하는 평가 함수:

```python
def compute_metrics(self, eval_preds) -> Dict[str, float]:
    """평가 메트릭 계산 (ROUGE)"""
    predictions, labels = eval_preds

    # -100을 패딩 토큰으로 변경
    labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)

    # 디코딩
    decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)
    decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)

    # ROUGE 계산
    scores = self.rouge_calculator.calculate_batch(
        decoded_preds,
        decoded_labels
    )

    # 결과 포맷팅
    result = {
        'rouge1': scores['rouge1']['fmeasure'],
        'rouge2': scores['rouge2']['fmeasure'],
        'rougeL': scores['rougeL']['fmeasure'],
        'rouge_sum': scores['rouge_sum']['fmeasure']
    }

    return result
```

---

## 🧪 테스트

### 테스트 파일 위치
```
src/tests/test_metrics.py
```

### 테스트 실행

```bash
# 가상환경 활성화
source ~/.pyenv/versions/nlp_py3_11_9/bin/activate

# 테스트 실행
python src/tests/test_metrics.py
```

### 테스트 항목 (총 6개)

1. ✅ 기본 ROUGE 계산 (단일 샘플)
2. ✅ Multi-reference ROUGE 계산
3. ✅ 배치 ROUGE 계산
4. ✅ 빈 입력 처리
5. ✅ 편의 함수 (calculate_rouge_scores)
6. ✅ 점수 포맷팅 (format_rouge_scores)

---

## 🎯 실전 활용 예시

### 예시 1: 모델 성능 직접 평가

```python
from src.evaluation import calculate_rouge_scores
import pandas as pd

# 테스트 데이터 로드
test_df = pd.read_csv("data/raw/test.csv")

# 모델로 예측 생성
predictions = model_predict(test_df)  # 사용자 정의 함수

# ROUGE 계산
scores = calculate_rouge_scores(
    predictions=predictions,
    references=test_df['summary'].tolist()
)

print(f"ROUGE-1 F1: {scores['rouge1']['fmeasure']:.4f}")
print(f"ROUGE-2 F1: {scores['rouge2']['fmeasure']:.4f}")
print(f"ROUGE-L F1: {scores['rougeL']['fmeasure']:.4f}")
print(f"ROUGE Sum: {scores['rouge_sum']['fmeasure']:.4f}")
```

### 예시 2: 여러 모델 비교

```python
from src.evaluation import RougeCalculator

calculator = RougeCalculator()

models = {
    "KoBART": model1,
    "T5-small": model2,
    "mBART": model3
}

results = {}

for model_name, model in models.items():
    predictions = model_predict(model, test_df)
    scores = calculator.calculate_batch(predictions, references)
    results[model_name] = scores['rouge_sum']['fmeasure']

# 결과 출력
for model_name, score in sorted(results.items(), key=lambda x: x[1], reverse=True):
    print(f"{model_name}: {score:.4f}")

# 출력:
# KoBART: 1.8560
# mBART: 1.7320
# T5-small: 1.6100
```

### 예시 3: 샘플별 상세 분석

```python
from src.evaluation import RougeCalculator

calculator = RougeCalculator()

# 각 샘플별 ROUGE 계산
sample_scores = []

for pred, ref in zip(predictions, references):
    score = calculator.calculate_single(pred, ref)
    sample_scores.append({
        'prediction': pred,
        'reference': ref,
        'rouge1': score['rouge1']['fmeasure'],
        'rouge2': score['rouge2']['fmeasure'],
        'rougeL': score['rougeL']['fmeasure']
    })

# DataFrame으로 변환
import pandas as pd
df_scores = pd.DataFrame(sample_scores)

# 성능이 낮은 샘플 찾기
low_scores = df_scores[df_scores['rouge1'] < 0.3].sort_values('rouge1')
print("성능이 낮은 샘플:")
print(low_scores[['prediction', 'reference', 'rouge1']])
```

---

## 📌 주의사항

### 1. 한국어 형태소 분석기

기본적으로 `use_stemmer=False`로 설정됩니다. 한국어에는 영어용 stemmer가 적합하지 않습니다.

```python
# ✅ 한국어에 적합
calculator = RougeCalculator(use_stemmer=False)

# ❌ 한국어에 부적합
calculator = RougeCalculator(use_stemmer=True)
```

### 2. 빈 문자열 처리

빈 예측이나 정답은 자동으로 0점 처리됩니다:

```python
scores = calculator.calculate_single("", "정답 요약")
# {'rouge1': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0}, ...}
```

### 3. Multi-reference 성능

Multi-reference 평가는 정답 개수에 비례하여 계산 시간이 증가합니다:

```python
# 단일 정답: O(1)
scores = calculator.calculate_single(pred, ref)

# 3개 정답: O(3)
scores = calculator.calculate_single(pred, [ref1, ref2, ref3])
```

---

## 🔗 관련 파일

**소스 코드:**
- `src/evaluation/metrics.py` - RougeCalculator 클래스
- `src/evaluation/__init__.py` - 외부 API

**테스트:**
- `src/tests/test_metrics.py` - 단위 테스트

**통합:**
- `src/training/trainer.py` - Trainer에서 자동 사용
