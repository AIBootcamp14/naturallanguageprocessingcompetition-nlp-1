# 명령어 옵션 완전 가이드

> **PRD 14: 실행 옵션 시스템** - 모든 PRD 기능을 명령어로 실행하는 완전한 가이드

## 📋 목차

1. [기본 실행 모드](#1-기본-실행-모드)
2. [모델 선택](#2-모델-선택)
3. [학습 설정](#3-학습-설정)
4. [K-Fold 교차검증](#4-k-fold-교차검증)
5. [앙상블 전략](#5-앙상블-전략)
6. [Optuna 최적화](#6-optuna-최적화)
7. [데이터 증강](#7-데이터-증강)
8. [Solar API](#8-solar-api)
9. [프롬프트 전략](#9-프롬프트-전략)
10. [데이터 품질 검증](#10-데이터-품질-검증)
11. [추론 최적화](#11-추론-최적화)
12. [로깅 및 모니터링](#12-로깅-및-모니터링)
13. [실전 예시](#13-실전-예시)

---

## 1. 기본 실행 모드

### `--mode` (실행 모드 선택)

**PRD**: 14번 - 실행 옵션 시스템

| 모드 | 설명 | 사용 시나리오 |
|------|------|---------------|
| `single` | 단일 모델 학습 | 빠른 실험, 베이스라인 검증 |
| `kfold` | K-Fold 교차 검증 | 모델 안정성 평가 |
| `multi_model` | 다중 모델 앙상블 | 성능 향상, 여러 모델 비교 |
| `optuna` | 하이퍼파라미터 최적화 | 최적 설정 탐색 |
| `full` | 전체 파이프라인 | 최종 제출, 모든 기능 통합 |

```bash
# ==================== 실행 모드 선택 ==================== #

# ---------------------- 단일 모델 학습 ---------------------- #
# 빠른 실험 및 베이스라인 검증을 위한 단일 모델 학습 모드
python scripts/train.py --mode single

# ---------------------- 전체 파이프라인 실행 ---------------------- #
# 모든 고급 기능을 통합한 최종 제출용 파이프라인 모드
python scripts/train.py --mode full
```

---

## 2. 모델 선택

### `--models` (사용할 모델 선택)

**PRD**: 05-07번 - 모델 시스템

| 모델명 | 설명 | 권장 용도 |
|--------|------|-----------|
| `kobart` | 한국어 BART | 빠른 실험, 베이스라인 |
| `solar-10.7b` | Upstage Solar LLM | 고품질 요약, 최종 제출 |
| `polyglot-ko-12.8b` | 대규모 한국어 모델 | 높은 성능 |
| `llama-3.2-korean-3b` | Llama 한국어 버전 | 균형잡힌 성능 |
| `qwen3-4b` | Qwen 모델 | 효율적 학습 |
| `kullm-v2` | 고려대 LLM | 한국어 특화 |
| `all` | 모든 모델 (자동 확장) | 앙상블, 풀 파이프라인 |

**참고**: `--models all` 옵션 사용 시 자동으로 6개의 모든 모델(`kobart`, `llama-3.2-korean-3b`, `qwen3-4b`, `solar-10.7b`, `polyglot-ko-12.8b`, `kullm-v2`)로 확장됩니다.

```bash
# ==================== 모델 선택 옵션 ==================== #

# ---------------------- 단일 모델 학습 ---------------------- #
# KoBART 모델로 빠른 실험 및 베이스라인 검증
python scripts/train.py --models kobart

# ---------------------- 다중 모델 앙상블 ---------------------- #
# KoBART와 Solar 모델을 앙상블하여 성능 향상
python scripts/train.py --mode multi_model --models kobart solar-10.7b

# ---------------------- 전체 모델 사용 ---------------------- #
# 사용 가능한 모든 모델을 통합한 앙상블 학습
python scripts/train.py --mode full --models all
```

---

## 3. 학습 설정

### 기본 하이퍼파라미터

**PRD**: 06번 - 기술 요구사항

#### `--epochs` (학습 에포크 수)
```bash
# ==================== 에포크 수 설정 ==================== #

# ---------------------- 빠른 실험 (1 에포크) ---------------------- #
# 코드 테스트 및 빠른 검증을 위한 최소 학습
python scripts/train.py --epochs 1

# ---------------------- 정상 학습 (3 에포크) ---------------------- #
# 표준적인 학습 설정으로 균형잡힌 성능 확보
python scripts/train.py --epochs 3

# ---------------------- 긴 학습 (10 에포크) ---------------------- #
# 최고 성능을 위한 충분한 학습 시간 확보
python scripts/train.py --epochs 10
```

#### `--batch_size` (배치 크기)
```bash
# ==================== 배치 크기 설정 ==================== #

# ---------------------- 작은 GPU 메모리 (배치 4) ---------------------- #
# GPU 메모리가 부족할 때 작은 배치 크기 사용
python scripts/train.py --batch_size 4

# ---------------------- 균형잡힌 설정 (배치 8) ---------------------- #
# 대부분의 상황에서 권장되는 표준 배치 크기
python scripts/train.py --batch_size 8

# ---------------------- 큰 GPU 메모리 (배치 16) ---------------------- #
# 충분한 GPU 메모리가 있을 때 큰 배치 크기로 학습 가속화
python scripts/train.py --batch_size 16
```

#### `--learning_rate` (학습률)
```bash
# ==================== 학습률 설정 ==================== #

# ---------------------- 작은 모델용 학습률 ---------------------- #
# KoBART 등 작은 모델에 적합한 학습률
python scripts/train.py --learning_rate 5e-5

# ---------------------- LLM용 학습률 ---------------------- #
# Solar, Llama 등 대규모 언어 모델에 적합한 학습률
python scripts/train.py --learning_rate 1e-5

# ---------------------- 미세 조정용 학습률 ---------------------- #
# 이미 학습된 모델을 미세 조정할 때 사용하는 낮은 학습률
python scripts/train.py --learning_rate 1e-6
```

---

## 4. K-Fold 교차검증

**PRD**: 10번 - 교차 검증 시스템

### `--k_folds` (Fold 수)
```bash
# ==================== K-Fold 수 설정 ==================== #

# ---------------------- 3-Fold (빠른 검증) ---------------------- #
# 빠른 교차 검증을 위한 최소 Fold 수
python scripts/train.py --mode kfold --k_folds 3

# ---------------------- 5-Fold (표준 설정) ---------------------- #
# 가장 일반적으로 사용되는 표준 Fold 수
python scripts/train.py --mode kfold --k_folds 5

# ---------------------- 10-Fold (안정적 평가) ---------------------- #
# 더 안정적인 성능 평가를 위한 많은 Fold 수
python scripts/train.py --mode kfold --k_folds 10
```

### `--fold_seed` (재현성 보장)
```bash
# ==================== Fold 분할 시드 설정 ==================== #

# ---------------------- 재현 가능한 Fold 분할 ---------------------- #
# 동일한 시드로 항상 같은 방식으로 데이터 분할
python scripts/train.py --mode kfold --fold_seed 42
```

**완전한 예시**:
```bash
# ==================== K-Fold 교차 검증 전체 예시 ==================== #

# ---------------------- Solar 모델 5-Fold 검증 ---------------------- #
# Solar 모델로 5-Fold 교차 검증 수행 (재현성 보장)
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8
```

---

## 5. 앙상블 전략

**PRD**: 12번 - 다중 모델 앙상블 전략

### `--ensemble_strategy` (앙상블 방법)

| 전략 | 설명 | 사용 시나리오 |
|------|------|---------------|
| `averaging` | 단순 평균 | 빠른 실험 |
| `weighted_avg` | 가중 평균 | 성능 기반 조합 |
| `majority_vote` | 투표 | 다양성 확보 |
| `stacking` | 메타 학습기 | 최고 성능 |
| `blending` | Validation 기반 | 과적합 방지 |
| `rouge_weighted` | ROUGE 기반 가중치 | 자동 최적화 |

```bash
# ==================== 앙상블 전략 선택 ==================== #

# ---------------------- 가중 평균 앙상블 ---------------------- #
# 각 모델의 성능에 따라 가중치를 부여한 평균 앙상블
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg

# ---------------------- Stacking 앙상블 (최고 성능) ---------------------- #
# 메타 학습기를 사용한 고급 앙상블 기법 (3개 모델)
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking

# ---------------------- Blending 앙상블 ---------------------- #
# Validation 데이터 기반 블렌딩으로 과적합 방지
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy blending
```

### `--ensemble_weights` (수동 가중치 지정)
```bash
# ==================== 앙상블 가중치 수동 설정 ==================== #

# ---------------------- 모델별 가중치 지정 ---------------------- #
# KoBART 30%, Solar 70% 가중치로 앙상블
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.3 0.7
```

### TTA (Test Time Augmentation)

**PRD**: 12번 - TTA 전략

#### `--use_tta` (TTA 활성화)
```bash
# ==================== TTA (Test Time Augmentation) 활성화 ==================== #

# ---------------------- TTA 기본 활성화 ---------------------- #
# 추론 시 데이터 증강을 통해 예측 안정성 향상
python scripts/train.py --mode full --use_tta
```

#### `--tta_strategies` (TTA 방법)
```bash
# ==================== TTA 전략 선택 ==================== #

# ---------------------- 다중 TTA 전략 조합 ---------------------- #
# 패러프레이징, 재정렬, 동의어 치환 전략으로 5번 증강
python scripts/train.py \
  --mode full \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 5
```

---

## 6. Optuna 최적화

**PRD**: 13번 - Optuna 하이퍼파라미터 최적화

### `--optuna_trials` (시도 횟수)
```bash
# ==================== Optuna 시도 횟수 설정 ==================== #

# ---------------------- 빠른 탐색 (20회) ---------------------- #
# 빠른 하이퍼파라미터 탐색 (약 1-2시간)
python scripts/train.py --mode optuna --optuna_trials 20

# ---------------------- 정밀 탐색 (100회) ---------------------- #
# 표준적인 최적화 탐색 (약 4-6시간)
python scripts/train.py --mode optuna --optuna_trials 100

# ---------------------- 철저한 탐색 (500회) ---------------------- #
# 매우 정밀한 최적 파라미터 탐색 (약 20-24시간)
python scripts/train.py --mode optuna --optuna_trials 500
```

### `--optuna_timeout` (제한 시간)
```bash
# ==================== Optuna 제한 시간 설정 ==================== #

# ---------------------- 1시간 제한 ---------------------- #
# 최대 1시간 동안 하이퍼파라미터 최적화 수행
python scripts/train.py --mode optuna --optuna_timeout 3600

# ---------------------- 2시간 제한 ---------------------- #
# 최대 2시간 동안 하이퍼파라미터 최적화 수행
python scripts/train.py --mode optuna --optuna_timeout 7200
```

### `--optuna_sampler` (샘플러 선택)
```bash
# ==================== Optuna 샘플러 선택 ==================== #

# ---------------------- TPE 샘플러 (기본, 권장) ---------------------- #
# Tree-structured Parzen Estimator 알고리즘 사용
python scripts/train.py --mode optuna --optuna_sampler tpe

# ---------------------- Random 샘플러 ---------------------- #
# 무작위 샘플링으로 하이퍼파라미터 탐색
python scripts/train.py --mode optuna --optuna_sampler random

# ---------------------- GP 샘플러 ---------------------- #
# Gaussian Process 기반 샘플링
python scripts/train.py --mode optuna --optuna_sampler gp
```

### `--optuna_pruner` (가지치기 전략)
```bash
# ==================== Optuna 가지치기 전략 ==================== #

# ---------------------- Median Pruner (기본) ---------------------- #
# 중앙값 기반 조기 종료로 비효율적 시도 제거
python scripts/train.py --mode optuna --optuna_pruner median

# ---------------------- Percentile Pruner ---------------------- #
# 백분위수 기반 조기 종료
python scripts/train.py --mode optuna --optuna_pruner percentile

# ---------------------- Hyperband Pruner ---------------------- #
# Hyperband 알고리즘 기반 적응적 자원 할당
python scripts/train.py --mode optuna --optuna_pruner hyperband
```

**완전한 예시**:
```bash
# ==================== Optuna 최적화 전체 예시 ==================== #

# ---------------------- Solar 모델 최적화 (100회 시도) ---------------------- #
# TPE 샘플러와 Median Pruner로 2시간 동안 최적 파라미터 탐색
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

**탐색되는 15개 파라미터**:
- **학습 파라미터 (7개)**: learning_rate, batch_size, gradient_accumulation_steps, warmup_ratio, weight_decay, max_grad_norm, label_smoothing
- **생성 파라미터 (8개)**: num_beams, temperature, top_p, top_k, repetition_penalty, length_penalty, no_repeat_ngram_size, early_stopping_patience

---

## 7. 데이터 증강

**PRD**: 04번 - 성능 개선 전략 (데이터 증강)

### `--use_augmentation` (데이터 증강 활성화)
```bash
# ==================== 데이터 증강 활성화 ==================== #

# ---------------------- 데이터 증강 기능 활성화 ---------------------- #
# 학습 데이터를 자동으로 증강하여 모델 성능 향상
python scripts/train.py --use_augmentation
```

### `--augmentation_methods` (증강 방법)

| 방법 | 설명 | 효과 |
|------|------|------|
| `back_translation` | 역번역 (한→영→한) | 다양한 표현 |
| `paraphrase` | 의역 | 문장 구조 변화 |
| `synonym` | 동의어 치환 | 어휘 다양성 |
| `turn_shuffle` | 대화 순서 섞기 | 순서 불변성 |

```bash
# ==================== 데이터 증강 방법 선택 ==================== #

# ---------------------- 역번역만 사용 ---------------------- #
# 한→영→한 역번역으로 다양한 표현 생성
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation

# ---------------------- 여러 방법 조합 ---------------------- #
# 역번역, 패러프레이징, 동의어 치환을 조합하여 50% 증강
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.5
```

### `--augmentation_ratio` (증강 비율)
```bash
# ==================== 데이터 증강 비율 설정 ==================== #

# ---------------------- 30% 증강 ---------------------- #
# 원본 데이터의 30%만큼 증강 데이터 생성
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.3

# ---------------------- 50% 증강 ---------------------- #
# 원본 데이터의 50%만큼 증강 데이터 생성
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.5
```

---

## 8. Solar API

**PRD**: 09번 - Solar API 최적화

### `--use_solar_api` (Solar API 활성화)
```bash
# ==================== Solar API 활성화 ==================== #

# ---------------------- Solar API 기능 활성화 ---------------------- #
# Upstage Solar LLM API를 사용하여 고품질 요약 생성
python scripts/train.py --use_solar_api
```

### `--solar_api_key` (API 키 지정)
```bash
# ==================== Solar API 키 설정 ==================== #

# ---------------------- 명령어로 직접 지정 ---------------------- #
# API 키를 명령어 옵션으로 직접 전달
python scripts/train.py \
  --use_solar_api \
  --solar_api_key "your-api-key-here"

# ---------------------- 환경변수 사용 (권장) ---------------------- #
# 환경변수로 API 키 설정 후 스크립트 실행
export SOLAR_API_KEY="your-api-key"
python scripts/train.py --use_solar_api
```

### `--solar_model` (Solar 모델 선택)
```bash
# ==================== Solar 모델 선택 ==================== #

# ---------------------- Mini 모델 (빠른 처리) ---------------------- #
# 빠른 처리 속도와 저렴한 비용의 Mini 모델 사용
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-mini-chat

# ---------------------- Full 모델 (고품질) ---------------------- #
# 최고 품질의 요약을 위한 Full 모델 사용
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-chat
```

**완전한 예시**:
```bash
# ==================== Solar API 전체 예시 ==================== #

# ---------------------- Solar API + Few-shot 프롬프트 ---------------------- #
# 환경변수로 API 키 설정 후 Mini 모델과 Few-shot 전략 사용
export SOLAR_API_KEY="your-api-key"
python scripts/train.py \
  --mode full \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard
```

---

## 9. 프롬프트 전략

**PRD**: 15번 - 프롬프트 엔지니어링 전략

### `--prompt_strategy` (프롬프트 선택)

| 전략 | 설명 | 사용 시나리오 |
|------|------|---------------|
| `zero_shot_simple` | 기본 프롬프트 | 빠른 실험 |
| `zero_shot_detailed` | 상세 지시 | 명확한 가이드 필요 |
| `few_shot_standard` | 2개 예시 | 표준 성능 |
| `few_shot_diverse` | 3개 다양한 예시 | 다양성 확보 |
| `chain_of_thought` | 단계별 추론 | 복잡한 요약 |
| `role_playing` | 역할 기반 | 전문적 요약 |
| `self_consistency` | 다중 생성 + 투표 | 안정적 결과 |

```bash
# ==================== 프롬프트 전략 선택 ==================== #

# ---------------------- Few-shot 프롬프트 (표준) ---------------------- #
# 2개의 예시와 함께 제공하는 표준 Few-shot 프롬프트
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy few_shot_standard

# ---------------------- Chain-of-Thought (고품질) ---------------------- #
# 단계별 추론 과정을 포함한 CoT 프롬프트
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy chain_of_thought

# ---------------------- Self-consistency (최고 안정성) ---------------------- #
# 다중 생성 후 투표로 가장 안정적인 결과 선택
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy self_consistency
```

---

## 10. 데이터 품질 검증

**PRD**: 16번 - 데이터 품질 검증 시스템

### `--validate_data_quality` (품질 검증 활성화)
```bash
# ==================== 데이터 품질 검증 활성화 ==================== #

# ---------------------- 데이터 품질 자동 검증 ---------------------- #
# 구조, 중복, 통계, 이상치 등 4단계 품질 검증 수행
python scripts/train.py --validate_data_quality
```

### `--quality_threshold` (품질 임계값)
```bash
# ==================== 품질 임계값 설정 ==================== #

# ---------------------- 엄격한 기준 (0.8) ---------------------- #
# 높은 품질 기준으로 문제 데이터 엄격하게 필터링
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.8

# ---------------------- 표준 기준 (0.7) ---------------------- #
# 일반적으로 권장되는 표준 품질 기준
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.7

# ---------------------- 느슨한 기준 (0.6) ---------------------- #
# 더 많은 데이터를 포함하는 느슨한 품질 기준
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.6
```

**검증 항목**:
- 구조 검증 (컬럼, NULL, 공백)
- 중복 검증
- 통계 검증 (길이 분포)
- 이상치 탐지 (Z-score)
- Solar API 교차 검증

---

## 11. 추론 최적화

**PRD**: 17번 - 추론 최적화 전략

### `--optimize_inference` (추론 최적화 활성화)
```bash
# ==================== 추론 최적화 활성화 ==================== #

# ---------------------- 추론 속도 및 메모리 최적화 ---------------------- #
# 학습 후 모델 추론 성능을 자동으로 최적화
python scripts/train.py --optimize_inference
```

### `--optimization_method` (최적화 방법)

| 방법 | 설명 | 속도 향상 | 메모리 절감 |
|------|------|-----------|-------------|
| `quantization` | 양자화 | 2-3x | 50-75% |
| `onnx` | ONNX 변환 | 1.5-2x | 10-20% |
| `tensorrt` | TensorRT 가속 | 3-5x | 20-30% |
| `pruning` | 가지치기 | 1.5-2x | 30-50% |

```bash
# ==================== 최적화 방법 선택 ==================== #

# ---------------------- INT8 양자화 ---------------------- #
# INT8 양자화로 속도 2-3배, 메모리 50-75% 절감
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8

# ---------------------- FP16 양자화 ---------------------- #
# FP16 양자화로 고품질 유지하며 속도 향상
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 16

# ---------------------- ONNX 변환 ---------------------- #
# ONNX Runtime으로 추론 속도 1.5-2배 향상
python scripts/train.py \
  --optimize_inference \
  --optimization_method onnx \
  --use_onnx

# ---------------------- TensorRT 가속 (GPU 전용) ---------------------- #
# NVIDIA TensorRT로 GPU 추론 속도 3-5배 향상
python scripts/train.py \
  --optimize_inference \
  --optimization_method tensorrt

# ---------------------- Pruning 경량화 ---------------------- #
# 가지치기로 모델 크기 30-50% 감소
python scripts/train.py \
  --optimize_inference \
  --optimization_method pruning
```

### `--quantization_bits` (양자화 비트)
```bash
# ==================== 양자화 비트 수 설정 ==================== #

# ---------------------- INT4 양자화 (최대 압축) ---------------------- #
# 4비트 양자화로 최대 압축 (품질 다소 저하)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 4

# ---------------------- INT8 양자화 (균형) ---------------------- #
# 8비트 양자화로 속도와 품질 균형
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 8

# ---------------------- FP16 양자화 (고품질) ---------------------- #
# 16비트 양자화로 높은 품질 유지
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 16
```

### `--use_batch_optimization` (배치 최적화)
```bash
# ==================== 배치 크기 자동 최적화 ==================== #

# ---------------------- 추론 배치 최적화 ---------------------- #
# GPU 메모리에 맞춰 추론 배치 크기 자동 최적화
python scripts/train.py \
  --optimize_inference \
  --use_batch_optimization
```

---

## 12. 로깅 및 모니터링

**PRD**: 11번 - 로깅 및 모니터링 시스템

### `--no_wandb` (WandB 비활성화)
```bash
# ==================== WandB 로깅 활성화 ==================== #

# ---------------------- WandB 실험 추적 ---------------------- #
# Weights & Biases로 학습 과정 자동 로깅 및 시각화
python scripts/train.py --no_wandb  # WandB 비활성화 (기본값: 활성화)
```

### `--wandb_project` (프로젝트명)
```bash
# ==================== WandB 프로젝트명 설정 ==================== #

# ---------------------- 커스텀 프로젝트명 지정 ---------------------- #
# WandB 대시보드에서 사용할 프로젝트명 설정
python scripts/train.py \
  --no_wandb \
  --wandb_project dialogue-summarization
```

### `--save_visualizations` (시각화 저장)
```bash
# ==================== 시각화 자동 저장 ==================== #

# ---------------------- 학습 시각화 자동 생성 및 저장 ---------------------- #
# Loss curve, ROUGE 점수 변화, Confusion matrix 등 자동 저장
python scripts/train.py --save_visualizations
```

**자동 로깅되는 항목 (PRD 11)**:
- Learning rate 스케줄
- Gradient norms (레이어별)
- Loss curve (train/val)
- GPU 메모리 사용량
- 학습 속도 (samples/sec)
- ROUGE 점수 변화
- Confusion matrix
- 예측 샘플

---

## 13. 실전 예시

### 13.1 빠른 베이스라인 검증
```bash
# ==================== 빠른 베이스라인 검증 ==================== #

# ---------------------- 10분 이내 빠른 실험 ---------------------- #
# KoBART로 1 에포크만 학습하여 코드 검증 및 빠른 성능 확인
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --batch_size 8 \
  --debug
```

### 13.2 고품질 단일 모델 학습
```bash
# ==================== 고품질 단일 모델 학습 ==================== #

# ---------------------- Solar 모델 정식 학습 ---------------------- #
# 데이터 증강 + 품질 검증 + WandB 로깅 포함한 완전한 학습
python scripts/train.py \
  --mode single \
  --models solar-10.7b \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --validate_data_quality \
  --no_wandb
```

### 13.3 K-Fold 교차 검증
```bash
# ==================== K-Fold 교차 검증 예시 ==================== #

# ---------------------- 5-Fold 안정성 검증 ---------------------- #
# Solar 모델로 5-Fold 교차 검증 + 시각화 저장
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8 \
  --no_wandb \
  --save_visualizations
```

### 13.4 다중 모델 앙상블 (Stacking)
```bash
# ==================== 다중 모델 Stacking 앙상블 ==================== #

# ---------------------- 3개 모델 Stacking ---------------------- #
# KoBART + Solar + Polyglot 모델을 Stacking 앙상블로 최고 성능 달성
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking \
  --epochs 3 \
  --batch_size 4 \
  --use_augmentation \
  --no_wandb
```

### 13.5 Optuna 하이퍼파라미터 최적화
```bash
# ==================== Optuna 하이퍼파라미터 최적화 ==================== #

# ---------------------- Solar 모델 최적화 ---------------------- #
# 100회 시도로 2시간 동안 최적 하이퍼파라미터 탐색
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

### 13.6 전체 파이프라인 (최종 제출)

**SOLAR_API_KEY 환경변수 설정:**
```bash
# ==================== Solar API 키 설정 방법 ==================== #

# ---------------------- 방법 1: 환경변수로 설정 (권장) ---------------------- #
# 환경변수로 API 키를 설정하여 명령어에서 직접 사용
export SOLAR_API_KEY="your-api-key"

# ---------------------- 방법 2: .env 파일 사용 (기본값) ---------------------- #
# .env 파일에 SOLAR_API_KEY=your-api-key 저장
# 별도 export 없이 자동으로 .env 파일에서 로드됨

# ---------------------- 방법 3: 명령어 옵션으로 지정 ---------------------- #
# --solar_api_key 옵션으로 .env 값 오버라이드
# --solar_api_key "your-api-key"
```

**설명:**
- 기본적으로 `.env` 파일의 `SOLAR_API_KEY` 값을 사용합니다
- `export SOLAR_API_KEY="your-api-key"`는 .env 파일 값을 오버라이드하거나, .env 파일이 없을 때 사용합니다
- 명령어 옵션 `--solar_api_key`로도 지정 가능하며, 이는 환경변수와 .env 값을 모두 오버라이드합니다

#### 13.6.1 단일 모델 전체 파이프라인

```bash
# ==================== 단일 모델 (KoBART) 전체 파이프라인 ==================== #

# ---------------------- KoBART 단일 모델 + 모든 고급 기능 ---------------------- #
# 빠른 실행 속도와 안정적 성능으로 전체 파이프라인 검증
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 15 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_kobart_premium \
  --seed 42
```

```bash
# ==================== 단일 모델 (Solar-10.7B) 전체 파이프라인 ==================== #

# ---------------------- Solar 단일 모델 + 고품질 설정 ---------------------- #
# 대규모 LLM의 고품질 요약 능력을 활용한 전체 파이프라인
python scripts/train.py \
  --mode full \
  --models solar-10.7b \
  --epochs 10 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 8 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase synonym \
  --tta_num_aug 3 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_solar_premium \
  --seed 42
```

#### 13.6.2 다중 모델 (2-3개) 전체 파이프라인

```bash
# ==================== 2개 모델 (KoBART + Solar) 전체 파이프라인 ==================== #

# ---------------------- 균형잡힌 2개 모델 조합 ---------------------- #
# 빠른 모델(KoBART)과 고품질 모델(Solar)의 조합으로 효율성과 성능 확보
python scripts/train.py \
  --mode full \
  --models kobart solar-10.7b \
  --epochs 12 \
  --batch_size 8 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.4 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 4 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_2models_premium \
  --seed 42
```

```bash
# ==================== 3개 모델 (KoBART + Solar + Llama) 전체 파이프라인 ==================== #

# ---------------------- 3개 모델 Stacking 앙상블 ---------------------- #
# 다양한 모델 조합으로 Stacking 앙상블 최고 성능 달성
python scripts/train.py \
  --mode full \
  --models kobart solar-10.7b llama-3.2-korean-3b \
  --epochs 10 \
  --batch_size 6 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 6 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 5 \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --num_beams 7 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_3models_stacking \
  --seed 42
```

#### 13.6.3 전체 모델 (6개 모델) 전체 파이프라인

**제출 파일 이중 저장**:
- Full 파이프라인은 학습 완료 후 자동으로 추론을 실행하여 제출 파일을 생성합니다
- 제출 파일은 **두 곳에 동시 저장**됩니다:
  - `experiments/{날짜}/{실행폴더명}/submissions/{실행폴더명}.csv`
  - `submissions/{날짜}/{실행폴더명}.csv`
- 예시: `20251012_101219_test_full_pipeline_quick` 실행 시
  - `experiments/20251012/20251012_101219_test_full_pipeline_quick/submissions/20251012_101219_test_full_pipeline_quick.csv`
  - `submissions/20251012/20251012_101219_test_full_pipeline_quick.csv`

```bash
# ==================== 전체 모델 (6개 모두) 전체 파이프라인 - 최상급 ==================== #

# ---------------------- 모든 모델 + 모든 고급 기능 통합 ---------------------- #
# 6개 모델 전체를 활용한 최고 성능의 최종 제출용 파이프라인
# 실험명: final_all_models_premium (자동 확장되어 full_kobart로 표시되지만 실제로는 6개 모델 사용)
# 학습 완료 후 자동으로 추론 실행 → 제출 파일 이중 저장
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 20 \
  --batch_size 8 \
  --learning_rate 5e-6 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 5 \
  --use_solar_api \
  --solar_model solar-1-chat \
  --prompt_strategy self_consistency \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --optimize_inference \
  --optimization_method tensorrt \
  --use_batch_optimization \
  --num_beams 8 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --wandb_project final-submission \
  --save_visualizations \
  --experiment_name final_all_models_premium \
  --seed 42
```

```bash
# ==================== 전체 모델 명시적 지정 전체 파이프라인 ==================== #

# ---------------------- 6개 모델 명시적 나열 ---------------------- #
# --models all 대신 모든 모델을 명시적으로 나열하여 실행
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b solar-10.7b polyglot-ko-12.8b kullm-v2 \
  --epochs 18 \
  --batch_size 6 \
  --learning_rate 8e-6 \
  --gradient_accumulation_steps 5 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy blending \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 5 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 8 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_6models_explicit \
  --seed 42
```

```bash
# ==================== 전체 모델 (6개) 빠른 테스트 (예상 소요 시간: 2-3시간) ==================== #

# ---------------------- 코드 검증용 최소 반복 설정 테스트 ---------------------- #
# 6개 모델 전체 파이프라인의 모든 기능이 정상 작동하는지 빠르게 검증
# 반복 실행 수치만 최소화: epochs=1, k_folds=2, augmentation_ratio=0.1, tta_num_aug=2
# 모든 고급 기능 포함하여 전체 플로우 완전 테스트
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 5e-6 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --optimize_inference \
  --optimization_method quantization \
  --use_batch_optimization \
  --num_beams 4 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name test_full_pipeline_quick \
  --seed 42
```

#### 13.6.4 Config 파일 기반 전체 파이프라인

```bash
# ==================== Config 파일 사용 전체 파이프라인 ==================== #

# ---------------------- all.yaml 설정 파일 활용 ---------------------- #
# configs/models/all.yaml 파일의 앙상블 메타 설정을 활용
# 주의: --config 옵션으로 all.yaml을 직접 사용하는 것은 지원되지 않음
# 대신 --models all 옵션이 자동으로 6개 모델로 확장됨

# ---------------------- 개별 모델 Config 사용 ---------------------- #
# 특정 모델의 config 파일을 사용한 전체 파이프라인
python scripts/train.py \
  --mode full \
  --config configs/models/kobart.yaml \
  --epochs 15 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_augmentation \
  --augmentation_ratio 0.4 \
  --use_tta \
  --validate_data_quality \
  --no_wandb \
  --experiment_name full_config_based \
  --seed 42
```

**참고:**
- `--models all` 옵션은 자동으로 6개 모델(`kobart`, `llama-3.2-korean-3b`, `qwen3-4b`, `solar-10.7b`, `polyglot-ko-12.8b`, `kullm-v2`)로 확장됩니다
- 실험 폴더명은 첫 번째 모델 이름(`kobart`)으로 생성되지만, 실제로는 6개 모델 모두 학습됩니다
- 명시적으로 6개 모델을 나열하면 동일한 효과를 얻을 수 있습니다
- `configs/models/all.yaml`은 앙상블 메타 설정 파일로, 개별 모델 config 파일들을 참조합니다

### 13.7 빠른 실험 (디버그 모드)
```bash
# ==================== 디버그 모드 빠른 실험 ==================== #

# ---------------------- 코드 테스트용 빠른 실행 ---------------------- #
# 디버그 모드로 최소 데이터셋 사용하여 빠르게 코드 검증
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --debug \
  --train_data data/raw/train.csv \
  --dev_data data/raw/dev.csv \
  --output_dir experiments/quick_test
```

### 13.8 추론만 (학습된 모델 사용)
```bash
# ==================== 학습된 모델로 추론 실행 ==================== #

# ---------------------- 기본 추론 ---------------------- #
# 학습된 모델로 테스트 데이터에 대해 추론 수행
python scripts/inference.py \
  --model outputs/baseline_kobart/final_model \
  --test_data data/raw/test.csv \
  --output submissions/submission.csv \
  --batch_size 32 \
  --num_beams 4
```

---

## 14. 옵션 조합 전략

### 상황별 권장 조합

#### 🚀 빠른 실험 (10분 이내)
```bash
# ==================== 10분 이내 빠른 실험 ==================== #

# ---------------------- 디버그 모드 최소 실행 ---------------------- #
# KoBART로 1 에포크만 학습하여 코드 검증
--mode single --models kobart --epochs 1 --debug
```

#### 🎯 베이스라인 검증 (1시간)
```bash
# ==================== 1시간 베이스라인 검증 ==================== #

# ---------------------- Solar 모델 + 품질 검증 ---------------------- #
# Solar 모델로 3 에포크 학습 + 데이터 품질 검증
--mode single --models solar-10.7b --epochs 3 --validate_data_quality
```

#### 🔬 성능 극대화 (6시간)
```bash
# ==================== 6시간 성능 극대화 ==================== #

# ---------------------- 풀 파이프라인 + 앙상블 + TTA ---------------------- #
# 모든 모델 앙상블 + 데이터 증강 + TTA로 최고 성능 달성
--mode full --models all --epochs 5 --use_augmentation --ensemble_strategy stacking --use_tta
```

#### 🏆 최종 제출 (12시간)
```bash
# ==================== 12시간 최종 제출 ==================== #

# ---------------------- 모든 고급 기능 통합 ---------------------- #
# 전체 파이프라인 + 앙상블 + TTA + Solar API + 추론 최적화
--mode full --models all --use_augmentation --ensemble_strategy stacking --use_tta --use_solar_api --optimize_inference
```

---

## 15. 트러블슈팅

### GPU 메모리 부족
```bash
# ==================== GPU 메모리 부족 해결 ==================== #

# ---------------------- 배치 크기 줄이고 Gradient Accumulation ---------------------- #
# 배치 크기를 2로 줄이고 4번 누적하여 효과적으로 배치 8 효과
--batch_size 2 --gradient_accumulation_steps 4

# ---------------------- 4비트 양자화로 메모리 절감 ---------------------- #
# INT4 양자화로 모델 메모리 사용량 대폭 감소
--optimization_method quantization --quantization_bits 4

# ---------------------- Gradient Checkpointing ---------------------- #
# Config 파일에서 gradient_checkpointing=True 설정
# (메모리 절감, 속도 약간 감소)
```

### 학습 속도 느림
```bash
# ==================== 학습 속도 개선 ==================== #

# ---------------------- 배치 크기 자동 최적화 ---------------------- #
# GPU 메모리에 맞는 최적 배치 크기 자동 탐색
--use_batch_optimization

# ---------------------- Mixed Precision 학습 ---------------------- #
# Config 파일에서 fp16=True 설정
# (학습 속도 약 2배 향상)

# ---------------------- DataLoader 병렬 처리 ---------------------- #
# Config 파일에서 dataloader_num_workers=8 설정
# (데이터 로딩 병렬화로 속도 향상)
```

### ROUGE 점수 낮음
```bash
# ==================== ROUGE 점수 향상 방법 ==================== #

# ---------------------- 데이터 증강으로 성능 향상 ---------------------- #
# 50% 데이터 증강으로 모델 일반화 성능 개선
--use_augmentation --augmentation_ratio 0.5

# ---------------------- Stacking 앙상블로 성능 극대화 ---------------------- #
# 여러 모델을 Stacking 앙상블하여 최고 성능 달성
--mode multi_model --ensemble_strategy stacking

# ---------------------- Optuna로 최적 하이퍼파라미터 탐색 ---------------------- #
# 100회 시도로 최적 설정 자동 탐색
--mode optuna --optuna_trials 100

# ---------------------- Solar API로 고품질 학습 데이터 생성 ---------------------- #
# Few-shot diverse 전략으로 다양한 요약 생성
--use_solar_api --prompt_strategy few_shot_diverse
```

---

## 16. 요약

### 필수 옵션 (모든 실행에 권장)
```bash
# ==================== 기본 필수 옵션 ==================== #

# ---------------------- 모든 실행에 필수인 기본 옵션 ---------------------- #
# 실행 모드, 모델, 에포크, 배치 크기 지정
python scripts/train.py \
  --mode [실행모드] \
  --models [모델명] \
  --epochs 3 \
  --batch_size 8
```

### 성능 향상 옵션
```bash
# ==================== 성능 향상을 위한 옵션 ==================== #

# ---------------------- 데이터 증강 + 앙상블 + TTA ---------------------- #
# 성능을 극대화하기 위한 3가지 핵심 기법
--use_augmentation \
--ensemble_strategy stacking \
--use_tta
```

### 품질 보장 옵션
```bash
# ==================== 품질 보장 옵션 ==================== #

# ---------------------- 데이터 검증 + Solar API + Few-shot ---------------------- #
# 데이터 품질 검증 및 고품질 요약 생성
--validate_data_quality \
--use_solar_api \
--prompt_strategy few_shot_diverse
```

### 최적화 옵션
```bash
# ==================== 최적화 옵션 ==================== #

# ---------------------- 하이퍼파라미터 자동 탐색 + 추론 최적화 ---------------------- #
# 최적 설정 탐색 및 추론 속도 향상
--mode optuna \
--optimize_inference
```

### 모니터링 옵션
```bash
# ==================== 모니터링 및 시각화 옵션 ==================== #

# ---------------------- WandB 로깅 + 시각화 저장 ---------------------- #
# 학습 과정 추적 및 결과 시각화 자동 저장
--no_wandb \
--save_visualizations
```

---

## 17. 참고 자료

- **PRD 문서**: `docs/PRD/` 폴더
- **모듈 가이드**: `docs/모듈화/` 폴더
- **Config 예시**: `configs/` 폴더
- **실험 결과**: `experiments/` 폴더

**모든 옵션은 `--help`로 확인 가능**:
```bash
# ==================== 도움말 확인 ==================== #

# ---------------------- 전체 옵션 목록 확인 ---------------------- #
# train.py 스크립트의 모든 사용 가능한 옵션 및 설명 출력
python scripts/train.py --help
```
