# ëª…ë ¹ì–´ ì˜µì…˜ ì™„ì „ ê°€ì´ë“œ

> **PRD 14: ì‹¤í–‰ ì˜µì…˜ ì‹œìŠ¤í…œ** - ëª¨ë“  PRD ê¸°ëŠ¥ì„ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œ](#1-ê¸°ë³¸-ì‹¤í–‰-ëª¨ë“œ)
2. [ëª¨ë¸ ì„ íƒ](#2-ëª¨ë¸-ì„ íƒ)
3. [í•™ìŠµ ì„¤ì •](#3-í•™ìŠµ-ì„¤ì •)
4. [K-Fold êµì°¨ê²€ì¦](#4-k-fold-êµì°¨ê²€ì¦)
5. [ì•™ìƒë¸” ì „ëµ](#5-ì•™ìƒë¸”-ì „ëµ)
6. [Optuna ìµœì í™”](#6-optuna-ìµœì í™”)
7. [ë°ì´í„° ì¦ê°•](#7-ë°ì´í„°-ì¦ê°•)
8. [Solar API](#8-solar-api)
9. [í”„ë¡¬í”„íŠ¸ ì „ëµ](#9-í”„ë¡¬í”„íŠ¸-ì „ëµ)
10. [ë°ì´í„° í’ˆì§ˆ ê²€ì¦](#10-ë°ì´í„°-í’ˆì§ˆ-ê²€ì¦)
11. [ì¶”ë¡  ìµœì í™”](#11-ì¶”ë¡ -ìµœì í™”)
12. [ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§](#12-ë¡œê¹…-ë°-ëª¨ë‹ˆí„°ë§)
13. [ì‹¤ì „ ì˜ˆì‹œ](#13-ì‹¤ì „-ì˜ˆì‹œ)

---

## 1. ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œ

### `--mode` (ì‹¤í–‰ ëª¨ë“œ ì„ íƒ)

**PRD**: 14ë²ˆ - ì‹¤í–‰ ì˜µì…˜ ì‹œìŠ¤í…œ

| ëª¨ë“œ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|---------------|
| `single` | ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ | ë¹ ë¥¸ ì‹¤í—˜, ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ |
| `kfold` | K-Fold êµì°¨ ê²€ì¦ | ëª¨ë¸ ì•ˆì •ì„± í‰ê°€ |
| `multi_model` | ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” | ì„±ëŠ¥ í–¥ìƒ, ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ |
| `optuna` | í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” | ìµœì  ì„¤ì • íƒìƒ‰ |
| `full` | ì „ì²´ íŒŒì´í”„ë¼ì¸ | ìµœì¢… ì œì¶œ, ëª¨ë“  ê¸°ëŠ¥ í†µí•© |

```bash
# ==================== ì‹¤í–‰ ëª¨ë“œ ì„ íƒ ==================== #

# ---------------------- ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ ---------------------- #
# ë¹ ë¥¸ ì‹¤í—˜ ë° ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ì„ ìœ„í•œ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ ëª¨ë“œ
python scripts/train.py --mode single

# ---------------------- ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---------------------- #
# ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ì„ í†µí•©í•œ ìµœì¢… ì œì¶œìš© íŒŒì´í”„ë¼ì¸ ëª¨ë“œ
python scripts/train.py --mode full
```

---

## 2. ëª¨ë¸ ì„ íƒ

### `--models` (ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ)

**PRD**: 05-07ë²ˆ - ëª¨ë¸ ì‹œìŠ¤í…œ

| ëª¨ë¸ëª… | ì„¤ëª… | ê¶Œì¥ ìš©ë„ |
|--------|------|-----------|
| `kobart` | í•œêµ­ì–´ BART | ë¹ ë¥¸ ì‹¤í—˜, ë² ì´ìŠ¤ë¼ì¸ |
| `solar-10.7b` | Upstage Solar LLM | ê³ í’ˆì§ˆ ìš”ì•½, ìµœì¢… ì œì¶œ |
| `polyglot-ko-12.8b` | ëŒ€ê·œëª¨ í•œêµ­ì–´ ëª¨ë¸ | ë†’ì€ ì„±ëŠ¥ |
| `llama-3.2-korean-3b` | Llama í•œêµ­ì–´ ë²„ì „ | ê· í˜•ì¡íŒ ì„±ëŠ¥ |
| `qwen3-4b` | Qwen ëª¨ë¸ | íš¨ìœ¨ì  í•™ìŠµ |
| `kullm-v2` | ê³ ë ¤ëŒ€ LLM | í•œêµ­ì–´ íŠ¹í™” |
| `all` | ëª¨ë“  ëª¨ë¸ (ìë™ í™•ì¥) | ì•™ìƒë¸”, í’€ íŒŒì´í”„ë¼ì¸ |

**ì°¸ê³ **: `--models all` ì˜µì…˜ ì‚¬ìš© ì‹œ ìë™ìœ¼ë¡œ 6ê°œì˜ ëª¨ë“  ëª¨ë¸(`kobart`, `llama-3.2-korean-3b`, `qwen3-4b`, `solar-10.7b`, `polyglot-ko-12.8b`, `kullm-v2`)ë¡œ í™•ì¥ë©ë‹ˆë‹¤.

```bash
# ==================== ëª¨ë¸ ì„ íƒ ì˜µì…˜ ==================== #

# ---------------------- ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ ---------------------- #
# KoBART ëª¨ë¸ë¡œ ë¹ ë¥¸ ì‹¤í—˜ ë° ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦
python scripts/train.py --models kobart

# ---------------------- ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ---------------------- #
# KoBARTì™€ Solar ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
python scripts/train.py --mode multi_model --models kobart solar-10.7b

# ---------------------- ì „ì²´ ëª¨ë¸ ì‚¬ìš© ---------------------- #
# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ì„ í†µí•©í•œ ì•™ìƒë¸” í•™ìŠµ
python scripts/train.py --mode full --models all
```

---

## 3. í•™ìŠµ ì„¤ì •

### ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

**PRD**: 06ë²ˆ - ê¸°ìˆ  ìš”êµ¬ì‚¬í•­

#### `--epochs` (í•™ìŠµ ì—í¬í¬ ìˆ˜)
```bash
# ==================== ì—í¬í¬ ìˆ˜ ì„¤ì • ==================== #

# ---------------------- ë¹ ë¥¸ ì‹¤í—˜ (1 ì—í¬í¬) ---------------------- #
# ì½”ë“œ í…ŒìŠ¤íŠ¸ ë° ë¹ ë¥¸ ê²€ì¦ì„ ìœ„í•œ ìµœì†Œ í•™ìŠµ
python scripts/train.py --epochs 1

# ---------------------- ì •ìƒ í•™ìŠµ (3 ì—í¬í¬) ---------------------- #
# í‘œì¤€ì ì¸ í•™ìŠµ ì„¤ì •ìœ¼ë¡œ ê· í˜•ì¡íŒ ì„±ëŠ¥ í™•ë³´
python scripts/train.py --epochs 3

# ---------------------- ê¸´ í•™ìŠµ (10 ì—í¬í¬) ---------------------- #
# ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ì¶©ë¶„í•œ í•™ìŠµ ì‹œê°„ í™•ë³´
python scripts/train.py --epochs 10
```

#### `--batch_size` (ë°°ì¹˜ í¬ê¸°)
```bash
# ==================== ë°°ì¹˜ í¬ê¸° ì„¤ì • ==================== #

# ---------------------- ì‘ì€ GPU ë©”ëª¨ë¦¬ (ë°°ì¹˜ 4) ---------------------- #
# GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ë•Œ ì‘ì€ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
python scripts/train.py --batch_size 4

# ---------------------- ê· í˜•ì¡íŒ ì„¤ì • (ë°°ì¹˜ 8) ---------------------- #
# ëŒ€ë¶€ë¶„ì˜ ìƒí™©ì—ì„œ ê¶Œì¥ë˜ëŠ” í‘œì¤€ ë°°ì¹˜ í¬ê¸°
python scripts/train.py --batch_size 8

# ---------------------- í° GPU ë©”ëª¨ë¦¬ (ë°°ì¹˜ 16) ---------------------- #
# ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ê°€ ìˆì„ ë•Œ í° ë°°ì¹˜ í¬ê¸°ë¡œ í•™ìŠµ ê°€ì†í™”
python scripts/train.py --batch_size 16
```

#### `--learning_rate` (í•™ìŠµë¥ )
```bash
# ==================== í•™ìŠµë¥  ì„¤ì • ==================== #

# ---------------------- ì‘ì€ ëª¨ë¸ìš© í•™ìŠµë¥  ---------------------- #
# KoBART ë“± ì‘ì€ ëª¨ë¸ì— ì í•©í•œ í•™ìŠµë¥ 
python scripts/train.py --learning_rate 5e-5

# ---------------------- LLMìš© í•™ìŠµë¥  ---------------------- #
# Solar, Llama ë“± ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ì í•©í•œ í•™ìŠµë¥ 
python scripts/train.py --learning_rate 1e-5

# ---------------------- ë¯¸ì„¸ ì¡°ì •ìš© í•™ìŠµë¥  ---------------------- #
# ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë‚®ì€ í•™ìŠµë¥ 
python scripts/train.py --learning_rate 1e-6
```

---

## 4. K-Fold êµì°¨ê²€ì¦

**PRD**: 10ë²ˆ - êµì°¨ ê²€ì¦ ì‹œìŠ¤í…œ

### `--k_folds` (Fold ìˆ˜)
```bash
# ==================== K-Fold ìˆ˜ ì„¤ì • ==================== #

# ---------------------- 3-Fold (ë¹ ë¥¸ ê²€ì¦) ---------------------- #
# ë¹ ë¥¸ êµì°¨ ê²€ì¦ì„ ìœ„í•œ ìµœì†Œ Fold ìˆ˜
python scripts/train.py --mode kfold --k_folds 3

# ---------------------- 5-Fold (í‘œì¤€ ì„¤ì •) ---------------------- #
# ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í‘œì¤€ Fold ìˆ˜
python scripts/train.py --mode kfold --k_folds 5

# ---------------------- 10-Fold (ì•ˆì •ì  í‰ê°€) ---------------------- #
# ë” ì•ˆì •ì ì¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ ë§ì€ Fold ìˆ˜
python scripts/train.py --mode kfold --k_folds 10
```

### `--fold_seed` (ì¬í˜„ì„± ë³´ì¥)
```bash
# ==================== Fold ë¶„í•  ì‹œë“œ ì„¤ì • ==================== #

# ---------------------- ì¬í˜„ ê°€ëŠ¥í•œ Fold ë¶„í•  ---------------------- #
# ë™ì¼í•œ ì‹œë“œë¡œ í•­ìƒ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ë¶„í• 
python scripts/train.py --mode kfold --fold_seed 42
```

**ì™„ì „í•œ ì˜ˆì‹œ**:
```bash
# ==================== K-Fold êµì°¨ ê²€ì¦ ì „ì²´ ì˜ˆì‹œ ==================== #

# ---------------------- Solar ëª¨ë¸ 5-Fold ê²€ì¦ ---------------------- #
# Solar ëª¨ë¸ë¡œ 5-Fold êµì°¨ ê²€ì¦ ìˆ˜í–‰ (ì¬í˜„ì„± ë³´ì¥)
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8
```

---

## 5. ì•™ìƒë¸” ì „ëµ

**PRD**: 12ë²ˆ - ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì „ëµ

### `--ensemble_strategy` (ì•™ìƒë¸” ë°©ë²•)

| ì „ëµ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|---------------|
| `averaging` | ë‹¨ìˆœ í‰ê·  | ë¹ ë¥¸ ì‹¤í—˜ |
| `weighted_avg` | ê°€ì¤‘ í‰ê·  | ì„±ëŠ¥ ê¸°ë°˜ ì¡°í•© |
| `majority_vote` | íˆ¬í‘œ | ë‹¤ì–‘ì„± í™•ë³´ |
| `stacking` | ë©”íƒ€ í•™ìŠµê¸° | ìµœê³  ì„±ëŠ¥ |
| `blending` | Validation ê¸°ë°˜ | ê³¼ì í•© ë°©ì§€ |
| `rouge_weighted` | ROUGE ê¸°ë°˜ ê°€ì¤‘ì¹˜ | ìë™ ìµœì í™” |

```bash
# ==================== ì•™ìƒë¸” ì „ëµ ì„ íƒ ==================== #

# ---------------------- ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” ---------------------- #
# ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë”°ë¼ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•œ í‰ê·  ì•™ìƒë¸”
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg

# ---------------------- Stacking ì•™ìƒë¸” (ìµœê³  ì„±ëŠ¥) ---------------------- #
# ë©”íƒ€ í•™ìŠµê¸°ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ì•™ìƒë¸” ê¸°ë²• (3ê°œ ëª¨ë¸)
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking

# ---------------------- Blending ì•™ìƒë¸” ---------------------- #
# Validation ë°ì´í„° ê¸°ë°˜ ë¸”ë Œë”©ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy blending
```

### `--ensemble_weights` (ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì§€ì •)
```bash
# ==================== ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìˆ˜ë™ ì„¤ì • ==================== #

# ---------------------- ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ ì§€ì • ---------------------- #
# KoBART 30%, Solar 70% ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸”
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.3 0.7
```

### TTA (Test Time Augmentation)

**PRD**: 12ë²ˆ - TTA ì „ëµ

#### `--use_tta` (TTA í™œì„±í™”)
```bash
# ==================== TTA (Test Time Augmentation) í™œì„±í™” ==================== #

# ---------------------- TTA ê¸°ë³¸ í™œì„±í™” ---------------------- #
# ì¶”ë¡  ì‹œ ë°ì´í„° ì¦ê°•ì„ í†µí•´ ì˜ˆì¸¡ ì•ˆì •ì„± í–¥ìƒ
python scripts/train.py --mode full --use_tta
```

#### `--tta_strategies` (TTA ë°©ë²•)
```bash
# ==================== TTA ì „ëµ ì„ íƒ ==================== #

# ---------------------- ë‹¤ì¤‘ TTA ì „ëµ ì¡°í•© ---------------------- #
# íŒ¨ëŸ¬í”„ë ˆì´ì§•, ì¬ì •ë ¬, ë™ì˜ì–´ ì¹˜í™˜ ì „ëµìœ¼ë¡œ 5ë²ˆ ì¦ê°•
python scripts/train.py \
  --mode full \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 5
```

---

## 6. Optuna ìµœì í™”

**PRD**: 13ë²ˆ - Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

### `--optuna_trials` (ì‹œë„ íšŸìˆ˜)
```bash
# ==================== Optuna ì‹œë„ íšŸìˆ˜ ì„¤ì • ==================== #

# ---------------------- ë¹ ë¥¸ íƒìƒ‰ (20íšŒ) ---------------------- #
# ë¹ ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ (ì•½ 1-2ì‹œê°„)
python scripts/train.py --mode optuna --optuna_trials 20

# ---------------------- ì •ë°€ íƒìƒ‰ (100íšŒ) ---------------------- #
# í‘œì¤€ì ì¸ ìµœì í™” íƒìƒ‰ (ì•½ 4-6ì‹œê°„)
python scripts/train.py --mode optuna --optuna_trials 100

# ---------------------- ì² ì €í•œ íƒìƒ‰ (500íšŒ) ---------------------- #
# ë§¤ìš° ì •ë°€í•œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰ (ì•½ 20-24ì‹œê°„)
python scripts/train.py --mode optuna --optuna_trials 500
```

### `--optuna_timeout` (ì œí•œ ì‹œê°„)
```bash
# ==================== Optuna ì œí•œ ì‹œê°„ ì„¤ì • ==================== #

# ---------------------- 1ì‹œê°„ ì œí•œ ---------------------- #
# ìµœëŒ€ 1ì‹œê°„ ë™ì•ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ìˆ˜í–‰
python scripts/train.py --mode optuna --optuna_timeout 3600

# ---------------------- 2ì‹œê°„ ì œí•œ ---------------------- #
# ìµœëŒ€ 2ì‹œê°„ ë™ì•ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ìˆ˜í–‰
python scripts/train.py --mode optuna --optuna_timeout 7200
```

### `--optuna_sampler` (ìƒ˜í”ŒëŸ¬ ì„ íƒ)
```bash
# ==================== Optuna ìƒ˜í”ŒëŸ¬ ì„ íƒ ==================== #

# ---------------------- TPE ìƒ˜í”ŒëŸ¬ (ê¸°ë³¸, ê¶Œì¥) ---------------------- #
# Tree-structured Parzen Estimator ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
python scripts/train.py --mode optuna --optuna_sampler tpe

# ---------------------- Random ìƒ˜í”ŒëŸ¬ ---------------------- #
# ë¬´ì‘ìœ„ ìƒ˜í”Œë§ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
python scripts/train.py --mode optuna --optuna_sampler random

# ---------------------- GP ìƒ˜í”ŒëŸ¬ ---------------------- #
# Gaussian Process ê¸°ë°˜ ìƒ˜í”Œë§
python scripts/train.py --mode optuna --optuna_sampler gp
```

### `--optuna_pruner` (ê°€ì§€ì¹˜ê¸° ì „ëµ)
```bash
# ==================== Optuna ê°€ì§€ì¹˜ê¸° ì „ëµ ==================== #

# ---------------------- Median Pruner (ê¸°ë³¸) ---------------------- #
# ì¤‘ì•™ê°’ ê¸°ë°˜ ì¡°ê¸° ì¢…ë£Œë¡œ ë¹„íš¨ìœ¨ì  ì‹œë„ ì œê±°
python scripts/train.py --mode optuna --optuna_pruner median

# ---------------------- Percentile Pruner ---------------------- #
# ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì¡°ê¸° ì¢…ë£Œ
python scripts/train.py --mode optuna --optuna_pruner percentile

# ---------------------- Hyperband Pruner ---------------------- #
# Hyperband ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì ì‘ì  ìì› í• ë‹¹
python scripts/train.py --mode optuna --optuna_pruner hyperband
```

**ì™„ì „í•œ ì˜ˆì‹œ**:
```bash
# ==================== Optuna ìµœì í™” ì „ì²´ ì˜ˆì‹œ ==================== #

# ---------------------- Solar ëª¨ë¸ ìµœì í™” (100íšŒ ì‹œë„) ---------------------- #
# TPE ìƒ˜í”ŒëŸ¬ì™€ Median Prunerë¡œ 2ì‹œê°„ ë™ì•ˆ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

**íƒìƒ‰ë˜ëŠ” 15ê°œ íŒŒë¼ë¯¸í„°**:
- **í•™ìŠµ íŒŒë¼ë¯¸í„° (7ê°œ)**: learning_rate, batch_size, gradient_accumulation_steps, warmup_ratio, weight_decay, max_grad_norm, label_smoothing
- **ìƒì„± íŒŒë¼ë¯¸í„° (8ê°œ)**: num_beams, temperature, top_p, top_k, repetition_penalty, length_penalty, no_repeat_ngram_size, early_stopping_patience

---

## 7. ë°ì´í„° ì¦ê°•

**PRD**: 04ë²ˆ - ì„±ëŠ¥ ê°œì„  ì „ëµ (ë°ì´í„° ì¦ê°•)

### `--use_augmentation` (ë°ì´í„° ì¦ê°• í™œì„±í™”)
```bash
# ==================== ë°ì´í„° ì¦ê°• í™œì„±í™” ==================== #

# ---------------------- ë°ì´í„° ì¦ê°• ê¸°ëŠ¥ í™œì„±í™” ---------------------- #
# í•™ìŠµ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ì¦ê°•í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ
python scripts/train.py --use_augmentation
```

### `--augmentation_methods` (ì¦ê°• ë°©ë²•)

| ë°©ë²• | ì„¤ëª… | íš¨ê³¼ |
|------|------|------|
| `back_translation` | ì—­ë²ˆì—­ (í•œâ†’ì˜â†’í•œ) | ë‹¤ì–‘í•œ í‘œí˜„ |
| `paraphrase` | ì˜ì—­ | ë¬¸ì¥ êµ¬ì¡° ë³€í™” |
| `synonym` | ë™ì˜ì–´ ì¹˜í™˜ | ì–´íœ˜ ë‹¤ì–‘ì„± |
| `turn_shuffle` | ëŒ€í™” ìˆœì„œ ì„ê¸° | ìˆœì„œ ë¶ˆë³€ì„± |

```bash
# ==================== ë°ì´í„° ì¦ê°• ë°©ë²• ì„ íƒ ==================== #

# ---------------------- ì—­ë²ˆì—­ë§Œ ì‚¬ìš© ---------------------- #
# í•œâ†’ì˜â†’í•œ ì—­ë²ˆì—­ìœ¼ë¡œ ë‹¤ì–‘í•œ í‘œí˜„ ìƒì„±
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation

# ---------------------- ì—¬ëŸ¬ ë°©ë²• ì¡°í•© ---------------------- #
# ì—­ë²ˆì—­, íŒ¨ëŸ¬í”„ë ˆì´ì§•, ë™ì˜ì–´ ì¹˜í™˜ì„ ì¡°í•©í•˜ì—¬ 50% ì¦ê°•
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.5
```

### `--augmentation_ratio` (ì¦ê°• ë¹„ìœ¨)
```bash
# ==================== ë°ì´í„° ì¦ê°• ë¹„ìœ¨ ì„¤ì • ==================== #

# ---------------------- 30% ì¦ê°• ---------------------- #
# ì›ë³¸ ë°ì´í„°ì˜ 30%ë§Œí¼ ì¦ê°• ë°ì´í„° ìƒì„±
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.3

# ---------------------- 50% ì¦ê°• ---------------------- #
# ì›ë³¸ ë°ì´í„°ì˜ 50%ë§Œí¼ ì¦ê°• ë°ì´í„° ìƒì„±
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.5
```

---

## 8. Solar API

**PRD**: 09ë²ˆ - Solar API ìµœì í™”

### `--use_solar_api` (Solar API í™œì„±í™”)
```bash
# ==================== Solar API í™œì„±í™” ==================== #

# ---------------------- Solar API ê¸°ëŠ¥ í™œì„±í™” ---------------------- #
# Upstage Solar LLM APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ìš”ì•½ ìƒì„±
python scripts/train.py --use_solar_api
```

### `--solar_api_key` (API í‚¤ ì§€ì •)
```bash
# ==================== Solar API í‚¤ ì„¤ì • ==================== #

# ---------------------- ëª…ë ¹ì–´ë¡œ ì§ì ‘ ì§€ì • ---------------------- #
# API í‚¤ë¥¼ ëª…ë ¹ì–´ ì˜µì…˜ìœ¼ë¡œ ì§ì ‘ ì „ë‹¬
python scripts/train.py \
  --use_solar_api \
  --solar_api_key "your-api-key-here"

# ---------------------- í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© (ê¶Œì¥) ---------------------- #
# í™˜ê²½ë³€ìˆ˜ë¡œ API í‚¤ ì„¤ì • í›„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
export SOLAR_API_KEY="your-api-key"
python scripts/train.py --use_solar_api
```

### `--solar_model` (Solar ëª¨ë¸ ì„ íƒ)
```bash
# ==================== Solar ëª¨ë¸ ì„ íƒ ==================== #

# ---------------------- Mini ëª¨ë¸ (ë¹ ë¥¸ ì²˜ë¦¬) ---------------------- #
# ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ì™€ ì €ë ´í•œ ë¹„ìš©ì˜ Mini ëª¨ë¸ ì‚¬ìš©
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-mini-chat

# ---------------------- Full ëª¨ë¸ (ê³ í’ˆì§ˆ) ---------------------- #
# ìµœê³  í’ˆì§ˆì˜ ìš”ì•½ì„ ìœ„í•œ Full ëª¨ë¸ ì‚¬ìš©
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-chat
```

**ì™„ì „í•œ ì˜ˆì‹œ**:
```bash
# ==================== Solar API ì „ì²´ ì˜ˆì‹œ ==================== #

# ---------------------- Solar API + Few-shot í”„ë¡¬í”„íŠ¸ ---------------------- #
# í™˜ê²½ë³€ìˆ˜ë¡œ API í‚¤ ì„¤ì • í›„ Mini ëª¨ë¸ê³¼ Few-shot ì „ëµ ì‚¬ìš©
export SOLAR_API_KEY="your-api-key"
python scripts/train.py \
  --mode full \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard
```

---

## 9. í”„ë¡¬í”„íŠ¸ ì „ëµ

**PRD**: 15ë²ˆ - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì „ëµ

### `--prompt_strategy` (í”„ë¡¬í”„íŠ¸ ì„ íƒ)

| ì „ëµ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|---------------|
| `zero_shot_simple` | ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ | ë¹ ë¥¸ ì‹¤í—˜ |
| `zero_shot_detailed` | ìƒì„¸ ì§€ì‹œ | ëª…í™•í•œ ê°€ì´ë“œ í•„ìš” |
| `few_shot_standard` | 2ê°œ ì˜ˆì‹œ | í‘œì¤€ ì„±ëŠ¥ |
| `few_shot_diverse` | 3ê°œ ë‹¤ì–‘í•œ ì˜ˆì‹œ | ë‹¤ì–‘ì„± í™•ë³´ |
| `chain_of_thought` | ë‹¨ê³„ë³„ ì¶”ë¡  | ë³µì¡í•œ ìš”ì•½ |
| `role_playing` | ì—­í•  ê¸°ë°˜ | ì „ë¬¸ì  ìš”ì•½ |
| `self_consistency` | ë‹¤ì¤‘ ìƒì„± + íˆ¬í‘œ | ì•ˆì •ì  ê²°ê³¼ |

```bash
# ==================== í”„ë¡¬í”„íŠ¸ ì „ëµ ì„ íƒ ==================== #

# ---------------------- Few-shot í”„ë¡¬í”„íŠ¸ (í‘œì¤€) ---------------------- #
# 2ê°œì˜ ì˜ˆì‹œì™€ í•¨ê»˜ ì œê³µí•˜ëŠ” í‘œì¤€ Few-shot í”„ë¡¬í”„íŠ¸
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy few_shot_standard

# ---------------------- Chain-of-Thought (ê³ í’ˆì§ˆ) ---------------------- #
# ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ì„ í¬í•¨í•œ CoT í”„ë¡¬í”„íŠ¸
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy chain_of_thought

# ---------------------- Self-consistency (ìµœê³  ì•ˆì •ì„±) ---------------------- #
# ë‹¤ì¤‘ ìƒì„± í›„ íˆ¬í‘œë¡œ ê°€ì¥ ì•ˆì •ì ì¸ ê²°ê³¼ ì„ íƒ
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy self_consistency
```

---

## 10. ë°ì´í„° í’ˆì§ˆ ê²€ì¦

**PRD**: 16ë²ˆ - ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ

### `--validate_data_quality` (í’ˆì§ˆ ê²€ì¦ í™œì„±í™”)
```bash
# ==================== ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í™œì„±í™” ==================== #

# ---------------------- ë°ì´í„° í’ˆì§ˆ ìë™ ê²€ì¦ ---------------------- #
# êµ¬ì¡°, ì¤‘ë³µ, í†µê³„, ì´ìƒì¹˜ ë“± 4ë‹¨ê³„ í’ˆì§ˆ ê²€ì¦ ìˆ˜í–‰
python scripts/train.py --validate_data_quality
```

### `--quality_threshold` (í’ˆì§ˆ ì„ê³„ê°’)
```bash
# ==================== í’ˆì§ˆ ì„ê³„ê°’ ì„¤ì • ==================== #

# ---------------------- ì—„ê²©í•œ ê¸°ì¤€ (0.8) ---------------------- #
# ë†’ì€ í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì œ ë°ì´í„° ì—„ê²©í•˜ê²Œ í•„í„°ë§
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.8

# ---------------------- í‘œì¤€ ê¸°ì¤€ (0.7) ---------------------- #
# ì¼ë°˜ì ìœ¼ë¡œ ê¶Œì¥ë˜ëŠ” í‘œì¤€ í’ˆì§ˆ ê¸°ì¤€
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.7

# ---------------------- ëŠìŠ¨í•œ ê¸°ì¤€ (0.6) ---------------------- #
# ë” ë§ì€ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ëŠìŠ¨í•œ í’ˆì§ˆ ê¸°ì¤€
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.6
```

**ê²€ì¦ í•­ëª©**:
- êµ¬ì¡° ê²€ì¦ (ì»¬ëŸ¼, NULL, ê³µë°±)
- ì¤‘ë³µ ê²€ì¦
- í†µê³„ ê²€ì¦ (ê¸¸ì´ ë¶„í¬)
- ì´ìƒì¹˜ íƒì§€ (Z-score)
- Solar API êµì°¨ ê²€ì¦

---

## 11. ì¶”ë¡  ìµœì í™”

**PRD**: 17ë²ˆ - ì¶”ë¡  ìµœì í™” ì „ëµ

### `--optimize_inference` (ì¶”ë¡  ìµœì í™” í™œì„±í™”)
```bash
# ==================== ì¶”ë¡  ìµœì í™” í™œì„±í™” ==================== #

# ---------------------- ì¶”ë¡  ì†ë„ ë° ë©”ëª¨ë¦¬ ìµœì í™” ---------------------- #
# í•™ìŠµ í›„ ëª¨ë¸ ì¶”ë¡  ì„±ëŠ¥ì„ ìë™ìœ¼ë¡œ ìµœì í™”
python scripts/train.py --optimize_inference
```

### `--optimization_method` (ìµœì í™” ë°©ë²•)

| ë°©ë²• | ì„¤ëª… | ì†ë„ í–¥ìƒ | ë©”ëª¨ë¦¬ ì ˆê° |
|------|------|-----------|-------------|
| `quantization` | ì–‘ìí™” | 2-3x | 50-75% |
| `onnx` | ONNX ë³€í™˜ | 1.5-2x | 10-20% |
| `tensorrt` | TensorRT ê°€ì† | 3-5x | 20-30% |
| `pruning` | ê°€ì§€ì¹˜ê¸° | 1.5-2x | 30-50% |

```bash
# ==================== ìµœì í™” ë°©ë²• ì„ íƒ ==================== #

# ---------------------- INT8 ì–‘ìí™” ---------------------- #
# INT8 ì–‘ìí™”ë¡œ ì†ë„ 2-3ë°°, ë©”ëª¨ë¦¬ 50-75% ì ˆê°
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8

# ---------------------- FP16 ì–‘ìí™” ---------------------- #
# FP16 ì–‘ìí™”ë¡œ ê³ í’ˆì§ˆ ìœ ì§€í•˜ë©° ì†ë„ í–¥ìƒ
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 16

# ---------------------- ONNX ë³€í™˜ ---------------------- #
# ONNX Runtimeìœ¼ë¡œ ì¶”ë¡  ì†ë„ 1.5-2ë°° í–¥ìƒ
python scripts/train.py \
  --optimize_inference \
  --optimization_method onnx \
  --use_onnx

# ---------------------- TensorRT ê°€ì† (GPU ì „ìš©) ---------------------- #
# NVIDIA TensorRTë¡œ GPU ì¶”ë¡  ì†ë„ 3-5ë°° í–¥ìƒ
python scripts/train.py \
  --optimize_inference \
  --optimization_method tensorrt

# ---------------------- Pruning ê²½ëŸ‰í™” ---------------------- #
# ê°€ì§€ì¹˜ê¸°ë¡œ ëª¨ë¸ í¬ê¸° 30-50% ê°ì†Œ
python scripts/train.py \
  --optimize_inference \
  --optimization_method pruning
```

### `--quantization_bits` (ì–‘ìí™” ë¹„íŠ¸)
```bash
# ==================== ì–‘ìí™” ë¹„íŠ¸ ìˆ˜ ì„¤ì • ==================== #

# ---------------------- INT4 ì–‘ìí™” (ìµœëŒ€ ì••ì¶•) ---------------------- #
# 4ë¹„íŠ¸ ì–‘ìí™”ë¡œ ìµœëŒ€ ì••ì¶• (í’ˆì§ˆ ë‹¤ì†Œ ì €í•˜)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 4

# ---------------------- INT8 ì–‘ìí™” (ê· í˜•) ---------------------- #
# 8ë¹„íŠ¸ ì–‘ìí™”ë¡œ ì†ë„ì™€ í’ˆì§ˆ ê· í˜•
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 8

# ---------------------- FP16 ì–‘ìí™” (ê³ í’ˆì§ˆ) ---------------------- #
# 16ë¹„íŠ¸ ì–‘ìí™”ë¡œ ë†’ì€ í’ˆì§ˆ ìœ ì§€
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 16
```

### `--use_batch_optimization` (ë°°ì¹˜ ìµœì í™”)
```bash
# ==================== ë°°ì¹˜ í¬ê¸° ìë™ ìµœì í™” ==================== #

# ---------------------- ì¶”ë¡  ë°°ì¹˜ ìµœì í™” ---------------------- #
# GPU ë©”ëª¨ë¦¬ì— ë§ì¶° ì¶”ë¡  ë°°ì¹˜ í¬ê¸° ìë™ ìµœì í™”
python scripts/train.py \
  --optimize_inference \
  --use_batch_optimization
```

---

## 12. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

**PRD**: 11ë²ˆ - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### `--no_wandb` (WandB ë¹„í™œì„±í™”)
```bash
# ==================== WandB ë¡œê¹… í™œì„±í™” ==================== #

# ---------------------- WandB ì‹¤í—˜ ì¶”ì  ---------------------- #
# Weights & Biasesë¡œ í•™ìŠµ ê³¼ì • ìë™ ë¡œê¹… ë° ì‹œê°í™”
python scripts/train.py --no_wandb  # WandB ë¹„í™œì„±í™” (ê¸°ë³¸ê°’: í™œì„±í™”)
```

### `--wandb_project` (í”„ë¡œì íŠ¸ëª…)
```bash
# ==================== WandB í”„ë¡œì íŠ¸ëª… ì„¤ì • ==================== #

# ---------------------- ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ëª… ì§€ì • ---------------------- #
# WandB ëŒ€ì‹œë³´ë“œì—ì„œ ì‚¬ìš©í•  í”„ë¡œì íŠ¸ëª… ì„¤ì •
python scripts/train.py \
  --no_wandb \
  --wandb_project dialogue-summarization
```

### `--save_visualizations` (ì‹œê°í™” ì €ì¥)
```bash
# ==================== ì‹œê°í™” ìë™ ì €ì¥ ==================== #

# ---------------------- í•™ìŠµ ì‹œê°í™” ìë™ ìƒì„± ë° ì €ì¥ ---------------------- #
# Loss curve, ROUGE ì ìˆ˜ ë³€í™”, Confusion matrix ë“± ìë™ ì €ì¥
python scripts/train.py --save_visualizations
```

**ìë™ ë¡œê¹…ë˜ëŠ” í•­ëª© (PRD 11)**:
- Learning rate ìŠ¤ì¼€ì¤„
- Gradient norms (ë ˆì´ì–´ë³„)
- Loss curve (train/val)
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- í•™ìŠµ ì†ë„ (samples/sec)
- ROUGE ì ìˆ˜ ë³€í™”
- Confusion matrix
- ì˜ˆì¸¡ ìƒ˜í”Œ

---

## 13. ì‹¤ì „ ì˜ˆì‹œ

### 13.1 ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦
```bash
# ==================== ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ ==================== #

# ---------------------- 10ë¶„ ì´ë‚´ ë¹ ë¥¸ ì‹¤í—˜ ---------------------- #
# KoBARTë¡œ 1 ì—í¬í¬ë§Œ í•™ìŠµí•˜ì—¬ ì½”ë“œ ê²€ì¦ ë° ë¹ ë¥¸ ì„±ëŠ¥ í™•ì¸
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --batch_size 8 \
  --debug
```

### 13.2 ê³ í’ˆì§ˆ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ
```bash
# ==================== ê³ í’ˆì§ˆ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ ==================== #

# ---------------------- Solar ëª¨ë¸ ì •ì‹ í•™ìŠµ ---------------------- #
# ë°ì´í„° ì¦ê°• + í’ˆì§ˆ ê²€ì¦ + WandB ë¡œê¹… í¬í•¨í•œ ì™„ì „í•œ í•™ìŠµ
python scripts/train.py \
  --mode single \
  --models solar-10.7b \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --validate_data_quality \
  --no_wandb
```

### 13.3 K-Fold êµì°¨ ê²€ì¦
```bash
# ==================== K-Fold êµì°¨ ê²€ì¦ ì˜ˆì‹œ ==================== #

# ---------------------- 5-Fold ì•ˆì •ì„± ê²€ì¦ ---------------------- #
# Solar ëª¨ë¸ë¡œ 5-Fold êµì°¨ ê²€ì¦ + ì‹œê°í™” ì €ì¥
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8 \
  --no_wandb \
  --save_visualizations
```

### 13.4 ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” (Stacking)
```bash
# ==================== ë‹¤ì¤‘ ëª¨ë¸ Stacking ì•™ìƒë¸” ==================== #

# ---------------------- 3ê°œ ëª¨ë¸ Stacking ---------------------- #
# KoBART + Solar + Polyglot ëª¨ë¸ì„ Stacking ì•™ìƒë¸”ë¡œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking \
  --epochs 3 \
  --batch_size 4 \
  --use_augmentation \
  --no_wandb
```

### 13.5 Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
```bash
# ==================== Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ==================== #

# ---------------------- Solar ëª¨ë¸ ìµœì í™” ---------------------- #
# 100íšŒ ì‹œë„ë¡œ 2ì‹œê°„ ë™ì•ˆ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

### 13.6 ì „ì²´ íŒŒì´í”„ë¼ì¸ (ìµœì¢… ì œì¶œ)

**SOLAR_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •:**
```bash
# ==================== Solar API í‚¤ ì„¤ì • ë°©ë²• ==================== #

# ---------------------- ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (ê¶Œì¥) ---------------------- #
# í™˜ê²½ë³€ìˆ˜ë¡œ API í‚¤ë¥¼ ì„¤ì •í•˜ì—¬ ëª…ë ¹ì–´ì—ì„œ ì§ì ‘ ì‚¬ìš©
export SOLAR_API_KEY="your-api-key"

# ---------------------- ë°©ë²• 2: .env íŒŒì¼ ì‚¬ìš© (ê¸°ë³¸ê°’) ---------------------- #
# .env íŒŒì¼ì— SOLAR_API_KEY=your-api-key ì €ì¥
# ë³„ë„ export ì—†ì´ ìë™ìœ¼ë¡œ .env íŒŒì¼ì—ì„œ ë¡œë“œë¨

# ---------------------- ë°©ë²• 3: ëª…ë ¹ì–´ ì˜µì…˜ìœ¼ë¡œ ì§€ì • ---------------------- #
# --solar_api_key ì˜µì…˜ìœ¼ë¡œ .env ê°’ ì˜¤ë²„ë¼ì´ë“œ
# --solar_api_key "your-api-key"
```

**ì„¤ëª…:**
- ê¸°ë³¸ì ìœ¼ë¡œ `.env` íŒŒì¼ì˜ `SOLAR_API_KEY` ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤
- `export SOLAR_API_KEY="your-api-key"`ëŠ” .env íŒŒì¼ ê°’ì„ ì˜¤ë²„ë¼ì´ë“œí•˜ê±°ë‚˜, .env íŒŒì¼ì´ ì—†ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤
- ëª…ë ¹ì–´ ì˜µì…˜ `--solar_api_key`ë¡œë„ ì§€ì • ê°€ëŠ¥í•˜ë©°, ì´ëŠ” í™˜ê²½ë³€ìˆ˜ì™€ .env ê°’ì„ ëª¨ë‘ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤

#### 13.6.1 ë‹¨ì¼ ëª¨ë¸ ì „ì²´ íŒŒì´í”„ë¼ì¸

```bash
# ==================== ë‹¨ì¼ ëª¨ë¸ (KoBART) ì „ì²´ íŒŒì´í”„ë¼ì¸ ==================== #

# ---------------------- KoBART ë‹¨ì¼ ëª¨ë¸ + ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ ---------------------- #
# ë¹ ë¥¸ ì‹¤í–‰ ì†ë„ì™€ ì•ˆì •ì  ì„±ëŠ¥ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 15 \
  --batch_size 16 \
  --learning_rate 5e-5 \
  --gradient_accumulation_steps 2 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --num_beams 5 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_kobart_premium \
  --seed 42
```

```bash
# ==================== ë‹¨ì¼ ëª¨ë¸ (Solar-10.7B) ì „ì²´ íŒŒì´í”„ë¼ì¸ ==================== #

# ---------------------- Solar ë‹¨ì¼ ëª¨ë¸ + ê³ í’ˆì§ˆ ì„¤ì • ---------------------- #
# ëŒ€ê·œëª¨ LLMì˜ ê³ í’ˆì§ˆ ìš”ì•½ ëŠ¥ë ¥ì„ í™œìš©í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸
python scripts/train.py \
  --mode full \
  --models solar-10.7b \
  --epochs 10 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  --gradient_accumulation_steps 8 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase synonym \
  --tta_num_aug 3 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_solar_premium \
  --seed 42
```

#### 13.6.2 ë‹¤ì¤‘ ëª¨ë¸ (2-3ê°œ) ì „ì²´ íŒŒì´í”„ë¼ì¸

```bash
# ==================== 2ê°œ ëª¨ë¸ (KoBART + Solar) ì „ì²´ íŒŒì´í”„ë¼ì¸ ==================== #

# ---------------------- ê· í˜•ì¡íŒ 2ê°œ ëª¨ë¸ ì¡°í•© ---------------------- #
# ë¹ ë¥¸ ëª¨ë¸(KoBART)ê³¼ ê³ í’ˆì§ˆ ëª¨ë¸(Solar)ì˜ ì¡°í•©ìœ¼ë¡œ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ í™•ë³´
python scripts/train.py \
  --mode full \
  --models kobart solar-10.7b \
  --epochs 12 \
  --batch_size 8 \
  --learning_rate 3e-5 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.4 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.4 0.6 \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 4 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 6 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_2models_premium \
  --seed 42
```

```bash
# ==================== 3ê°œ ëª¨ë¸ (KoBART + Solar + Llama) ì „ì²´ íŒŒì´í”„ë¼ì¸ ==================== #

# ---------------------- 3ê°œ ëª¨ë¸ Stacking ì•™ìƒë¸” ---------------------- #
# ë‹¤ì–‘í•œ ëª¨ë¸ ì¡°í•©ìœ¼ë¡œ Stacking ì•™ìƒë¸” ìµœê³  ì„±ëŠ¥ ë‹¬ì„±
python scripts/train.py \
  --mode full \
  --models kobart solar-10.7b llama-3.2-korean-3b \
  --epochs 10 \
  --batch_size 6 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 6 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 5 \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --num_beams 7 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_3models_stacking \
  --seed 42
```

#### 13.6.3 ì „ì²´ ëª¨ë¸ (6ê°œ ëª¨ë¸) ì „ì²´ íŒŒì´í”„ë¼ì¸

**ì œì¶œ íŒŒì¼ ì´ì¤‘ ì €ì¥**:
- Full íŒŒì´í”„ë¼ì¸ì€ í•™ìŠµ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ì—¬ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤
- ì œì¶œ íŒŒì¼ì€ **ë‘ ê³³ì— ë™ì‹œ ì €ì¥**ë©ë‹ˆë‹¤:
  - `experiments/{ë‚ ì§œ}/{ì‹¤í–‰í´ë”ëª…}/submissions/{ì‹¤í–‰í´ë”ëª…}.csv`
  - `submissions/{ë‚ ì§œ}/{ì‹¤í–‰í´ë”ëª…}.csv`
- ì˜ˆì‹œ: `20251012_101219_test_full_pipeline_quick` ì‹¤í–‰ ì‹œ
  - `experiments/20251012/20251012_101219_test_full_pipeline_quick/submissions/20251012_101219_test_full_pipeline_quick.csv`
  - `submissions/20251012/20251012_101219_test_full_pipeline_quick.csv`

```bash
# ==================== ì „ì²´ ëª¨ë¸ (6ê°œ ëª¨ë‘) ì „ì²´ íŒŒì´í”„ë¼ì¸ - ìµœìƒê¸‰ ==================== #

# ---------------------- ëª¨ë“  ëª¨ë¸ + ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ í†µí•© ---------------------- #
# 6ê°œ ëª¨ë¸ ì „ì²´ë¥¼ í™œìš©í•œ ìµœê³  ì„±ëŠ¥ì˜ ìµœì¢… ì œì¶œìš© íŒŒì´í”„ë¼ì¸
# ì‹¤í—˜ëª…: final_all_models_premium (ìë™ í™•ì¥ë˜ì–´ full_kobartë¡œ í‘œì‹œë˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” 6ê°œ ëª¨ë¸ ì‚¬ìš©)
# í•™ìŠµ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì¶”ë¡  ì‹¤í–‰ â†’ ì œì¶œ íŒŒì¼ ì´ì¤‘ ì €ì¥
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 20 \
  --batch_size 8 \
  --learning_rate 5e-6 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 5 \
  --use_solar_api \
  --solar_model solar-1-chat \
  --prompt_strategy self_consistency \
  --validate_data_quality \
  --quality_threshold 0.8 \
  --optimize_inference \
  --optimization_method tensorrt \
  --use_batch_optimization \
  --num_beams 8 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --wandb_project final-submission \
  --save_visualizations \
  --experiment_name final_all_models_premium \
  --seed 42
```

```bash
# ==================== ì „ì²´ ëª¨ë¸ ëª…ì‹œì  ì§€ì • ì „ì²´ íŒŒì´í”„ë¼ì¸ ==================== #

# ---------------------- 6ê°œ ëª¨ë¸ ëª…ì‹œì  ë‚˜ì—´ ---------------------- #
# --models all ëŒ€ì‹  ëª¨ë“  ëª¨ë¸ì„ ëª…ì‹œì ìœ¼ë¡œ ë‚˜ì—´í•˜ì—¬ ì‹¤í–‰
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b solar-10.7b polyglot-ko-12.8b kullm-v2 \
  --epochs 18 \
  --batch_size 6 \
  --learning_rate 8e-6 \
  --gradient_accumulation_steps 5 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.5 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy blending \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 5 \
  --validate_data_quality \
  --quality_threshold 0.75 \
  --num_beams 8 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name full_6models_explicit \
  --seed 42
```

```bash
# ==================== ì „ì²´ ëª¨ë¸ (6ê°œ) ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2-3ì‹œê°„) ==================== #

# ---------------------- ì½”ë“œ ê²€ì¦ìš© ìµœì†Œ ë°˜ë³µ ì„¤ì • í…ŒìŠ¤íŠ¸ ---------------------- #
# 6ê°œ ëª¨ë¸ ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ ë¹ ë¥´ê²Œ ê²€ì¦
# ë°˜ë³µ ì‹¤í–‰ ìˆ˜ì¹˜ë§Œ ìµœì†Œí™”: epochs=1, k_folds=2, augmentation_ratio=0.1, tta_num_aug=2
# ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ í¬í•¨í•˜ì—¬ ì „ì²´ í”Œë¡œìš° ì™„ì „ í…ŒìŠ¤íŠ¸
python scripts/train.py \
  --mode full \
  --models all \
  --epochs 1 \
  --batch_size 8 \
  --learning_rate 5e-6 \
  --gradient_accumulation_steps 4 \
  --warmup_ratio 0.1 \
  --weight_decay 0.01 \
  --max_grad_norm 1.0 \
  --label_smoothing 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym turn_shuffle \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder synonym mask \
  --tta_num_aug 2 \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard \
  --validate_data_quality \
  --quality_threshold 0.7 \
  --optimize_inference \
  --optimization_method quantization \
  --use_batch_optimization \
  --num_beams 4 \
  --temperature 0.7 \
  --top_p 0.9 \
  --top_k 50 \
  --repetition_penalty 1.2 \
  --length_penalty 1.0 \
  --no_repeat_ngram_size 3 \
  --no_wandb \
  --save_visualizations \
  --experiment_name test_full_pipeline_quick \
  --seed 42
```

#### 13.6.4 Config íŒŒì¼ ê¸°ë°˜ ì „ì²´ íŒŒì´í”„ë¼ì¸

```bash
# ==================== Config íŒŒì¼ ì‚¬ìš© ì „ì²´ íŒŒì´í”„ë¼ì¸ ==================== #

# ---------------------- all.yaml ì„¤ì • íŒŒì¼ í™œìš© ---------------------- #
# configs/models/all.yaml íŒŒì¼ì˜ ì•™ìƒë¸” ë©”íƒ€ ì„¤ì •ì„ í™œìš©
# ì£¼ì˜: --config ì˜µì…˜ìœ¼ë¡œ all.yamlì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì§€ì›ë˜ì§€ ì•ŠìŒ
# ëŒ€ì‹  --models all ì˜µì…˜ì´ ìë™ìœ¼ë¡œ 6ê°œ ëª¨ë¸ë¡œ í™•ì¥ë¨

# ---------------------- ê°œë³„ ëª¨ë¸ Config ì‚¬ìš© ---------------------- #
# íŠ¹ì • ëª¨ë¸ì˜ config íŒŒì¼ì„ ì‚¬ìš©í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸
python scripts/train.py \
  --mode full \
  --config configs/models/kobart.yaml \
  --epochs 15 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --use_augmentation \
  --augmentation_ratio 0.4 \
  --use_tta \
  --validate_data_quality \
  --no_wandb \
  --experiment_name full_config_based \
  --seed 42
```

**ì°¸ê³ :**
- `--models all` ì˜µì…˜ì€ ìë™ìœ¼ë¡œ 6ê°œ ëª¨ë¸(`kobart`, `llama-3.2-korean-3b`, `qwen3-4b`, `solar-10.7b`, `polyglot-ko-12.8b`, `kullm-v2`)ë¡œ í™•ì¥ë©ë‹ˆë‹¤
- ì‹¤í—˜ í´ë”ëª…ì€ ì²« ë²ˆì§¸ ëª¨ë¸ ì´ë¦„(`kobart`)ìœ¼ë¡œ ìƒì„±ë˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” 6ê°œ ëª¨ë¸ ëª¨ë‘ í•™ìŠµë©ë‹ˆë‹¤
- ëª…ì‹œì ìœ¼ë¡œ 6ê°œ ëª¨ë¸ì„ ë‚˜ì—´í•˜ë©´ ë™ì¼í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- `configs/models/all.yaml`ì€ ì•™ìƒë¸” ë©”íƒ€ ì„¤ì • íŒŒì¼ë¡œ, ê°œë³„ ëª¨ë¸ config íŒŒì¼ë“¤ì„ ì°¸ì¡°í•©ë‹ˆë‹¤

### 13.7 ë¹ ë¥¸ ì‹¤í—˜ (ë””ë²„ê·¸ ëª¨ë“œ)
```bash
# ==================== ë””ë²„ê·¸ ëª¨ë“œ ë¹ ë¥¸ ì‹¤í—˜ ==================== #

# ---------------------- ì½”ë“œ í…ŒìŠ¤íŠ¸ìš© ë¹ ë¥¸ ì‹¤í–‰ ---------------------- #
# ë””ë²„ê·¸ ëª¨ë“œë¡œ ìµœì†Œ ë°ì´í„°ì…‹ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ ì½”ë“œ ê²€ì¦
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --debug \
  --train_data data/raw/train.csv \
  --dev_data data/raw/dev.csv \
  --output_dir experiments/quick_test
```

### 13.8 ì¶”ë¡ ë§Œ (í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©)
```bash
# ==================== í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰ ==================== #

# ---------------------- ê¸°ë³¸ ì¶”ë¡  ---------------------- #
# í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì¶”ë¡  ìˆ˜í–‰
python scripts/inference.py \
  --model outputs/baseline_kobart/final_model \
  --test_data data/raw/test.csv \
  --output submissions/submission.csv \
  --batch_size 32 \
  --num_beams 4
```

---

## 14. ì˜µì…˜ ì¡°í•© ì „ëµ

### ìƒí™©ë³„ ê¶Œì¥ ì¡°í•©

#### ğŸš€ ë¹ ë¥¸ ì‹¤í—˜ (10ë¶„ ì´ë‚´)
```bash
# ==================== 10ë¶„ ì´ë‚´ ë¹ ë¥¸ ì‹¤í—˜ ==================== #

# ---------------------- ë””ë²„ê·¸ ëª¨ë“œ ìµœì†Œ ì‹¤í–‰ ---------------------- #
# KoBARTë¡œ 1 ì—í¬í¬ë§Œ í•™ìŠµí•˜ì—¬ ì½”ë“œ ê²€ì¦
--mode single --models kobart --epochs 1 --debug
```

#### ğŸ¯ ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ (1ì‹œê°„)
```bash
# ==================== 1ì‹œê°„ ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ ==================== #

# ---------------------- Solar ëª¨ë¸ + í’ˆì§ˆ ê²€ì¦ ---------------------- #
# Solar ëª¨ë¸ë¡œ 3 ì—í¬í¬ í•™ìŠµ + ë°ì´í„° í’ˆì§ˆ ê²€ì¦
--mode single --models solar-10.7b --epochs 3 --validate_data_quality
```

#### ğŸ”¬ ì„±ëŠ¥ ê·¹ëŒ€í™” (6ì‹œê°„)
```bash
# ==================== 6ì‹œê°„ ì„±ëŠ¥ ê·¹ëŒ€í™” ==================== #

# ---------------------- í’€ íŒŒì´í”„ë¼ì¸ + ì•™ìƒë¸” + TTA ---------------------- #
# ëª¨ë“  ëª¨ë¸ ì•™ìƒë¸” + ë°ì´í„° ì¦ê°• + TTAë¡œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±
--mode full --models all --epochs 5 --use_augmentation --ensemble_strategy stacking --use_tta
```

#### ğŸ† ìµœì¢… ì œì¶œ (12ì‹œê°„)
```bash
# ==================== 12ì‹œê°„ ìµœì¢… ì œì¶œ ==================== #

# ---------------------- ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ í†µí•© ---------------------- #
# ì „ì²´ íŒŒì´í”„ë¼ì¸ + ì•™ìƒë¸” + TTA + Solar API + ì¶”ë¡  ìµœì í™”
--mode full --models all --use_augmentation --ensemble_strategy stacking --use_tta --use_solar_api --optimize_inference
```

---

## 15. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ==================== GPU ë©”ëª¨ë¦¬ ë¶€ì¡± í•´ê²° ==================== #

# ---------------------- ë°°ì¹˜ í¬ê¸° ì¤„ì´ê³  Gradient Accumulation ---------------------- #
# ë°°ì¹˜ í¬ê¸°ë¥¼ 2ë¡œ ì¤„ì´ê³  4ë²ˆ ëˆ„ì í•˜ì—¬ íš¨ê³¼ì ìœ¼ë¡œ ë°°ì¹˜ 8 íš¨ê³¼
--batch_size 2 --gradient_accumulation_steps 4

# ---------------------- 4ë¹„íŠ¸ ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì ˆê° ---------------------- #
# INT4 ì–‘ìí™”ë¡œ ëª¨ë¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëŒ€í­ ê°ì†Œ
--optimization_method quantization --quantization_bits 4

# ---------------------- Gradient Checkpointing ---------------------- #
# Config íŒŒì¼ì—ì„œ gradient_checkpointing=True ì„¤ì •
# (ë©”ëª¨ë¦¬ ì ˆê°, ì†ë„ ì•½ê°„ ê°ì†Œ)
```

### í•™ìŠµ ì†ë„ ëŠë¦¼
```bash
# ==================== í•™ìŠµ ì†ë„ ê°œì„  ==================== #

# ---------------------- ë°°ì¹˜ í¬ê¸° ìë™ ìµœì í™” ---------------------- #
# GPU ë©”ëª¨ë¦¬ì— ë§ëŠ” ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ íƒìƒ‰
--use_batch_optimization

# ---------------------- Mixed Precision í•™ìŠµ ---------------------- #
# Config íŒŒì¼ì—ì„œ fp16=True ì„¤ì •
# (í•™ìŠµ ì†ë„ ì•½ 2ë°° í–¥ìƒ)

# ---------------------- DataLoader ë³‘ë ¬ ì²˜ë¦¬ ---------------------- #
# Config íŒŒì¼ì—ì„œ dataloader_num_workers=8 ì„¤ì •
# (ë°ì´í„° ë¡œë”© ë³‘ë ¬í™”ë¡œ ì†ë„ í–¥ìƒ)
```

### ROUGE ì ìˆ˜ ë‚®ìŒ
```bash
# ==================== ROUGE ì ìˆ˜ í–¥ìƒ ë°©ë²• ==================== #

# ---------------------- ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ ---------------------- #
# 50% ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ ê°œì„ 
--use_augmentation --augmentation_ratio 0.5

# ---------------------- Stacking ì•™ìƒë¸”ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™” ---------------------- #
# ì—¬ëŸ¬ ëª¨ë¸ì„ Stacking ì•™ìƒë¸”í•˜ì—¬ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±
--mode multi_model --ensemble_strategy stacking

# ---------------------- Optunaë¡œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ---------------------- #
# 100íšŒ ì‹œë„ë¡œ ìµœì  ì„¤ì • ìë™ íƒìƒ‰
--mode optuna --optuna_trials 100

# ---------------------- Solar APIë¡œ ê³ í’ˆì§ˆ í•™ìŠµ ë°ì´í„° ìƒì„± ---------------------- #
# Few-shot diverse ì „ëµìœ¼ë¡œ ë‹¤ì–‘í•œ ìš”ì•½ ìƒì„±
--use_solar_api --prompt_strategy few_shot_diverse
```

---

## 16. ìš”ì•½

### í•„ìˆ˜ ì˜µì…˜ (ëª¨ë“  ì‹¤í–‰ì— ê¶Œì¥)
```bash
# ==================== ê¸°ë³¸ í•„ìˆ˜ ì˜µì…˜ ==================== #

# ---------------------- ëª¨ë“  ì‹¤í–‰ì— í•„ìˆ˜ì¸ ê¸°ë³¸ ì˜µì…˜ ---------------------- #
# ì‹¤í–‰ ëª¨ë“œ, ëª¨ë¸, ì—í¬í¬, ë°°ì¹˜ í¬ê¸° ì§€ì •
python scripts/train.py \
  --mode [ì‹¤í–‰ëª¨ë“œ] \
  --models [ëª¨ë¸ëª…] \
  --epochs 3 \
  --batch_size 8
```

### ì„±ëŠ¥ í–¥ìƒ ì˜µì…˜
```bash
# ==================== ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì˜µì…˜ ==================== #

# ---------------------- ë°ì´í„° ì¦ê°• + ì•™ìƒë¸” + TTA ---------------------- #
# ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•œ 3ê°€ì§€ í•µì‹¬ ê¸°ë²•
--use_augmentation \
--ensemble_strategy stacking \
--use_tta
```

### í’ˆì§ˆ ë³´ì¥ ì˜µì…˜
```bash
# ==================== í’ˆì§ˆ ë³´ì¥ ì˜µì…˜ ==================== #

# ---------------------- ë°ì´í„° ê²€ì¦ + Solar API + Few-shot ---------------------- #
# ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ê³ í’ˆì§ˆ ìš”ì•½ ìƒì„±
--validate_data_quality \
--use_solar_api \
--prompt_strategy few_shot_diverse
```

### ìµœì í™” ì˜µì…˜
```bash
# ==================== ìµœì í™” ì˜µì…˜ ==================== #

# ---------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íƒìƒ‰ + ì¶”ë¡  ìµœì í™” ---------------------- #
# ìµœì  ì„¤ì • íƒìƒ‰ ë° ì¶”ë¡  ì†ë„ í–¥ìƒ
--mode optuna \
--optimize_inference
```

### ëª¨ë‹ˆí„°ë§ ì˜µì…˜
```bash
# ==================== ëª¨ë‹ˆí„°ë§ ë° ì‹œê°í™” ì˜µì…˜ ==================== #

# ---------------------- WandB ë¡œê¹… + ì‹œê°í™” ì €ì¥ ---------------------- #
# í•™ìŠµ ê³¼ì • ì¶”ì  ë° ê²°ê³¼ ì‹œê°í™” ìë™ ì €ì¥
--no_wandb \
--save_visualizations
```

---

## 17. ì°¸ê³  ìë£Œ

- **PRD ë¬¸ì„œ**: `docs/PRD/` í´ë”
- **ëª¨ë“ˆ ê°€ì´ë“œ**: `docs/ëª¨ë“ˆí™”/` í´ë”
- **Config ì˜ˆì‹œ**: `configs/` í´ë”
- **ì‹¤í—˜ ê²°ê³¼**: `experiments/` í´ë”

**ëª¨ë“  ì˜µì…˜ì€ `--help`ë¡œ í™•ì¸ ê°€ëŠ¥**:
```bash
# ==================== ë„ì›€ë§ í™•ì¸ ==================== #

# ---------------------- ì „ì²´ ì˜µì…˜ ëª©ë¡ í™•ì¸ ---------------------- #
# train.py ìŠ¤í¬ë¦½íŠ¸ì˜ ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ ë° ì„¤ëª… ì¶œë ¥
python scripts/train.py --help
```
