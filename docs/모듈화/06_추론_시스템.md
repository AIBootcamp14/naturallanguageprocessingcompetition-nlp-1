# 추론 시스템 상세 가이드

## 📋 목차
1. [개요](#개요)
2. [Predictor 클래스](#predictor-클래스)
3. [사용 방법](#사용-방법)
4. [생성 파라미터](#생성-파라미터)
5. [제출 파일 생성](#제출-파일-생성)

---

## 📝 개요

### 목적
- 학습된 모델로 대화 요약 예측
- 배치 추론 및 진행 표시
- 제출 파일 자동 생성
- 생성 파라미터 유연한 설정

### 핵심 기능
- ✅ 단일/배치 추론 지원
- ✅ DataFrame 직접 처리
- ✅ 제출 파일 자동 생성
- ✅ 생성 파라미터 오버라이드
- ✅ Logger 통합 지원

---

## 🏗️ Predictor 클래스

### 파일 위치
```
src/inference/predictor.py
```

### 클래스 구조

```python
class Predictor:
    def __init__(self, model, tokenizer, config=None, device=None, logger=None):
        """추론 시스템 초기화"""

    def _setup_generation_config(self) -> Dict:
        """생성 파라미터 설정"""

    def predict_single(self, dialogue: str, **generation_kwargs) -> str:
        """단일 대화 요약 예측"""

    def predict_batch(self, dialogues: List[str], batch_size=32,
                     show_progress=True, **generation_kwargs) -> List[str]:
        """배치 대화 요약 예측"""

    def predict_dataframe(self, df: pd.DataFrame, batch_size=32,
                          show_progress=True, **generation_kwargs) -> pd.DataFrame:
        """DataFrame에 대해 예측 수행"""

    def create_submission(self, test_df: pd.DataFrame, output_path: str,
                         batch_size=32, show_progress=True, **generation_kwargs) -> pd.DataFrame:
        """제출 파일 생성"""
```

---

## 💻 사용 방법

### 1. 기본 사용법 (단일 예측)

```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from src.inference import create_predictor

# 모델 및 토크나이저 로드
model = AutoModelForSeq2SeqLM.from_pretrained("outputs/baseline_kobart/final_model")
tokenizer = AutoTokenizer.from_pretrained("outputs/baseline_kobart/final_model")

# Predictor 생성
predictor = create_predictor(model, tokenizer)

# 단일 예측
dialogue = "#Person1#: 안녕하세요 #Person2#: 네 안녕하세요"
summary = predictor.predict_single(dialogue)

print(f"예측 요약: {summary}")
```

### 2. 배치 예측

```python
dialogues = [
    "#Person1#: 저녁 뭐 먹을까? #Person2#: 김치찌개 어때?",
    "#Person1#: 내일 회의 몇 시야? #Person2#: 3시로 잡혔어",
    "#Person1#: 날씨 좋네 #Person2#: 산책 가자"
]

# 배치 예측
summaries = predictor.predict_batch(
    dialogues,
    batch_size=32,
    show_progress=True
)

for dialogue, summary in zip(dialogues, summaries):
    print(f"대화: {dialogue}")
    print(f"요약: {summary}\n")
```

### 3. DataFrame 예측

```python
import pandas as pd

# 테스트 데이터 로드
test_df = pd.read_csv("data/raw/test.csv")

# DataFrame 예측
result_df = predictor.predict_dataframe(
    test_df,
    batch_size=32,
    show_progress=True
)

# 결과 확인
print(result_df[['fname', 'dialogue', 'summary']].head())
```

### 4. 제출 파일 생성

```python
# 제출 파일 자동 생성
submission_df = predictor.create_submission(
    test_df=test_df,
    output_path="submissions/submission.csv",
    batch_size=32,
    show_progress=True
)

print(f"제출 파일 생성 완료: submissions/submission.csv")
print(f"샘플 수: {len(submission_df)}")
```

---

## ⚙️ 생성 파라미터

### 기본 생성 파라미터

```python
default_config = {
    'max_length': 100,              # 최대 생성 길이
    'num_beams': 4,                 # Beam search 빔 개수
    'early_stopping': True,         # EOS 토큰 생성 시 조기 종료
    'no_repeat_ngram_size': 2,      # n-gram 반복 방지
    'length_penalty': 1.0,          # 길이 페널티
}
```

### Config에서 자동 로드

```yaml
# configs/experiments/baseline_kobart.yaml
inference:
  generate_max_length: 100
  num_beams: 4
  early_stopping: true
  no_repeat_ngram_size: 2
  length_penalty: 1.0
```

### 런타임 오버라이드

```python
# Config 값 무시하고 파라미터 지정
summaries = predictor.predict_batch(
    dialogues,
    batch_size=16,
    num_beams=8,            # 오버라이드
    max_length=150,         # 오버라이드
    temperature=0.8         # 추가 파라미터
)
```

### 주요 생성 파라미터 설명

| 파라미터 | 기본값 | 설명 |
|---------|-------|------|
| `max_length` | 100 | 생성할 최대 토큰 수 |
| `num_beams` | 4 | Beam search 빔 개수 (높을수록 품질↑, 속도↓) |
| `early_stopping` | True | EOS 토큰 생성 시 즉시 종료 |
| `no_repeat_ngram_size` | 2 | n-gram 반복 방지 크기 |
| `length_penalty` | 1.0 | 길이 페널티 (>1: 긴 문장 선호, <1: 짧은 문장 선호) |
| `temperature` | 1.0 | 샘플링 온도 (낮을수록 결정적, 높을수록 다양) |
| `top_k` | 50 | Top-k 샘플링 |
| `top_p` | 1.0 | Nucleus 샘플링 |

---

## 📊 제출 파일 생성

### 기본 사용법

```python
import pandas as pd
from src.inference import create_predictor

# 모델 로드
model = AutoModelForSeq2SeqLM.from_pretrained("outputs/baseline_kobart/final_model")
tokenizer = AutoTokenizer.from_pretrained("outputs/baseline_kobart/final_model")

# Predictor 생성
predictor = create_predictor(model, tokenizer)

# 테스트 데이터 로드
test_df = pd.read_csv("data/raw/test.csv")

# 제출 파일 생성
submission_df = predictor.create_submission(
    test_df=test_df,
    output_path="submissions/submission.csv",
    batch_size=32,
    show_progress=True
)
```

### Logger와 함께 사용

```python
from src.logging.logger import Logger
from src.utils.core.common import create_log_path

# Logger 초기화
log_path = create_log_path("inference", "inference.log")
logger = Logger(log_path, print_also=True)
logger.start_redirect()

try:
    # Predictor 생성 (Logger 전달)
    predictor = create_predictor(model, tokenizer, logger=logger)

    # 제출 파일 생성
    submission_df = predictor.create_submission(
        test_df=test_df,
        output_path="submissions/submission.csv",
        batch_size=32,
        show_progress=True
    )

finally:
    logger.stop_redirect()
    logger.close()
```

### 출력 예시

```
============================================================
제출 파일 생성 시작
============================================================

샘플 수: 2500
Predicting: 100%|██████████| 79/79 [02:15<00:00,  1.71s/it]

✅ 제출 파일 저장 완료: submissions/submission.csv
============================================================
```

### 제출 파일 형식

```csv
fname,summary
test_001,두 사람이 저녁 약속을 잡았다
test_002,회의 시간을 3시로 정했다
test_003,내일 점심 메뉴는 김치찌개다
...
```

---

## 🧪 테스트

### 테스트 파일 위치
```
src/tests/test_predictor.py
```

### 테스트 실행

```bash
python src/tests/test_predictor.py
```

### 테스트 항목 (총 4개)

1. ✅ Predictor 생성
2. ✅ 생성 파라미터 설정
3. ✅ 단일 예측
4. ✅ 편의 함수 (create_predictor)

---

## 🎯 실전 활용 예시

### 예시 1: 여러 체크포인트 비교

```python
checkpoints = [
    "outputs/baseline_kobart/checkpoint-500",
    "outputs/baseline_kobart/checkpoint-1000",
    "outputs/baseline_kobart/final_model"
]

for checkpoint_path in checkpoints:
    # 모델 로드
    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)
    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)

    # 예측
    predictor = create_predictor(model, tokenizer)
    submission_df = predictor.create_submission(
        test_df=test_df,
        output_path=f"submissions/{Path(checkpoint_path).name}.csv",
        batch_size=32
    )

    print(f"✅ {checkpoint_path} 완료")
```

### 예시 2: 다양한 생성 파라미터 실험

```python
params_list = [
    {"num_beams": 4, "max_length": 100},
    {"num_beams": 8, "max_length": 100},
    {"num_beams": 4, "max_length": 150},
]

for i, params in enumerate(params_list):
    summaries = predictor.predict_batch(
        dialogues,
        **params
    )

    print(f"\n파라미터 세트 {i+1}: {params}")
    print(f"예측 예시: {summaries[0]}")
```

### 예시 3: 샘플별 품질 확인

```python
# 예측 생성
test_df = pd.read_csv("data/raw/test.csv")
result_df = predictor.predict_dataframe(test_df)

# 요약 길이 분포 확인
result_df['summary_length'] = result_df['summary'].str.len()

print("요약 길이 통계:")
print(result_df['summary_length'].describe())

# 긴 요약 샘플 확인
long_summaries = result_df[result_df['summary_length'] > 200]
print(f"\n긴 요약 (>200자): {len(long_summaries)}개")
print(long_summaries[['fname', 'summary', 'summary_length']].head())

# 짧은 요약 샘플 확인
short_summaries = result_df[result_df['summary_length'] < 20]
print(f"\n짧은 요약 (<20자): {len(short_summaries)}개")
print(short_summaries[['fname', 'summary', 'summary_length']].head())
```

---

## 📌 주의사항

### 1. GPU 메모리 관리

배치 크기가 크면 GPU 메모리 부족 발생 가능:

```python
# GPU 메모리 부족 시 배치 크기 줄이기
predictor.create_submission(
    test_df=test_df,
    output_path="submissions/submission.csv",
    batch_size=16  # 32 → 16
)
```

### 2. 토크나이저 일치

학습 시 사용한 토크나이저와 동일한 토크나이저를 사용해야 합니다:

```python
# ✅ 올바른 방법
tokenizer = AutoTokenizer.from_pretrained("outputs/baseline_kobart/final_model")

# ❌ 잘못된 방법
tokenizer = AutoTokenizer.from_pretrained("digit82/kobart-summarization")  # 학습 시와 다름
```

### 3. 진행 표시 비활성화

자동화 스크립트에서는 진행 표시를 비활성화:

```python
summaries = predictor.predict_batch(
    dialogues,
    batch_size=32,
    show_progress=False  # 진행 표시 끄기
)
```

---

## 🔗 관련 파일

**소스 코드:**
- `src/inference/predictor.py` - Predictor 클래스
- `src/inference/__init__.py` - 외부 API

**테스트:**
- `src/tests/test_predictor.py` - 단위 테스트

**스크립트:**
- `scripts/inference.py` - 추론 실행 스크립트
- `scripts/run_pipeline.py` - 전체 파이프라인 (학습 + 추론)
