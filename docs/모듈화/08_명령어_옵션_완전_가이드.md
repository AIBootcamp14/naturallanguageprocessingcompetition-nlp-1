# ëª…ë ¹ì–´ ì˜µì…˜ ì™„ì „ ê°€ì´ë“œ

> **PRD 14: ì‹¤í–‰ ì˜µì…˜ ì‹œìŠ¤í…œ** - ëª¨ë“  PRD ê¸°ëŠ¥ì„ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œ](#1-ê¸°ë³¸-ì‹¤í–‰-ëª¨ë“œ)
2. [ëª¨ë¸ ì„ íƒ](#2-ëª¨ë¸-ì„ íƒ)
3. [í•™ìŠµ ì„¤ì •](#3-í•™ìŠµ-ì„¤ì •)
4. [K-Fold êµì°¨ê²€ì¦](#4-k-fold-êµì°¨ê²€ì¦)
5. [ì•™ìƒë¸” ì „ëµ](#5-ì•™ìƒë¸”-ì „ëµ)
6. [Optuna ìµœì í™”](#6-optuna-ìµœì í™”)
7. [ë°ì´í„° ì¦ê°•](#7-ë°ì´í„°-ì¦ê°•)
8. [Solar API](#8-solar-api)
9. [í”„ë¡¬í”„íŠ¸ ì „ëµ](#9-í”„ë¡¬í”„íŠ¸-ì „ëµ)
10. [ë°ì´í„° í’ˆì§ˆ ê²€ì¦](#10-ë°ì´í„°-í’ˆì§ˆ-ê²€ì¦)
11. [ì¶”ë¡  ìµœì í™”](#11-ì¶”ë¡ -ìµœì í™”)
12. [ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§](#12-ë¡œê¹…-ë°-ëª¨ë‹ˆí„°ë§)
13. [ì‹¤ì „ ì˜ˆì‹œ](#13-ì‹¤ì „-ì˜ˆì‹œ)

---

## 1. ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œ

### `--mode` (ì‹¤í–‰ ëª¨ë“œ ì„ íƒ)

**PRD**: 14ë²ˆ - ì‹¤í–‰ ì˜µì…˜ ì‹œìŠ¤í…œ

| ëª¨ë“œ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|---------------|
| `single` | ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ | ë¹ ë¥¸ ì‹¤í—˜, ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ |
| `kfold` | K-Fold êµì°¨ ê²€ì¦ | ëª¨ë¸ ì•ˆì •ì„± í‰ê°€ |
| `multi_model` | ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” | ì„±ëŠ¥ í–¥ìƒ, ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ |
| `optuna` | í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” | ìµœì  ì„¤ì • íƒìƒ‰ |
| `full` | ì „ì²´ íŒŒì´í”„ë¼ì¸ | ìµœì¢… ì œì¶œ, ëª¨ë“  ê¸°ëŠ¥ í†µí•© |

```bash
# ë‹¨ì¼ ëª¨ë¸ (ê¸°ë³¸ê°’)
python scripts/train.py --mode single

# ì „ì²´ íŒŒì´í”„ë¼ì¸
python scripts/train.py --mode full
```

---

## 2. ëª¨ë¸ ì„ íƒ

### `--models` (ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ)

**PRD**: 05-07ë²ˆ - ëª¨ë¸ ì‹œìŠ¤í…œ

| ëª¨ë¸ëª… | ì„¤ëª… | ê¶Œì¥ ìš©ë„ |
|--------|------|-----------|
| `kobart` | í•œêµ­ì–´ BART | ë¹ ë¥¸ ì‹¤í—˜, ë² ì´ìŠ¤ë¼ì¸ |
| `solar-10.7b` | Upstage Solar LLM | ê³ í’ˆì§ˆ ìš”ì•½, ìµœì¢… ì œì¶œ |
| `polyglot-ko-12.8b` | ëŒ€ê·œëª¨ í•œêµ­ì–´ ëª¨ë¸ | ë†’ì€ ì„±ëŠ¥ |
| `llama-3.2-korean-3b` | Llama í•œêµ­ì–´ ë²„ì „ | ê· í˜•ì¡íŒ ì„±ëŠ¥ |
| `qwen3-4b` | Qwen ëª¨ë¸ | íš¨ìœ¨ì  í•™ìŠµ |
| `kullm-v2` | ê³ ë ¤ëŒ€ LLM | í•œêµ­ì–´ íŠ¹í™” |
| `all` | ëª¨ë“  ëª¨ë¸ | ì•™ìƒë¸”, í’€ íŒŒì´í”„ë¼ì¸ |

```bash
# ë‹¨ì¼ ëª¨ë¸
python scripts/train.py --models kobart

# ë‹¤ì¤‘ ëª¨ë¸ (ì•™ìƒë¸”)
python scripts/train.py --mode multi_model --models kobart solar-10.7b

# ëª¨ë“  ëª¨ë¸
python scripts/train.py --mode full --models all
```

---

## 3. í•™ìŠµ ì„¤ì •

### ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

**PRD**: 06ë²ˆ - ê¸°ìˆ  ìš”êµ¬ì‚¬í•­

#### `--epochs` (í•™ìŠµ ì—í¬í¬ ìˆ˜)
```bash
# ë¹ ë¥¸ ì‹¤í—˜
python scripts/train.py --epochs 1

# ì •ìƒ í•™ìŠµ
python scripts/train.py --epochs 3

# ê¸´ í•™ìŠµ
python scripts/train.py --epochs 10
```

#### `--batch_size` (ë°°ì¹˜ í¬ê¸°)
```bash
# GPU ë©”ëª¨ë¦¬ ì‘ì„ ë•Œ
python scripts/train.py --batch_size 4

# ê· í˜•ì¡íŒ ì„¤ì •
python scripts/train.py --batch_size 8

# í° GPU
python scripts/train.py --batch_size 16
```

#### `--learning_rate` (í•™ìŠµë¥ )
```bash
# ì‘ì€ ëª¨ë¸
python scripts/train.py --learning_rate 5e-5

# LLM
python scripts/train.py --learning_rate 1e-5

# ë¯¸ì„¸ ì¡°ì •
python scripts/train.py --learning_rate 1e-6
```

---

## 4. K-Fold êµì°¨ê²€ì¦

**PRD**: 10ë²ˆ - êµì°¨ ê²€ì¦ ì‹œìŠ¤í…œ

### `--k_folds` (Fold ìˆ˜)
```bash
# 3-Fold (ë¹ ë¦„)
python scripts/train.py --mode kfold --k_folds 3

# 5-Fold (í‘œì¤€)
python scripts/train.py --mode kfold --k_folds 5

# 10-Fold (ì•ˆì •ì )
python scripts/train.py --mode kfold --k_folds 10
```

### `--fold_seed` (ì¬í˜„ì„± ë³´ì¥)
```bash
python scripts/train.py --mode kfold --fold_seed 42
```

**ì™„ì „í•œ ì˜ˆì‹œ**:
```bash
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8
```

---

## 5. ì•™ìƒë¸” ì „ëµ

**PRD**: 12ë²ˆ - ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì „ëµ

### `--ensemble_strategy` (ì•™ìƒë¸” ë°©ë²•)

| ì „ëµ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|---------------|
| `averaging` | ë‹¨ìˆœ í‰ê·  | ë¹ ë¥¸ ì‹¤í—˜ |
| `weighted_avg` | ê°€ì¤‘ í‰ê·  | ì„±ëŠ¥ ê¸°ë°˜ ì¡°í•© |
| `majority_vote` | íˆ¬í‘œ | ë‹¤ì–‘ì„± í™•ë³´ |
| `stacking` | ë©”íƒ€ í•™ìŠµê¸° | ìµœê³  ì„±ëŠ¥ |
| `blending` | Validation ê¸°ë°˜ | ê³¼ì í•© ë°©ì§€ |
| `rouge_weighted` | ROUGE ê¸°ë°˜ ê°€ì¤‘ì¹˜ | ìë™ ìµœì í™” |

```bash
# ê°€ì¤‘ í‰ê· 
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg

# Stacking (ìµœê³  ì„±ëŠ¥)
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking

# Blending (Validation ê¸°ë°˜)
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy blending
```

### `--ensemble_weights` (ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì§€ì •)
```bash
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.3 0.7
```

### TTA (Test Time Augmentation)

**PRD**: 12ë²ˆ - TTA ì „ëµ

#### `--use_tta` (TTA í™œì„±í™”)
```bash
python scripts/train.py --mode full --use_tta
```

#### `--tta_strategies` (TTA ë°©ë²•)
```bash
python scripts/train.py \
  --mode full \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 5
```

---

## 6. Optuna ìµœì í™”

**PRD**: 13ë²ˆ - Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

### `--optuna_trials` (ì‹œë„ íšŸìˆ˜)
```bash
# ë¹ ë¥¸ íƒìƒ‰
python scripts/train.py --mode optuna --optuna_trials 20

# ì •ë°€ íƒìƒ‰
python scripts/train.py --mode optuna --optuna_trials 100

# ì² ì €í•œ íƒìƒ‰
python scripts/train.py --mode optuna --optuna_trials 500
```

### `--optuna_timeout` (ì œí•œ ì‹œê°„)
```bash
# 1ì‹œê°„
python scripts/train.py --mode optuna --optuna_timeout 3600

# 2ì‹œê°„
python scripts/train.py --mode optuna --optuna_timeout 7200
```

### `--optuna_sampler` (ìƒ˜í”ŒëŸ¬ ì„ íƒ)
```bash
# TPE (ê¸°ë³¸, ê¶Œì¥)
python scripts/train.py --mode optuna --optuna_sampler tpe

# Random
python scripts/train.py --mode optuna --optuna_sampler random

# GP
python scripts/train.py --mode optuna --optuna_sampler gp
```

### `--optuna_pruner` (ê°€ì§€ì¹˜ê¸° ì „ëµ)
```bash
# Median (ê¸°ë³¸)
python scripts/train.py --mode optuna --optuna_pruner median

# Percentile
python scripts/train.py --mode optuna --optuna_pruner percentile

# Hyperband
python scripts/train.py --mode optuna --optuna_pruner hyperband
```

**ì™„ì „í•œ ì˜ˆì‹œ**:
```bash
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

**íƒìƒ‰ë˜ëŠ” 15ê°œ íŒŒë¼ë¯¸í„°**:
- **í•™ìŠµ íŒŒë¼ë¯¸í„° (7ê°œ)**: learning_rate, batch_size, gradient_accumulation_steps, warmup_ratio, weight_decay, max_grad_norm, label_smoothing
- **ìƒì„± íŒŒë¼ë¯¸í„° (8ê°œ)**: num_beams, temperature, top_p, top_k, repetition_penalty, length_penalty, no_repeat_ngram_size, early_stopping_patience

---

## 7. ë°ì´í„° ì¦ê°•

**PRD**: 04ë²ˆ - ì„±ëŠ¥ ê°œì„  ì „ëµ (ë°ì´í„° ì¦ê°•)

### `--use_augmentation` (ë°ì´í„° ì¦ê°• í™œì„±í™”)
```bash
python scripts/train.py --use_augmentation
```

### `--augmentation_methods` (ì¦ê°• ë°©ë²•)

| ë°©ë²• | ì„¤ëª… | íš¨ê³¼ |
|------|------|------|
| `back_translation` | ì—­ë²ˆì—­ (í•œâ†’ì˜â†’í•œ) | ë‹¤ì–‘í•œ í‘œí˜„ |
| `paraphrase` | ì˜ì—­ | ë¬¸ì¥ êµ¬ì¡° ë³€í™” |
| `synonym` | ë™ì˜ì–´ ì¹˜í™˜ | ì–´íœ˜ ë‹¤ì–‘ì„± |
| `turn_shuffle` | ëŒ€í™” ìˆœì„œ ì„ê¸° | ìˆœì„œ ë¶ˆë³€ì„± |

```bash
# ì—­ë²ˆì—­ë§Œ
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation

# ì—¬ëŸ¬ ë°©ë²• ì¡°í•©
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.5
```

### `--augmentation_ratio` (ì¦ê°• ë¹„ìœ¨)
```bash
# 30% ì¦ê°•
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.3

# 50% ì¦ê°•
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.5
```

---

## 8. Solar API

**PRD**: 09ë²ˆ - Solar API ìµœì í™”

### `--use_solar_api` (Solar API í™œì„±í™”)
```bash
python scripts/train.py --use_solar_api
```

### `--solar_api_key` (API í‚¤ ì§€ì •)
```bash
# ì§ì ‘ ì§€ì •
python scripts/train.py \
  --use_solar_api \
  --solar_api_key "your-api-key-here"

# í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© (ê¶Œì¥)
export SOLAR_API_KEY="your-api-key"
python scripts/train.py --use_solar_api
```

### `--solar_model` (Solar ëª¨ë¸ ì„ íƒ)
```bash
# Mini (ë¹ ë¦„)
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-mini-chat

# Full (ê³ í’ˆì§ˆ)
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-chat
```

**ì™„ì „í•œ ì˜ˆì‹œ**:
```bash
export SOLAR_API_KEY="your-api-key"
python scripts/train.py \
  --mode full \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard
```

---

## 9. í”„ë¡¬í”„íŠ¸ ì „ëµ

**PRD**: 15ë²ˆ - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì „ëµ

### `--prompt_strategy` (í”„ë¡¬í”„íŠ¸ ì„ íƒ)

| ì „ëµ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|---------------|
| `zero_shot_simple` | ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ | ë¹ ë¥¸ ì‹¤í—˜ |
| `zero_shot_detailed` | ìƒì„¸ ì§€ì‹œ | ëª…í™•í•œ ê°€ì´ë“œ í•„ìš” |
| `few_shot_standard` | 2ê°œ ì˜ˆì‹œ | í‘œì¤€ ì„±ëŠ¥ |
| `few_shot_diverse` | 3ê°œ ë‹¤ì–‘í•œ ì˜ˆì‹œ | ë‹¤ì–‘ì„± í™•ë³´ |
| `chain_of_thought` | ë‹¨ê³„ë³„ ì¶”ë¡  | ë³µì¡í•œ ìš”ì•½ |
| `role_playing` | ì—­í•  ê¸°ë°˜ | ì „ë¬¸ì  ìš”ì•½ |
| `self_consistency` | ë‹¤ì¤‘ ìƒì„± + íˆ¬í‘œ | ì•ˆì •ì  ê²°ê³¼ |

```bash
# Few-shot (í‘œì¤€)
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy few_shot_standard

# Chain-of-Thought (ê³ í’ˆì§ˆ)
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy chain_of_thought

# Self-consistency (ìµœê³  ì•ˆì •ì„±)
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy self_consistency
```

---

## 10. ë°ì´í„° í’ˆì§ˆ ê²€ì¦

**PRD**: 16ë²ˆ - ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ

### `--validate_data_quality` (í’ˆì§ˆ ê²€ì¦ í™œì„±í™”)
```bash
python scripts/train.py --validate_data_quality
```

### `--quality_threshold` (í’ˆì§ˆ ì„ê³„ê°’)
```bash
# ì—„ê²©í•œ ê¸°ì¤€
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.8

# í‘œì¤€ ê¸°ì¤€
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.7

# ëŠìŠ¨í•œ ê¸°ì¤€
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.6
```

**ê²€ì¦ í•­ëª©**:
- êµ¬ì¡° ê²€ì¦ (ì»¬ëŸ¼, NULL, ê³µë°±)
- ì¤‘ë³µ ê²€ì¦
- í†µê³„ ê²€ì¦ (ê¸¸ì´ ë¶„í¬)
- ì´ìƒì¹˜ íƒì§€ (Z-score)
- Solar API êµì°¨ ê²€ì¦

---

## 11. ì¶”ë¡  ìµœì í™”

**PRD**: 17ë²ˆ - ì¶”ë¡  ìµœì í™” ì „ëµ

### `--optimize_inference` (ì¶”ë¡  ìµœì í™” í™œì„±í™”)
```bash
python scripts/train.py --optimize_inference
```

### `--optimization_method` (ìµœì í™” ë°©ë²•)

| ë°©ë²• | ì„¤ëª… | ì†ë„ í–¥ìƒ | ë©”ëª¨ë¦¬ ì ˆê° |
|------|------|-----------|-------------|
| `quantization` | ì–‘ìí™” | 2-3x | 50-75% |
| `onnx` | ONNX ë³€í™˜ | 1.5-2x | 10-20% |
| `tensorrt` | TensorRT ê°€ì† | 3-5x | 20-30% |
| `pruning` | ê°€ì§€ì¹˜ê¸° | 1.5-2x | 30-50% |

```bash
# INT8 ì–‘ìí™”
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8

# FP16 ì–‘ìí™”
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 16

# ONNX ë³€í™˜
python scripts/train.py \
  --optimize_inference \
  --optimization_method onnx \
  --use_onnx

# TensorRT (GPU ì „ìš©)
python scripts/train.py \
  --optimize_inference \
  --optimization_method tensorrt

# Pruning (ê²½ëŸ‰í™”)
python scripts/train.py \
  --optimize_inference \
  --optimization_method pruning
```

### `--quantization_bits` (ì–‘ìí™” ë¹„íŠ¸)
```bash
# INT4 (ìµœëŒ€ ì••ì¶•)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 4

# INT8 (ê· í˜•)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 8

# FP16 (ê³ í’ˆì§ˆ)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 16
```

### `--use_batch_optimization` (ë°°ì¹˜ ìµœì í™”)
```bash
python scripts/train.py \
  --optimize_inference \
  --use_batch_optimization
```

---

## 12. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

**PRD**: 11ë²ˆ - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### `--use_wandb` (WandB í™œì„±í™”)
```bash
python scripts/train.py --use_wandb
```

### `--wandb_project` (í”„ë¡œì íŠ¸ëª…)
```bash
python scripts/train.py \
  --use_wandb \
  --wandb_project dialogue-summarization
```

### `--save_visualizations` (ì‹œê°í™” ì €ì¥)
```bash
python scripts/train.py --save_visualizations
```

**ìë™ ë¡œê¹…ë˜ëŠ” í•­ëª© (PRD 11)**:
- Learning rate ìŠ¤ì¼€ì¤„
- Gradient norms (ë ˆì´ì–´ë³„)
- Loss curve (train/val)
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- í•™ìŠµ ì†ë„ (samples/sec)
- ROUGE ì ìˆ˜ ë³€í™”
- Confusion matrix
- ì˜ˆì¸¡ ìƒ˜í”Œ

---

## 13. ì‹¤ì „ ì˜ˆì‹œ

### 13.1 ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦
```bash
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --batch_size 8 \
  --debug
```

### 13.2 ê³ í’ˆì§ˆ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ
```bash
python scripts/train.py \
  --mode single \
  --models solar-10.7b \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --validate_data_quality \
  --use_wandb
```

### 13.3 K-Fold êµì°¨ ê²€ì¦
```bash
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8 \
  --use_wandb \
  --save_visualizations
```

### 13.4 ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” (Stacking)
```bash
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking \
  --epochs 3 \
  --batch_size 4 \
  --use_augmentation \
  --use_wandb
```

### 13.5 Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
```bash
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

### 13.6 ì „ì²´ íŒŒì´í”„ë¼ì¸ (ìµœì¢… ì œì¶œ)
```bash
export SOLAR_API_KEY="your-api-key"

python scripts/train.py \
  --mode full \
  --models all \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.3 \
  \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_diverse \
  \
  --validate_data_quality \
  --quality_threshold 0.7 \
  \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8 \
  \
  --use_wandb \
  --wandb_project final-submission \
  --save_visualizations \
  \
  --experiment_name final_run_v1
```

### 13.7 ë¹ ë¥¸ ì‹¤í—˜ (ë””ë²„ê·¸ ëª¨ë“œ)
```bash
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --debug \
  --train_data data/raw/train.csv \
  --dev_data data/raw/dev.csv \
  --output_dir experiments/quick_test
```

### 13.8 ì¶”ë¡ ë§Œ (í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©)
```bash
python scripts/predict.py \
  --model_path experiments/best_model \
  --test_data data/raw/test.csv \
  --output_path submissions/submission.csv \
  \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8 \
  --use_batch_optimization \
  \
  --max_length 200 \
  --num_beams 4 \
  --batch_size 32
```

---

## 14. ì˜µì…˜ ì¡°í•© ì „ëµ

### ìƒí™©ë³„ ê¶Œì¥ ì¡°í•©

#### ğŸš€ ë¹ ë¥¸ ì‹¤í—˜ (10ë¶„ ì´ë‚´)
```bash
--mode single --models kobart --epochs 1 --debug
```

#### ğŸ¯ ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ (1ì‹œê°„)
```bash
--mode single --models solar-10.7b --epochs 3 --validate_data_quality
```

#### ğŸ”¬ ì„±ëŠ¥ ê·¹ëŒ€í™” (6ì‹œê°„)
```bash
--mode full --models all --epochs 5 --use_augmentation --ensemble_strategy stacking --use_tta
```

#### ğŸ† ìµœì¢… ì œì¶œ (12ì‹œê°„)
```bash
--mode full --models all --use_augmentation --ensemble_strategy stacking --use_tta --use_solar_api --optimize_inference --use_wandb
```

---

## 15. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
--batch_size 2 --gradient_accumulation_steps 4

# ëª¨ë¸ ì–‘ìí™”
--optimization_method quantization --quantization_bits 4

# Gradient checkpointing
# (Config íŒŒì¼ì—ì„œ ì„¤ì •)
```

### í•™ìŠµ ì†ë„ ëŠë¦¼
```bash
# ë°°ì¹˜ ìµœì í™”
--use_batch_optimization

# Mixed precision
# (Config íŒŒì¼ì—ì„œ fp16=True)

# DataLoader workers
# (Config íŒŒì¼ì—ì„œ dataloader_num_workers=8)
```

### ROUGE ì ìˆ˜ ë‚®ìŒ
```bash
# ë°ì´í„° ì¦ê°•
--use_augmentation --augmentation_ratio 0.5

# ì•™ìƒë¸”
--mode multi_model --ensemble_strategy stacking

# Optuna ìµœì í™”
--mode optuna --optuna_trials 100

# Solar API í™œìš©
--use_solar_api --prompt_strategy few_shot_diverse
```

---

## 16. ìš”ì•½

### í•„ìˆ˜ ì˜µì…˜ (ëª¨ë“  ì‹¤í–‰ì— ê¶Œì¥)
```bash
python scripts/train.py \
  --mode [ì‹¤í–‰ëª¨ë“œ] \
  --models [ëª¨ë¸ëª…] \
  --epochs 3 \
  --batch_size 8
```

### ì„±ëŠ¥ í–¥ìƒ ì˜µì…˜
```bash
--use_augmentation \
--ensemble_strategy stacking \
--use_tta
```

### í’ˆì§ˆ ë³´ì¥ ì˜µì…˜
```bash
--validate_data_quality \
--use_solar_api \
--prompt_strategy few_shot_diverse
```

### ìµœì í™” ì˜µì…˜
```bash
--mode optuna \
--optimize_inference
```

### ëª¨ë‹ˆí„°ë§ ì˜µì…˜
```bash
--use_wandb \
--save_visualizations
```

---

## 17. ì°¸ê³  ìë£Œ

- **PRD ë¬¸ì„œ**: `docs/PRD/` í´ë”
- **ëª¨ë“ˆ ê°€ì´ë“œ**: `docs/ëª¨ë“ˆí™”/` í´ë”
- **Config ì˜ˆì‹œ**: `configs/` í´ë”
- **ì‹¤í—˜ ê²°ê³¼**: `experiments/` í´ë”

**ëª¨ë“  ì˜µì…˜ì€ `--help`ë¡œ í™•ì¸ ê°€ëŠ¥**:
```bash
python scripts/train.py --help
```

---

**ğŸ“Œ ì´ ê°€ì´ë“œëŠ” 19ê°œ PRDì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•˜ëŠ” ì™„ì „í•œ ë ˆí¼ëŸ°ìŠ¤ì…ë‹ˆë‹¤.**
