# 명령어 옵션 완전 가이드

> **PRD 14: 실행 옵션 시스템** - 모든 PRD 기능을 명령어로 실행하는 완전한 가이드

## 📋 목차

1. [기본 실행 모드](#1-기본-실행-모드)
2. [모델 선택](#2-모델-선택)
3. [학습 설정](#3-학습-설정)
4. [K-Fold 교차검증](#4-k-fold-교차검증)
5. [앙상블 전략](#5-앙상블-전략)
6. [Optuna 최적화](#6-optuna-최적화)
7. [데이터 증강](#7-데이터-증강)
8. [Solar API](#8-solar-api)
9. [프롬프트 전략](#9-프롬프트-전략)
10. [데이터 품질 검증](#10-데이터-품질-검증)
11. [추론 최적화](#11-추론-최적화)
12. [로깅 및 모니터링](#12-로깅-및-모니터링)
13. [실전 예시](#13-실전-예시)

---

## 1. 기본 실행 모드

### `--mode` (실행 모드 선택)

**PRD**: 14번 - 실행 옵션 시스템

| 모드 | 설명 | 사용 시나리오 |
|------|------|---------------|
| `single` | 단일 모델 학습 | 빠른 실험, 베이스라인 검증 |
| `kfold` | K-Fold 교차 검증 | 모델 안정성 평가 |
| `multi_model` | 다중 모델 앙상블 | 성능 향상, 여러 모델 비교 |
| `optuna` | 하이퍼파라미터 최적화 | 최적 설정 탐색 |
| `full` | 전체 파이프라인 | 최종 제출, 모든 기능 통합 |

```bash
# 단일 모델 (기본값)
python scripts/train.py --mode single

# 전체 파이프라인
python scripts/train.py --mode full
```

---

## 2. 모델 선택

### `--models` (사용할 모델 선택)

**PRD**: 05-07번 - 모델 시스템

| 모델명 | 설명 | 권장 용도 |
|--------|------|-----------|
| `kobart` | 한국어 BART | 빠른 실험, 베이스라인 |
| `solar-10.7b` | Upstage Solar LLM | 고품질 요약, 최종 제출 |
| `polyglot-ko-12.8b` | 대규모 한국어 모델 | 높은 성능 |
| `llama-3.2-korean-3b` | Llama 한국어 버전 | 균형잡힌 성능 |
| `qwen3-4b` | Qwen 모델 | 효율적 학습 |
| `kullm-v2` | 고려대 LLM | 한국어 특화 |
| `all` | 모든 모델 | 앙상블, 풀 파이프라인 |

```bash
# 단일 모델
python scripts/train.py --models kobart

# 다중 모델 (앙상블)
python scripts/train.py --mode multi_model --models kobart solar-10.7b

# 모든 모델
python scripts/train.py --mode full --models all
```

---

## 3. 학습 설정

### 기본 하이퍼파라미터

**PRD**: 06번 - 기술 요구사항

#### `--epochs` (학습 에포크 수)
```bash
# 빠른 실험
python scripts/train.py --epochs 1

# 정상 학습
python scripts/train.py --epochs 3

# 긴 학습
python scripts/train.py --epochs 10
```

#### `--batch_size` (배치 크기)
```bash
# GPU 메모리 작을 때
python scripts/train.py --batch_size 4

# 균형잡힌 설정
python scripts/train.py --batch_size 8

# 큰 GPU
python scripts/train.py --batch_size 16
```

#### `--learning_rate` (학습률)
```bash
# 작은 모델
python scripts/train.py --learning_rate 5e-5

# LLM
python scripts/train.py --learning_rate 1e-5

# 미세 조정
python scripts/train.py --learning_rate 1e-6
```

---

## 4. K-Fold 교차검증

**PRD**: 10번 - 교차 검증 시스템

### `--k_folds` (Fold 수)
```bash
# 3-Fold (빠름)
python scripts/train.py --mode kfold --k_folds 3

# 5-Fold (표준)
python scripts/train.py --mode kfold --k_folds 5

# 10-Fold (안정적)
python scripts/train.py --mode kfold --k_folds 10
```

### `--fold_seed` (재현성 보장)
```bash
python scripts/train.py --mode kfold --fold_seed 42
```

**완전한 예시**:
```bash
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8
```

---

## 5. 앙상블 전략

**PRD**: 12번 - 다중 모델 앙상블 전략

### `--ensemble_strategy` (앙상블 방법)

| 전략 | 설명 | 사용 시나리오 |
|------|------|---------------|
| `averaging` | 단순 평균 | 빠른 실험 |
| `weighted_avg` | 가중 평균 | 성능 기반 조합 |
| `majority_vote` | 투표 | 다양성 확보 |
| `stacking` | 메타 학습기 | 최고 성능 |
| `blending` | Validation 기반 | 과적합 방지 |
| `rouge_weighted` | ROUGE 기반 가중치 | 자동 최적화 |

```bash
# 가중 평균
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg

# Stacking (최고 성능)
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking

# Blending (Validation 기반)
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy blending
```

### `--ensemble_weights` (수동 가중치 지정)
```bash
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.3 0.7
```

### TTA (Test Time Augmentation)

**PRD**: 12번 - TTA 전략

#### `--use_tta` (TTA 활성화)
```bash
python scripts/train.py --mode full --use_tta
```

#### `--tta_strategies` (TTA 방법)
```bash
python scripts/train.py \
  --mode full \
  --use_tta \
  --tta_strategies paraphrase reorder synonym \
  --tta_num_aug 5
```

---

## 6. Optuna 최적화

**PRD**: 13번 - Optuna 하이퍼파라미터 최적화

### `--optuna_trials` (시도 횟수)
```bash
# 빠른 탐색
python scripts/train.py --mode optuna --optuna_trials 20

# 정밀 탐색
python scripts/train.py --mode optuna --optuna_trials 100

# 철저한 탐색
python scripts/train.py --mode optuna --optuna_trials 500
```

### `--optuna_timeout` (제한 시간)
```bash
# 1시간
python scripts/train.py --mode optuna --optuna_timeout 3600

# 2시간
python scripts/train.py --mode optuna --optuna_timeout 7200
```

### `--optuna_sampler` (샘플러 선택)
```bash
# TPE (기본, 권장)
python scripts/train.py --mode optuna --optuna_sampler tpe

# Random
python scripts/train.py --mode optuna --optuna_sampler random

# GP
python scripts/train.py --mode optuna --optuna_sampler gp
```

### `--optuna_pruner` (가지치기 전략)
```bash
# Median (기본)
python scripts/train.py --mode optuna --optuna_pruner median

# Percentile
python scripts/train.py --mode optuna --optuna_pruner percentile

# Hyperband
python scripts/train.py --mode optuna --optuna_pruner hyperband
```

**완전한 예시**:
```bash
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

**탐색되는 15개 파라미터**:
- **학습 파라미터 (7개)**: learning_rate, batch_size, gradient_accumulation_steps, warmup_ratio, weight_decay, max_grad_norm, label_smoothing
- **생성 파라미터 (8개)**: num_beams, temperature, top_p, top_k, repetition_penalty, length_penalty, no_repeat_ngram_size, early_stopping_patience

---

## 7. 데이터 증강

**PRD**: 04번 - 성능 개선 전략 (데이터 증강)

### `--use_augmentation` (데이터 증강 활성화)
```bash
python scripts/train.py --use_augmentation
```

### `--augmentation_methods` (증강 방법)

| 방법 | 설명 | 효과 |
|------|------|------|
| `back_translation` | 역번역 (한→영→한) | 다양한 표현 |
| `paraphrase` | 의역 | 문장 구조 변화 |
| `synonym` | 동의어 치환 | 어휘 다양성 |
| `turn_shuffle` | 대화 순서 섞기 | 순서 불변성 |

```bash
# 역번역만
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation

# 여러 방법 조합
python scripts/train.py \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.5
```

### `--augmentation_ratio` (증강 비율)
```bash
# 30% 증강
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.3

# 50% 증강
python scripts/train.py \
  --use_augmentation \
  --augmentation_ratio 0.5
```

---

## 8. Solar API

**PRD**: 09번 - Solar API 최적화

### `--use_solar_api` (Solar API 활성화)
```bash
python scripts/train.py --use_solar_api
```

### `--solar_api_key` (API 키 지정)
```bash
# 직접 지정
python scripts/train.py \
  --use_solar_api \
  --solar_api_key "your-api-key-here"

# 환경변수 사용 (권장)
export SOLAR_API_KEY="your-api-key"
python scripts/train.py --use_solar_api
```

### `--solar_model` (Solar 모델 선택)
```bash
# Mini (빠름)
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-mini-chat

# Full (고품질)
python scripts/train.py \
  --use_solar_api \
  --solar_model solar-1-chat
```

**완전한 예시**:
```bash
export SOLAR_API_KEY="your-api-key"
python scripts/train.py \
  --mode full \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_standard
```

---

## 9. 프롬프트 전략

**PRD**: 15번 - 프롬프트 엔지니어링 전략

### `--prompt_strategy` (프롬프트 선택)

| 전략 | 설명 | 사용 시나리오 |
|------|------|---------------|
| `zero_shot_simple` | 기본 프롬프트 | 빠른 실험 |
| `zero_shot_detailed` | 상세 지시 | 명확한 가이드 필요 |
| `few_shot_standard` | 2개 예시 | 표준 성능 |
| `few_shot_diverse` | 3개 다양한 예시 | 다양성 확보 |
| `chain_of_thought` | 단계별 추론 | 복잡한 요약 |
| `role_playing` | 역할 기반 | 전문적 요약 |
| `self_consistency` | 다중 생성 + 투표 | 안정적 결과 |

```bash
# Few-shot (표준)
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy few_shot_standard

# Chain-of-Thought (고품질)
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy chain_of_thought

# Self-consistency (최고 안정성)
python scripts/train.py \
  --use_solar_api \
  --prompt_strategy self_consistency
```

---

## 10. 데이터 품질 검증

**PRD**: 16번 - 데이터 품질 검증 시스템

### `--validate_data_quality` (품질 검증 활성화)
```bash
python scripts/train.py --validate_data_quality
```

### `--quality_threshold` (품질 임계값)
```bash
# 엄격한 기준
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.8

# 표준 기준
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.7

# 느슨한 기준
python scripts/train.py \
  --validate_data_quality \
  --quality_threshold 0.6
```

**검증 항목**:
- 구조 검증 (컬럼, NULL, 공백)
- 중복 검증
- 통계 검증 (길이 분포)
- 이상치 탐지 (Z-score)
- Solar API 교차 검증

---

## 11. 추론 최적화

**PRD**: 17번 - 추론 최적화 전략

### `--optimize_inference` (추론 최적화 활성화)
```bash
python scripts/train.py --optimize_inference
```

### `--optimization_method` (최적화 방법)

| 방법 | 설명 | 속도 향상 | 메모리 절감 |
|------|------|-----------|-------------|
| `quantization` | 양자화 | 2-3x | 50-75% |
| `onnx` | ONNX 변환 | 1.5-2x | 10-20% |
| `tensorrt` | TensorRT 가속 | 3-5x | 20-30% |
| `pruning` | 가지치기 | 1.5-2x | 30-50% |

```bash
# INT8 양자화
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8

# FP16 양자화
python scripts/train.py \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 16

# ONNX 변환
python scripts/train.py \
  --optimize_inference \
  --optimization_method onnx \
  --use_onnx

# TensorRT (GPU 전용)
python scripts/train.py \
  --optimize_inference \
  --optimization_method tensorrt

# Pruning (경량화)
python scripts/train.py \
  --optimize_inference \
  --optimization_method pruning
```

### `--quantization_bits` (양자화 비트)
```bash
# INT4 (최대 압축)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 4

# INT8 (균형)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 8

# FP16 (고품질)
python scripts/train.py \
  --optimize_inference \
  --quantization_bits 16
```

### `--use_batch_optimization` (배치 최적화)
```bash
python scripts/train.py \
  --optimize_inference \
  --use_batch_optimization
```

---

## 12. 로깅 및 모니터링

**PRD**: 11번 - 로깅 및 모니터링 시스템

### `--use_wandb` (WandB 활성화)
```bash
python scripts/train.py --use_wandb
```

### `--wandb_project` (프로젝트명)
```bash
python scripts/train.py \
  --use_wandb \
  --wandb_project dialogue-summarization
```

### `--save_visualizations` (시각화 저장)
```bash
python scripts/train.py --save_visualizations
```

**자동 로깅되는 항목 (PRD 11)**:
- Learning rate 스케줄
- Gradient norms (레이어별)
- Loss curve (train/val)
- GPU 메모리 사용량
- 학습 속도 (samples/sec)
- ROUGE 점수 변화
- Confusion matrix
- 예측 샘플

---

## 13. 실전 예시

### 13.1 빠른 베이스라인 검증
```bash
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --batch_size 8 \
  --debug
```

### 13.2 고품질 단일 모델 학습
```bash
python scripts/train.py \
  --mode single \
  --models solar-10.7b \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --validate_data_quality \
  --use_wandb
```

### 13.3 K-Fold 교차 검증
```bash
python scripts/train.py \
  --mode kfold \
  --models solar-10.7b \
  --k_folds 5 \
  --fold_seed 42 \
  --epochs 3 \
  --batch_size 8 \
  --use_wandb \
  --save_visualizations
```

### 13.4 다중 모델 앙상블 (Stacking)
```bash
python scripts/train.py \
  --mode multi_model \
  --models kobart solar-10.7b polyglot-ko-12.8b \
  --ensemble_strategy stacking \
  --epochs 3 \
  --batch_size 4 \
  --use_augmentation \
  --use_wandb
```

### 13.5 Optuna 하이퍼파라미터 최적화
```bash
python scripts/train.py \
  --mode optuna \
  --models solar-10.7b \
  --optuna_trials 100 \
  --optuna_timeout 7200 \
  --optuna_sampler tpe \
  --optuna_pruner median \
  --save_visualizations
```

### 13.6 전체 파이프라인 (최종 제출)
```bash
export SOLAR_API_KEY="your-api-key"

python scripts/train.py \
  --mode full \
  --models all \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 1e-5 \
  \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase synonym \
  --augmentation_ratio 0.3 \
  \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --prompt_strategy few_shot_diverse \
  \
  --validate_data_quality \
  --quality_threshold 0.7 \
  \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8 \
  \
  --use_wandb \
  --wandb_project final-submission \
  --save_visualizations \
  \
  --experiment_name final_run_v1
```

### 13.7 빠른 실험 (디버그 모드)
```bash
python scripts/train.py \
  --mode single \
  --models kobart \
  --epochs 1 \
  --debug \
  --train_data data/raw/train.csv \
  --dev_data data/raw/dev.csv \
  --output_dir experiments/quick_test
```

### 13.8 추론만 (학습된 모델 사용)
```bash
python scripts/predict.py \
  --model_path experiments/best_model \
  --test_data data/raw/test.csv \
  --output_path submissions/submission.csv \
  \
  --optimize_inference \
  --optimization_method quantization \
  --quantization_bits 8 \
  --use_batch_optimization \
  \
  --max_length 200 \
  --num_beams 4 \
  --batch_size 32
```

---

## 14. 옵션 조합 전략

### 상황별 권장 조합

#### 🚀 빠른 실험 (10분 이내)
```bash
--mode single --models kobart --epochs 1 --debug
```

#### 🎯 베이스라인 검증 (1시간)
```bash
--mode single --models solar-10.7b --epochs 3 --validate_data_quality
```

#### 🔬 성능 극대화 (6시간)
```bash
--mode full --models all --epochs 5 --use_augmentation --ensemble_strategy stacking --use_tta
```

#### 🏆 최종 제출 (12시간)
```bash
--mode full --models all --use_augmentation --ensemble_strategy stacking --use_tta --use_solar_api --optimize_inference --use_wandb
```

---

## 15. 트러블슈팅

### GPU 메모리 부족
```bash
# 배치 크기 줄이기
--batch_size 2 --gradient_accumulation_steps 4

# 모델 양자화
--optimization_method quantization --quantization_bits 4

# Gradient checkpointing
# (Config 파일에서 설정)
```

### 학습 속도 느림
```bash
# 배치 최적화
--use_batch_optimization

# Mixed precision
# (Config 파일에서 fp16=True)

# DataLoader workers
# (Config 파일에서 dataloader_num_workers=8)
```

### ROUGE 점수 낮음
```bash
# 데이터 증강
--use_augmentation --augmentation_ratio 0.5

# 앙상블
--mode multi_model --ensemble_strategy stacking

# Optuna 최적화
--mode optuna --optuna_trials 100

# Solar API 활용
--use_solar_api --prompt_strategy few_shot_diverse
```

---

## 16. 요약

### 필수 옵션 (모든 실행에 권장)
```bash
python scripts/train.py \
  --mode [실행모드] \
  --models [모델명] \
  --epochs 3 \
  --batch_size 8
```

### 성능 향상 옵션
```bash
--use_augmentation \
--ensemble_strategy stacking \
--use_tta
```

### 품질 보장 옵션
```bash
--validate_data_quality \
--use_solar_api \
--prompt_strategy few_shot_diverse
```

### 최적화 옵션
```bash
--mode optuna \
--optimize_inference
```

### 모니터링 옵션
```bash
--use_wandb \
--save_visualizations
```

---

## 17. 참고 자료

- **PRD 문서**: `docs/PRD/` 폴더
- **모듈 가이드**: `docs/모듈화/` 폴더
- **Config 예시**: `configs/` 폴더
- **실험 결과**: `experiments/` 폴더

**모든 옵션은 `--help`로 확인 가능**:
```bash
python scripts/train.py --help
```

---

**📌 이 가이드는 19개 PRD의 모든 기능을 명령어로 실행하는 완전한 레퍼런스입니다.**
