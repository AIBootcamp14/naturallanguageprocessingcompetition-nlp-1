# Config ì‹œìŠ¤í…œ ìƒì„¸ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [Config êµ¬ì¡°](#config-êµ¬ì¡°)
3. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
4. [Config íŒŒì¼ ì‘ì„±](#config-íŒŒì¼-ì‘ì„±)
5. [í…ŒìŠ¤íŠ¸ ê²°ê³¼](#í…ŒìŠ¤íŠ¸-ê²°ê³¼)

---

## ğŸ“ ê°œìš”

### ëª©ì 
- ì‹¤í—˜ ì„¤ì •ì˜ ì²´ê³„ì  ê´€ë¦¬
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ í™˜ê²½
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²„ì „ ê´€ë¦¬
- ë‹¤ì–‘í•œ ì‹¤í—˜ ì„¤ì •ì˜ ë¹ ë¥¸ ì „í™˜

### í•µì‹¬ ê¸°ëŠ¥
- âœ… ê³„ì¸µì  YAML ë³‘í•©
- âœ… ì‹¤í—˜ë³„ Config ì˜¤ë²„ë¼ì´ë“œ
- âœ… OmegaConf ê¸°ë°˜ íƒ€ì… ì•ˆì „ì„±
- âœ… ëˆ„ë½ëœ íŒŒì¼ ìë™ ì²˜ë¦¬

---

## ğŸ—ï¸ Config êµ¬ì¡°

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
configs/
â”œâ”€â”€ base/                           # ê¸°ë³¸ ì„¤ì •
â”‚   â”œâ”€â”€ default.yaml               # ì „ì²´ ê¸°ë³¸ê°’
â”‚   â””â”€â”€ encoder_decoder.yaml       # ëª¨ë¸ íƒ€ì…ë³„ ê¸°ë³¸ê°’
â”‚
â”œâ”€â”€ models/                         # ëª¨ë¸ë³„ ì„¤ì •
â”‚   â”œâ”€â”€ kobart.yaml                # KoBART ì„¤ì •
â”‚   â”œâ”€â”€ t5.yaml                    # T5 ì„¤ì • (ì˜ˆì‹œ)
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ experiments/                    # ì‹¤í—˜ë³„ ì„¤ì •
    â”œâ”€â”€ baseline_kobart.yaml       # ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜
    â”œâ”€â”€ finetuned_kobart.yaml      # íŒŒì¸íŠœë‹ ì‹¤í—˜ (ì˜ˆì‹œ)
    â””â”€â”€ ...
```

### Config ë³‘í•© í”Œë¡œìš°

```mermaid
graph TD
    A[ì‹¤í—˜ ì‹œì‘] --> B{ì‹¤í—˜ ì´ë¦„ ì§€ì •}
    B --> C[1. base/default.yaml ë¡œë“œ]
    C --> D[2. base/encoder_decoder.yaml ë¡œë“œ]
    D --> E[3. models/kobart.yaml ë¡œë“œ]
    E --> F[4. experiments/baseline_kobart.yaml ë¡œë“œ]

    F --> G[OmegaConfë¡œ ë³‘í•©]
    G --> H[ìµœì¢… í†µí•© Config]

    H --> I[í•™ìŠµ/ì¶”ë¡  ì‹œìŠ¤í…œìœ¼ë¡œ ì „ë‹¬]

    style C fill:#e3f2fd
    style D fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5
    style H fill:#c8e6c9
```

### ë³‘í•© ìš°ì„ ìˆœìœ„

**ë‚®ìŒ â†’ ë†’ìŒ ìˆœì„œ:**
1. `base/default.yaml` - ì „ì²´ ê¸°ë³¸ ì„¤ì •
2. `base/encoder_decoder.yaml` - ëª¨ë¸ íƒ€ì… ì„¤ì •
3. `models/{model_name}.yaml` - íŠ¹ì • ëª¨ë¸ ì„¤ì •
4. `experiments/{experiment_name}.yaml` - **ì‹¤í—˜ ì„¤ì • (ìµœìš°ì„ )**

**ì˜ˆì‹œ:**
```yaml
# base/default.yaml
training:
  batch_size: 8
  learning_rate: 5e-5
  epochs: 10

# experiments/baseline_kobart.yaml
training:
  batch_size: 50        # ì˜¤ë²„ë¼ì´ë“œ
  learning_rate: 1e-5   # ì˜¤ë²„ë¼ì´ë“œ
  # epochs: 10ì€ default ê°’ ì‚¬ìš©
```

**ë³‘í•© ê²°ê³¼:**
```yaml
training:
  batch_size: 50        # experimentsì—ì„œ ì˜¤ë²„ë¼ì´ë“œ
  learning_rate: 1e-5   # experimentsì—ì„œ ì˜¤ë²„ë¼ì´ë“œ
  epochs: 10            # default ê°’ ìœ ì§€
```

---

## ğŸ’» ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from src.config import load_config

# ì‹¤í—˜ ì´ë¦„ìœ¼ë¡œ Config ë¡œë“œ
config = load_config("baseline_kobart")

# Config ê°’ ì ‘ê·¼
print(config.training.batch_size)     # 50
print(config.model.checkpoint)        # "digit82/kobart-summarization"
print(config.experiment.name)         # "baseline_kobart"
```

### 2. Config ê°’ í™•ì¸

```python
from omegaconf import OmegaConf

# Config ì „ì²´ ì¶œë ¥
print(OmegaConf.to_yaml(config))

# íŠ¹ì • ì„¹ì…˜ë§Œ ì¶œë ¥
print(OmegaConf.to_yaml(config.training))
print(OmegaConf.to_yaml(config.model))
```

### 3. Config ê°’ ìˆ˜ì • (ëŸ°íƒ€ì„)

```python
# ê°’ ë³€ê²½
config.training.batch_size = 32
config.training.learning_rate = 2e-5

# ìƒˆë¡œìš´ í‚¤ ì¶”ê°€
config.custom_param = "value"
```

### 4. ConfigLoader ì§ì ‘ ì‚¬ìš©

```python
from src.config import ConfigLoader

# ConfigLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
loader = ConfigLoader(config_dir="configs")

# ìˆ˜ë™ìœ¼ë¡œ ë³‘í•©
config = loader.merge_configs("baseline_kobart")

# íŠ¹ì • íŒŒì¼ë§Œ ë¡œë“œ
base_config = loader.load_base_config()
model_config = loader.load_model_config("kobart")
```

---

## ğŸ“„ Config íŒŒì¼ ì‘ì„±

### base/default.yaml êµ¬ì¡°

```yaml
# ==================== ê¸°ë³¸ ì„¤ì • ==================== #

# ì‹¤í—˜ ì •ë³´
experiment:
  name: "default"
  seed: 42
  deterministic: true

# ê²½ë¡œ ì„¤ì •
paths:
  train_data: "data/raw/train.csv"
  dev_data: "data/raw/dev.csv"
  test_data: "data/raw/test.csv"
  output_dir: "outputs"

# í•™ìŠµ ì„¤ì •
training:
  output_dir: "outputs"
  epochs: 10
  batch_size: 8
  learning_rate: 5e-5
  device: "cuda"

# í‰ê°€ ì„¤ì •
evaluation:
  metric: "rouge"
  rouge_types:
    - "rouge1"
    - "rouge2"
    - "rougeL"
```

### base/encoder_decoder.yaml êµ¬ì¡°

```yaml
# ==================== Encoder-Decoder ê³µí†µ ì„¤ì • ==================== #

model:
  type: "encoder_decoder"
  architecture: "bart"

# í† í¬ë‚˜ì´ì € ì„¤ì •
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 100
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    # ... ì¶”ê°€ íŠ¹ìˆ˜ í† í°

# ì¶”ë¡  ì„¤ì •
inference:
  batch_size: 32
  num_beams: 4
  early_stopping: true
  generate_max_length: 100
  no_repeat_ngram_size: 2
```

### models/kobart.yaml êµ¬ì¡°

```yaml
# ==================== KoBART ëª¨ë¸ ì„¤ì • ==================== #

model:
  name: "kobart"
  checkpoint: "digit82/kobart-summarization"

# KoBART íŠ¹í™” ì„¤ì •
# (í•„ìš”ì‹œ ì¶”ê°€)
```

### experiments/baseline_kobart.yaml êµ¬ì¡°

```yaml
# ==================== ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜ ì„¤ì • ==================== #

experiment:
  name: "baseline_kobart"
  description: "ëŒ€íšŒ ë² ì´ìŠ¤ë¼ì¸ ì¬í˜„ ì‹¤í—˜"
  tags:
    - "baseline"
    - "kobart"

# WandB ì„¤ì •
wandb:
  enabled: true
  project: "nlp-competition"
  entity: "ieyeppo"

# ëª¨ë¸ ì„¤ì •
model:
  name: "kobart"

# í•™ìŠµ ì„¤ì • (ë² ì´ìŠ¤ë¼ì¸ ì˜¤ë²„ë¼ì´ë“œ)
training:
  epochs: 20
  batch_size: 50
  learning_rate: 1e-5

# ê²½ë¡œ ì„¤ì •
paths:
  output_dir: "outputs/baseline_kobart"
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼

### í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source ~/.pyenv/versions/nlp_py3_11_9/bin/activate

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python tests/test_config_loader.py
```

### í…ŒìŠ¤íŠ¸ í•­ëª© (ì´ 6ê°œ)

#### 1. âœ… ê¸°ë³¸ Config ë¡œë“œ
```python
def test_load_base_config():
    """base/default.yaml ë¡œë“œ í™•ì¸"""
    loader = ConfigLoader()
    config = loader.load_base_config()

    assert config.experiment.seed == 42
    assert config.paths.train_data == "data/raw/train.csv"
```

**ê²°ê³¼:**
```
âœ… ê¸°ë³¸ Config ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!
  experiment.seed: 42
  paths.train_data: data/raw/train.csv
```

#### 2. âœ… ëª¨ë¸ íƒ€ì… Config ë¡œë“œ
```python
def test_load_model_type_config():
    """base/encoder_decoder.yaml ë¡œë“œ í™•ì¸"""
    loader = ConfigLoader()
    config = loader.load_model_type_config("encoder_decoder")

    assert config.model.type == "encoder_decoder"
    assert config.tokenizer.encoder_max_len == 512
```

**ê²°ê³¼:**
```
âœ… ëª¨ë¸ íƒ€ì… Config ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!
  model.type: encoder_decoder
  tokenizer.encoder_max_len: 512
```

#### 3. âœ… ëª¨ë¸ë³„ Config ë¡œë“œ
```python
def test_load_model_config():
    """models/kobart.yaml ë¡œë“œ í™•ì¸"""
    loader = ConfigLoader()
    config = loader.load_model_config("kobart")

    assert config.model.name == "kobart"
    assert "digit82" in config.model.checkpoint
```

**ê²°ê³¼:**
```
âœ… ëª¨ë¸ë³„ Config ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!
  model.name: kobart
  model.checkpoint: digit82/kobart-summarization
```

#### 4. âœ… ì‹¤í—˜ Config ë¡œë“œ
```python
def test_load_experiment_config():
    """experiments/baseline_kobart.yaml ë¡œë“œ í™•ì¸"""
    loader = ConfigLoader()
    config = loader.load_experiment_config("baseline_kobart")

    assert config.experiment.name == "baseline_kobart"
    assert config.wandb.enabled == True
```

**ê²°ê³¼:**
```
âœ… ì‹¤í—˜ Config ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!
  experiment.name: baseline_kobart
  wandb.enabled: True
```

#### 5. âœ… ê³„ì¸µì  Config ë³‘í•©
```python
def test_merge_configs():
    """ì „ì²´ Config ë³‘í•© í™•ì¸"""
    loader = ConfigLoader()
    config = loader.merge_configs("baseline_kobart")

    # ë³‘í•© ìš°ì„ ìˆœìœ„ í™•ì¸
    assert config.training.batch_size == 50      # experimentì—ì„œ ì˜¤ë²„ë¼ì´ë“œ
    assert config.training.epochs == 20          # experimentì—ì„œ ì˜¤ë²„ë¼ì´ë“œ
    assert config.tokenizer.encoder_max_len == 512  # base ê°’ ìœ ì§€
```

**ê²°ê³¼:**
```
âœ… ê³„ì¸µì  Config ë³‘í•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!
  training.batch_size: 50 (ì˜¤ë²„ë¼ì´ë“œë¨)
  training.epochs: 20 (ì˜¤ë²„ë¼ì´ë“œë¨)
  tokenizer.encoder_max_len: 512 (base ê°’ ìœ ì§€)
```

#### 6. âœ… í¸ì˜ í•¨ìˆ˜
```python
def test_load_config_function():
    """load_config() í¸ì˜ í•¨ìˆ˜ í™•ì¸"""
    config = load_config("baseline_kobart")

    assert config.experiment.name == "baseline_kobart"
    assert config.model.checkpoint is not None
```

**ê²°ê³¼:**
```
âœ… í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ!
  Config ë¡œë“œ ì™„ë£Œ
  ëª¨ë“  ì„¹ì…˜ ì ‘ê·¼ ê°€ëŠ¥
```

### ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½

```
============================================================
Config Loader í…ŒìŠ¤íŠ¸ ì‹œì‘
============================================================

í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ Config ë¡œë“œ                    âœ… í†µê³¼
í…ŒìŠ¤íŠ¸ 2: ëª¨ë¸ íƒ€ì… Config ë¡œë“œ                âœ… í†µê³¼
í…ŒìŠ¤íŠ¸ 3: ëª¨ë¸ë³„ Config ë¡œë“œ                   âœ… í†µê³¼
í…ŒìŠ¤íŠ¸ 4: ì‹¤í—˜ Config ë¡œë“œ                     âœ… í†µê³¼
í…ŒìŠ¤íŠ¸ 5: ê³„ì¸µì  Config ë³‘í•©                   âœ… í†µê³¼
í…ŒìŠ¤íŠ¸ 6: í¸ì˜ í•¨ìˆ˜                           âœ… í†µê³¼

============================================================
ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! (6/6)
============================================================
```

---

## ğŸ¯ ì‹¤ì „ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ìƒˆë¡œìš´ ì‹¤í—˜ ì„¤ì • ì¶”ê°€

```yaml
# configs/experiments/finetuned_kobart.yaml
experiment:
  name: "finetuned_kobart_v2"
  description: "íŒŒì¸íŠœë‹ ì‹¤í—˜ ë²„ì „ 2"
  tags:
    - "finetuned"
    - "v2"

training:
  epochs: 30                    # ë” ê¸´ í•™ìŠµ
  batch_size: 32                # ì‘ì€ ë°°ì¹˜
  learning_rate: 5e-6           # ë‚®ì€ í•™ìŠµë¥ 
  warmup_steps: 1000            # ë” ê¸´ warmup

paths:
  output_dir: "outputs/finetuned_v2"
```

**ì‚¬ìš©:**
```python
config = load_config("finetuned_kobart_v2")
```

### ì˜ˆì‹œ 2: ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •

```yaml
# configs/experiments/debug.yaml
experiment:
  name: "debug"

debug:
  use_subset: true
  subset_size: 100              # 100ê°œ ìƒ˜í”Œë§Œ ì‚¬ìš©

training:
  epochs: 2                     # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
  batch_size: 4

wandb:
  enabled: false                # WandB ë¹„í™œì„±í™”
```

### ì˜ˆì‹œ 3: ëŸ°íƒ€ì„ì—ì„œ Config ìˆ˜ì •

```python
config = load_config("baseline_kobart")

# GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
config.training.batch_size = 16

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì—í¬í¬ ì¤„ì´ê¸°
config.training.epochs = 5

# WandB ë¹„í™œì„±í™”
config.wandb.enabled = False

# ìˆ˜ì •ëœ Configë¡œ í•™ìŠµ ì§„í–‰
trainer = create_trainer(config, ...)
```

---

## ğŸ“Œ ì£¼ì˜ì‚¬í•­

### 1. YAML ë¬¸ë²•
- ë“¤ì—¬ì“°ê¸°ëŠ” **ê³µë°± 2ì¹¸** ì‚¬ìš© (íƒ­ ì‚¬ìš© ê¸ˆì§€)
- ë¬¸ìì—´ì— íŠ¹ìˆ˜ë¬¸ì í¬í•¨ ì‹œ ë”°ì˜´í‘œ ì‚¬ìš©
- ë¦¬ìŠ¤íŠ¸ëŠ” `-` ì‚¬ìš©

### 2. íŒŒì¼ëª… ê·œì¹™
- `experiments/` í´ë”ì˜ YAML íŒŒì¼ëª… = ì‹¤í—˜ ì´ë¦„
- ì˜ˆ: `baseline_kobart.yaml` â†’ `load_config("baseline_kobart")`

### 3. Config ê°’ ì ‘ê·¼
```python
# âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼
config.training.batch_size

# âŒ ì˜ëª»ëœ ì ‘ê·¼ (Key Error ë°œìƒ ê°€ëŠ¥)
config['training']['batch_size']

# âœ… ì•ˆì „í•œ ì ‘ê·¼ (ê¸°ë³¸ê°’ ì œê³µ)
config.get('training', {}).get('batch_size', 32)
```

### 4. ëˆ„ë½ëœ Config ì²˜ë¦¬
- ConfigLoaderëŠ” ëˆ„ë½ëœ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ê±´ë„ˆëœ€
- í•„ìˆ˜ ì„¤ì •ì€ `base/default.yaml`ì— ì •ì˜ ê¶Œì¥

---

## ğŸ”— ê´€ë ¨ íŒŒì¼

**ì†ŒìŠ¤ ì½”ë“œ:**
- `src/config/loader.py` - ConfigLoader í´ë˜ìŠ¤
- `src/config/__init__.py` - ì™¸ë¶€ API

**ì„¤ì • íŒŒì¼:**
- `configs/base/default.yaml` - ê¸°ë³¸ ì„¤ì •
- `configs/base/encoder_decoder.yaml` - ëª¨ë¸ íƒ€ì… ì„¤ì •
- `configs/models/kobart.yaml` - KoBART ì„¤ì •
- `configs/experiments/baseline_kobart.yaml` - ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜

**í…ŒìŠ¤íŠ¸:**
- `tests/test_config_loader.py` - Config Loader í…ŒìŠ¤íŠ¸

---

**ì‘ì„±ì¼:** 2025-10-11
**ë²„ì „:** 1.0.0
