# ì‹¤í—˜ ë¶„ì„ ë³´ê³ ì„œ: ì‚¼ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì „ëµ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)

> **ì‹¤í—˜ ID**: 20251013_161056_test_strategy3_triple
> **ì‹¤í–‰ ì¼ì‹œ**: 2025-10-13 16:10:56
> **ì‹¤í–‰ ëª¨ë“œ**: FULL Pipeline (ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ)
> **ì‹¤í—˜ ìƒíƒœ**: ğŸ”„ ì§„í–‰ ì¤‘ (3ê°œ ëª¨ë¸ ì¤‘ 2ê°œ ì™„ë£Œ, 1ê°œ ì§„í–‰ ì¤‘)

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹¤í—˜ ê°œìš”](#1-ì‹¤í—˜-ê°œìš”)
2. [ì‹¤í—˜ ì„¤ì •](#2-ì‹¤í—˜-ì„¤ì •)
3. [í•™ìŠµ ì§€í‘œ ìƒì„¸ ì„¤ëª…](#3-í•™ìŠµ-ì§€í‘œ-ìƒì„¸-ì„¤ëª…)
4. [ëª¨ë¸ë³„ í•™ìŠµ ê²°ê³¼ ë¶„ì„](#4-ëª¨ë¸ë³„-í•™ìŠµ-ê²°ê³¼-ë¶„ì„)
5. [ëª¨ë¸ ê°„ ì„±ëŠ¥ ë¹„êµ](#5-ëª¨ë¸-ê°„-ì„±ëŠ¥-ë¹„êµ)
6. [ì£¼ìš” ë°œê²¬ ë° ì¸ì‚¬ì´íŠ¸](#6-ì£¼ìš”-ë°œê²¬-ë°-ì¸ì‚¬ì´íŠ¸)
7. [ë¬¸ì œì  ë° ê°œì„  ë°©í–¥](#7-ë¬¸ì œì -ë°-ê°œì„ -ë°©í–¥)
8. [ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­](#8-ê²°ë¡ -ë°-ê¶Œì¥ì‚¬í•­)
9. [ë¶€ë¡: ìƒì„¸ ë¡œê·¸ ë°ì´í„°](#9-ë¶€ë¡-ìƒì„¸-ë¡œê·¸-ë°ì´í„°)

---

## 1. ì‹¤í—˜ ê°œìš”

### 1.1 ì‹¤í—˜ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph Input["ì…ë ¥ ê³„ì¸µ"]
        A[3ê°œ ëª¨ë¸<br/>kobart + llama + qwen]
        B[í•™ìŠµ ë°ì´í„°<br/>2500ê°œ ìƒ˜í”Œ]
        C[ê²€ì¦ ë°ì´í„°<br/>499ê°œ ìƒ˜í”Œ]
    end

    subgraph Models["ëª¨ë¸ ê³„ì¸µ"]
        D[Model 1<br/>KoBART]
        E[Model 2<br/>Llama-3.2-Korean-3B]
        F[Model 3<br/>Qwen3-4B]
    end

    subgraph Training["í•™ìŠµ ê³„ì¸µ"]
        G[2 Epochs<br/>ë¹ ë¥¸ í…ŒìŠ¤íŠ¸]
        H[K-Fold: 2<br/>Stacking ì•™ìƒë¸”]
        I[TTA<br/>Paraphrase]
    end

    subgraph Output["ì¶œë ¥ ê³„ì¸µ"]
        J[ì²´í¬í¬ì¸íŠ¸<br/>3ê°œ ëª¨ë¸]
        K[ì•™ìƒë¸” ê²°ê³¼<br/>ìµœì¢… submission]
    end

    A --> D
    A --> E
    A --> F
    B --> G
    C --> G
    D --> G
    E --> G
    F --> G
    G --> H
    H --> I
    I --> J
    J --> K

    style Input fill:#e3f2fd,stroke:#1976d2,color:#000
    style Models fill:#fff3e0,stroke:#f57c00,color:#000
    style Training fill:#e8f5e9,stroke:#388e3c,color:#000
    style Output fill:#c8e6c9,stroke:#2e7d32,color:#000

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#90caf9,stroke:#1976d2,color:#000
    style C fill:#90caf9,stroke:#1976d2,color:#000
    style D fill:#ffb74d,stroke:#f57c00,color:#000
    style E fill:#ffb74d,stroke:#f57c00,color:#000
    style F fill:#ffb74d,stroke:#f57c00,color:#000
    style G fill:#81c784,stroke:#388e3c,color:#000
    style H fill:#a5d6a7,stroke:#388e3c,color:#000
    style I fill:#a5d6a7,stroke:#388e3c,color:#000
    style J fill:#aed581,stroke:#2e7d32,color:#000
    style K fill:#aed581,stroke:#2e7d32,color:#000
```

### 1.2 ì‹¤í—˜ ëª©ì 

- ì‚¼ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì „ëµì˜ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸** ê²€ì¦
- ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜(Seq2Seq + 2ê°œ Causal LM) ì¡°í•© íš¨ê³¼ í™•ì¸
- `gradient_accumulation_steps` ì„¤ì •ì´ í•™ìŠµ ì‹œê°„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
- Stacking ì•™ìƒë¸” ì „ëµì˜ íš¨ê³¼ ì¸¡ì •

### 1.3 ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# ==================== ì „ëµ 3: ì‚¼ì¤‘ ëª¨ë¸ ì•™ìƒë¸” - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ==================== #
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b \
  --epochs 2 \
  --batch_size 10 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation \
  --augmentation_ratio 0.1 \
  --k_folds 2 \
  --fold_seed 42 \
  --ensemble_strategy stacking \
  --use_tta \
  --tta_strategies paraphrase \
  --tta_num_aug 2 \
  --max_train_samples 2500 \
  --num_beams 4 \
  --save_visualizations \
  --experiment_name test_strategy3_triple \
  --seed 42
```

### 1.4 ì‹¤í—˜ ì§„í–‰ ìƒí™©

```mermaid
gantt
    title ì‹¤í—˜ ì‹¤í–‰ íƒ€ì„ë¼ì¸
    dateFormat HH:mm:ss
    axisFormat %H:%M

    section ë°ì´í„° ë¡œë“œ
    ë°ì´í„° ì¤€ë¹„           :16:10:56, 16:10:59

    section Model 1: KoBART
    KoBART í•™ìŠµ (ì„±ê³µ)    :done, kobart, 16:11:01, 16:12:41

    section Model 2: Llama
    Llama í•™ìŠµ (ì„±ê³µ)     :done, llama, 16:13:23, 18:02:39

    section Model 3: Qwen
    Qwen í•™ìŠµ (ì§„í–‰ ì¤‘)   :active, qwen, 18:21:14, 00:28:32
```

**ì‹¤í—˜ í˜„í™© ìš”ì•½**:

| ëª¨ë¸ | ìƒíƒœ | í•™ìŠµ ì‹œê°„ | ë¹„ê³  |
|------|------|----------|------|
| **KoBART** | âœ… ì™„ë£Œ | 1ë¶„ 40ì´ˆ | ë¹ ë¥¸ í•™ìŠµ ì†ë„ |
| **Llama 3.2 Korean 3B** | âœ… ì™„ë£Œ | 1ì‹œê°„ 49ë¶„ | ì •ìƒ ì™„ë£Œ |
| **Qwen3-4B** | ğŸ”„ ì§„í–‰ ì¤‘ | 6ì‹œê°„+ (ì˜ˆìƒ 9ì‹œê°„) | gradient_accumulation_steps: 10 |

---

## 2. ì‹¤í—˜ ì„¤ì •

### 2.1 ëª¨ë¸ ì„¤ì •

```python
# ==================== 3ê°œ ëª¨ë¸ ì„¤ì • ==================== #
models = [
    'kobart',                   # Seq2Seq (Encoder-Decoder)
    'llama-3.2-korean-3b',      # Causal LM (LoRA)
    'qwen3-4b'                  # Causal LM (QLoRA)
]

# ==================== ëª¨ë¸ë³„ ì„¸ë¶€ ì •ë³´ ==================== #
model_details = {
    'kobart': {
        'type': 'encoder_decoder',
        'checkpoint': 'digit82/kobart-summarization',
        'size': '123M',
        'trainable_params': 123_859_968,
        'config_batch_size': 50,        # Config ì„¤ì •
        'effective_batch_size': 50
    },
    'llama-3.2-korean-3b': {
        'type': 'causal_lm',
        'checkpoint': 'beomi/Llama-3.2-Korean-3B-Instruct',
        'size': '3B',
        'lora': True,
        'trainable_params': 24_313_856,  # 0.75% of total
        'config_batch_size': 8,          # Config ì„¤ì •
        'config_gradient_accumulation': 4,   # Config ì„¤ì • (ëª…ë ¹í–‰ ì˜¤ë²„ë¼ì´ë“œ ì•ˆë¨)
        'effective_batch_size': 32       # 8 Ã— 4 = 32
    },
    'qwen3-4b': {
        'type': 'causal_lm',
        'checkpoint': 'Qwen/Qwen3-4B-Instruct-2507',
        'size': '4B',
        'qlora': True,
        'trainable_params': 33_030_144,  # 0.81% of total
        'config_batch_size': 6,          # Config ì„¤ì •
        'config_gradient_accumulation': 10,  # âš ï¸ Config ì„¤ì • (ëª…ë ¹í–‰ ì˜¤ë²„ë¼ì´ë“œ ì•ˆë¨!)
        'effective_batch_size': 60       # 6 Ã— 10 = 60
    }
}
```

### 2.2 ë°ì´í„° ì„¤ì •

```python
# ==================== ë°ì´í„° í†µê³„ ==================== #
data_config = {
    'original_train_samples': 12457,     # ì›ë³¸ í•™ìŠµ ë°ì´í„°
    'original_val_samples': 499,         # ì›ë³¸ ê²€ì¦ ë°ì´í„°
    'max_train_samples': 2500,           # ì œí•œëœ í•™ìŠµ ë°ì´í„°
    'actual_train_samples': 2500,        # ì‹¤ì œ ì‚¬ìš©ëœ ë°ì´í„°
    'val_samples': 499                   # ê²€ì¦ ë°ì´í„° (ì œí•œ ì—†ìŒ)
}
```

### 2.3 í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```python
# ==================== ê³µí†µ í•™ìŠµ íŒŒë¼ë¯¸í„° (ëª…ë ¹í–‰ ì§€ì •) ==================== #
training_args = {
    'epochs': 2,                                # ì´ ì—í¬í¬ ìˆ˜
    'batch_size': 10,                           # ë°°ì¹˜ í¬ê¸° (ëª…ë ¹í–‰)
    'learning_rate': 2e-5,                      # ì´ˆê¸° í•™ìŠµë¥ 
    'gradient_accumulation_steps': 1,           # ëª…ë ¹í–‰ ì§€ì • (âš ï¸ Config íŒŒì¼ì— ì˜¤ë²„ë¼ì´ë“œ ì•ˆë¨)
    'warmup_ratio': 0.1,                        # Warmup ë¹„ìœ¨
    'k_folds': 2,                               # K-Fold ìˆ˜
    'ensemble_strategy': 'stacking',            # ì•™ìƒë¸” ì „ëµ
    'use_tta': True,                            # TTA ì‚¬ìš©
    'tta_strategies': ['paraphrase'],           # TTA ì „ëµ
    'tta_num_aug': 2,                           # TTA ì¦ê°• íšŸìˆ˜
    'max_train_samples': 2500,                  # í•™ìŠµ ìƒ˜í”Œ ì œí•œ
    'augmentation_methods': ['back_translation'], # ì¦ê°• ë°©ë²•
    'augmentation_ratio': 0.1                   # ì¦ê°• ë¹„ìœ¨
}

# ==================== ì‹¤ì œ ì ìš©ëœ ì„¤ì • (Config íŒŒì¼ ìš°ì„ ) ==================== #
actual_training_config = {
    'kobart': {
        'batch_size': 50,                      # Config íŒŒì¼ì˜ ì„¤ì • ì‚¬ìš©
        'gradient_accumulation_steps': 1,
        'effective_batch_size': 50
    },
    'llama-3.2-korean-3b': {
        'batch_size': 8,                       # Config íŒŒì¼ì˜ ì„¤ì • ì‚¬ìš©
        'gradient_accumulation_steps': 4,      # âš ï¸ Config íŒŒì¼ ìš°ì„ !
        'effective_batch_size': 32             # 8 Ã— 4 = 32
    },
    'qwen3-4b': {
        'batch_size': 6,                       # Config íŒŒì¼ì˜ ì„¤ì • ì‚¬ìš©
        'gradient_accumulation_steps': 10,     # âš ï¸ Config íŒŒì¼ ìš°ì„ ! (ë¬¸ì œ ì›ì¸)
        'effective_batch_size': 60             # 6 Ã— 10 = 60
    }
}
```

---

## 3. í•™ìŠµ ì§€í‘œ ìƒì„¸ ì„¤ëª…

### 3.1 í•™ìŠµ ì§€í‘œ ì •ì˜

```python
# ==================== í•™ìŠµ ì§€í‘œ ì™„ì „ ê°€ì´ë“œ ==================== #
training_metrics_guide = {
    # ---------------------- 1. Loss (ì†ì‹¤) ---------------------- #
    'loss': {
        'definition': 'ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ì •ë‹µ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìˆ˜ì¹˜í™”í•œ ê°’',
        'formula': 'Cross Entropy Loss = -Î£(y_true Ã— log(y_pred))',
        'range': '[0, +âˆ)',
        'optimal_direction': 'â¬‡ï¸ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ',
        'interpretation': {
            'high_loss': '2.0 ì´ìƒ = ëª¨ë¸ì´ ì˜ í•™ìŠµë˜ì§€ ì•ŠìŒ',
            'medium_loss': '1.0 ~ 2.0 = í•™ìŠµ ì¤‘ê°„ ë‹¨ê³„',
            'low_loss': '0.5 ~ 1.0 = ì˜ í•™ìŠµëœ ìƒíƒœ',
            'very_low_loss': '0.5 ì´í•˜ = ë§¤ìš° ì˜ í•™ìŠµë¨ (ê³¼ì í•© ì£¼ì˜)'
        },
        'what_to_watch': [
            'âœ… ê°ì†Œ ì¶”ì„¸: Lossê°€ ê³„ì† ê°ì†Œí•˜ë©´ í•™ìŠµì´ ì˜ ë˜ê³  ìˆìŒ',
            'âš ï¸ ì •ì²´: Lossê°€ ë” ì´ìƒ ê°ì†Œí•˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥  ì¡°ì • í•„ìš”',
            'âŒ ì¦ê°€: Lossê°€ ì¦ê°€í•˜ë©´ í•™ìŠµë¥ ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ë¬¸ì œ ë°œìƒ'
        ]
    },

    # ---------------------- 2. Gradient Norm (ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„) ---------------------- #
    'grad_norm': {
        'definition': 'ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ì— ì‚¬ìš©ë˜ëŠ” ê·¸ë˜ë””ì–¸íŠ¸(ê²½ì‚¬)ì˜ í¬ê¸°',
        'formula': '||âˆ‡L|| = sqrt(Î£(grad_iÂ²))',
        'range': '[0, +âˆ)',
        'optimal_direction': 'ğŸ“Š ì ì • ë²”ìœ„ ìœ ì§€ (1.0 ~ 3.0)',
        'interpretation': {
            'too_small': '< 0.1 = ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ (Vanishing Gradient)',
            'optimal': '0.5 ~ 3.0 = ì•ˆì •ì  í•™ìŠµ',
            'high': '3.0 ~ 10.0 = ì•½ê°„ ë¶ˆì•ˆì •í•˜ì§€ë§Œ í•™ìŠµ ê°€ëŠ¥',
            'too_high': '> 10.0 = ê·¸ë˜ë””ì–¸íŠ¸ í­ë°œ (Exploding Gradient)'
        },
        'what_to_watch': [
            'âœ… ì•ˆì •ì : 0.5~3.0 ë²”ìœ„ë¥¼ ìœ ì§€í•˜ë©´ í•™ìŠµì´ ì•ˆì •ì ',
            'âš ï¸ ë†’ìŒ: 3.0~10.0ì´ë©´ max_grad_normìœ¼ë¡œ í´ë¦¬í•‘ ê³ ë ¤',
            'âŒ ë§¤ìš° ë†’ìŒ: 10.0 ì´ìƒì´ë©´ í•™ìŠµë¥ ì„ ë‚®ì¶°ì•¼ í•¨'
        ]
    },

    # ---------------------- 3. Learning Rate (í•™ìŠµë¥ ) ---------------------- #
    'learning_rate': {
        'definition': 'ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì–¼ë§ˆë‚˜ í¬ê²Œ ì—…ë°ì´íŠ¸í• ì§€ ê²°ì •í•˜ëŠ” ê°’',
        'formula': 'w_new = w_old - learning_rate Ã— gradient',
        'range': '[0, 1]',
        'optimal_direction': 'ğŸ“ˆ ìŠ¤ì¼€ì¤„ì— ë”°ë¼ ë³€í™” (ë³´í†µ ê°ì†Œ)',
        'typical_values': {
            'pretrained_large_models': '1e-6 ~ 5e-5',
            'fine_tuning': '1e-5 ~ 5e-4',
            'training_from_scratch': '1e-4 ~ 1e-2'
        },
        'scheduler_patterns': {
            'warmup': 'ì´ˆê¸°ì— ì‘ê²Œ ì‹œì‘ â†’ ì ì§„ì  ì¦ê°€',
            'linear_decay': 'ìµœê³ ì  ì´í›„ ì„ í˜• ê°ì†Œ',
            'cosine_decay': 'ìµœê³ ì  ì´í›„ ì½”ì‚¬ì¸ ê³¡ì„ ìœ¼ë¡œ ê°ì†Œ',
            'constant': 'ì¼ì •í•˜ê²Œ ìœ ì§€'
        },
        'what_to_watch': [
            'âœ… Warmup ì™„ë£Œ: Learning rateê°€ ëª©í‘œê°’ì— ë„ë‹¬',
            'âœ… ì„ í˜• ê°ì†Œ: Epochê°€ ì§„í–‰ë˜ë©´ì„œ ì ì§„ì  ê°ì†Œ',
            'âš ï¸ ë„ˆë¬´ í¼: Lossê°€ ë°œì‚°í•˜ë©´ í•™ìŠµë¥ ì´ ë„ˆë¬´ í° ê²ƒ',
            'âš ï¸ ë„ˆë¬´ ì‘ìŒ: Lossê°€ ê±°ì˜ ê°ì†Œí•˜ì§€ ì•Šìœ¼ë©´ ë„ˆë¬´ ì‘ì€ ê²ƒ'
        ]
    },

    # ---------------------- 4. Epoch (ì—í¬í¬) ---------------------- #
    'epoch': {
        'definition': 'ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ í•œ ë²ˆ ëª¨ë‘ í•™ìŠµí•œ íšŸìˆ˜',
        'range': '[0, total_epochs]',
        'optimal_direction': 'ğŸ”„ ì§„í–‰ë„ (ì¦ê°€)',
        'interpretation': {
            'epoch_0_to_1': 'ì´ˆê¸° í•™ìŠµ ë‹¨ê³„ - Lossê°€ ë¹ ë¥´ê²Œ ê°ì†Œ',
            'epoch_1_to_5': 'ì¤‘ê°„ í•™ìŠµ ë‹¨ê³„ - Lossê°€ ì•ˆì •ì ìœ¼ë¡œ ê°ì†Œ',
            'epoch_5_plus': 'í›„ê¸° í•™ìŠµ ë‹¨ê³„ - Loss ê°ì†Œ ì†ë„ ë‘”í™”'
        },
        'what_to_watch': [
            'âœ… 1.0 Epoch ì™„ë£Œ: ì²« ë²ˆì§¸ í‰ê°€ ì§€í‘œ í™•ì¸',
            'âœ… 2.0 Epoch ì™„ë£Œ: ë‘ ë²ˆì§¸ í‰ê°€ ì§€í‘œë¡œ ê°œì„ ë„ ì¸¡ì •',
            'âš ï¸ ê³¼ì í•© ì§•í›„: Eval LossëŠ” ì¦ê°€í•˜ëŠ”ë° Train LossëŠ” ê°ì†Œ'
        ]
    },

    # ---------------------- 5. Eval Loss (í‰ê°€ ì†ì‹¤) ---------------------- #
    'eval_loss': {
        'definition': 'ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ì˜ ì†ì‹¤ê°’',
        'range': '[0, +âˆ)',
        'optimal_direction': 'â¬‡ï¸ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ',
        'comparison_with_train_loss': {
            'eval_loss < train_loss': 'âœ… ì •ìƒ - ëª¨ë¸ì´ ì¼ë°˜í™” ì˜ ë¨',
            'eval_loss â‰ˆ train_loss': 'âœ… ì •ìƒ - ê· í˜•ì¡íŒ í•™ìŠµ',
            'eval_loss > train_loss (ì•½ê°„)': 'âš ï¸ ì£¼ì˜ - ê³¼ì í•© ì´ˆê¸° ì§•í›„',
            'eval_loss >> train_loss': 'âŒ ê³¼ì í•© - í•™ìŠµ ì¤‘ë‹¨ ê³ ë ¤'
        }
    },

    # ---------------------- 6. ROUGE Scores ---------------------- #
    'rouge_scores': {
        'rouge1': 'Unigram (ë‹¨ì–´ 1ê°œ) ë‹¨ìœ„ ì¼ì¹˜ìœ¨',
        'rouge2': 'Bigram (ë‹¨ì–´ 2ê°œ) ë‹¨ìœ„ ì¼ì¹˜ìœ¨',
        'rougeL': 'Longest Common Subsequence (ê°€ì¥ ê¸´ ê³µí†µ ë¶€ë¶„ìˆ˜ì—´)',
        'rouge_sum': 'ROUGE-1 + ROUGE-2 + ROUGE-L (ì¢…í•© ì ìˆ˜)',
        'range': '[0, 1]',
        'optimal_direction': 'â¬†ï¸ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ',
        'interpretation': {
            'poor': '< 0.3 (30%) = ì„±ëŠ¥ ë‚®ìŒ',
            'acceptable': '0.3 ~ 0.5 (30~50%) = ê¸°ë³¸ ìˆ˜ì¤€',
            'good': '0.5 ~ 0.7 (50~70%) = ì¢‹ì€ ì„±ëŠ¥',
            'excellent': '> 0.7 (70%) = ë§¤ìš° ìš°ìˆ˜'
        }
    }
}
```

### 3.2 í•™ìŠµ ì§€í‘œ ì˜ˆì‹œ í•´ì„

```python
# ==================== ì‹¤ì œ ë¡œê·¸ ì˜ˆì‹œ í•´ì„ ==================== #
example_log_interpretation = {
    # ---------------------- ì˜ˆì‹œ 1: KoBART Epoch 0.4 ---------------------- #
    'example_1': {
        'raw_log': "{'loss': 2.3843, 'grad_norm': 6.778, 'learning_rate': 3.96e-06, 'epoch': 0.4}",
        'interpretation': {
            'loss': '2.3843 â†’ ë†’ìŒ. í•™ìŠµ ì´ˆê¸° ë‹¨ê³„ë¡œ ì•„ì§ ìµœì í™” ì¤‘',
            'grad_norm': '6.778 â†’ ì•½ê°„ ë†’ì§€ë§Œ ì •ìƒ ë²”ìœ„. í•™ìŠµ ì´ˆê¸°ì— í”í•¨',
            'learning_rate': '3.96e-06 â†’ ë§¤ìš° ì‘ìŒ. Warmup ë‹¨ê³„ë¡œ ì²œì²œíˆ ì¦ê°€ ì¤‘',
            'epoch': '0.4 â†’ ì „ì²´ ë°ì´í„°ì˜ 40% í•™ìŠµ ì™„ë£Œ',
            'overall': 'âœ… ì •ìƒì ì¸ í•™ìŠµ ì´ˆê¸° ë‹¨ê³„'
        }
    },

    # ---------------------- ì˜ˆì‹œ 2: Llama Epoch 1.0 ---------------------- #
    'example_2': {
        'raw_log': "{'loss': 1.2031, 'grad_norm': 1.721, 'learning_rate': 9.96e-06, 'epoch': 1.0}",
        'interpretation': {
            'loss': '1.2031 â†’ ì¤‘ê°„. 1 Epoch ì™„ë£Œ ì‹œì ìœ¼ë¡œ ì ì ˆí•œ ê°ì†Œ',
            'grad_norm': '1.721 â†’ ë§¤ìš° ì•ˆì •ì . ìµœì  ë²”ìœ„ ë‚´',
            'learning_rate': '9.96e-06 â†’ Warmup ì™„ë£Œ. ëª©í‘œ í•™ìŠµë¥ ì— ë„ë‹¬',
            'epoch': '1.0 â†’ ì²« ë²ˆì§¸ Epoch ì™„ë£Œ',
            'overall': 'âœ… ë§¤ìš° ì•ˆì •ì ì¸ í•™ìŠµ. Loss ê°ì†Œ ì¶”ì„¸ ì¢‹ìŒ'
        }
    },

    # ---------------------- ì˜ˆì‹œ 3: Qwen Epoch 0.6 ---------------------- #
    'example_3': {
        'raw_log': "{'loss': 0.8971, 'grad_norm': 1.084, 'learning_rate': 5.96e-06, 'epoch': 0.6}",
        'interpretation': {
            'loss': '0.8971 â†’ ë‚®ìŒ. ë¹ ë¥¸ í•™ìŠµ ì§„í–‰',
            'grad_norm': '1.084 â†’ ë§¤ìš° ì•ˆì •ì . ì´ìƒì ì¸ ë²”ìœ„',
            'learning_rate': '5.96e-06 â†’ Warmup ì§„í–‰ ì¤‘',
            'epoch': '0.6 â†’ 60% í•™ìŠµ ì™„ë£Œ',
            'overall': 'âœ… ìš°ìˆ˜í•œ í•™ìŠµ ì§„í–‰. Lossê°€ ë¹ ë¥´ê²Œ ê°ì†Œ ì¤‘'
        }
    },

    # ---------------------- ì˜ˆì‹œ 4: í‰ê°€ ì§€í‘œ ---------------------- #
    'example_4': {
        'raw_log': "{'eval_loss': 1.4684, 'eval_rouge1': 0.3988, 'eval_rouge2': 0.2523, 'eval_rougeL': 0.3913, 'eval_rouge_sum': 1.0424}",
        'interpretation': {
            'eval_loss': '1.4684 â†’ Train Lossë³´ë‹¤ ì•½ê°„ ë‚®ìŒ. ê³¼ì í•© ì—†ìŒ',
            'eval_rouge1': '0.3988 (39.88%) â†’ ê¸°ë³¸ ìˆ˜ì¤€',
            'eval_rouge2': '0.2523 (25.23%) â†’ ê¸°ë³¸ ìˆ˜ì¤€',
            'eval_rougeL': '0.3913 (39.13%) â†’ ê¸°ë³¸ ìˆ˜ì¤€',
            'eval_rouge_sum': '1.0424 â†’ ì¢…í•© ì ìˆ˜ ì–‘í˜¸',
            'overall': 'âœ… ëª¨ë¸ì´ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ì„œë„ ì˜ ì‘ë™í•¨'
        }
    }
}
```

---

## 4. ëª¨ë¸ë³„ í•™ìŠµ ê²°ê³¼ ë¶„ì„

### 4.1 Model 1: KoBART (âœ… ì™„ë£Œ)

#### 4.1.1 í•™ìŠµ ì§„í–‰ í”Œë¡œìš°

```mermaid
graph LR
    A[ì´ˆê¸°<br/>Loss: 2.38<br/>Epoch: 0.4] --> B[ì¤‘ê°„<br/>Loss: 1.76<br/>Epoch: 0.8]
    B --> C[Epoch 1<br/>Loss: 1.52<br/>âœ… í‰ê°€ ì™„ë£Œ]
    C --> D[ìµœì¢…<br/>Loss: 1.52<br/>Epoch: 2.0<br/>âœ… ì™„ë£Œ]

    style A fill:#ffccbc,stroke:#d84315,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#c5e1a5,stroke:#558b2f,color:#000
    style D fill:#a5d6a7,stroke:#2e7d32,color:#000
```

#### 4.1.2 í•™ìŠµ ì§€í‘œ ìƒì„¸

```python
# ==================== KoBART í•™ìŠµ ë°ì´í„° ==================== #
kobart_training_metrics = [
    # ---------------------- Epoch 1 ---------------------- #
    {'epoch': 0.4, 'loss': 2.3843, 'grad_norm': 6.778, 'lr': 3.96e-06},
    {'epoch': 0.8, 'loss': 1.7590, 'grad_norm': 6.949, 'lr': 7.96e-06},
    {'epoch': 1.0, 'loss': 1.7634, 'grad_norm': None, 'lr': None},  # Train ì™„ë£Œ

    # ---------------------- Epoch 2 ---------------------- #
    {'epoch': 1.2, 'loss': 1.6345, 'grad_norm': 5.923, 'lr': 1.196e-05},
    {'epoch': 1.6, 'loss': 1.5213, 'grad_norm': 4.771, 'lr': 1.596e-05},
    {'epoch': 2.0, 'loss': 1.5178, 'grad_norm': 4.546, 'lr': 1.996e-05}  # âœ… ìµœì¢…
]

# ==================== KoBART í‰ê°€ ì§€í‘œ ==================== #
kobart_eval_metrics = [
    # ---------------------- Epoch 1 í‰ê°€ ---------------------- #
    {
        'epoch': 1.0,
        'eval_loss': 1.5624,
        'eval_rouge1': 0.4048,      # 40.48%
        'eval_rouge2': 0.2480,      # 24.80%
        'eval_rougeL': 0.3952,      # 39.52%
        'eval_rouge_sum': 1.0480,   # ì¢…í•©
        'eval_runtime': 36.41,      # 36ì´ˆ
        'status': 'âœ… ì •ìƒ'
    },

    # ---------------------- Epoch 2 í‰ê°€ ---------------------- #
    {
        'epoch': 2.0,
        'eval_loss': 1.4684,        # â¬‡ï¸ ê°ì†Œ (ê°œì„ )
        'eval_rouge1': 0.3988,      # â¬‡ï¸ ì•½ê°„ í•˜ë½
        'eval_rouge2': 0.2523,      # â¬†ï¸ ì•½ê°„ ìƒìŠ¹
        'eval_rougeL': 0.3913,      # â¬‡ï¸ ì•½ê°„ í•˜ë½
        'eval_rouge_sum': 1.0424,   # â‰ˆ ìœ ì‚¬
        'eval_runtime': 36.73,      # 36ì´ˆ
        'status': 'âœ… ì •ìƒ'
    }
]

# ==================== KoBART ìµœì¢… ê²°ê³¼ ==================== #
kobart_final_summary = {
    'train_runtime': 99.23,                  # 1ë¶„ 39ì´ˆ
    'train_samples_per_second': 50.39,      # ì´ˆë‹¹ 50ê°œ ìƒ˜í”Œ
    'train_steps_per_second': 5.04,         # ì´ˆë‹¹ 5 ìŠ¤í…
    'train_loss': 1.7634,                   # í‰ê·  Train Loss
    'best_eval_rouge_sum': 1.0480,          # ìµœê³  ROUGE Sum (Epoch 1)
    'final_eval_rouge_sum': 1.0424,         # ìµœì¢… ROUGE Sum (Epoch 2)
    'status': 'âœ… í•™ìŠµ ì„±ê³µ'
}
```

#### 4.1.3 KoBART ì„±ëŠ¥ ë¶„ì„

```mermaid
graph TB
    subgraph Initial["ì´ˆê¸° ë‹¨ê³„ (Epoch 0.0-1.0)"]
        A1[Loss: 2.38 â†’ 1.76<br/>ê°ì†Œìœ¨: 26%]
        A2[Grad Norm: 6.8<br/>ì•ˆì •ì ]
        A3[LR: Warmup ì§„í–‰<br/>4e-6 â†’ 8e-6]
    end

    subgraph Final["ìµœì¢… ë‹¨ê³„ (Epoch 1.0-2.0)"]
        B1[Loss: 1.76 â†’ 1.52<br/>ê°ì†Œìœ¨: 14%]
        B2[Grad Norm: 4.5~6.0<br/>ë§¤ìš° ì•ˆì •]
        B3[LR: ì„ í˜• ì¦ê°€<br/>8e-6 â†’ 2e-5]
    end

    subgraph Evaluation["í‰ê°€ ê²°ê³¼"]
        C1[Eval Loss: 1.56 â†’ 1.47<br/>ê°œì„ ]
        C2[ROUGE Sum: 1.048<br/>ì–‘í˜¸í•œ ì„±ëŠ¥]
        C3[í•™ìŠµ ì‹œê°„: 99ì´ˆ<br/>ë§¤ìš° ë¹ ë¦„]
    end

    Initial --> Final --> Evaluation

    style Initial fill:#ffccbc,stroke:#d84315,color:#000
    style Final fill:#fff9c4,stroke:#f57f17,color:#000
    style Evaluation fill:#c8e6c9,stroke:#2e7d32,color:#000

    style A1 fill:#ef9a9a,stroke:#d84315,color:#000
    style A2 fill:#ef9a9a,stroke:#d84315,color:#000
    style A3 fill:#ef9a9a,stroke:#d84315,color:#000
    style B1 fill:#fff59d,stroke:#f57f17,color:#000
    style B2 fill:#fff59d,stroke:#f57f17,color:#000
    style B3 fill:#fff59d,stroke:#f57f17,color:#000
    style C1 fill:#aed581,stroke:#2e7d32,color:#000
    style C2 fill:#aed581,stroke:#2e7d32,color:#000
    style C3 fill:#aed581,stroke:#2e7d32,color:#000
```

**KoBART ì£¼ìš” ë°œê²¬:**

- âœ… **ë§¤ìš° ë¹ ë¥¸ í•™ìŠµ ì†ë„**: 99ì´ˆ ë§Œì— 2 Epoch ì™„ë£Œ
- âœ… **ì•ˆì •ì ì¸ Loss ê°ì†Œ**: 2.38 â†’ 1.52 (36% ê°ì†Œ)
- âœ… **Gradient Norm ì•ˆì •**: 4.5~7.0 ë²”ìœ„ ìœ ì§€
- âœ… **ROUGE ì ìˆ˜ ì–‘í˜¸**: ROUGE Sum 1.048 (ì²« Epochì—ì„œ ë‹¬ì„±)
- âš ï¸ **Epoch 2 ì•½ê°„ í•˜ë½**: ROUGE-1, ROUGE-Lì´ ì†Œí­ í•˜ë½ (ê³¼ì í•© ì´ˆê¸° ì§•í›„ ê°€ëŠ¥)

---

### 4.2 Model 2: Llama-3.2-Korean-3B (âœ… ì™„ë£Œ)

#### 4.2.1 í•™ìŠµ ì§„í–‰ í”Œë¡œìš°

```mermaid
graph LR
    A[ì´ˆê¸°<br/>Loss: 1.63<br/>Epoch: 0.04] --> B[ì¤‘ê°„ 1<br/>Loss: 1.20<br/>Epoch: 1.0]
    B --> C[ì¤‘ê°„ 2<br/>Loss: 1.08<br/>Epoch: 1.6]
    C --> D[ìµœì¢…<br/>Loss: 1.05<br/>Epoch: 2.0<br/>âœ… ì™„ë£Œ]

    style A fill:#ffccbc,stroke:#d84315,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#c5e1a5,stroke:#558b2f,color:#000
    style D fill:#a5d6a7,stroke:#2e7d32,color:#000
```

#### 4.2.2 í•™ìŠµ ì§€í‘œ ìƒì„¸ (ëŒ€í‘œ ì²´í¬í¬ì¸íŠ¸)

```python
# ==================== Llama í•™ìŠµ ë°ì´í„° (25ê°œ ì¤‘ ëŒ€í‘œ 5ê°œ) ==================== #
llama_training_metrics_summary = [
    # ---------------------- ì´ˆê¸° (Warmup ë‹¨ê³„) ---------------------- #
    {'epoch': 0.04, 'loss': 1.6346, 'grad_norm': 2.071, 'lr': 3.6e-07},  # í•™ìŠµ ì‹œì‘
    {'epoch': 0.4,  'loss': 1.4115, 'grad_norm': 1.444, 'lr': 3.96e-06}, # Warmup ì¤‘

    # ---------------------- ì¤‘ê°„ (ì•ˆì • ë‹¨ê³„) ---------------------- #
    {'epoch': 1.0,  'loss': 1.2031, 'grad_norm': 1.721, 'lr': 9.96e-06}, # Epoch 1 ì™„ë£Œ

    # ---------------------- í›„ê¸° (ìˆ˜ë ´ ë‹¨ê³„) ---------------------- #
    {'epoch': 1.6,  'loss': 1.0785, 'grad_norm': 2.061, 'lr': 1.596e-05}, # ë¹ ë¥¸ ê°ì†Œ
    {'epoch': 2.0,  'loss': 1.0497, 'grad_norm': 2.574, 'lr': 1.996e-05}  # âœ… ìµœì¢…
]

# ==================== Llama í‰ê°€ ì§€í‘œ ==================== #
llama_eval_metrics = [
    # ---------------------- Epoch 1 í‰ê°€ ---------------------- #
    {
        'epoch': 1.0,
        'eval_loss': 1.2082,
        'eval_rouge1': 0.1097,      # âš ï¸ 10.97% (ë‚®ìŒ)
        'eval_rouge2': 0.0735,      # âš ï¸ 7.35% (ë‚®ìŒ)
        'eval_rougeL': 0.1097,      # âš ï¸ 10.97% (ë‚®ìŒ)
        'eval_rouge_sum': 0.2928,   # âš ï¸ ì¢…í•© ì ìˆ˜ ë‚®ìŒ
        'eval_runtime': 394.36,     # 6ë¶„ 34ì´ˆ (ëŠë¦¼)
        'status': 'âš ï¸ ROUGE ì ìˆ˜ ë§¤ìš° ë‚®ìŒ'
    },

    # ---------------------- Epoch 2 í‰ê°€ ---------------------- #
    {
        'epoch': 2.0,
        'eval_loss': 1.1322,        # â¬‡ï¸ ê°ì†Œ (ê°œì„ )
        'eval_rouge1': 0.1060,      # â‰ˆ ìœ ì‚¬ (10.60%)
        'eval_rouge2': 0.0709,      # â‰ˆ ìœ ì‚¬ (7.09%)
        'eval_rougeL': 0.1060,      # â‰ˆ ìœ ì‚¬ (10.60%)
        'eval_rouge_sum': 0.2829,   # âš ï¸ ì˜¤íˆë ¤ ì•½ê°„ í•˜ë½
        'eval_runtime': 3655.20,    # 1ì‹œê°„ (ë§¤ìš° ëŠë¦¼)
        'status': 'âš ï¸ ROUGE ì ìˆ˜ ê°œì„  ì•ˆë¨'
    }
]

# ==================== Llama ìµœì¢… ê²°ê³¼ ==================== #
llama_final_summary = {
    'train_runtime': 6553.30,                # 1ì‹œê°„ 49ë¶„
    'train_samples_per_second': 0.763,      # ì´ˆë‹¹ 0.76ê°œ ìƒ˜í”Œ (ë§¤ìš° ëŠë¦¼)
    'train_steps_per_second': 0.076,        # ì´ˆë‹¹ 0.076 ìŠ¤í…
    'train_loss': 1.2595,                   # í‰ê·  Train Loss
    'best_eval_rouge_sum': 0.2928,          # ìµœê³  ROUGE Sum (Epoch 1)
    'final_eval_rouge_sum': 0.2829,         # ìµœì¢… ROUGE Sum (Epoch 2)
    'status': 'âš ï¸ í•™ìŠµ ì™„ë£Œí–ˆìœ¼ë‚˜ ì„±ëŠ¥ ë§¤ìš° ë‚®ìŒ'
}
```

#### 4.2.3 Llama ì„±ëŠ¥ ë¶„ì„

```mermaid
graph TB
    subgraph Training["í•™ìŠµ ì§„í–‰"]
        A1[Train Loss ê°ì†Œ<br/>1.63 â†’ 1.05<br/>36% ê°ì†Œ]
        A2[Gradient Norm<br/>1.4 ~ 2.6<br/>ì•ˆì •ì ]
        A3[í•™ìŠµ ì‹œê°„<br/>1ì‹œê°„ 49ë¶„<br/>ë§¤ìš° ëŠë¦¼]
    end

    subgraph Problems["ë¬¸ì œì "]
        B1[ROUGE ì ìˆ˜<br/>0.29<br/>âŒ ë§¤ìš° ë‚®ìŒ]
        B2[í‰ê°€ ì‹œê°„<br/>1ì‹œê°„<br/>âŒ ê³¼ë„í•˜ê²Œ ëŠë¦¼]
        B3[ê°œì„  ì—†ìŒ<br/>Epoch 2ì—ì„œ<br/>ì˜¤íˆë ¤ í•˜ë½]
    end

    subgraph RootCause["ê·¼ë³¸ ì›ì¸"]
        C1[gradient_accumulation<br/>= 4<br/>Config ì„¤ì •]
        C2[Effective Batch<br/>= 32<br/>í¬ê²Œ ì¦ê°€]
        C3[Steps ì¦ê°€<br/>625 Ã— 2 = 1250<br/>KoBARTì˜ 25ë°°]
    end

    Training --> Problems --> RootCause

    style Training fill:#fff9c4,stroke:#f57f17,color:#000
    style Problems fill:#ffccbc,stroke:#d84315,color:#000
    style RootCause fill:#ffcdd2,stroke:#c62828,color:#fff

    style A1 fill:#fff59d,stroke:#f57f17,color:#000
    style A2 fill:#fff59d,stroke:#f57f17,color:#000
    style A3 fill:#fff59d,stroke:#f57f17,color:#000
    style B1 fill:#ef9a9a,stroke:#d84315,color:#000
    style B2 fill:#ef9a9a,stroke:#d84315,color:#000
    style B3 fill:#ef9a9a,stroke:#d84315,color:#000
    style C1 fill:#f48fb1,stroke:#c62828,color:#fff
    style C2 fill:#f48fb1,stroke:#c62828,color:#fff
    style C3 fill:#f48fb1,stroke:#c62828,color:#fff
```

**Llama ì£¼ìš” ë°œê²¬:**

- âœ… **Train Loss ê°ì†Œ**: 1.63 â†’ 1.05 (36% ê°ì†Œ, ì•ˆì •ì )
- âœ… **Gradient Norm ì•ˆì •**: 1.4~2.6 ë²”ìœ„ ìœ ì§€
- âŒ **ROUGE ì ìˆ˜ ë§¤ìš° ë‚®ìŒ**: 0.29 (KoBART 1.048ì˜ 28% ìˆ˜ì¤€)
- âŒ **í•™ìŠµ ì‹œê°„ ê³¼ë„**: 1ì‹œê°„ 49ë¶„ (KoBART 99ì´ˆì˜ 66ë°°)
- âŒ **í‰ê°€ ì‹œê°„ ê³¼ë„**: Epoch 2 í‰ê°€ì— 1ì‹œê°„ ì†Œìš”
- âš ï¸ **ê°œì„  ì—†ìŒ**: Epoch 2ì—ì„œ ROUGE ì ìˆ˜ ì˜¤íˆë ¤ í•˜ë½

**ë¬¸ì œ ì›ì¸:**
- Config íŒŒì¼ì˜ `gradient_accumulation_steps: 4`ê°€ ëª…ë ¹í–‰ `--gradient_accumulation_steps 1`ì„ ì˜¤ë²„ë¼ì´ë“œ
- Effective batch size 32 (8Ã—4) â†’ Steps ìˆ˜ ì¦ê°€
- Causal LM ëª¨ë¸ì˜ ì¶”ë¡  ì†ë„ê°€ Seq2Seqë³´ë‹¤ ëŠë¦¼

---

### 4.3 Model 3: Qwen3-4B (ğŸ”„ ì§„í–‰ ì¤‘)

#### 4.3.1 í•™ìŠµ ì§„í–‰ í”Œë¡œìš° (í˜„ì¬ê¹Œì§€)

```mermaid
graph LR
    A[ì´ˆê¸°<br/>Loss: 2.69<br/>Epoch: 0.04] --> B[ì¤‘ê°„ 1<br/>Loss: 0.90<br/>Epoch: 0.6]
    B --> C[Epoch 1<br/>Loss: 0.89<br/>âœ… í‰ê°€ ì™„ë£Œ]
    C --> D[í˜„ì¬<br/>Loss: 0.86<br/>Epoch: 1.48<br/>ğŸ”„ ì§„í–‰ ì¤‘]

    style A fill:#ffccbc,stroke:#d84315,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#c5e1a5,stroke:#558b2f,color:#000
    style D fill:#90caf9,stroke:#1976d2,color:#000
```

#### 4.3.2 í•™ìŠµ ì§€í‘œ ìƒì„¸ (ëŒ€í‘œ ì²´í¬í¬ì¸íŠ¸)

```python
# ==================== Qwen í•™ìŠµ ë°ì´í„° (ëŒ€í‘œ 5ê°œ) ==================== #
qwen_training_metrics_summary = [
    # ---------------------- ì´ˆê¸° (Warmup ë‹¨ê³„) ---------------------- #
    {'epoch': 0.04, 'loss': 2.6867, 'grad_norm': 5.219, 'lr': 3.6e-07},  # í•™ìŠµ ì‹œì‘
    {'epoch': 0.4,  'loss': 1.5077, 'grad_norm': 3.137, 'lr': 3.96e-06}, # ë¹ ë¥¸ ê°ì†Œ

    # ---------------------- ì¤‘ê°„ (ë¹ ë¥¸ ìˆ˜ë ´) ---------------------- #
    {'epoch': 0.6,  'loss': 0.8971, 'grad_norm': 1.084, 'lr': 5.96e-06}, # âœ… ë§¤ìš° ë‚®ìŒ
    {'epoch': 1.0,  'loss': 0.8924, 'grad_norm': 1.054, 'lr': 9.96e-06}, # Epoch 1 ì™„ë£Œ

    # ---------------------- í˜„ì¬ (ì§„í–‰ ì¤‘) ---------------------- #
    {'epoch': 1.48, 'loss': 0.8612, 'grad_norm': 1.299, 'lr': 1.476e-05} # ğŸ”„ ìµœì‹ 
]

# ==================== Qwen í‰ê°€ ì§€í‘œ ==================== #
qwen_eval_metrics = [
    # ---------------------- Epoch 1 í‰ê°€ (ìœ ì¼í•œ í‰ê°€) ---------------------- #
    {
        'epoch': 1.0,
        'eval_loss': 0.8999,
        'eval_rouge1': 0.1432,      # 14.32%
        'eval_rouge2': 0.0966,      # 9.66%
        'eval_rougeL': 0.1432,      # 14.32%
        'eval_rouge_sum': 0.3831,   # ì¢…í•©
        'eval_runtime': 4852.32,    # 1ì‹œê°„ 21ë¶„ (ë§¤ìš° ëŠë¦¼)
        'status': 'âš ï¸ ROUGE ì ìˆ˜ ë‚®ìŒ, í‰ê°€ ì‹œê°„ ê³¼ë„'
    }
]

# ==================== Qwen í˜„ì¬ê¹Œì§€ í†µê³„ ==================== #
qwen_current_summary = {
    'elapsed_time': '6ì‹œê°„ 17ë¶„',            # 18:21 ~ 00:38
    'current_epoch': 1.48,                   # 148% ì§„í–‰ (Epoch 2 ì¤‘)
    'estimated_total_time': '8~9ì‹œê°„',      # ì˜ˆìƒ ì´ ì‹œê°„
    'remaining_time': 'ì•½ 2~3ì‹œê°„',          # ë‚¨ì€ ì‹œê°„
    'train_loss_current': 0.8612,           # í˜„ì¬ Loss
    'best_train_loss': 0.8357,              # ìµœì € Loss (Epoch 1.04)
    'eval_rouge_sum': 0.3831,               # í‰ê°€ ROUGE Sum
    'status': 'ğŸ”„ Epoch 2 ì§„í–‰ ì¤‘ (ì•½ 74% ì™„ë£Œ)'
}
```

#### 4.3.3 Qwen ì„±ëŠ¥ ë¶„ì„

```mermaid
graph TB
    subgraph Positive["ê¸ì •ì  ì¸¡ë©´"]
        A1[Train Loss<br/>2.69 â†’ 0.86<br/>68% ê°ì†Œ<br/>âœ… ë§¤ìš° ìš°ìˆ˜]
        A2[Gradient Norm<br/>0.9 ~ 1.3<br/>âœ… ë§¤ìš° ì•ˆì •]
        A3[ìˆ˜ë ´ ì†ë„<br/>Epoch 0.6ì—<br/>Loss < 0.9<br/>âœ… ë§¤ìš° ë¹ ë¦„]
    end

    subgraph Negative["ë¶€ì •ì  ì¸¡ë©´"]
        B1[í•™ìŠµ ì‹œê°„<br/>6ì‹œê°„+ (ì˜ˆìƒ 9ì‹œê°„)<br/>âŒ ê³¼ë„í•˜ê²Œ ëŠë¦¼]
        B2[í‰ê°€ ì‹œê°„<br/>1ì‹œê°„ 21ë¶„<br/>âŒ ë§¤ìš° ëŠë¦¼]
        B3[ROUGE ì ìˆ˜<br/>0.3831<br/>âš ï¸ ë‚®ìŒ]
    end

    subgraph Problem["ê·¼ë³¸ ë¬¸ì œ"]
        C1[gradient_accumulation<br/>= 10<br/>âŒ Config ì„¤ì •]
        C2[Effective Batch<br/>= 60<br/>âŒ ê³¼ë„í•˜ê²Œ í¼]
        C3[Steps ê³¼ë‹¤<br/>ì•½ 833 Ã— 2<br/>âŒ KoBARTì˜ 33ë°°]
    end

    Positive --> Problem
    Negative --> Problem

    style Positive fill:#c8e6c9,stroke:#2e7d32,color:#000
    style Negative fill:#ffccbc,stroke:#d84315,color:#000
    style Problem fill:#ffcdd2,stroke:#c62828,color:#fff

    style A1 fill:#aed581,stroke:#2e7d32,color:#000
    style A2 fill:#aed581,stroke:#2e7d32,color:#000
    style A3 fill:#aed581,stroke:#2e7d32,color:#000
    style B1 fill:#ef9a9a,stroke:#d84315,color:#000
    style B2 fill:#ef9a9a,stroke:#d84315,color:#000
    style B3 fill:#ef9a9a,stroke:#d84315,color:#000
    style C1 fill:#f48fb1,stroke:#c62828,color:#fff
    style C2 fill:#f48fb1,stroke:#c62828,color:#fff
    style C3 fill:#f48fb1,stroke:#c62828,color:#fff
```

**Qwen ì£¼ìš” ë°œê²¬:**

- âœ… **Train Loss ë§¤ìš° ìš°ìˆ˜**: 2.69 â†’ 0.86 (68% ê°ì†Œ, ê°€ì¥ ë¹ ë¥¸ ìˆ˜ë ´)
- âœ… **Gradient Norm ë§¤ìš° ì•ˆì •**: 0.9~1.3 ë²”ìœ„ (3ê°œ ëª¨ë¸ ì¤‘ ìµœê³ )
- âœ… **ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„**: Epoch 0.6ì— ì´ë¯¸ Loss < 0.9 ë‹¬ì„±
- âŒ **í•™ìŠµ ì‹œê°„ ê·¹ë„ë¡œ ëŠë¦¼**: 6ì‹œê°„+ (ì˜ˆìƒ 9ì‹œê°„, KoBARTì˜ 90ë°°)
- âŒ **í‰ê°€ ì‹œê°„ ê³¼ë„**: 1ì‹œê°„ 21ë¶„ (Llamaì˜ 2ë°°)
- âš ï¸ **ROUGE ì ìˆ˜ ë‚®ìŒ**: 0.3831 (KoBARTì˜ 37% ìˆ˜ì¤€)

**ë¬¸ì œ ì›ì¸:**
- **ì¹˜ëª…ì **: Config íŒŒì¼ì˜ `gradient_accumulation_steps: 10` ì„¤ì •
- Effective batch size 60 (6Ã—10) â†’ Steps ìˆ˜ê°€ 83 3ê°œë¡œ í­ì¦
- ëª…ë ¹í–‰ `--gradient_accumulation_steps 1`ì´ ì™„ì „íˆ ë¬´ì‹œë¨
- 4B ëª¨ë¸ì˜ í° í¬ê¸°ë¡œ ì¸í•œ ì¶”ê°€ ì‹œê°„

---

## 5. ëª¨ë¸ ê°„ ì„±ëŠ¥ ë¹„êµ

### 5.1 í•™ìŠµ ì‹œê°„ ë¹„êµ

```python
# ==================== í•™ìŠµ ì‹œê°„ ì¢…í•© ë¹„êµ ==================== #
training_time_comparison = {
    'kobart': {
        'total_time_seconds': 99.23,
        'total_time_formatted': '1ë¶„ 39ì´ˆ',
        'samples_per_second': 50.39,
        'speed_relative_to_kobart': '1.0x (ê¸°ì¤€)',
        'status': 'âœ… ë§¤ìš° ë¹ ë¦„'
    },
    'llama-3.2-korean-3b': {
        'total_time_seconds': 6553.30,
        'total_time_formatted': '1ì‹œê°„ 49ë¶„',
        'samples_per_second': 0.763,
        'speed_relative_to_kobart': '66.0x (66ë°° ëŠë¦¼)',
        'status': 'âŒ ë§¤ìš° ëŠë¦¼'
    },
    'qwen3-4b': {
        'total_time_seconds': 32400,  # ì˜ˆìƒ 9ì‹œê°„
        'total_time_formatted': 'ì•½ 9ì‹œê°„ (ì˜ˆìƒ)',
        'samples_per_second': 0.154,  # ì˜ˆìƒ
        'speed_relative_to_kobart': '327x (327ë°° ëŠë¦¼)',
        'status': 'âŒ ê·¹ë„ë¡œ ëŠë¦¼'
    }
}
```

**ì‹œê°„ ë¹„êµ ì‹œê°í™”:**

```mermaid
graph TB
    A[KoBART<br/>99ì´ˆ<br/>âœ… ê¸°ì¤€] --> B[Llama<br/>6553ì´ˆ<br/>66ë°° ëŠë¦¼]
    B --> C[Qwen<br/>32400ì´ˆ ì˜ˆìƒ<br/>327ë°° ëŠë¦¼]

    style A fill:#a5d6a7,stroke:#2e7d32,color:#000
    style B fill:#ffccbc,stroke:#d84315,color:#000
    style C fill:#ffcdd2,stroke:#c62828,color:#fff
```

| ëª¨ë¸ | í•™ìŠµ ì‹œê°„ | ë°°ì† (vs KoBART) | ì´ˆë‹¹ ìƒ˜í”Œ ìˆ˜ | ìƒíƒœ |
|------|----------|-----------------|-------------|------|
| **KoBART** | 1ë¶„ 39ì´ˆ | 1.0x | 50.39 | âœ… ë§¤ìš° ë¹ ë¦„ |
| **Llama** | 1ì‹œê°„ 49ë¶„ | **66.0x ëŠë¦¼** | 0.763 | âŒ ë§¤ìš° ëŠë¦¼ |
| **Qwen** | 9ì‹œê°„ (ì˜ˆìƒ) | **327x ëŠë¦¼** | 0.154 (ì˜ˆìƒ) | âŒ ê·¹ë„ë¡œ ëŠë¦¼ |

### 5.2 ROUGE ì„±ëŠ¥ ë¹„êµ

```python
# ==================== ROUGE ì ìˆ˜ ì¢…í•© ë¹„êµ ==================== #
rouge_performance_comparison = {
    'kobart': {
        'eval_rouge1': 0.4048,
        'eval_rouge2': 0.2480,
        'eval_rougeL': 0.3952,
        'eval_rouge_sum': 1.0480,
        'performance_level': 'âœ… ì–‘í˜¸ (ê¸°ì¤€)',
        'relative_to_kobart': '100%'
    },
    'llama-3.2-korean-3b': {
        'eval_rouge1': 0.1097,
        'eval_rouge2': 0.0735,
        'eval_rougeL': 0.1097,
        'eval_rouge_sum': 0.2928,
        'performance_level': 'âŒ ë§¤ìš° ë‚®ìŒ',
        'relative_to_kobart': '27.9% (1/4 ìˆ˜ì¤€)'
    },
    'qwen3-4b': {
        'eval_rouge1': 0.1432,
        'eval_rouge2': 0.0966,
        'eval_rougeL': 0.1432,
        'eval_rouge_sum': 0.3831,
        'performance_level': 'âš ï¸ ë‚®ìŒ',
        'relative_to_kobart': '36.6% (1/3 ìˆ˜ì¤€)'
    }
}
```

**ROUGE ë¹„êµ ì‹œê°í™”:**

```mermaid
graph TB
    A[KoBART<br/>ROUGE Sum: 1.048<br/>âœ… ìµœê³  ì„±ëŠ¥] --> B[Qwen<br/>ROUGE Sum: 0.383<br/>36.6% ìˆ˜ì¤€]
    A --> C[Llama<br/>ROUGE Sum: 0.293<br/>27.9% ìˆ˜ì¤€]

    style A fill:#a5d6a7,stroke:#2e7d32,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#ffccbc,stroke:#d84315,color:#000
```

| ëª¨ë¸ | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE Sum | ì„±ëŠ¥ (vs KoBART) |
|------|---------|---------|---------|-----------|-----------------|
| **KoBART** | 40.48% | 24.80% | 39.52% | **1.0480** | âœ… 100% (ê¸°ì¤€) |
| **Qwen** | 14.32% | 9.66% | 14.32% | **0.3831** | âš ï¸ 36.6% |
| **Llama** | 10.97% | 7.35% | 10.97% | **0.2928** | âŒ 27.9% |

### 5.3 Loss ìˆ˜ë ´ ì†ë„ ë¹„êµ

```python
# ==================== Loss ê°ì†Œ ì†ë„ ë¹„êµ ==================== #
loss_convergence_comparison = {
    'kobart': {
        'initial_loss': 2.3843,
        'final_loss': 1.5178,
        'reduction': 0.8665,
        'reduction_percent': 36.4,
        'convergence_speed': 'ë¹ ë¦„',
        'status': 'âœ… ì •ìƒ'
    },
    'llama-3.2-korean-3b': {
        'initial_loss': 1.6346,
        'final_loss': 1.0497,
        'reduction': 0.5849,
        'reduction_percent': 35.8,
        'convergence_speed': 'ë¹ ë¦„',
        'status': 'âœ… ì •ìƒ'
    },
    'qwen3-4b': {
        'initial_loss': 2.6867,
        'final_loss': 0.8612,  # í˜„ì¬ê¹Œì§€ ìµœì €
        'reduction': 1.8255,
        'reduction_percent': 67.9,
        'convergence_speed': 'ë§¤ìš° ë¹ ë¦„',
        'status': 'âœ… ìµœê³  ì„±ëŠ¥'
    }
}
```

**Loss ê°ì†Œ ë¹„êµ:**

| ëª¨ë¸ | ì´ˆê¸° Loss | ìµœì¢… Loss | ê°ì†ŒëŸ‰ | ê°ì†Œìœ¨ | ìˆ˜ë ´ ì†ë„ |
|------|----------|----------|--------|--------|----------|
| **Qwen** | 2.6867 | 0.8612 | -1.826 | **67.9%** | âœ… ë§¤ìš° ë¹ ë¦„ |
| **KoBART** | 2.3843 | 1.5178 | -0.867 | 36.4% | âœ… ë¹ ë¦„ |
| **Llama** | 1.6346 | 1.0497 | -0.585 | 35.8% | âœ… ë¹ ë¦„ |

### 5.4 Gradient Norm ì•ˆì •ì„± ë¹„êµ

```python
# ==================== Gradient Norm ì•ˆì •ì„± ë¹„êµ ==================== #
grad_norm_stability_comparison = {
    'kobart': {
        'range': (4.546, 6.949),
        'average': 5.748,
        'stability': 'ì•ˆì •ì ',
        'status': 'âœ… ì •ìƒ'
    },
    'llama-3.2-korean-3b': {
        'range': (1.444, 2.804),
        'average': 2.124,
        'stability': 'ë§¤ìš° ì•ˆì •ì ',
        'status': 'âœ… ìµœì '
    },
    'qwen3-4b': {
        'range': (0.857, 5.689),
        'average': 1.984,
        'stability': 'ë§¤ìš° ì•ˆì •ì  (í›„ë°˜ë¶€)',
        'status': 'âœ… ìµœì '
    }
}
```

| ëª¨ë¸ | Grad Norm ë²”ìœ„ | í‰ê·  | ì•ˆì •ì„± | í‰ê°€ |
|------|---------------|------|--------|------|
| **Qwen** | 0.86 ~ 5.69 | 1.98 | ë§¤ìš° ì•ˆì • (í›„ë°˜ë¶€) | âœ… ìµœì  |
| **Llama** | 1.44 ~ 2.80 | 2.12 | ë§¤ìš° ì•ˆì • | âœ… ìµœì  |
| **KoBART** | 4.55 ~ 6.95 | 5.75 | ì•ˆì • | âœ… ì •ìƒ |

### 5.5 ì¢…í•© ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸ (ê°œë…ì )

```python
# ==================== ì¢…í•© ì„±ëŠ¥ í‰ê°€ (5ì  ë§Œì ) ==================== #
overall_performance_rating = {
    'kobart': {
        'í•™ìŠµ ì†ë„': 5.0,      # ë§¤ìš° ë¹ ë¦„
        'ROUGE ì„±ëŠ¥': 5.0,     # ê°€ì¥ ë†’ìŒ
        'Loss ìˆ˜ë ´': 4.0,      # ë¹ ë¦„
        'Gradient ì•ˆì •ì„±': 4.0, # ì•ˆì •
        'íš¨ìœ¨ì„±': 5.0,         # ìµœê³ 
        'total_score': 4.6     # í‰ê· 
    },
    'llama-3.2-korean-3b': {
        'í•™ìŠµ ì†ë„': 1.0,      # ë§¤ìš° ëŠë¦¼
        'ROUGE ì„±ëŠ¥': 1.0,     # ë§¤ìš° ë‚®ìŒ
        'Loss ìˆ˜ë ´': 4.0,      # ë¹ ë¦„
        'Gradient ì•ˆì •ì„±': 5.0, # ë§¤ìš° ì•ˆì •
        'íš¨ìœ¨ì„±': 1.0,         # ë‚®ìŒ
        'total_score': 2.4     # í‰ê· 
    },
    'qwen3-4b': {
        'í•™ìŠµ ì†ë„': 0.5,      # ê·¹ë„ë¡œ ëŠë¦¼
        'ROUGE ì„±ëŠ¥': 2.0,     # ë‚®ìŒ
        'Loss ìˆ˜ë ´': 5.0,      # ë§¤ìš° ë¹ ë¦„
        'Gradient ì•ˆì •ì„±': 5.0, # ë§¤ìš° ì•ˆì •
        'íš¨ìœ¨ì„±': 0.5,         # ë§¤ìš° ë‚®ìŒ
        'total_score': 2.6     # í‰ê· 
    }
}
```

**ì¢…í•© ìˆœìœ„:**

1. ğŸ¥‡ **KoBART** - 4.6ì  (ì••ë„ì  1ìœ„)
2. ğŸ¥‰ **Qwen3-4B** - 2.6ì  (2ìœ„, but ì‹œê°„ ë¬¸ì œ ì‹¬ê°)
3. ğŸ¥ˆ **Llama-3.2-Korean-3B** - 2.4ì  (3ìœ„)

---

## 6. ì£¼ìš” ë°œê²¬ ë° ì¸ì‚¬ì´íŠ¸

### 6.1 í•µì‹¬ ë°œê²¬ ì‚¬í•­

```python
# ==================== ì‹¤í—˜ì˜ 5ëŒ€ í•µì‹¬ ë°œê²¬ ==================== #
key_findings = {
    # ---------------------- ë°œê²¬ 1: Config íŒŒì¼ ìš°ì„ ìˆœìœ„ ë¬¸ì œ ---------------------- #
    'finding_1': {
        'title': 'Config íŒŒì¼ ì„¤ì •ì´ ëª…ë ¹í–‰ ì¸ìë¥¼ ì˜¤ë²„ë¼ì´ë“œí•¨',
        'severity': 'âŒ Critical',
        'description': [
            'ëª…ë ¹í–‰ì—ì„œ `--gradient_accumulation_steps 1`ì„ ì§€ì •í–ˆì§€ë§Œ',
            'Config íŒŒì¼ì˜ `gradient_accumulation_steps` ê°’ì´ ìš°ì„  ì ìš©ë¨',
            'Llama: 4, Qwen: 10ìœ¼ë¡œ ì„¤ì •ë˜ì–´ í•™ìŠµ ì‹œê°„ í­ì¦'
        ],
        'impact': {
            'llama': 'í•™ìŠµ ì‹œê°„ 66ë°° ì¦ê°€ (99ì´ˆ â†’ 6553ì´ˆ)',
            'qwen': 'í•™ìŠµ ì‹œê°„ 327ë°° ì¦ê°€ (99ì´ˆ â†’ 32400ì´ˆ ì˜ˆìƒ)'
        },
        'root_cause': 'Config ë¡œë”© ì‹œ ëª…ë ¹í–‰ ì¸ì ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ ë¯¸êµ¬í˜„',
        'solution': [
            'ì¦‰ì‹œ: Config íŒŒì¼ì˜ gradient_accumulation_stepsë¥¼ 1ë¡œ ìˆ˜ì •',
            'ì¥ê¸°: Config ë¡œë”© ì‹œ ëª…ë ¹í–‰ ì¸ì ìš°ì„  ì ìš© ë¡œì§ êµ¬í˜„'
        ]
    },

    # ---------------------- ë°œê²¬ 2: ëª¨ë¸ í¬ê¸°ì™€ ì„±ëŠ¥ ë¶ˆì¼ì¹˜ ---------------------- #
    'finding_2': {
        'title': 'í° ëª¨ë¸ì´ ì‘ì€ ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ë‚®ìŒ',
        'severity': 'âš ï¸ High',
        'description': [
            'KoBART (123M): ROUGE Sum 1.048',
            'Llama (3B): ROUGE Sum 0.293 (KoBARTì˜ 28%)',
            'Qwen (4B): ROUGE Sum 0.383 (KoBARTì˜ 37%)'
        ],
        'possible_reasons': [
            '1. Causal LM ëª¨ë¸ì´ Seq2Seqë³´ë‹¤ ìš”ì•½ íƒœìŠ¤í¬ì— ë¶€ì í•©',
            '2. Prompt ì—”ì§€ë‹ˆì–´ë§ ë¶€ì¡± (Instruct ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ê°€ ì¤‘ìš”)',
            '3. 2 Epochë§Œìœ¼ë¡œëŠ” ëŒ€í˜• ëª¨ë¸ í•™ìŠµ ë¶€ì¡±',
            '4. LoRA/QLoRAë¡œ ì¸í•œ í‘œí˜„ë ¥ ì œí•œ',
            '5. í•œêµ­ì–´ ë°ì´í„°ì— ëŒ€í•œ ì‚¬ì „í•™ìŠµ ë¶€ì¡±'
        ],
        'recommendation': [
            'Causal LM ëª¨ë¸ì— ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©',
            'Epoch ìˆ˜ ì¦ê°€ (ìµœì†Œ 5~10 Epoch)',
            'Full fine-tuning ê³ ë ¤ (LoRA ëŒ€ì‹ )'
        ]
    },

    # ---------------------- ë°œê²¬ 3: KoBARTì˜ ì••ë„ì  íš¨ìœ¨ì„± ---------------------- #
    'finding_3': {
        'title': 'KoBARTê°€ ì†ë„ì™€ ì„±ëŠ¥ ëª¨ë‘ ìµœê³ ',
        'severity': 'âœ… Insight',
        'description': [
            'í•™ìŠµ ì‹œê°„: 99ì´ˆ (ë‹¤ë¥¸ ëª¨ë¸ì˜ 1/66 ~ 1/327)',
            'ROUGE Sum: 1.048 (ë‹¤ë¥¸ ëª¨ë¸ì˜ 2.7 ~ 3.6ë°°)',
            'Effective Batch Size: 50 (ì ì ˆí•œ í¬ê¸°)'
        ],
        'why_kobart_wins': [
            '1. Seq2Seq ì•„í‚¤í…ì²˜ê°€ ìš”ì•½ íƒœìŠ¤í¬ì— ìµœì í™”ë¨',
            '2. ëª¨ë¸ í¬ê¸°ê°€ ì‘ì•„ ë¹ ë¥¸ í•™ìŠµê³¼ ì¶”ë¡  ê°€ëŠ¥',
            '3. Config ì„¤ì •ì´ ëª…ë ¹í–‰ ì¸ìì™€ ì¶©ëŒí•˜ì§€ ì•ŠìŒ',
            '4. í•œêµ­ì–´ ìš”ì•½ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ (digit82/kobart-summarization)'
        ],
        'recommendation': [
            'ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…: KoBART ë‹¨ë… ì‚¬ìš©',
            'ì•™ìƒë¸”: KoBARTë¥¼ main ëª¨ë¸ë¡œ, ë‹¤ë¥¸ ëª¨ë¸ì€ ë³´ì¡°'
        ]
    },

    # ---------------------- ë°œê²¬ 4: Qwenì˜ ë¹ ë¥¸ ìˆ˜ë ´ vs ëŠë¦° ì†ë„ ---------------------- #
    'finding_4': {
        'title': 'Qwenì€ Loss ìˆ˜ë ´ì€ ë¹ ë¥´ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ê·¹ë„ë¡œ ëŠë¦¼',
        'severity': 'âš ï¸ High',
        'description': [
            'Train Loss: 2.69 â†’ 0.86 (67.9% ê°ì†Œ, ìµœê³ )',
            'Gradient Norm: 0.9~1.3 (ë§¤ìš° ì•ˆì •, ìµœê³ )',
            'í•˜ì§€ë§Œ í•™ìŠµ ì‹œê°„: 9ì‹œê°„ ì˜ˆìƒ (KoBARTì˜ 327ë°°)'
        ],
        'trade_off': {
            'pros': 'Loss ìˆ˜ë ´ ì†ë„ì™€ ì•ˆì •ì„±ì´ ìš°ìˆ˜',
            'cons': 'í•™ìŠµ ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ì–´ ì‹¤ìš©ì„± ì—†ìŒ'
        },
        'root_cause': 'gradient_accumulation_steps: 10 (Config ì„¤ì •)',
        'recommendation': [
            'ì¦‰ì‹œ: Config íŒŒì¼ ìˆ˜ì • (gradient_accumulation_steps: 1)',
            'ì¬ì‹¤í—˜: ìˆ˜ì • í›„ í•™ìŠµ ì‹œê°„ì´ 1~2ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒ'
        ]
    },

    # ---------------------- ë°œê²¬ 5: Causal LMì˜ í‰ê°€ ì‹œê°„ ë¬¸ì œ ---------------------- #
    'finding_5': {
        'title': 'Causal LM ëª¨ë¸ì˜ í‰ê°€(ì¶”ë¡ ) ì‹œê°„ì´ ê³¼ë„í•˜ê²Œ ëŠë¦¼',
        'severity': 'âš ï¸ High',
        'description': [
            'KoBART í‰ê°€: 36ì´ˆ (499ê°œ ìƒ˜í”Œ)',
            'Llama í‰ê°€: 3655ì´ˆ = 1ì‹œê°„ (100ë°° ëŠë¦¼)',
            'Qwen í‰ê°€: 4852ì´ˆ = 1ì‹œê°„ 21ë¶„ (134ë°° ëŠë¦¼)'
        ],
        'root_cause': [
            'Causal LMì€ í† í°ì„ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„± (autoregressive)',
            'Seq2SeqëŠ” ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥',
            'Beam searchê°€ Causal LMì—ì„œ ë” ëŠë¦¼'
        ],
        'recommendation': [
            'num_beams ì¤„ì´ê¸° (4 â†’ 1)',
            'max_length ì¤„ì´ê¸° (200 â†’ 100)',
            'í‰ê°€ ìƒ˜í”Œ ìˆ˜ ì¤„ì´ê¸° (499 â†’ 100)'
        ]
    }
}
```

### 6.2 í•™ìŠµ ì§€í‘œ ì¸ì‚¬ì´íŠ¸

```python
# ==================== í•™ìŠµ ì§€í‘œë¡œë¶€í„°ì˜ ì¸ì‚¬ì´íŠ¸ ==================== #
metrics_insights = {
    # ---------------------- Loss vs ROUGE ìƒê´€ê´€ê³„ ---------------------- #
    'loss_rouge_correlation': {
        'observation': 'Train Lossê°€ ë‚®ë‹¤ê³  ROUGE ì ìˆ˜ê°€ ë†’ì€ ê²ƒì€ ì•„ë‹˜',
        'data': [
            'Qwen: Train Loss 0.86 (ìµœì €) â†’ ROUGE Sum 0.38 (ì¤‘ê°„)',
            'Llama: Train Loss 1.05 (ì¤‘ê°„) â†’ ROUGE Sum 0.29 (ìµœì €)',
            'KoBART: Train Loss 1.52 (ìµœê³ ) â†’ ROUGE Sum 1.05 (ìµœê³ )'
        ],
        'explanation': [
            'Train LossëŠ” í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì í•©ë„',
            'ROUGEëŠ” ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ìƒì„± í’ˆì§ˆ',
            'ë‘ ì§€í‘œëŠ” ë…ë¦½ì ì´ë©°, ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ ì‚¬ì „í•™ìŠµì´ ë” ì¤‘ìš”'
        ]
    },

    # ---------------------- Gradient Normì˜ ì¤‘ìš”ì„± ---------------------- #
    'grad_norm_importance': {
        'observation': 'Gradient Normì´ ì•ˆì •ì ì¼ìˆ˜ë¡ í•™ìŠµì´ ì•ˆì •ì ',
        'data': [
            'Qwen: Grad Norm 0.9~1.3 â†’ ì•ˆì •ì  í•™ìŠµ, ë¹ ë¥¸ ìˆ˜ë ´',
            'Llama: Grad Norm 1.4~2.8 â†’ ì•ˆì •ì  í•™ìŠµ',
            'KoBART: Grad Norm 4.5~7.0 â†’ ì•½ê°„ ë†’ì§€ë§Œ ì •ìƒ'
        ],
        'recommendation': 'Gradient Normì´ 3.0 ì´ìƒì´ë©´ max_grad_norm í´ë¦¬í•‘ ê³ ë ¤'
    },

    # ---------------------- Learning Rate ìŠ¤ì¼€ì¤„ì˜ íš¨ê³¼ ---------------------- #
    'lr_schedule_effect': {
        'observation': 'Warmup + Linear Decayê°€ ëª¨ë“  ëª¨ë¸ì—ì„œ ì •ìƒ ì‘ë™',
        'data': [
            'ëª¨ë“  ëª¨ë¸ì´ ì´ˆê¸°ì— ì‘ì€ LRë¡œ ì‹œì‘ (3.6e-07)',
            'Warmup í›„ ëª©í‘œ LR ë„ë‹¬ (KoBART: 2e-5, Llama/Qwen: 1e-5)',
            'Epochê°€ ì§„í–‰ë˜ë©´ì„œ ì„ í˜• ê°ì†Œ'
        ],
        'recommendation': 'Warmup ratio 0.1ì´ ì ì ˆí•¨ (ì „ì²´ ìŠ¤í…ì˜ 10%)'
    }
}
```

---

## 7. ë¬¸ì œì  ë° ê°œì„  ë°©í–¥

### 7.1 ì¦‰ì‹œ í•´ê²° í•„ìš” (P0 - Critical)

```python
# ==================== P0: ì¦‰ì‹œ ìˆ˜ì • ì‚¬í•­ ==================== #
p0_critical_fixes = [
    # ---------------------- 1. Config íŒŒì¼ ìˆ˜ì • (ìµœìš°ì„ ) ---------------------- #
    {
        'priority': 'P0',
        'title': 'Llamaì™€ Qwen Config íŒŒì¼ì˜ gradient_accumulation_steps ìˆ˜ì •',
        'affected_files': [
            'configs/models/llama_3.2_korean_3b.yaml',
            'configs/models/qwen3_4b.yaml'
        ],
        'current_values': {
            'llama': 'gradient_accumulation_steps: 4',
            'qwen': 'gradient_accumulation_steps: 10'
        },
        'required_changes': {
            'llama': 'gradient_accumulation_steps: 1',
            'qwen': 'gradient_accumulation_steps: 1'
        },
        'expected_improvement': {
            'llama': 'í•™ìŠµ ì‹œê°„ 1/4 ë‹¨ì¶• (1ì‹œê°„ 49ë¶„ â†’ 27ë¶„)',
            'qwen': 'í•™ìŠµ ì‹œê°„ 1/10 ë‹¨ì¶• (9ì‹œê°„ â†’ 54ë¶„)'
        },
        'action_items': [
            '1. configs/models/llama_3.2_korean_3b.yaml íŒŒì¼ ì—´ê¸°',
            '2. training.gradient_accumulation_steps: 4 â†’ 1 ë³€ê²½',
            '3. configs/models/qwen3_4b.yaml íŒŒì¼ ì—´ê¸°',
            '4. training.gradient_accumulation_steps: 10 â†’ 1 ë³€ê²½',
            '5. ì‹¤í—˜ ì¬ì‹¤í–‰'
        ],
        'estimated_effort': '5ë¶„',
        'impact': 'í•™ìŠµ ì‹œê°„ 4~10ë°° ë‹¨ì¶•'
    },

    # ---------------------- 2. Config ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ êµ¬í˜„ ---------------------- #
    {
        'priority': 'P0',
        'title': 'ëª…ë ¹í–‰ ì¸ìê°€ Config íŒŒì¼ì„ ì˜¤ë²„ë¼ì´ë“œí•˜ë„ë¡ ë¡œì§ ìˆ˜ì •',
        'problem': 'í˜„ì¬ Config íŒŒì¼ ê°’ì´ ëª…ë ¹í–‰ ì¸ìë¥¼ ë¬´ì‹œí•¨',
        'solution': [
            '1. Config ë¡œë”© í›„ ëª…ë ¹í–‰ ì¸ì ì¬ì ìš©',
            '2. argsì— ê°’ì´ ìˆìœ¼ë©´ config ê°’ì„ ì˜¤ë²„ë¼ì´ë“œ',
            '3. ë¡œê·¸ì— ìµœì¢… ì ìš©ëœ ê°’ ì¶œë ¥'
        ],
        'implementation': '''
# src/config/config_loader.py (ì˜ˆì‹œ)
def override_config_with_args(config, args):
    """ëª…ë ¹í–‰ ì¸ìë¡œ Config ì˜¤ë²„ë¼ì´ë“œ"""
    if hasattr(args, 'batch_size') and args.batch_size is not None:
        config.training.batch_size = args.batch_size
        print(f"âœ… Config overridden: batch_size = {args.batch_size}")

    if hasattr(args, 'gradient_accumulation_steps') and args.gradient_accumulation_steps is not None:
        config.training.gradient_accumulation_steps = args.gradient_accumulation_steps
        print(f"âœ… Config overridden: gradient_accumulation_steps = {args.gradient_accumulation_steps}")

    # ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
    return config
        ''',
        'estimated_effort': '1ì‹œê°„',
        'impact': 'í–¥í›„ ëª¨ë“  ì‹¤í—˜ì—ì„œ ëª…ë ¹í–‰ ì¸ì ì •ìƒ ì‘ë™'
    }
]
```

### 7.2 ë†’ì€ ìš°ì„ ìˆœìœ„ (P1 - High)

```python
# ==================== P1: ë†’ì€ ìš°ì„ ìˆœìœ„ ê°œì„  ì‚¬í•­ ==================== #
p1_high_priority = [
    # ---------------------- 1. Causal LM í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ---------------------- #
    {
        'priority': 'P1',
        'title': 'Llamaì™€ Qwenì— ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©',
        'problem': 'Causal LM ëª¨ë¸ì˜ ROUGE ì ìˆ˜ê°€ ë§¤ìš° ë‚®ìŒ (0.29, 0.38)',
        'root_cause': 'Instruct ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì´ ì¤‘ìš”í•œë° í˜„ì¬ ë¯¸ì ìš©',
        'solution': [
            '1. src/prompts/templates.pyì— ì •ì˜ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©',
            '2. Few-shot ë˜ëŠ” Chain-of-Thought í”„ë¡¬í”„íŠ¸ ì‚¬ìš©',
            '3. í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì‘ì„±'
        ],
        'example_prompt': '''
# Few-shot í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
prompt = """ë‹¤ìŒì€ ëŒ€í™”ë¥¼ ìš”ì•½í•œ ì˜ˆì‹œì…ë‹ˆë‹¤:

ì˜ˆì‹œ 1:
ëŒ€í™”: #Person1#: ë‚´ì¼ ëª‡ ì‹œì— ë§Œë‚ ê¹Œìš”? #Person2#: ì˜¤í›„ 3ì‹œëŠ” ì–´ë– ì„¸ìš”?
ìš”ì•½: ë‘ ì‚¬ëŒì´ ë‚´ì¼ ì˜¤í›„ 3ì‹œì— ë§Œë‚˜ê¸°ë¡œ ì•½ì†í•¨.

ì´ì œ ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:
ëŒ€í™”: {dialogue}
ìš”ì•½:"""
        ''',
        'expected_improvement': 'ROUGE Sum 0.3~0.4 â†’ 0.6~0.8 (2ë°° í–¥ìƒ)',
        'estimated_effort': '2ì‹œê°„',
        'impact': 'Causal LM ëª¨ë¸ì˜ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ'
    },

    # ---------------------- 2. í‰ê°€ ì‹œê°„ ìµœì í™” ---------------------- #
    {
        'priority': 'P1',
        'title': 'Causal LM í‰ê°€(ì¶”ë¡ ) ì‹œê°„ ë‹¨ì¶•',
        'problem': 'Llamaì™€ Qwenì˜ í‰ê°€ ì‹œê°„ì´ 1ì‹œê°„ ì´ìƒ ì†Œìš”',
        'solution': [
            '1. num_beams ê°ì†Œ (4 â†’ 2 or 1)',
            '2. max_length ê°ì†Œ (200 â†’ 100)',
            '3. í‰ê°€ ìƒ˜í”Œ ìˆ˜ ì œí•œ (499 â†’ 100)',
            '4. batch_size ì¦ê°€ (í‰ê°€ ì‹œì—ë§Œ)'
        ],
        'expected_improvement': 'í‰ê°€ ì‹œê°„ 1ì‹œê°„ â†’ 10ë¶„ (6ë°° ë‹¨ì¶•)',
        'estimated_effort': '30ë¶„',
        'impact': 'ì „ì²´ ì‹¤í—˜ ì‹œê°„ ëŒ€í­ ë‹¨ì¶•'
    },

    # ---------------------- 3. Epoch ìˆ˜ ì¦ê°€ ---------------------- #
    {
        'priority': 'P1',
        'title': 'Epoch ìˆ˜ë¥¼ 2 â†’ 5~10ìœ¼ë¡œ ì¦ê°€',
        'problem': '2 Epochë§Œìœ¼ë¡œëŠ” ëŒ€í˜• ëª¨ë¸ í•™ìŠµ ë¶€ì¡±',
        'rationale': [
            'KoBART: 2 Epochë¡œ ì¶©ë¶„ (ì‘ì€ ëª¨ë¸)',
            'Llama/Qwen: 5~10 Epoch í•„ìš” (í° ëª¨ë¸, LoRA)'
        ],
        'solution': 'Config íŒŒì¼ì—ì„œ epochs: 2 â†’ epochs: 5 ë˜ëŠ” 10',
        'expected_improvement': 'ROUGE Sum 10~20% í–¥ìƒ',
        'estimated_effort': '5ë¶„ (ì„¤ì • ë³€ê²½)',
        'impact': 'Causal LM ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒ'
    }
]
```

### 7.3 ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (P2 - Medium)

```python
# ==================== P2: ì¤‘ê°„ ìš°ì„ ìˆœìœ„ ê°œì„  ì‚¬í•­ ==================== #
p2_medium_priority = [
    # ---------------------- 1. ì•™ìƒë¸” ì „ëµ ìµœì í™” ---------------------- #
    {
        'priority': 'P2',
        'title': 'KoBART ì¤‘ì‹¬ì˜ ì•™ìƒë¸” ì „ëµ',
        'problem': 'í˜„ì¬ Llamaì™€ Qwenì˜ ì„±ëŠ¥ì´ ë„ˆë¬´ ë‚®ì•„ ì•™ìƒë¸” íš¨ê³¼ ë¯¸ë¯¸',
        'solution': [
            '1. KoBARTë¥¼ main ëª¨ë¸ë¡œ ì‚¬ìš© (ê°€ì¤‘ì¹˜ 0.7)',
            '2. Llamaì™€ Qwenì€ ë³´ì¡° ëª¨ë¸ (ê°€ì¤‘ì¹˜ 0.15ì”©)',
            '3. Weighted Average ì•™ìƒë¸” ì „ëµ ì‚¬ìš©',
            '4. Stacking ëŒ€ì‹  ê°„ë‹¨í•œ Voting ê³ ë ¤'
        ],
        'expected_improvement': 'ROUGE Sum 1.05 â†’ 1.10 (5% í–¥ìƒ)',
        'estimated_effort': '1ì‹œê°„',
        'impact': 'ì•™ìƒë¸” íš¨ê³¼ ê°œì„ '
    },

    # ---------------------- 2. Full Fine-tuning ì‹¤í—˜ ---------------------- #
    {
        'priority': 'P2',
        'title': 'LoRA ëŒ€ì‹  Full Fine-tuning ì‹œë„',
        'problem': 'LoRA/QLoRAë¡œ ì¸í•œ í‘œí˜„ë ¥ ì œí•œ ê°€ëŠ¥ì„±',
        'solution': [
            '1. Llamaì™€ Qwenì—ì„œ LoRA ë¹„í™œì„±í™”',
            '2. ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ (GPU ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)',
            '3. ë” ì‘ì€ Batch Sizeë¡œ ì¡°ì •'
        ],
        'expected_improvement': 'ROUGE Sum 20~30% í–¥ìƒ (ì˜ˆìƒ)',
        'estimated_effort': '2ì‹œê°„',
        'impact': 'Causal LM ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ ê°€ëŠ¥'
    },

    # ---------------------- 3. ë°ì´í„° ì¦ê°• ê°•í™” ---------------------- #
    {
        'priority': 'P2',
        'title': 'ë°ì´í„° ì¦ê°• ë¹„ìœ¨ ì¦ê°€',
        'current': 'augmentation_ratio: 0.1 (10%)',
        'solution': [
            '1. augmentation_ratio: 0.1 â†’ 0.3 (30%)',
            '2. augmentation_methods ì¶”ê°€ (synonym, paraphrase)',
            '3. max_train_samples ì¦ê°€ (2500 â†’ 5000)'
        ],
        'expected_improvement': 'ROUGE Sum 5~10% í–¥ìƒ',
        'estimated_effort': '1ì‹œê°„',
        'impact': 'ëª¨ë“  ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ'
    }
]
```

### 7.4 ê°œì„  ë°©í–¥ ìš°ì„ ìˆœìœ„ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph P0["P0 - Critical (ì¦‰ì‹œ)"]
        A1[Config íŒŒì¼ ìˆ˜ì •<br/>gradient_accumulation_steps]
        A2[Config ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ êµ¬í˜„<br/>ëª…ë ¹í–‰ ì¸ì ìš°ì„ ]
    end

    subgraph P1["P1 - High (1ì£¼ì¼)"]
        B1[í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§<br/>Causal LM ìµœì í™”]
        B2[í‰ê°€ ì‹œê°„ ìµœì í™”<br/>num_beams, max_length ê°ì†Œ]
        B3[Epoch ìˆ˜ ì¦ê°€<br/>2 â†’ 5~10]
    end

    subgraph P2["P2 - Medium (2ì£¼ì¼)"]
        C1[ì•™ìƒë¸” ì „ëµ ìµœì í™”<br/>KoBART ì¤‘ì‹¬]
        C2[Full Fine-tuning ì‹¤í—˜<br/>LoRA ëŒ€ì‹ ]
        C3[ë°ì´í„° ì¦ê°• ê°•í™”<br/>ë¹„ìœ¨ ì¦ê°€]
    end

    P0 --> P1 --> P2

    style P0 fill:#ffcdd2,stroke:#c62828,color:#000
    style P1 fill:#fff9c4,stroke:#f57f17,color:#000
    style P2 fill:#c5e1a5,stroke:#558b2f,color:#000

    style A1 fill:#ef9a9a,stroke:#c62828,color:#000
    style A2 fill:#ef9a9a,stroke:#c62828,color:#000
    style B1 fill:#fff59d,stroke:#f57f17,color:#000
    style B2 fill:#fff59d,stroke:#f57f17,color:#000
    style B3 fill:#fff59d,stroke:#f57f17,color:#000
    style C1 fill:#dce775,stroke:#558b2f,color:#000
    style C2 fill:#dce775,stroke:#558b2f,color:#000
    style C3 fill:#dce775,stroke:#558b2f,color:#000
```

---

## 8. ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### 8.1 ì‹¤í—˜ ì¢…í•© í‰ê°€

```python
# ==================== ì‹¤í—˜ ì¢…í•© í‰ê°€ ==================== #
experiment_summary = {
    # ---------------------- ì„±ê³µ ìš”ì†Œ ---------------------- #
    'successes': [
        'âœ… KoBART ëª¨ë¸ í•™ìŠµ ì„±ê³µ (1ë¶„ 39ì´ˆ, ROUGE Sum 1.048)',
        'âœ… Llama ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ì•ˆì •ì ì¸ Loss ê°ì†Œ)',
        'âœ… Qwen ëª¨ë¸ ë§¤ìš° ë¹ ë¥¸ ìˆ˜ë ´ (Loss 2.69 â†’ 0.86)',
        'âœ… ëª¨ë“  ëª¨ë¸ì—ì„œ Gradient Norm ì•ˆì •ì ',
        'âœ… í•™ìŠµ ì§€í‘œ ë¡œê¹… ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì •ìƒ ì‘ë™'
    ],

    # ---------------------- ì‹¤íŒ¨ ìš”ì†Œ ---------------------- #
    'failures': [
        'âŒ Config íŒŒì¼ ì„¤ì •ì´ ëª…ë ¹í–‰ ì¸ìë¥¼ ì˜¤ë²„ë¼ì´ë“œ',
        'âŒ Llamaì™€ Qwenì˜ í•™ìŠµ ì‹œê°„ ê³¼ë„ (66ë°°, 327ë°°)',
        'âŒ Causal LM ëª¨ë¸ì˜ ROUGE ì ìˆ˜ ë§¤ìš° ë‚®ìŒ (0.29, 0.38)',
        'âŒ í‰ê°€ ì‹œê°„ ê³¼ë„ (Causal LMì—ì„œ 1ì‹œê°„ ì´ìƒ)',
        'âŒ ì•™ìƒë¸” ì „ëµ ë¯¸ì‹¤í–‰ (Qwen í•™ìŠµ ë¯¸ì™„ë£Œ)'
    ],

    # ---------------------- í•™ìŠµëœ êµí›ˆ ---------------------- #
    'lessons_learned': [
        'ğŸ“ Config íŒŒì¼ ì„¤ì •ì´ ëª…ë ¹í–‰ë³´ë‹¤ ìš°ì„  ì ìš©ë¨ â†’ ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ í•„ìš”',
        'ğŸ“ gradient_accumulation_stepsê°€ í•™ìŠµ ì‹œê°„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ë§¤ìš° í¼',
        'ğŸ“ KoBART(Seq2Seq)ê°€ Causal LMë³´ë‹¤ ìš”ì•½ íƒœìŠ¤í¬ì— í›¨ì”¬ íš¨ìœ¨ì ',
        'ğŸ“ Causal LMì€ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì—†ì´ëŠ” ì„±ëŠ¥ì´ ë§¤ìš° ë‚®ìŒ',
        'ğŸ“ ëª¨ë¸ í¬ê¸°ê°€ í¬ë‹¤ê³  ì„±ëŠ¥ì´ ì¢‹ì€ ê²ƒì€ ì•„ë‹˜ (task-specific)'
    ],

    # ---------------------- ì•ìœ¼ë¡œì˜ ë°©í–¥ ---------------------- #
    'future_direction': [
        'ğŸ¯ ì¦‰ì‹œ: Config íŒŒì¼ ìˆ˜ì • í›„ ì¬ì‹¤í—˜ (í•™ìŠµ ì‹œê°„ ëŒ€í­ ë‹¨ì¶• ì˜ˆìƒ)',
        'ğŸ¯ ë‹¨ê¸°: Causal LMì— í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©',
        'ğŸ¯ ì¤‘ê¸°: KoBART ì¤‘ì‹¬ì˜ ì•™ìƒë¸” ì „ëµ êµ¬í˜„',
        'ğŸ¯ ì¥ê¸°: Config ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ ë° í‰ê°€ ìµœì í™” êµ¬í˜„'
    ]
}
```

### 8.2 ëª¨ë¸ë³„ ê¶Œì¥ì‚¬í•­

| ëª¨ë¸ | í˜„ì¬ ìƒíƒœ | ê¶Œì¥ ì¡°ì¹˜ | ì˜ˆìƒ íš¨ê³¼ |
|------|----------|----------|----------|
| **KoBART** | âœ… ìµœê³  ì„±ëŠ¥ | í˜„ì¬ ì„¤ì • ìœ ì§€<br/>Epoch 3~5ë¡œ ì¦ê°€ ê³ ë ¤ | ROUGE Sum 1.05 â†’ 1.15 |
| **Llama** | âš ï¸ ì„±ëŠ¥ ë‚®ìŒ, ì‹œê°„ ê³¼ë„ | gradient_accumulation_steps: 1<br/>í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©<br/>Epoch 5~10ìœ¼ë¡œ ì¦ê°€ | í•™ìŠµ ì‹œê°„ 1/4 ë‹¨ì¶•<br/>ROUGE Sum 0.29 â†’ 0.6~0.8 |
| **Qwen** | ğŸ”„ ì§„í–‰ ì¤‘, ì‹œê°„ ê·¹ë„ë¡œ ëŠë¦¼ | gradient_accumulation_steps: 1<br/>í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©<br/>Epoch 5~10ìœ¼ë¡œ ì¦ê°€ | í•™ìŠµ ì‹œê°„ 1/10 ë‹¨ì¶•<br/>ROUGE Sum 0.38 â†’ 0.7~0.9 |

### 8.3 ìµœì¢… ê¶Œì¥ ì‹¤í—˜ ì„¤ì •

```bash
# ==================== ê¶Œì¥ ì‹¤í—˜ ì„¤ì • (ê°œì„  ë²„ì „) ==================== #

# ---------------------- 1. Config íŒŒì¼ ë¨¼ì € ìˆ˜ì • ---------------------- #
# configs/models/llama_3.2_korean_3b.yaml
# training.gradient_accumulation_steps: 4 â†’ 1

# configs/models/qwen3_4b.yaml
# training.gradient_accumulation_steps: 10 â†’ 1

# ---------------------- 2. ëª…ë ¹ì–´ ì‹¤í–‰ ---------------------- #
python scripts/train.py \
  --mode full \
  --models kobart llama-3.2-korean-3b qwen3-4b \
  --epochs 5 \
  --batch_size 10 \
  --learning_rate 2e-5 \
  --gradient_accumulation_steps 1 \
  --warmup_ratio 0.1 \
  --use_augmentation \
  --augmentation_methods back_translation paraphrase \
  --augmentation_ratio 0.3 \
  --k_folds 5 \
  --fold_seed 42 \
  --ensemble_strategy weighted_avg \
  --ensemble_weights 0.7 0.15 0.15 \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --max_train_samples 5000 \
  --num_beams 2 \
  --max_length 150 \
  --save_visualizations \
  --experiment_name strategy3_triple_optimized \
  --seed 42

# ---------------------- ì˜ˆìƒ ê²°ê³¼ ---------------------- #
# KoBART: 5ë¶„, ROUGE Sum 1.15
# Llama: 30ë¶„, ROUGE Sum 0.7
# Qwen: 1ì‹œê°„, ROUGE Sum 0.8
# ì•™ìƒë¸”: ROUGE Sum 1.2~1.3
# ì „ì²´ ì‹œê°„: ì•½ 1.5ì‹œê°„
```

### 8.4 í•µì‹¬ ìš”ì•½

```mermaid
graph TB
    A[ì‹¤í—˜ ê²°ê³¼] --> B[KoBART ì••ë„ì  1ìœ„<br/>ì†ë„ Ã— ì„±ëŠ¥ ìµœê³ ]
    A --> C[Llama & Qwen<br/>Config ë¬¸ì œë¡œ ì‹¤íŒ¨]

    B --> D[ê¶Œì¥: KoBART ë‹¨ë… ë˜ëŠ”<br/>KoBART ì¤‘ì‹¬ ì•™ìƒë¸”]
    C --> E[ì¦‰ì‹œ ìˆ˜ì •: Config íŒŒì¼<br/>gradient_accumulation_steps: 1]

    D --> F[ë‹¨ê¸° ëª©í‘œ<br/>ROUGE Sum 1.2~1.3]
    E --> F

    style A fill:#e3f2fd,stroke:#1976d2,color:#000
    style B fill:#a5d6a7,stroke:#2e7d32,color:#000
    style C fill:#ffccbc,stroke:#d84315,color:#000
    style D fill:#c8e6c9,stroke:#2e7d32,color:#000
    style E fill:#fff9c4,stroke:#f57f17,color:#000
    style F fill:#66bb6a,stroke:#1b5e20,color:#fff
```

**í•µì‹¬ ë©”ì‹œì§€:**
1. ğŸ¥‡ **KoBARTê°€ ìµœê³ **: ì†ë„(99ì´ˆ)ì™€ ì„±ëŠ¥(1.048) ëª¨ë‘ ì••ë„ì 
2. âš ï¸ **Config íŒŒì¼ ë¬¸ì œ ì‹¬ê°**: gradient_accumulation_steps ì„¤ì •ìœ¼ë¡œ í•™ìŠµ ì‹œê°„ 66~327ë°° ì¦ê°€
3. ğŸ”§ **ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”**: Config íŒŒì¼ ìˆ˜ì •ë§Œìœ¼ë¡œë„ ê·¹ì ì¸ ê°œì„  ì˜ˆìƒ
4. ğŸ¯ **ì•™ìƒë¸” ì „ëµ**: KoBART ì¤‘ì‹¬(70%)ìœ¼ë¡œ êµ¬ì„±
5. ğŸ“ˆ **í–¥í›„ ê°œì„ **: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ + Epoch ì¦ê°€ë¡œ Causal LM ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥

---

## 9. ë¶€ë¡: ìƒì„¸ ë¡œê·¸ ë°ì´í„°

### 9.1 KoBART ì „ì²´ í•™ìŠµ ë¡œê·¸

```python
# ==================== KoBART ì „ì²´ í•™ìŠµ ë¡œê·¸ ==================== #
kobart_full_training_log = [
    {'timestamp': '16:11:07', 'epoch': 0.4, 'loss': 2.3843, 'grad_norm': 6.778, 'lr': 3.96e-06},
    {'timestamp': '16:11:11', 'epoch': 0.8, 'loss': 1.7590, 'grad_norm': 6.949, 'lr': 7.96e-06},
    {'timestamp': '16:11:50', 'epoch': 1.0, 'eval_loss': 1.5624, 'eval_rouge1': 0.4048, 'eval_rouge2': 0.2480, 'eval_rougeL': 0.3952, 'eval_rouge_sum': 1.0480},
    {'timestamp': '16:11:54', 'epoch': 1.2, 'loss': 1.6345, 'grad_norm': 5.923, 'lr': 1.196e-05},
    {'timestamp': '16:11:58', 'epoch': 1.6, 'loss': 1.5213, 'grad_norm': 4.771, 'lr': 1.596e-05},
    {'timestamp': '16:12:03', 'epoch': 2.0, 'loss': 1.5178, 'grad_norm': 4.546, 'lr': 1.996e-05},
    {'timestamp': '16:12:39', 'epoch': 2.0, 'eval_loss': 1.4684, 'eval_rouge1': 0.3988, 'eval_rouge2': 0.2523, 'eval_rougeL': 0.3913, 'eval_rouge_sum': 1.0424},
    {'timestamp': '16:12:41', 'train_runtime': 99.23, 'train_samples_per_second': 50.39, 'train_loss': 1.7634, 'status': 'âœ… ì™„ë£Œ'}
]
```

### 9.2 Llama ì „ì²´ í•™ìŠµ ë¡œê·¸ (ëŒ€í‘œ 10ê°œ)

```python
# ==================== Llama ëŒ€í‘œ í•™ìŠµ ë¡œê·¸ ==================== #
llama_representative_log = [
    {'timestamp': '16:14:11', 'epoch': 0.04, 'loss': 1.6346, 'grad_norm': 2.071, 'lr': 3.6e-07},
    {'timestamp': '16:21:07', 'epoch': 0.4,  'loss': 1.4115, 'grad_norm': 1.444, 'lr': 3.96e-06},
    {'timestamp': '16:33:55', 'epoch': 1.0,  'loss': 1.2031, 'grad_norm': 1.721, 'lr': 9.96e-06},
    {'timestamp': '16:40:30', 'epoch': 1.0,  'eval_loss': 1.2082, 'eval_rouge1': 0.1097, 'eval_rouge2': 0.0735, 'eval_rougeL': 0.1097, 'eval_rouge_sum': 0.2928},
    {'timestamp': '16:44:39', 'epoch': 1.2,  'loss': 1.1544, 'grad_norm': 1.847, 'lr': 1.196e-05},
    {'timestamp': '16:53:13', 'epoch': 1.6,  'loss': 1.0785, 'grad_norm': 2.061, 'lr': 1.596e-05},
    {'timestamp': '17:01:43', 'epoch': 2.0,  'loss': 1.0497, 'grad_norm': 2.574, 'lr': 1.996e-05},
    {'timestamp': '18:02:38', 'epoch': 2.0,  'eval_loss': 1.1322, 'eval_rouge1': 0.1060, 'eval_rouge2': 0.0709, 'eval_rougeL': 0.1060, 'eval_rouge_sum': 0.2829},
    {'timestamp': '18:02:39', 'train_runtime': 6553.30, 'train_samples_per_second': 0.763, 'train_loss': 1.2595, 'status': 'âœ… ì™„ë£Œ'}
]
```

### 9.3 Qwen ì „ì²´ í•™ìŠµ ë¡œê·¸ (ëŒ€í‘œ 10ê°œ)

```python
# ==================== Qwen ëŒ€í‘œ í•™ìŠµ ë¡œê·¸ ==================== #
qwen_representative_log = [
    {'timestamp': '18:36:49', 'epoch': 0.04, 'loss': 2.6867, 'grad_norm': 5.219, 'lr': 3.6e-07},
    {'timestamp': '20:01:49', 'epoch': 0.4,  'loss': 1.5077, 'grad_norm': 3.137, 'lr': 3.96e-06},
    {'timestamp': '20:35:51', 'epoch': 0.6,  'loss': 0.8971, 'grad_norm': 1.084, 'lr': 5.96e-06},
    {'timestamp': '21:46:41', 'epoch': 1.0,  'loss': 0.8924, 'grad_norm': 1.054, 'lr': 9.96e-06},
    {'timestamp': '23:07:34', 'epoch': 1.0,  'eval_loss': 0.8999, 'eval_rouge1': 0.1432, 'eval_rouge2': 0.0966, 'eval_rougeL': 0.1432, 'eval_rouge_sum': 0.3831},
    {'timestamp': '23:14:20', 'epoch': 1.04, 'loss': 0.8357, 'grad_norm': 0.930, 'lr': 1.036e-05},  # ìµœì € Loss
    {'timestamp': '23:41:17', 'epoch': 1.2,  'loss': 0.8704, 'grad_norm': 1.147, 'lr': 1.196e-05},
    {'timestamp': '00:14:33', 'epoch': 1.4,  'loss': 0.8425, 'grad_norm': 1.246, 'lr': 1.396e-05},
    {'timestamp': '00:28:32', 'epoch': 1.48, 'loss': 0.8612, 'grad_norm': 1.299, 'lr': 1.476e-05},  # ğŸ”„ ìµœì‹ 
    {'timestamp': 'TBD',      'status': 'ğŸ”„ Epoch 2 ì§„í–‰ ì¤‘ (ì˜ˆìƒ ì™„ë£Œ: 02:00~03:00)'}
]
```

---

**ë¬¸ì„œ ì‘ì„± ì™„ë£Œ**: 2025-10-14 00:30 (ì˜ˆìƒ)
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: Qwen í•™ìŠµ ì™„ë£Œ í›„ ìµœì¢… ê²°ê³¼ ì¶”ê°€ ì˜ˆì •
