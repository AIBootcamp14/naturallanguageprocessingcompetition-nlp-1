# ì‹¤í—˜ ë¶„ì„ ë³´ê³ ì„œ: 20251013_111525_strategy1_kobart_optimized

> **ì‹¤í—˜ ID**: 20251013_111525_strategy1_kobart_optimized
> **ì‹¤í–‰ ì¼ì‹œ**: 2025-10-13 11:15:25
> **ì‹¤í–‰ ëª¨ë“œ**: FULL Pipeline (ë‹¨ì¼ ëª¨ë¸)
> **ì‹¤í—˜ ìƒíƒœ**: âš ï¸ ë¶€ë¶„ ì„±ê³µ (í•™ìŠµ ì™„ë£Œ, ì œì¶œ íŒŒì¼ ë¯¸ìƒì„±)

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹¤í—˜ ê°œìš”](#1-ì‹¤í—˜-ê°œìš”)
2. [ì‹¤í—˜ ì„¤ì •](#2-ì‹¤í—˜-ì„¤ì •)
3. [í•™ìŠµ ì§€í‘œ ë¶„ì„](#3-í•™ìŠµ-ì§€í‘œ-ë¶„ì„)
4. [ê²°ê³¼ ë¶„ì„](#4-ê²°ê³¼-ë¶„ì„)
5. [ë°œìƒ ì˜¤ë¥˜ ë° ì›ì¸](#5-ë°œìƒ-ì˜¤ë¥˜-ë°-ì›ì¸)
6. [ìˆ˜ì • ë°©í–¥ ë° ê°œì„ ì•ˆ](#6-ìˆ˜ì •-ë°©í–¥-ë°-ê°œì„ ì•ˆ)

---

## 1. ì‹¤í—˜ ê°œìš”

### 1.1 ì‹¤í—˜ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph Input["ì…ë ¥"]
        A[KoBART ëª¨ë¸<br/>ë‹¨ì¼ ëª¨ë¸]
        B[í•™ìŠµ ë°ì´í„°<br/>12,457ê°œ]
        C[ê²€ì¦ ë°ì´í„°<br/>499ê°œ]
    end

    subgraph Training["í•™ìŠµ ê³„ì¸µ"]
        D[ëª¨ë¸ í•™ìŠµ<br/>Batch Size: 16]
        E[Early Stopping<br/>Patience: 3]
        F[Best Model<br/>Epoch 5]
    end

    subgraph Evaluation["í‰ê°€ ê³„ì¸µ"]
        G[ROUGE í‰ê°€<br/>ê²€ì¦ ë°ì´í„°]
        H[Solar API<br/>50 ìƒ˜í”Œ]
        I[TTA<br/>ë¯¸êµ¬í˜„]
    end

    subgraph Output["ì¶œë ¥"]
        J[ì¶”ë¡  ìˆ˜í–‰<br/>499 ìƒ˜í”Œ]
        K[âŒ ì œì¶œ íŒŒì¼<br/>ìƒì„± ì‹¤íŒ¨]
    end

    A --> D
    B --> D
    C --> D

    D --> E
    E --> F
    F --> G
    G --> H
    H --> I

    I --> J
    J --> K

    style Input fill:#e3f2fd,stroke:#1976d2,color:#000
    style Training fill:#e8f5e9,stroke:#388e3c,color:#000
    style Evaluation fill:#f3e5f5,stroke:#7b1fa2,color:#000
    style Output fill:#c8e6c9,stroke:#2e7d32,color:#000

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#90caf9,stroke:#1976d2,color:#000
    style C fill:#90caf9,stroke:#1976d2,color:#000
    style D fill:#81c784,stroke:#388e3c,color:#000
    style E fill:#81c784,stroke:#388e3c,color:#000
    style F fill:#a5d6a7,stroke:#388e3c,color:#000
    style G fill:#ce93d8,stroke:#7b1fa2,color:#000
    style H fill:#ce93d8,stroke:#7b1fa2,color:#000
    style I fill:#fff9c4,stroke:#f57f17,color:#000
    style J fill:#aed581,stroke:#2e7d32,color:#000
    style K fill:#ffccbc,stroke:#d84315,color:#000
```

### 1.2 ì‹¤í—˜ ëª©ì 
- KoBART ë‹¨ì¼ ëª¨ë¸ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦
- Batch Size 16, Epoch 8 ì„¤ì • ìµœì í™” í…ŒìŠ¤íŠ¸
- Data Augmentation ë° TTA í†µí•© í…ŒìŠ¤íŠ¸
- ì œì¶œ íŒŒì¼ ìë™ ìƒì„± ê²€ì¦

### 1.3 ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# ==================== ì‹¤í–‰ëœ ëª…ë ¹ì–´ (ì¶”ì •) ==================== #
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 8 \
  --batch_size 16 \
  --use_augmentation \
  --use_tta \
  --tta_strategies paraphrase reorder \
  --tta_num_aug 3 \
  --use_solar_api \
  --experiment_name strategy1_kobart_optimized
```

### 1.4 ì‹¤í—˜ ê²°ê³¼ ìš”ì•½

```mermaid
%%{init: {
  "theme": "default",
  "themeVariables": {
    "pie1": "#A8E6CF",   /* ë¯¼íŠ¸ íŒŒìŠ¤í…” */
    "pie2": "#FFD3B6",   /* ì‚´êµ¬ íŒŒìŠ¤í…” */
    "pie3": "#FFAAA5",   /* ì½”ë„ í•‘í¬ íŒŒìŠ¤í…” */
    "pie4": "#D1C4E9",   /* ì—°ë³´ë¼ íŒŒìŠ¤í…” */
    "textColor": "#333333",              /* ì œëª©, ë²”ë¡€, ìˆ˜ì¹˜ ë“± ì „ì²´ í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    "pieSectionTextColor": "#333333",    /* íŒŒì´ ì¡°ê° ìœ„ì— í‘œì‹œë˜ëŠ” í¼ì„¼íŠ¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    "pieTitleTextSize": "20px",          /* ì œëª© í¬ê¸° (ì„ íƒ ì‚¬í•­) */
    "pieSectionTextSize": "16px"         /* ì¡°ê° ë‚´ë¶€ í…ìŠ¤íŠ¸ í¬ê¸° (ì„ íƒ ì‚¬í•­) */
  }
}}%%
pie title íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì„±ê³µ í˜„í™©
    "í•™ìŠµ ì„±ê³µ" : 1
    "í‰ê°€ ì„±ê³µ" : 1
    "ì¶”ë¡  ì„±ê³µ" : 1
    "ì œì¶œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨" : 1
```

```mermaid
graph LR
    A[íŒŒì´í”„ë¼ì¸<br/>ì‹œì‘] --> B{ëª¨ë¸<br/>í•™ìŠµ}
    B -->|ì„±ê³µ<br/>8 Epoch| C[âœ… í•™ìŠµ<br/>ì™„ë£Œ]
    C --> D{ROUGE<br/>í‰ê°€}
    D -->|ì„±ê³µ| E[âœ… í‰ê°€<br/>ì™„ë£Œ]
    E --> F{ì¶”ë¡ <br/>ìˆ˜í–‰}
    F -->|ì„±ê³µ<br/>499ê°œ| G[âœ… ì¶”ë¡ <br/>ì™„ë£Œ]
    G --> H{ì œì¶œ íŒŒì¼<br/>ìƒì„±}
    H -->|ì‹¤íŒ¨<br/>KeyError| I[âŒ ì˜¤ë¥˜<br/>ë°œìƒ]

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#c8e6c9,stroke:#2e7d32,color:#000
    style D fill:#fff9c4,stroke:#f57f17,color:#000
    style E fill:#c8e6c9,stroke:#2e7d32,color:#000
    style F fill:#fff9c4,stroke:#f57f17,color:#000
    style G fill:#c8e6c9,stroke:#2e7d32,color:#000
    style H fill:#fff9c4,stroke:#f57f17,color:#000
    style I fill:#ffcdd2,stroke:#c62828,color:#fff
```

| í•­ëª© | ê²°ê³¼ |
|------|------|
| **ëª¨ë¸** | KoBART (gogamza/kobart-base-v2) |
| **í•™ìŠµ ì™„ë£Œ ì—¬ë¶€** | âœ… ì™„ë£Œ (8 Epoch, Early Stopping) |
| **ìµœì¢… Eval Loss** | 1.4201 (Best: Epoch 5) |
| **ìµœê³  ROUGE-Sum** | 1.2369 (Epoch 5) |
| **ì´ í•™ìŠµ ì‹œê°„** | ì•½ 10ë¶„ 40ì´ˆ |
| **ì¶”ë¡  ìˆ˜í–‰** | âœ… ì™„ë£Œ (499ê°œ ìƒ˜í”Œ) |
| **ì œì¶œ íŒŒì¼ ìƒì„±** | âŒ ì‹¤íŒ¨ (KeyError: 'id') |

---

## 2. ì‹¤í—˜ ì„¤ì •

### 2.1 ëª¨ë¸ ì„¤ì •

```python
# ==================== ëª¨ë¸ ì„¤ì • ==================== #
model_name = 'kobart'                       # KoBART ëª¨ë¸
model_type = 'encoder_decoder'              # Seq2Seq ëª¨ë¸
base_model = 'gogamza/kobart-base-v2'       # HuggingFace ëª¨ë¸

# ---------------------- ëª¨ë¸ íŒŒë¼ë¯¸í„° ---------------------- #
total_params = 123_859_968                  # ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜
trainable_params = 123_859_968              # í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„° ìˆ˜
model_size = 'ì•½ 472MB'                     # ëª¨ë¸ í¬ê¸° (FP32 ê¸°ì¤€)
```

### 2.2 ë°ì´í„° ì„¤ì •

```python
# ==================== ë°ì´í„° í†µê³„ ==================== #
train_samples = 12457                       # í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ ìˆ˜
val_samples = 499                           # ê²€ì¦ ë°ì´í„° ìƒ˜í”Œ ìˆ˜
test_samples = 499                          # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œ ìˆ˜
total_samples = 13455                       # ì „ì²´ ë°ì´í„° ìƒ˜í”Œ ìˆ˜

# ---------------------- ë°ì´í„° ì¦ê°• ---------------------- #
use_augmentation = True                     # ë°ì´í„° ì¦ê°• ì‚¬ìš©
augmentation_ratio = 0.5                    # ì¦ê°• ë¹„ìœ¨ (ì¶”ì •)
```

### 2.3 í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```python
# ==================== í•™ìŠµ íŒŒë¼ë¯¸í„° ==================== #
epochs = 8                                  # ì´ ì—í¬í¬ ìˆ˜
batch_size = 16                             # ë°°ì¹˜ í¬ê¸°
learning_rate = 5e-5                        # ì´ˆê¸° í•™ìŠµë¥  (ì¶”ì •)
warmup_ratio = 0.1                          # Warmup ë¹„ìœ¨ (ì¶”ì •)
weight_decay = 0.01                         # ê°€ì¤‘ì¹˜ ê°ì‡  (ì¶”ì •)
max_grad_norm = 1.0                         # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (ì¶”ì •)

# ---------------------- Early Stopping ---------------------- #
early_stopping_patience = 3                 # Early Stopping Patience
early_stopping_threshold = 0.0              # Early Stopping ì„ê³„ê°’

# ---------------------- ì²´í¬í¬ì¸íŠ¸ ì„¤ì • ---------------------- #
save_steps = 500                            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê°„ê²©
logging_steps = 100                         # ë¡œê¹… ê°„ê²©
eval_steps = 500                            # í‰ê°€ ê°„ê²©
```

### 2.4 ì¶”ë¡  ë° ê³ ê¸‰ ê¸°ëŠ¥

```python
# ==================== ì¶”ë¡  ì„¤ì • ==================== #
inference_batch_size = 32                   # ì¶”ë¡  ë°°ì¹˜ í¬ê¸°
max_length = 100                            # ìµœëŒ€ ìƒì„± ê¸¸ì´
num_beams = 4                               # Beam Search í¬ê¸°
no_repeat_ngram_size = 2                    # N-gram ë°˜ë³µ ë°©ì§€

# ==================== TTA ì„¤ì • ==================== #
use_tta = True                              # TTA í™œì„±í™”
tta_strategies = ['paraphrase', 'reorder']  # TTA ì „ëµ
tta_num_aug = 3                             # TTA ì¦ê°• íšŸìˆ˜
tta_applied = False                         # TTA êµ¬í˜„ ë¯¸ì™„ë£Œ

# ==================== Solar API ì„¤ì • ==================== #
use_solar_api = True                        # Solar API ì‚¬ìš©
solar_samples = 50                          # Solar API í‰ê°€ ìƒ˜í”Œ ìˆ˜
```

---

## 3. í•™ìŠµ ì§€í‘œ ë¶„ì„

### 3.1 Loss ë° ROUGE ì¶”ì´

#### 3.1.1 Epochë³„ í•™ìŠµ ì§„í–‰ íƒ€ì„ë¼ì¸

```mermaid
graph LR
    A[Epoch 1<br/>Loss: 1.35<br/>ROUGE-Sum: 1.05] --> B[Epoch 2<br/>Loss: 1.29<br/>ROUGE-Sum: 1.13]
    B --> C[Epoch 3<br/>Loss: 1.31<br/>ROUGE-Sum: 1.16]
    C --> D[Epoch 4<br/>Loss: 1.37<br/>ROUGE-Sum: 1.19]
    D --> E[Epoch 5<br/>Loss: 1.42<br/>âœ… BEST<br/>ROUGE-Sum: 1.24]
    E --> F[Epoch 6<br/>Loss: 1.47<br/>ROUGE-Sum: 1.18]
    F --> G[Epoch 7<br/>Loss: 1.50<br/>ROUGE-Sum: 1.20]
    G --> H[Epoch 8<br/>Loss: 1.52<br/>ROUGE-Sum: 1.20<br/>ğŸ›‘ Early Stop]

    style A fill:#ef9a9a,stroke:#c62828,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#fff9c4,stroke:#f57f17,color:#000
    style D fill:#c5e1a5,stroke:#558b2f,color:#000
    style E fill:#c8e6c9,stroke:#2e7d32,color:#000
    style F fill:#fff9c4,stroke:#f57f17,color:#000
    style G fill:#fff9c4,stroke:#f57f17,color:#000
    style H fill:#ef9a9a,stroke:#c62828,color:#000
```

#### 3.1.2 ROUGE ì ìˆ˜ ë¹„êµ (ì£¼ìš” Epoch)

```mermaid
graph TB
    subgraph Epoch1["Epoch 1 - ì´ˆê¸° ì„±ëŠ¥"]
        E1R1[ROUGE-1: 0.3989]
        E1R2[ROUGE-2: 0.2554]
        E1RL[ROUGE-L: 0.3940]
        E1SUM[ROUGE-Sum: 1.0484]
    end

    subgraph Epoch5["Epoch 5 - ìµœê³  ì„±ëŠ¥ âœ…"]
        E5R1[ROUGE-1: 0.4700]
        E5R2[ROUGE-2: 0.3056]
        E5RL[ROUGE-L: 0.4613]
        E5SUM[ROUGE-Sum: 1.2369]
    end

    subgraph Epoch8["Epoch 8 - ìµœì¢… ì„±ëŠ¥"]
        E8R1[ROUGE-1: 0.4576]
        E8R2[ROUGE-2: 0.2963]
        E8RL[ROUGE-L: 0.4496]
        E8SUM[ROUGE-Sum: 1.2035]
    end

    Epoch1 --> Epoch5
    Epoch5 --> Epoch8

    style Epoch1 fill:#e3f2fd,stroke:#1976d2,color:#000
    style Epoch5 fill:#e8f5e9,stroke:#388e3c,color:#000
    style Epoch8 fill:#fff3e0,stroke:#f57c00,color:#000

    style E1R1 fill:#90caf9,stroke:#1976d2,color:#000
    style E1R2 fill:#90caf9,stroke:#1976d2,color:#000
    style E1RL fill:#90caf9,stroke:#1976d2,color:#000
    style E1SUM fill:#90caf9,stroke:#1976d2,color:#000

    style E5R1 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style E5R2 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style E5RL fill:#a5d6a7,stroke:#2e7d32,color:#000
    style E5SUM fill:#a5d6a7,stroke:#2e7d32,color:#000

    style E8R1 fill:#fff9c4,stroke:#f57f17,color:#000
    style E8R2 fill:#fff9c4,stroke:#f57f17,color:#000
    style E8RL fill:#fff9c4,stroke:#f57f17,color:#000
    style E8SUM fill:#fff9c4,stroke:#f57f17,color:#000
```

#### 3.1.3 í•™ìŠµ ì‹œê°„ ë¶„í•´ (ì´ 10ë¶„ 40ì´ˆ)

```mermaid
graph LR
    A[ì‹œì‘<br/>0ì´ˆ] --> B[Epoch 1-2<br/>ì•½ 2ë¶„ 40ì´ˆ<br/>ë¹ ë¥¸ ìˆ˜ë ´]
    B --> C[Epoch 3-5<br/>ì•½ 4ë¶„<br/>ìµœì  ì„±ëŠ¥ ë„ë‹¬]
    C --> D[Epoch 6-8<br/>ì•½ 4ë¶„<br/>ê³¼ì í•© ê°ì§€]
    D --> E[ì™„ë£Œ<br/>10ë¶„ 40ì´ˆ]

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#c8e6c9,stroke:#2e7d32,color:#000
    style C fill:#a5d6a7,stroke:#2e7d32,color:#000
    style D fill:#fff59d,stroke:#f57f17,color:#000
    style E fill:#ce93d8,stroke:#7b1fa2,color:#000
```

### 3.2 Epochë³„ ìƒì„¸ ì§€í‘œ

```python
# ==================== Epochë³„ í‰ê°€ ì§€í‘œ ==================== #
epoch_metrics = [
    {
        'epoch': 1,
        'eval_loss': 1.3519,
        'eval_rouge1': 0.3989,
        'eval_rouge2': 0.2554,
        'eval_rougeL': 0.3940,
        'eval_rouge_sum': 1.0484,
        'runtime': 27.84,
        'samples_per_second': 17.93
    },
    {
        'epoch': 2,
        'eval_loss': 1.2863,
        'eval_rouge1': 0.4312,
        'eval_rouge2': 0.2743,
        'eval_rougeL': 0.4240,
        'eval_rouge_sum': 1.1295,
        'runtime': 25.60,
        'samples_per_second': 19.49
    },
    {
        'epoch': 3,
        'eval_loss': 1.3126,
        'eval_rouge1': 0.4396,
        'eval_rouge2': 0.2823,
        'eval_rougeL': 0.4337,
        'eval_rouge_sum': 1.1556,
        'runtime': 29.92,
        'samples_per_second': 16.68
    },
    {
        'epoch': 4,
        'eval_loss': 1.3731,
        'eval_rouge1': 0.4535,
        'eval_rouge2': 0.2923,
        'eval_rougeL': 0.4468,
        'eval_rouge_sum': 1.1925,
        'runtime': 29.67,
        'samples_per_second': 16.82
    },
    {
        'epoch': 5,
        'eval_loss': 1.4201,
        'eval_rouge1': 0.4700,                  # ìµœê³  ROUGE-1
        'eval_rouge2': 0.3056,                  # ìµœê³  ROUGE-2
        'eval_rougeL': 0.4613,                  # ìµœê³  ROUGE-L
        'eval_rouge_sum': 1.2369,               # ìµœê³  ROUGE-Sum âœ…
        'runtime': 26.08,
        'samples_per_second': 19.14,
        'status': 'BEST_CHECKPOINT'             # Best Model
    },
    {
        'epoch': 6,
        'eval_loss': 1.4685,
        'eval_rouge1': 0.4498,
        'eval_rouge2': 0.2848,
        'eval_rougeL': 0.4417,
        'eval_rouge_sum': 1.1763,
        'runtime': 27.57,
        'samples_per_second': 18.10
    },
    {
        'epoch': 7,
        'eval_loss': 1.5023,
        'eval_rouge1': 0.4546,
        'eval_rouge2': 0.2946,
        'eval_rougeL': 0.4473,
        'eval_rouge_sum': 1.1965,
        'runtime': 30.03,
        'samples_per_second': 16.62
    },
    {
        'epoch': 8,
        'eval_loss': 1.5249,
        'eval_rouge1': 0.4576,
        'eval_rouge2': 0.2963,
        'eval_rougeL': 0.4496,
        'eval_rouge_sum': 1.2035,
        'runtime': 28.58,
        'samples_per_second': 17.46,
        'status': 'EARLY_STOPPING'              # Early Stopping ë°œë™
    }
]
```

### 3.3 í•™ìŠµ ì•ˆì •ì„± ë¶„ì„

```python
# ==================== í•™ìŠµ ì•ˆì •ì„± ì§€í‘œ ==================== #
stability_metrics = {
    # ---------------------- Loss ë¶„ì„ ---------------------- #
    'initial_loss': 2.1642,                     # ì´ˆê¸° Loss (Step 100)
    'best_eval_loss': 1.2863,                   # ìµœì € Eval Loss (Epoch 2)
    'final_eval_loss': 1.5249,                  # ìµœì¢… Eval Loss (Epoch 8)
    'loss_reduction': 0.6393,                   # Loss ê°ì†ŒëŸ‰ (29.5%)

    # ---------------------- ROUGE ë¶„ì„ ---------------------- #
    'initial_rouge_sum': 1.0484,                # ì´ˆê¸° ROUGE-Sum (Epoch 1)
    'best_rouge_sum': 1.2369,                   # ìµœê³  ROUGE-Sum (Epoch 5) âœ…
    'final_rouge_sum': 1.2035,                  # ìµœì¢… ROUGE-Sum (Epoch 8)
    'rouge_improvement': 0.1885,                # ROUGE ê°œì„ ëŸ‰ (18.0%)

    # ---------------------- Gradient Norm ì•ˆì •ì„± ---------------------- #
    'grad_norm_mean': 3.5,                      # í‰ê·  Gradient Norm
    'grad_norm_std': 1.2,                       # í‘œì¤€í¸ì°¨
    'grad_norm_range': (2.35, 8.22),            # ìµœì†Œ/ìµœëŒ€ ë²”ìœ„
    'grad_norm_stability': 'GOOD',              # ì•ˆì •ì„± í‰ê°€

    # ---------------------- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ---------------------- #
    'lr_initial': 4.99e-5,                      # ì´ˆê¸° í•™ìŠµë¥ 
    'lr_final': 2.88e-7,                        # ìµœì¢… í•™ìŠµë¥ 
    'lr_decay_pattern': 'LINEAR',               # í•™ìŠµë¥  ê°ì†Œ íŒ¨í„´
    'lr_scheduling': 'NORMAL'                   # ìŠ¤ì¼€ì¤„ë§ í‰ê°€
}
```

#### 3.3.1 Gradient Norm ì•ˆì •ì„± ì°¨íŠ¸

```mermaid
graph TB
    subgraph GradRange["Gradient Norm ë²”ìœ„ ë¶„ì„"]
        MIN[ìµœì†Œê°’: 2.35<br/>ì•ˆì •ì  í•˜í•œ]
        AVG[í‰ê· ê°’: 3.5<br/>ì •ìƒ ë²”ìœ„ âœ…]
        MAX[ìµœëŒ€ê°’: 8.22<br/>í´ë¦¬í•‘ ì ìš©]
    end

    subgraph Stability["ì•ˆì •ì„± í‰ê°€"]
        STD[í‘œì¤€í¸ì°¨: 1.2<br/>ë‚®ì€ ë³€ë™ì„±]
        EVAL[í‰ê°€: GOOD<br/>í•™ìŠµ ì•ˆì •]
    end

    MIN --> AVG --> MAX
    AVG --> STD --> EVAL

    style GradRange fill:#e8f5e9,stroke:#388e3c,color:#000
    style Stability fill:#e3f2fd,stroke:#1976d2,color:#000

    style MIN fill:#c8e6c9,stroke:#2e7d32,color:#000
    style AVG fill:#a5d6a7,stroke:#2e7d32,color:#000
    style MAX fill:#fff9c4,stroke:#f57f17,color:#000
    style STD fill:#90caf9,stroke:#1976d2,color:#000
    style EVAL fill:#a5d6a7,stroke:#2e7d32,color:#000
```

#### 3.3.2 í•™ìŠµë¥  ê°ì†Œ íŒ¨í„´ ì‹œê°í™”

```mermaid
graph LR
    A[ì´ˆê¸° í•™ìŠµë¥ <br/>4.99e-5<br/>100%] --> B[Epoch 2<br/>ì•½ 3.75e-5<br/>75%]
    B --> C[Epoch 4<br/>ì•½ 2.50e-5<br/>50%]
    C --> D[Epoch 6<br/>ì•½ 1.25e-5<br/>25%]
    D --> E[ìµœì¢… í•™ìŠµë¥ <br/>2.88e-7<br/>0.6%]

    style A fill:#ef9a9a,stroke:#c62828,color:#000
    style B fill:#fff59d,stroke:#f57f17,color:#000
    style C fill:#c8e6c9,stroke:#2e7d32,color:#000
    style D fill:#90caf9,stroke:#1976d2,color:#000
    style E fill:#bbdefb,stroke:#1976d2,color:#000
```

### 3.4 í•™ìŠµ ê³¡ì„  íŠ¹ì§•

```mermaid
graph TB
    subgraph Phase1["ì´ˆê¸° í•™ìŠµ (Epoch 1-2)"]
        A1[Loss ê¸‰ê²©íˆ ê°ì†Œ<br/>2.16 â†’ 1.29]
        A2[ROUGE ë¹ ë¥¸ ì¦ê°€<br/>1.05 â†’ 1.13]
    end

    subgraph Phase2["ì¤‘ê¸° í•™ìŠµ (Epoch 3-5)"]
        B1[Loss ì™„ë§Œí•œ ì¦ê°€<br/>1.29 â†’ 1.42]
        B2[ROUGE ê¾¸ì¤€í•œ ê°œì„ <br/>1.13 â†’ 1.24 âœ…]
    end

    subgraph Phase3["í›„ê¸° í•™ìŠµ (Epoch 6-8)"]
        C1[Loss ì§€ì† ì¦ê°€<br/>1.42 â†’ 1.52]
        C2[ROUGE í•˜ë½ í›„ íšŒë³µ<br/>1.24 â†’ 1.20]
        C3[Early Stopping ë°œë™<br/>Patience 3 ì´ˆê³¼]
    end

    Phase1 --> Phase2 --> Phase3

    style Phase1 fill:#e8f5e9,stroke:#388e3c,color:#000
    style Phase2 fill:#fff3e0,stroke:#f57c00,color:#000
    style Phase3 fill:#ffebee,stroke:#c62828,color:#000

    style A1 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style A2 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style B1 fill:#fff9c4,stroke:#f57f17,color:#000
    style B2 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style C1 fill:#ffccbc,stroke:#d84315,color:#000
    style C2 fill:#fff9c4,stroke:#f57f17,color:#000
    style C3 fill:#ffccbc,stroke:#d84315,color:#000
```

**í•™ìŠµ ê³¡ì„  ë¶„ì„:**
1. **ì´ˆê¸° ë¹ ë¥¸ í•™ìŠµ** (Epoch 1-2): Loss ê¸‰ê²© ê°ì†Œ, ROUGE ë¹ ë¥¸ ì¦ê°€
2. **ìµœì  ìˆ˜ë ´** (Epoch 3-5): Epoch 5ì—ì„œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„± (ROUGE-Sum: 1.2369)
3. **ê³¼ì í•© ì§•í›„** (Epoch 6-8): Loss ì¦ê°€, ROUGE í•˜ë½, Early Stopping ë°œë™

---

## 4. ê²°ê³¼ ë¶„ì„

### 4.1 ì„±ê³µ í•­ëª© âœ…

#### 4.1.1 ëª¨ë¸ í•™ìŠµ
- âœ… **í•™ìŠµ ì™„ë£Œ**: 8 Epoch ì •ìƒ ì™„ë£Œ (Early Stopping ì •ìƒ ì‘ë™)
- âœ… **ìµœì  ëª¨ë¸ ì„ íƒ**: Epoch 5 ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ROUGE-Sum: 1.2369)
- âœ… **í•™ìŠµ ì•ˆì •ì„±**: Gradient Norm ì•ˆì •ì , Loss ì •ìƒ ìˆ˜ë ´
- âœ… **ì²´í¬í¬ì¸íŠ¸ ì €ì¥**: checkpoint-3895 (Epoch 5), checkpoint-6232 (Epoch 8), final_model

#### 4.1.2 í‰ê°€ ë° ê²€ì¦
- âœ… **ROUGE í‰ê°€**: ê²€ì¦ ë°ì´í„° í‰ê°€ ì •ìƒ ì™„ë£Œ
  - ROUGE-1: 0.4700
  - ROUGE-2: 0.3056
  - ROUGE-L: 0.4613
- âœ… **Solar API í†µí•©**: 50ê°œ ìƒ˜í”Œ í‰ê°€ ì™„ë£Œ
  - Solar ROUGE-1: 0.2272
  - Solar ROUGE-2: 0.0765
  - Solar ROUGE-L: 0.2177

#### 4.1.3 ì¶”ë¡  ìˆ˜í–‰
- âœ… **ì¶”ë¡  ì™„ë£Œ**: 499ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¶”ë¡  ì •ìƒ ìˆ˜í–‰
- âœ… **ë°°ì¹˜ ì²˜ë¦¬**: ë°°ì¹˜ í¬ê¸° 32ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬
- âœ… **ì˜ˆì¸¡ ìƒì„±**: 499ê°œ ìš”ì•½ë¬¸ ìƒì„± ì™„ë£Œ

### 4.2 ì‹¤íŒ¨ í•­ëª© âŒ

#### 4.2.1 ì œì¶œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨
- âŒ **ì œì¶œ íŒŒì¼ ë¯¸ìƒì„±**: CSV íŒŒì¼ ìƒì„± ì‹¤íŒ¨ (KeyError: 'id')
- âŒ **ì˜¤ë¥˜ ë°œìƒ ì§€ì **: `full_pipeline_trainer.py:533`
- âŒ **ì˜¤ë¥˜ íƒ€ì…**: KeyError
- âŒ **ì˜¤ë¥˜ ë©”ì‹œì§€**: `'id'`

#### 4.2.2 TTA ë¯¸êµ¬í˜„
- âŒ **TTA ë¯¸ì ìš©**: TTA ê¸°ëŠ¥ êµ¬í˜„ ì¤‘
- âŒ **TTA ì „ëµ**: paraphrase, reorder ì„¤ì •í–ˆìœ¼ë‚˜ ë¯¸ì ìš©

### 4.3 ì„±ëŠ¥ í‰ê°€

```python
# ==================== KoBART ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ==================== #
performance_evaluation = {
    # ---------------------- ROUGE ì„±ëŠ¥ ---------------------- #
    'best_rouge1': 0.4700,                      # ROUGE-1 F1
    'best_rouge2': 0.3056,                      # ROUGE-2 F1
    'best_rougeL': 0.4613,                      # ROUGE-L F1
    'best_rouge_sum': 1.2369,                   # ROUGE-Sum (í•©ê³„)
    'rouge_evaluation': 'GOOD',                 # ì–‘í˜¸í•œ ì„±ëŠ¥

    # ---------------------- í•™ìŠµ íš¨ìœ¨ì„± ---------------------- #
    'epochs_completed': 8,                      # ì™„ë£Œëœ Epoch
    'training_time': '10ë¶„ 40ì´ˆ',               # ì´ í•™ìŠµ ì‹œê°„
    'time_per_epoch': '1ë¶„ 20ì´ˆ',               # Epochë‹¹ í‰ê·  ì‹œê°„
    'samples_per_second': 18.0,                 # ì´ˆë‹¹ ì²˜ë¦¬ ìƒ˜í”Œ ìˆ˜ (í‰ê· )
    'efficiency': 'EXCELLENT',                  # íš¨ìœ¨ì„± í‰ê°€

    # ---------------------- ì¶”ë¡  ì„±ëŠ¥ ---------------------- #
    'inference_samples': 499,                   # ì¶”ë¡  ìƒ˜í”Œ ìˆ˜
    'inference_batch_size': 32,                 # ì¶”ë¡  ë°°ì¹˜ í¬ê¸°
    'inference_time': 'ì•½ 1ë¶„ 9ì´ˆ',             # ì¶”ë¡  ì‹œê°„ (ì¶”ì •)
    'inference_speed': 'GOOD',                  # ì¶”ë¡  ì†ë„ í‰ê°€
}
```

#### 4.3.1 ROUGE ë©”íŠ¸ë¦­ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸

```mermaid
graph TB
    subgraph Metrics["ROUGE ë©”íŠ¸ë¦­ë³„ ì„±ëŠ¥"]
        R1[ROUGE-1<br/>0.4700<br/>ì•½ 47%]
        R2[ROUGE-2<br/>0.3056<br/>ì•½ 31%]
        RL[ROUGE-L<br/>0.4613<br/>ì•½ 46%]
    end

    subgraph Analysis["ì„±ëŠ¥ ë¶„ì„"]
        A1[1-gram ë§¤ì¹­<br/>ìš°ìˆ˜í•¨]
        A2[2-gram ë§¤ì¹­<br/>ì–‘í˜¸í•¨]
        A3[ìµœì¥ ê³µí†µ ë¶€ë¶„<br/>ìš°ìˆ˜í•¨]
    end

    R1 --> A1
    R2 --> A2
    RL --> A3

    style Metrics fill:#e8f5e9,stroke:#388e3c,color:#000
    style Analysis fill:#e3f2fd,stroke:#1976d2,color:#000

    style R1 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style R2 fill:#c8e6c9,stroke:#2e7d32,color:#000
    style RL fill:#a5d6a7,stroke:#2e7d32,color:#000
    style A1 fill:#90caf9,stroke:#1976d2,color:#000
    style A2 fill:#fff9c4,stroke:#f57f17,color:#000
    style A3 fill:#90caf9,stroke:#1976d2,color:#000
```

#### 4.3.2 Solar API vs KoBART ì„±ëŠ¥ ë¹„êµ

```mermaid
graph TB
    subgraph KoBART["KoBART ëª¨ë¸ (í•™ìŠµë¨)"]
        KB_R1[ROUGE-1: 0.4700<br/>âœ… +107%]
        KB_R2[ROUGE-2: 0.3056<br/>âœ… +300%]
        KB_RL[ROUGE-L: 0.4613<br/>âœ… +112%]
    end

    subgraph Solar["Solar API (ì œë¡œìƒ·)"]
        SOL_R1[ROUGE-1: 0.2272<br/>ê¸°ì¤€ì„ ]
        SOL_R2[ROUGE-2: 0.0765<br/>ê¸°ì¤€ì„ ]
        SOL_RL[ROUGE-L: 0.2177<br/>ê¸°ì¤€ì„ ]
    end

    subgraph Result["ë¹„êµ ê²°ê³¼"]
        WIN[KoBART ì••ë„ì  ìš°ì„¸<br/>í•™ìŠµ íš¨ê³¼ ê²€ì¦ âœ…]
    end

    Solar --> KoBART
    KoBART --> Result

    style KoBART fill:#e8f5e9,stroke:#388e3c,color:#000
    style Solar fill:#ffebee,stroke:#c62828,color:#000
    style Result fill:#e3f2fd,stroke:#1976d2,color:#000

    style KB_R1 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style KB_R2 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style KB_RL fill:#a5d6a7,stroke:#2e7d32,color:#000

    style SOL_R1 fill:#ffccbc,stroke:#d84315,color:#000
    style SOL_R2 fill:#ffccbc,stroke:#d84315,color:#000
    style SOL_RL fill:#ffccbc,stroke:#d84315,color:#000

    style WIN fill:#90caf9,stroke:#1976d2,color:#000
```

#### 4.3.3 í•™ìŠµ íš¨ìœ¨ì„± ì‹œê°í™”

```mermaid
graph LR
    A[ë°ì´í„° ì…ë ¥<br/>12,457 ìƒ˜í”Œ] --> B[í•™ìŠµ ì‹œì‘<br/>Batch 16]
    B --> C[Epoch 1-2<br/>2ë¶„ 40ì´ˆ<br/>ë¹ ë¥¸ ìˆ˜ë ´]
    C --> D[Epoch 3-5<br/>4ë¶„<br/>ìµœì í™”]
    D --> E[Epoch 6-8<br/>4ë¶„<br/>ë¯¸ì„¸ì¡°ì •]
    E --> F[ì™„ë£Œ<br/>10ë¶„ 40ì´ˆ<br/>âœ… íš¨ìœ¨ì ]

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#ffcc80,stroke:#f57c00,color:#000
    style C fill:#c8e6c9,stroke:#2e7d32,color:#000
    style D fill:#a5d6a7,stroke:#2e7d32,color:#000
    style E fill:#fff59d,stroke:#f57f17,color:#000
    style F fill:#ce93d8,stroke:#7b1fa2,color:#000
```

**ì„±ëŠ¥ í‰ê°€ ìš”ì•½:**
- **ROUGE ì ìˆ˜**: 0.47/0.31/0.46 (Rouge-1/2/L)ì€ ëŒ€í™” ìš”ì•½ íƒœìŠ¤í¬ì—ì„œ ì–‘í˜¸í•œ ìˆ˜ì¤€
- **í•™ìŠµ ì‹œê°„**: Epochë‹¹ ì•½ 1ë¶„ 20ì´ˆë¡œ ë§¤ìš° ë¹ ë¥¸ í•™ìŠµ ì†ë„
- **Early Stopping**: Epoch 5ì—ì„œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„± í›„ 3 Epoch ë‚´ ê°œì„  ì—†ì–´ ì •ìƒ ì¢…ë£Œ
- **ì¶”ë¡  ì†ë„**: ë°°ì¹˜ í¬ê¸° 32ë¡œ 499ê°œ ìƒ˜í”Œì„ ì•½ 1ë¶„ ë‚´ ì²˜ë¦¬
- **Solar API ëŒ€ë¹„**: ROUGE-1 +107%, ROUGE-2 +300%, ROUGE-L +112% í–¥ìƒ

---

## 5. ë°œìƒ ì˜¤ë¥˜ ë° ì›ì¸

### 5.1 ì˜¤ë¥˜ ë°œìƒ í”Œë¡œìš°

```mermaid
graph TB
    A[ì¶”ë¡  ì™„ë£Œ<br/>499ê°œ ì˜ˆì¸¡] --> B{ì œì¶œ íŒŒì¼<br/>ìƒì„± ì‹œì‘}
    B --> C[test_df ë¡œë“œ<br/>test.csv]
    C --> D[DataFrame ì»¬ëŸ¼<br/>í™•ì¸]
    D --> E{id ì»¬ëŸ¼<br/>ì¡´ì¬?}
    E -->|No| F[KeyError ë°œìƒ<br/>id]
    F --> G[âŒ ì œì¶œ íŒŒì¼<br/>ìƒì„± ì‹¤íŒ¨]

    style A fill:#c8e6c9,stroke:#2e7d32,color:#000
    style B fill:#fff59d,stroke:#f57f17,color:#000
    style C fill:#ffcc80,stroke:#f57c00,color:#000
    style D fill:#fff59d,stroke:#f57f17,color:#000
    style E fill:#fff59d,stroke:#f57f17,color:#000
    style F fill:#ef9a9a,stroke:#c62828,color:#000
    style G fill:#ffcdd2,stroke:#c62828,color:#fff
```

### 5.2 ì˜¤ë¥˜ ìƒì„¸ ì •ë³´

```python
# ==================== ì˜¤ë¥˜ ì •ë³´ ==================== #
error_details = {
    'error_type': 'KeyError',                                       # ì˜¤ë¥˜ íƒ€ì…
    'error_message': "'id'",                                        # ì˜¤ë¥˜ ë©”ì‹œì§€
    'error_location': 'src/trainers/full_pipeline_trainer.py:533', # ë°œìƒ ìœ„ì¹˜
    'occurrence_time': '2025-10-13 11:27:13',                       # ë°œìƒ ì‹œê°„
    'occurrence_stage': 'submission_file_creation'                  # ë°œìƒ ë‹¨ê³„
}
```

### 5.3 ì›ì¸ ë¶„ì„

```python
# ==================== ê·¼ë³¸ ì›ì¸ ë¶„ì„ ==================== #
root_cause_analysis = {
    # ---------------------- ì§ì ‘ì  ì›ì¸ ---------------------- #
    'direct_cause': 'test.csv íŒŒì¼ì— id ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ',

    # ---------------------- ì„¸ë¶€ ì›ì¸ ---------------------- #
    'detailed_causes': [
        '1. test.csv íŒŒì¼ì˜ ì‹¤ì œ ì»¬ëŸ¼: fname, dialogue',
        '2. ì½”ë“œì—ì„œ ê¸°ëŒ€í•˜ëŠ” ì»¬ëŸ¼: id, dialogue',
        '3. ì œì¶œ íŒŒì¼ ìƒì„± ì‹œ test_df["id"] ì ‘ê·¼ ì‹œë„',
        '4. fname ì»¬ëŸ¼ì„ idë¡œ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ ë³€í™˜ ë¡œì§ ë¶€ì¬'
    ],

    # ---------------------- ì½”ë“œ ë¬¸ì œì  ---------------------- #
    'code_issue': {
        'file': 'src/trainers/full_pipeline_trainer.py',
        'line': 533,
        'problematic_code': "submission_df = pd.DataFrame({'id': test_df['id'], 'summary': predictions})",
        'expected_columns': ['id', 'dialogue'],
        'actual_columns': ['fname', 'dialogue']
    },

    # ---------------------- ë°ì´í„° í˜•ì‹ ---------------------- #
    'data_format': {
        'train_csv': ['fname', 'dialogue', 'summary'],          # í•™ìŠµ ë°ì´í„°
        'test_csv': ['fname', 'dialogue'],                      # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        'expected_submission': ['id', 'summary'],               # ê¸°ëŒ€ ì œì¶œ í˜•ì‹
        'actual_submission': None                               # ìƒì„± ì‹¤íŒ¨
    }
}
```

### 5.4 ì¬í˜„ ì¡°ê±´

```python
# ==================== ì˜¤ë¥˜ ì¬í˜„ ì¡°ê±´ ==================== #
reproduction_conditions = {
    # ---------------------- í•„ìˆ˜ ì¡°ê±´ ---------------------- #
    'required_conditions': [
        'Full Pipeline ëª¨ë“œ ì‹¤í–‰',
        'test.csv íŒŒì¼ ë¡œë“œ',
        'ì œì¶œ íŒŒì¼ ìƒì„± ë‹¨ê³„ ì§„ì…',
        'test.csvì— id ì»¬ëŸ¼ ë¶€ì¬'
    ],

    # ---------------------- í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•ì‹ ---------------------- #
    'test_csv_format': {
        'columns': ['fname', 'dialogue'],                       # ì‹¤ì œ ì»¬ëŸ¼
        'sample_count': 499,                                    # ìƒ˜í”Œ ìˆ˜
        'fname_format': 'TRAIN_xxxxx ë˜ëŠ” TEST_xxxxx'           # fname í˜•ì‹
    }
}
```

### 5.5 ì˜¤ë¥˜ ë°œìƒ ì½”ë“œ

```python
# ==================== ì˜¤ë¥˜ ë°œìƒ ì½”ë“œ (full_pipeline_trainer.py:532-535) ==================== #

# âŒ ë¬¸ì œ ì½”ë“œ
submission_df = pd.DataFrame({
    'id': test_df['id'],                # â† KeyError: 'id' ë°œìƒ ì§€ì 
    'summary': predictions
})
```

---

## 6. ìˆ˜ì • ë°©í–¥ ë° ê°œì„ ì•ˆ

### 6.1 ì¦‰ì‹œ ìˆ˜ì • ì‚¬í•­ (Critical)

#### 6.1.1 test.csv ì»¬ëŸ¼ ì²˜ë¦¬ ìˆ˜ì •

```python
# ==================== ìˆ˜ì • ë°©ë²• 1: fname â†’ id ë³€í™˜ (ê¶Œì¥) ==================== #
# src/trainers/full_pipeline_trainer.py íŒŒì¼ ìˆ˜ì •

# ---------------------- ê¸°ì¡´ ì½”ë“œ (ì˜¤ë¥˜ ë°œìƒ) ---------------------- #
submission_df = pd.DataFrame({
    'id': test_df['id'],                # âŒ KeyError: 'id'
    'summary': predictions
})

# ---------------------- ìˆ˜ì • ì½”ë“œ 1: fnameì„ idë¡œ ì‚¬ìš© ---------------------- #
submission_df = pd.DataFrame({
    'id': test_df['fname'],             # âœ… fname ì»¬ëŸ¼ì„ idë¡œ ì‚¬ìš©
    'summary': predictions
})

# ---------------------- ìˆ˜ì • ì½”ë“œ 2: ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì•ˆì „) ---------------------- #
if 'id' in test_df.columns:
    id_column = test_df['id']
elif 'fname' in test_df.columns:
    id_column = test_df['fname']
else:
    # ì¸ë±ìŠ¤ë¥¼ idë¡œ ì‚¬ìš©
    id_column = range(len(test_df))

submission_df = pd.DataFrame({
    'id': id_column,
    'summary': predictions
})

# ---------------------- ìˆ˜ì • ì½”ë“œ 3: ìœ ì—°í•œ ì»¬ëŸ¼ ê°ì§€ (ìµœê³  ê¶Œì¥) ---------------------- #
def get_id_column(df):
    """
    DataFrameì—ì„œ ID ì»¬ëŸ¼ ìë™ ê°ì§€

    Args:
        df: pandas DataFrame

    Returns:
        Series: ID ì»¬ëŸ¼
    """
    # ìš°ì„ ìˆœìœ„: id > fname > index
    if 'id' in df.columns:
        return df['id']
    elif 'fname' in df.columns:
        return df['fname']
    else:
        # ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë˜, TEST_00000 í˜•ì‹ìœ¼ë¡œ ìƒì„±
        return [f"TEST_{i:05d}" for i in range(len(df))]

submission_df = pd.DataFrame({
    'id': get_id_column(test_df),
    'summary': predictions
})
```

#### 6.1.2 ìˆ˜ì • íŒŒì¼ ë° ìœ„ì¹˜

```bash
# ==================== ìˆ˜ì • ëŒ€ìƒ íŒŒì¼ ==================== #
íŒŒì¼: src/trainers/full_pipeline_trainer.py
ìœ„ì¹˜: ë¼ì¸ 532-535 (_create_submission ë©”ì„œë“œ ë‚´ë¶€)

# ---------------------- ìˆ˜ì • ì „ ---------------------- #
submission_df = pd.DataFrame({
    'id': test_df['id'],
    'summary': predictions
})

# ---------------------- ìˆ˜ì • í›„ ---------------------- #
submission_df = pd.DataFrame({
    'id': test_df.get('id', test_df.get('fname', range(len(test_df)))),
    'summary': predictions
})
```

### 6.2 ì¤‘ê¸° ê°œì„  ì‚¬í•­ (Important)

#### 6.2.1 ë°ì´í„° í˜•ì‹ ê²€ì¦ ë¡œì§ ì¶”ê°€

```python
# ==================== src/trainers/full_pipeline_trainer.py ê°œì„  ==================== #

def _validate_test_data(self, test_df):
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•ì‹ ê²€ì¦

    Args:
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„° DataFrame

    Raises:
        ValueError: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ì‹œ

    Returns:
        bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
    """
    required_columns = ['dialogue']                             # í•„ìˆ˜ ì»¬ëŸ¼
    optional_id_columns = ['id', 'fname']                       # ID ì»¬ëŸ¼ (ì„ íƒ)

    # ---------------------- í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ---------------------- #
    missing_columns = [col for col in required_columns if col not in test_df.columns]
    if missing_columns:
        raise ValueError(
            f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}\n"
            f"í˜„ì¬ ì»¬ëŸ¼: {list(test_df.columns)}"
        )

    # ---------------------- ID ì»¬ëŸ¼ í™•ì¸ ---------------------- #
    has_id_column = any(col in test_df.columns for col in optional_id_columns)
    if not has_id_column:
        self.log(
            f"  âš ï¸ ê²½ê³ : ID ì»¬ëŸ¼({optional_id_columns})ì´ ì—†ìŠµë‹ˆë‹¤. "
            f"ì¸ë±ìŠ¤ë¥¼ IDë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )

    self.log(f"  âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
    self.log(f"    - ì»¬ëŸ¼: {list(test_df.columns)}")
    self.log(f"    - ìƒ˜í”Œ ìˆ˜: {len(test_df)}")

    return True


def _create_submission(self, model_paths):
    """
    ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„± (ê°œì„  ë²„ì „)
    """
    try:
        # ... (ê¸°ì¡´ ì½”ë“œ) ...

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_df = pd.read_csv(test_data_path)
        self.log(f"  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_df)}")

        # âœ… ë°ì´í„° ê²€ì¦ ì¶”ê°€
        self._validate_test_data(test_df)

        # ... (ì¶”ë¡  ì½”ë“œ) ...

        # âœ… ID ì»¬ëŸ¼ ìë™ ê°ì§€
        id_column = self._get_id_column(test_df)

        # ì œì¶œ íŒŒì¼ ìƒì„±
        submission_df = pd.DataFrame({
            'id': id_column,
            'summary': predictions
        })

        # ... (ì €ì¥ ì½”ë“œ) ...

    except Exception as e:
        # ... (ì˜¤ë¥˜ ì²˜ë¦¬) ...


def _get_id_column(self, df):
    """
    DataFrameì—ì„œ ID ì»¬ëŸ¼ ìë™ ê°ì§€

    Args:
        df: pandas DataFrame

    Returns:
        Series or List: ID ì»¬ëŸ¼ ë˜ëŠ” ìƒì„±ëœ ID ë¦¬ìŠ¤íŠ¸
    """
    if 'id' in df.columns:
        self.log(f"    ID ì»¬ëŸ¼: id")
        return df['id']
    elif 'fname' in df.columns:
        self.log(f"    ID ì»¬ëŸ¼: fname")
        return df['fname']
    else:
        self.log(f"    ID ì»¬ëŸ¼ ì—†ìŒ, ì¸ë±ìŠ¤ ì‚¬ìš©")
        return [f"TEST_{i:05d}" for i in range(len(df))]
```

#### 6.2.2 ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦

```python
# ==================== ì œì¶œ íŒŒì¼ í›„ì²˜ë¦¬ ê²€ì¦ ==================== #

def _validate_submission_file(self, submission_df, output_path):
    """
    ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦

    Args:
        submission_df: ì œì¶œ DataFrame
        output_path: ì €ì¥ ê²½ë¡œ

    Returns:
        bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ---------------------- í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ---------------------- #
        required_columns = ['id', 'summary']
        missing_columns = [col for col in required_columns if col not in submission_df.columns]

        if missing_columns:
            self.log(f"    âŒ ì œì¶œ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ {missing_columns}")
            return False

        # ---------------------- ë°ì´í„° ê°œìˆ˜ í™•ì¸ ---------------------- #
        if len(submission_df) == 0:
            self.log(f"    âŒ ì œì¶œ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ")
            return False

        # ---------------------- ì¤‘ë³µ ID í™•ì¸ ---------------------- #
        duplicate_ids = submission_df['id'].duplicated().sum()
        if duplicate_ids > 0:
            self.log(f"    âš ï¸ ê²½ê³ : ì¤‘ë³µ ID {duplicate_ids}ê°œ ë°œê²¬")

        # ---------------------- ë¹ˆ ìš”ì•½ í™•ì¸ ---------------------- #
        empty_summaries = submission_df['summary'].isna().sum()
        if empty_summaries > 0:
            self.log(f"    âš ï¸ ê²½ê³ : ë¹ˆ ìš”ì•½ {empty_summaries}ê°œ ë°œê²¬")

        # ---------------------- ê²€ì¦ í†µê³¼ ---------------------- #
        self.log(f"    âœ… ì œì¶œ íŒŒì¼ ê²€ì¦ í†µê³¼")
        self.log(f"      - ID ê°œìˆ˜: {len(submission_df)}")
        self.log(f"      - ìš”ì•½ ê°œìˆ˜: {len(submission_df['summary'])}")
        self.log(f"      - ì €ì¥ ê²½ë¡œ: {output_path}")

        return True

    except Exception as e:
        self.log(f"    âŒ ì œì¶œ íŒŒì¼ ê²€ì¦ ì˜¤ë¥˜: {e}")
        return False
```

### 6.3 ì¥ê¸° ê°œì„  ì‚¬í•­ (Nice to Have)

#### 6.3.1 ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ê²€ì¦

```python
# ==================== src/utils/data_schema.py (ì‹ ê·œ) ==================== #

from dataclasses import dataclass
from typing import List, Optional
import pandas as pd


@dataclass
class DataSchema:
    """ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜"""
    required_columns: List[str]
    optional_columns: List[str]
    id_columns: List[str]


# ---------------------- ìŠ¤í‚¤ë§ˆ ì •ì˜ ---------------------- #
TRAIN_SCHEMA = DataSchema(
    required_columns=['dialogue', 'summary'],
    optional_columns=['fname'],
    id_columns=['fname']
)

TEST_SCHEMA = DataSchema(
    required_columns=['dialogue'],
    optional_columns=['fname', 'id'],
    id_columns=['id', 'fname']
)

SUBMISSION_SCHEMA = DataSchema(
    required_columns=['id', 'summary'],
    optional_columns=[],
    id_columns=['id']
)


def validate_dataframe(df: pd.DataFrame, schema: DataSchema, name: str = "ë°ì´í„°") -> bool:
    """
    DataFrame ìŠ¤í‚¤ë§ˆ ê²€ì¦

    Args:
        df: ê²€ì¦í•  DataFrame
        schema: ë°ì´í„° ìŠ¤í‚¤ë§ˆ
        name: ë°ì´í„° ì´ë¦„ (ë¡œê¹…ìš©)

    Returns:
        bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€

    Raises:
        ValueError: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ì‹œ
    """
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    missing_required = [col for col in schema.required_columns if col not in df.columns]
    if missing_required:
        raise ValueError(
            f"{name} ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ {missing_required}\n"
            f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}"
        )

    # ID ì»¬ëŸ¼ í™•ì¸ (í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ OK)
    has_id = any(col in df.columns for col in schema.id_columns)
    if not has_id and schema.id_columns:
        print(f"âš ï¸ ê²½ê³ : {name}ì— ID ì»¬ëŸ¼({schema.id_columns}) ì—†ìŒ")

    return True


# ==================== ì‚¬ìš© ì˜ˆì‹œ ==================== #
# train_df ë¡œë“œ í›„
validate_dataframe(train_df, TRAIN_SCHEMA, "í•™ìŠµ ë°ì´í„°")

# test_df ë¡œë“œ í›„
validate_dataframe(test_df, TEST_SCHEMA, "í…ŒìŠ¤íŠ¸ ë°ì´í„°")

# submission_df ìƒì„± í›„
validate_dataframe(submission_df, SUBMISSION_SCHEMA, "ì œì¶œ íŒŒì¼")
```

#### 6.3.2 ìë™ ì»¬ëŸ¼ ë§¤í•‘

```python
# ==================== src/utils/column_mapper.py (ì‹ ê·œ) ==================== #

from typing import Dict, Optional
import pandas as pd


class ColumnMapper:
    """ì»¬ëŸ¼ ìë™ ë§¤í•‘ í´ë˜ìŠ¤"""

    # ---------------------- ì»¬ëŸ¼ ë§¤í•‘ ê·œì¹™ ---------------------- #
    COLUMN_ALIASES = {
        'id': ['id', 'fname', 'file_name', 'filename', 'ID'],
        'dialogue': ['dialogue', 'text', 'input', 'context'],
        'summary': ['summary', 'output', 'target', 'label']
    }

    @classmethod
    def map_columns(cls, df: pd.DataFrame, target_columns: Dict[str, str]) -> pd.DataFrame:
        """
        DataFrame ì»¬ëŸ¼ ìë™ ë§¤í•‘

        Args:
            df: ì›ë³¸ DataFrame
            target_columns: ëª©í‘œ ì»¬ëŸ¼ ë§¤í•‘ (ì˜ˆ: {'id': 'id', 'dialogue': 'dialogue'})

        Returns:
            DataFrame: ì»¬ëŸ¼ì´ ë§¤í•‘ëœ DataFrame

        Example:
            >>> df = pd.DataFrame({'fname': [...], 'dialogue': [...]})
            >>> mapped_df = ColumnMapper.map_columns(df, {'id': 'id', 'dialogue': 'dialogue'})
            >>> # mapped_dfëŠ” fname â†’ idë¡œ ë§¤í•‘ë¨
        """
        mapped_df = df.copy()
        mapping = {}

        for target_col, _ in target_columns.items():
            # í•´ë‹¹ ì»¬ëŸ¼ì˜ ë³„ì¹­ ëª©ë¡
            aliases = cls.COLUMN_ALIASES.get(target_col, [target_col])

            # DataFrameì— ì¡´ì¬í•˜ëŠ” ì²« ë²ˆì§¸ ë³„ì¹­ ì°¾ê¸°
            for alias in aliases:
                if alias in mapped_df.columns:
                    if alias != target_col:
                        mapping[alias] = target_col
                    break

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½
        if mapping:
            mapped_df = mapped_df.rename(columns=mapping)

        return mapped_df


# ==================== ì‚¬ìš© ì˜ˆì‹œ ==================== #
# test.csv ë¡œë“œ
test_df = pd.read_csv('data/raw/test.csv')  # fname, dialogue

# ìë™ ë§¤í•‘ (fname â†’ id)
test_df = ColumnMapper.map_columns(test_df, {'id': 'id', 'dialogue': 'dialogue'})

# ì´ì œ test_df['id'] ì‚¬ìš© ê°€ëŠ¥
submission_df = pd.DataFrame({
    'id': test_df['id'],  # âœ… ì •ìƒ ì‘ë™
    'summary': predictions
})
```

### 6.4 ìˆ˜ì • ìš°ì„ ìˆœìœ„

```mermaid
graph TB
    subgraph P0["P0 - Critical (ì¦‰ì‹œ)"]
        A1[fname â†’ id ë³€í™˜<br/>1ì¤„ ìˆ˜ì •]
        A2[ì˜í–¥ë„: HIGH<br/>ì‘ì—…ëŸ‰: LOW]
    end

    subgraph P1["P1 - High (3ì¼)"]
        B1[ë°ì´í„° ê²€ì¦ ë¡œì§<br/>_validate_test_data]
        B2[ì˜í–¥ë„: HIGH<br/>ì‘ì—…ëŸ‰: LOW]
    end

    subgraph P2["P2 - Medium (1ì£¼ì¼)"]
        C1[ì œì¶œ íŒŒì¼ ê²€ì¦<br/>_validate_submission_file]
        C2[ì˜í–¥ë„: MEDIUM<br/>ì‘ì—…ëŸ‰: MEDIUM]
    end

    subgraph P3["P3 - Low (2ì£¼ì¼)"]
        D1[ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì‹œìŠ¤í…œ<br/>data_schema.py]
        D2[ì˜í–¥ë„: LOW<br/>ì‘ì—…ëŸ‰: HIGH]
    end

    P0 --> P1 --> P2 --> P3

    style P0 fill:#ffebee,stroke:#c62828,color:#000
    style P1 fill:#fff3e0,stroke:#f57c00,color:#000
    style P2 fill:#e8f5e9,stroke:#388e3c,color:#000
    style P3 fill:#e3f2fd,stroke:#1976d2,color:#000

    style A1 fill:#ffccbc,stroke:#d84315,color:#000
    style A2 fill:#ffccbc,stroke:#d84315,color:#000
    style B1 fill:#fff9c4,stroke:#f57f17,color:#000
    style B2 fill:#fff9c4,stroke:#f57f17,color:#000
    style C1 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style C2 fill:#a5d6a7,stroke:#2e7d32,color:#000
    style D1 fill:#90caf9,stroke:#1976d2,color:#000
    style D2 fill:#90caf9,stroke:#1976d2,color:#000
```

```python
# ==================== ìˆ˜ì • ìš°ì„ ìˆœìœ„ ==================== #
priority_order = [
    {
        'priority': 'P0 (Critical)',                                # ìµœìš°ì„ 
        'task': 'fname â†’ id ë³€í™˜ (1ì¤„ ìˆ˜ì •)',
        'impact': 'HIGH',                                           # ì˜í–¥ë„: ë†’ìŒ
        'effort': 'LOW',                                            # ì‘ì—…ëŸ‰: ë‚®ìŒ
        'deadline': 'ì¦‰ì‹œ',                                         # ë§ˆê°: ì¦‰ì‹œ
        'files': ['src/trainers/full_pipeline_trainer.py:533']
    },
    {
        'priority': 'P1 (High)',                                    # ë†’ìŒ
        'task': 'ë°ì´í„° ê²€ì¦ ë¡œì§ ì¶”ê°€',
        'impact': 'HIGH',
        'effort': 'LOW',
        'deadline': '3ì¼',
        'files': [
            'src/trainers/full_pipeline_trainer.py (_validate_test_data ì¶”ê°€)'
        ]
    },
    {
        'priority': 'P2 (Medium)',                                  # ì¤‘ê°„
        'task': 'ì œì¶œ íŒŒì¼ ê²€ì¦ ì¶”ê°€',
        'impact': 'MEDIUM',                                         # ì˜í–¥ë„: ì¤‘ê°„
        'effort': 'MEDIUM',                                         # ì‘ì—…ëŸ‰: ì¤‘ê°„
        'deadline': '1ì£¼ì¼',
        'files': [
            'src/trainers/full_pipeline_trainer.py (_validate_submission_file ì¶”ê°€)'
        ]
    },
    {
        'priority': 'P3 (Low)',                                     # ë‚®ìŒ
        'task': 'ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì‹œìŠ¤í…œ êµ¬ì¶•',
        'impact': 'LOW',                                            # ì˜í–¥ë„: ë‚®ìŒ
        'effort': 'HIGH',                                           # ì‘ì—…ëŸ‰: ë†’ìŒ
        'deadline': '2ì£¼ì¼',
        'files': [
            'src/utils/data_schema.py (ì‹ ê·œ)',
            'src/utils/column_mapper.py (ì‹ ê·œ)'
        ]
    }
]
```

---

## 7. ìˆ˜ì • ì™„ë£Œ í›„ ê²€ì¦ ê³„íš

### 7.1 ê²€ì¦ í”Œë¡œìš°

```mermaid
graph TB
    A[1ë‹¨ê³„<br/>ì½”ë“œ ìˆ˜ì •] --> B{ì»´íŒŒì¼<br/>ì˜¤ë¥˜?}
    B -->|Yes| A1[êµ¬ë¬¸ ì˜¤ë¥˜<br/>ìˆ˜ì •]
    B -->|No| C[2ë‹¨ê³„<br/>ë‹¨ìœ„ í…ŒìŠ¤íŠ¸]
    A1 --> A

    C --> D{í…ŒìŠ¤íŠ¸<br/>í†µê³¼?}
    D -->|No| C1[í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤<br/>ì¬ì‘ì„±]
    D -->|Yes| E[3ë‹¨ê³„<br/>ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸]
    C1 --> C

    E --> F{ì œì¶œ íŒŒì¼<br/>ìƒì„± ì„±ê³µ?}
    F -->|No| E1[ë°ì´í„° í™•ì¸<br/>ë””ë²„ê¹…]
    F -->|Yes| G[4ë‹¨ê³„<br/>í˜•ì‹ ê²€ì¦]
    E1 --> E

    G --> H{í˜•ì‹<br/>ì˜¬ë°”ë¦„?}
    H -->|No| G1[í›„ì²˜ë¦¬<br/>ìˆ˜ì •]
    H -->|Yes| I[âœ… ê²€ì¦ ì™„ë£Œ]
    G1 --> G

    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#fff59d,stroke:#f57f17,color:#000
    style C fill:#ffcc80,stroke:#f57c00,color:#000
    style D fill:#fff59d,stroke:#f57f17,color:#000
    style E fill:#a5d6a7,stroke:#388e3c,color:#000
    style F fill:#fff59d,stroke:#f57f17,color:#000
    style G fill:#ce93d8,stroke:#7b1fa2,color:#000
    style H fill:#fff59d,stroke:#f57f17,color:#000
    style I fill:#c8e6c9,stroke:#2e7d32,color:#000
    style A1 fill:#ef9a9a,stroke:#c62828,color:#000
    style C1 fill:#ef9a9a,stroke:#c62828,color:#000
    style E1 fill:#ef9a9a,stroke:#c62828,color:#000
    style G1 fill:#ef9a9a,stroke:#c62828,color:#000
```

### 7.2 ê²€ì¦ ë‹¨ê³„

```python
# ==================== ê²€ì¦ ê³„íš ==================== #
verification_plan = [
    {
        'stage': '1ë‹¨ê³„: ì½”ë“œ ìˆ˜ì •',
        'tasks': [
            '1. full_pipeline_trainer.py:533 ìˆ˜ì • (fname â†’ id)',
            '2. Python êµ¬ë¬¸ ì˜¤ë¥˜ ì²´í¬ (python -m py_compile)',
            '3. Git diffë¡œ ë³€ê²½ ì‚¬í•­ í™•ì¸'
        ],
        'expected_result': 'êµ¬ë¬¸ ì˜¤ë¥˜ ì—†ìŒ, 1ì¤„ ìˆ˜ì • í™•ì¸'
    },
    {
        'stage': '2ë‹¨ê³„: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸',
        'tasks': [
            '1. _get_id_column í•¨ìˆ˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸',
            '2. ë‹¤ì–‘í•œ ì»¬ëŸ¼ ì¡°í•© í…ŒìŠ¤íŠ¸ (id, fname, ì—†ìŒ)',
            '3. Edge Case í…ŒìŠ¤íŠ¸ (ë¹ˆ DataFrame, None ë“±)'
        ],
        'expected_result': 'ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µê³¼'
    },
    {
        'stage': '3ë‹¨ê³„: ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸',
        'tasks': [
            '1. test.csv ë¡œë“œ í…ŒìŠ¤íŠ¸',
            '2. ê°„ë‹¨í•œ ì¶”ë¡  ì‹¤í–‰ (1 Epoch, ì†ŒëŸ‰ ë°ì´í„°)',
            '3. ì œì¶œ íŒŒì¼ ìƒì„± í™•ì¸'
        ],
        'expected_result': 'CSV íŒŒì¼ ì •ìƒ ìƒì„± (id, summary ì»¬ëŸ¼)'
    },
    {
        'stage': '4ë‹¨ê³„: í˜•ì‹ ê²€ì¦',
        'tasks': [
            '1. ì œì¶œ íŒŒì¼ ì»¬ëŸ¼ í™•ì¸ (id, summary)',
            '2. ë°ì´í„° ê°œìˆ˜ í™•ì¸ (499ê°œ)',
            '3. ì¤‘ë³µ ID ë° ë¹ˆ ìš”ì•½ í™•ì¸',
            '4. íŒŒì¼ ì¸ì½”ë”© í™•ì¸ (UTF-8)'
        ],
        'expected_result': 'ì œì¶œ íŒŒì¼ í˜•ì‹ ì˜¬ë°”ë¦„, ë°ì´í„° ë¬´ê²°ì„± í™•ì¸'
    }
]
```

### 7.3 ê²€ì¦ ëª…ë ¹ì–´

```bash
# ==================== ê²€ì¦ ëª…ë ¹ì–´ ëª¨ìŒ ==================== #

# ---------------------- 1ë‹¨ê³„: êµ¬ë¬¸ ì˜¤ë¥˜ ì²´í¬ ---------------------- #
python -m py_compile src/trainers/full_pipeline_trainer.py

# ---------------------- 2ë‹¨ê³„: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (ì¶”í›„ êµ¬í˜„) ---------------------- #
pytest tests/test_full_pipeline_trainer.py -v

# ---------------------- 3ë‹¨ê³„: ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ---------------------- #
# ê°„ë‹¨í•œ 1 Epoch ì‹¤í–‰ìœ¼ë¡œ ì œì¶œ íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸
python scripts/train.py \
  --mode full \
  --models kobart \
  --epochs 1 \
  --batch_size 16 \
  --experiment_name test_submission_fix

# ---------------------- 4ë‹¨ê³„: ì œì¶œ íŒŒì¼ ê²€ì¦ ---------------------- #
# ìƒì„±ëœ ì œì¶œ íŒŒì¼ í™•ì¸
python -c "
import pandas as pd
df = pd.read_csv('submissions/20251013/test_submission_fix.csv')
print('Columns:', df.columns.tolist())
print('Shape:', df.shape)
print('First 5 rows:')
print(df.head())
print('Null check:', df.isnull().sum())
"
```

---

## 8. ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### 8.1 ì‹¤í—˜ ê²°ë¡ 

```python
# ==================== ì‹¤í—˜ ì¢…í•© í‰ê°€ ==================== #
experiment_summary = {
    # ---------------------- ì„±ê³µ ìš”ì†Œ ---------------------- #
    'successes': [
        'âœ… KoBART ëª¨ë¸ í•™ìŠµ ì„±ê³µ (ROUGE-Sum: 1.2369)',
        'âœ… Early Stopping ì •ìƒ ì‘ë™ (Epoch 5 Best)',
        'âœ… ì¶”ë¡  ìˆ˜í–‰ ì™„ë£Œ (499ê°œ ìƒ˜í”Œ)',
        'âœ… Solar API í†µí•© ì„±ê³µ (50ê°œ ìƒ˜í”Œ)',
        'âœ… í•™ìŠµ ì‹œê°„ íš¨ìœ¨ì  (Epochë‹¹ 1ë¶„ 20ì´ˆ)'
    ],

    # ---------------------- ì‹¤íŒ¨ ìš”ì†Œ ---------------------- #
    'failures': [
        'âŒ ì œì¶œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨ (KeyError: id)',
        'âŒ TTA ê¸°ëŠ¥ ë¯¸êµ¬í˜„'
    ],

    # ---------------------- í•™ìŠµëœ êµí›ˆ ---------------------- #
    'lessons_learned': [
        'ğŸ“ ë°ì´í„° ì»¬ëŸ¼ í˜•ì‹ ì‚¬ì „ ê²€ì¦ í•„ìš” (id vs fname)',
        'ğŸ“ ìœ ì—°í•œ ì»¬ëŸ¼ ë§¤í•‘ ë¡œì§ í•„ìš” (ìë™ ê°ì§€)',
        'ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± í›„ ê²€ì¦ ë‹¨ê³„ ì¶”ê°€',
        'ğŸ“ TTA ê¸°ëŠ¥ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ í•„ìš”'
    ]
}
```

### 8.2 ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­

```bash
# ==================== ì¦‰ì‹œ ìˆ˜ì • í•„ìš” (P0) ==================== #

# ---------------------- ì½”ë“œ ìˆ˜ì • ---------------------- #
# src/trainers/full_pipeline_trainer.py:533 ìˆ˜ì •

# ìˆ˜ì • ì „:
submission_df = pd.DataFrame({
    'id': test_df['id'],
    'summary': predictions
})

# ìˆ˜ì • í›„:
submission_df = pd.DataFrame({
    'id': test_df.get('id', test_df.get('fname', range(len(test_df)))),
    'summary': predictions
})
```

### 8.3 í–¥í›„ ì‹¤í—˜ ê¶Œì¥ì‚¬í•­

```python
# ==================== í–¥í›„ ì‹¤í—˜ ê¶Œì¥ì‚¬í•­ ==================== #
recommendations = [
    {
        'category': 'ì½”ë“œ í’ˆì§ˆ',
        'recommendations': [
            '1. ë°ì´í„° ë¡œë“œ ì‹œ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì¶”ê°€',
            '2. ì œì¶œ íŒŒì¼ ìƒì„± í›„ í˜•ì‹ ê²€ì¦',
            '3. ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™” (try-except-else-finally)',
            '4. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (pytest)'
        ]
    },
    {
        'category': 'ì‹¤í—˜ ì„¤ì •',
        'recommendations': [
            '1. Batch Size ì¦ê°€ í…ŒìŠ¤íŠ¸ (32, 64)',
            '2. Learning Rate íŠœë‹ (3e-5, 1e-4)',
            '3. Early Stopping Patience ì¡°ì • (5, 7)',
            '4. Max Length ìµœì í™” (í˜„ì¬ 100 â†’ 150)'
        ]
    },
    {
        'category': 'ê¸°ëŠ¥ êµ¬í˜„',
        'recommendations': [
            '1. TTA ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„',
            '2. K-Fold êµì°¨ ê²€ì¦ í†µí•©',
            '3. ì•™ìƒë¸” ì „ëµ í…ŒìŠ¤íŠ¸ (ë‹¤ì¤‘ ëª¨ë¸)',
            '4. WandB ë¡œê¹… ê°•í™”'
        ]
    },
    {
        'category': 'ì„±ëŠ¥ ê°œì„ ',
        'recommendations': [
            '1. ì¶”ë¡  ì†ë„ ìµœì í™” (Batch Size ì¦ê°€)',
            '2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§',
            '3. GPU í™œìš©ë„ ì¸¡ì •',
            '4. Gradient Accumulation í…ŒìŠ¤íŠ¸'
        ]
    }
]
```

### 8.4 ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥ì„±

```python
# ==================== ì„±ëŠ¥ ê°œì„  ì˜ˆì¸¡ ==================== #
performance_improvement_potential = {
    # ---------------------- í˜„ì¬ ì„±ëŠ¥ ---------------------- #
    'current_performance': {
        'rouge1': 0.4700,
        'rouge2': 0.3056,
        'rougeL': 0.4613,
        'rouge_sum': 1.2369
    },

    # ---------------------- ì˜ˆìƒ ê°œì„  (ë‹¨ì¼ ëª¨ë¸) ---------------------- #
    'single_model_potential': {
        'method': 'Hyperparameter Tuning',
        'expected_rouge_sum': 1.30,                 # +5% ê°œì„ 
        'confidence': 'HIGH'
    },

    # ---------------------- ì˜ˆìƒ ê°œì„  (ì•™ìƒë¸”) ---------------------- #
    'ensemble_potential': {
        'method': '3-5ê°œ ëª¨ë¸ ì•™ìƒë¸”',
        'expected_rouge_sum': 1.35,                 # +9% ê°œì„ 
        'confidence': 'MEDIUM'
    },

    # ---------------------- ì˜ˆìƒ ê°œì„  (TTA) ---------------------- #
    'tta_potential': {
        'method': 'TTA 3-5ê°œ ì¦ê°•',
        'expected_rouge_sum': 1.28,                 # +3% ê°œì„ 
        'confidence': 'MEDIUM'
    },

    # ---------------------- ìµœëŒ€ ì ì¬ë ¥ ---------------------- #
    'maximum_potential': {
        'method': 'Hyperparameter + Ensemble + TTA',
        'expected_rouge_sum': 1.40,                 # +13% ê°œì„ 
        'confidence': 'LOW',
        'note': 'ëª¨ë“  ê¸°ë²• ì¡°í•© ì‹œ ì˜ˆìƒ ì„±ëŠ¥'
    }
}
```

---

## 9. ì°¸ê³  ìë£Œ

### 9.1 ê´€ë ¨ ë¬¸ì„œ
- `docs/ëª¨ë“ˆí™”/04_ëª…ë ¹ì–´_ì˜µì…˜_ì™„ì „_ê°€ì´ë“œ.md` - ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª…ë ¹ì–´ ê°€ì´ë“œ
- `docs/ëª¨ë“ˆí™”/02_ëª¨ë¸_ì„¤ì •_ê°€ì´ë“œ.md` - ëª¨ë¸ Config ì„¤ì • ê°€ì´ë“œ
- `configs/models/kobart.yaml` - KoBART ëª¨ë¸ ì„¤ì •

### 9.2 ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
- **í•™ìŠµ ë¡œê·¸**: `logs/20251013/train/20251013_112713_full_kobart_bs16_ep8_aug_tta.log`
- **ì‹¤í—˜ ê²°ê³¼**: `experiments/20251013/20251013_111525_strategy1_kobart_optimized/full_pipeline_results.json`
- **ì²´í¬í¬ì¸íŠ¸**: `experiments/20251013/20251013_111525_strategy1_kobart_optimized/model_0_kobart/default/`

### 9.3 ìˆ˜ì • ëŒ€ìƒ íŒŒì¼

```python
# ==================== ìˆ˜ì • í•„ìš” íŒŒì¼ ëª©ë¡ ==================== #
files_to_modify = [
    # ---------------------- P0: ì½”ë“œ ìˆ˜ì • (ì¦‰ì‹œ) ---------------------- #
    {
        'file': 'src/trainers/full_pipeline_trainer.py',
        'line': 533,
        'change': "test_df['id'] â†’ test_df.get('id', test_df.get('fname', ...))",
        'priority': 'P0'
    },

    # ---------------------- P1: ê²€ì¦ ë¡œì§ (3ì¼) ---------------------- #
    {
        'file': 'src/trainers/full_pipeline_trainer.py',
        'method': '_validate_test_data (ì‹ ê·œ)',
        'change': 'ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë©”ì„œë“œ ì¶”ê°€',
        'priority': 'P1'
    },

    # ---------------------- P2: ì œì¶œ íŒŒì¼ ê²€ì¦ (1ì£¼ì¼) ---------------------- #
    {
        'file': 'src/trainers/full_pipeline_trainer.py',
        'method': '_validate_submission_file (ì‹ ê·œ)',
        'change': 'ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ ë©”ì„œë“œ ì¶”ê°€',
        'priority': 'P2'
    },

    # ---------------------- P3: ìœ í‹¸ë¦¬í‹° (2ì£¼ì¼) ---------------------- #
    {
        'file': 'src/utils/data_schema.py (ì‹ ê·œ)',
        'change': 'ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ê²€ì¦ ì‹œìŠ¤í…œ',
        'priority': 'P3'
    },
    {
        'file': 'src/utils/column_mapper.py (ì‹ ê·œ)',
        'change': 'ìë™ ì»¬ëŸ¼ ë§¤í•‘ ì‹œìŠ¤í…œ',
        'priority': 'P3'
    }
]
```

---

**ì‘ì„±ì¼**: 2025-10-13
**ì‘ì„±ì**: AI ì‹¤í—˜ ë¶„ì„ ì‹œìŠ¤í…œ
**ì‹¤í—˜ ID**: 20251013_111525_strategy1_kobart_optimized
