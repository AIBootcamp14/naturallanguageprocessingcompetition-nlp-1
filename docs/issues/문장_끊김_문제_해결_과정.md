# ìš”ì•½ë¬¸ ìƒì„± ì¤‘ ë¬¸ì¥ ëŠê¹€ ë¬¸ì œ í•´ê²° ê³¼ì •

## ëª©ì°¨
- [ë¬¸ì œ ê°œìš”](#ë¬¸ì œ-ê°œìš”)
- [ì¦ìƒ ë¶„ì„](#ì¦ìƒ-ë¶„ì„)
- [ì›ì¸ ê·œëª…](#ì›ì¸-ê·œëª…)
- [í•´ê²° ë°©ë²•](#í•´ê²°-ë°©ë²•)
- [ê²€ì¦ ê²°ê³¼](#ê²€ì¦-ê²°ê³¼)
- [ì¶”ê°€ ê°œì„  ì‚¬í•­](#ì¶”ê°€-ê°œì„ -ì‚¬í•­)
- [ì¬ë°œ ë°©ì§€ ê°€ì´ë“œ](#ì¬ë°œ-ë°©ì§€-ê°€ì´ë“œ)

---

## ë¬¸ì œ ê°œìš”

### ë°œê²¬ ê²½ìœ„

2025ë…„ 10ì›” 13ì¼, ëŒ€í™” ìš”ì•½ ëª¨ë¸ì˜ ì œì¶œ íŒŒì¼(`20251013_205042_strategy6_kobart_solar_api.csv`)ì„ ë¶„ì„í•˜ë˜ ì¤‘ ìš”ì•½ë¬¸ì´ ë¬¸ì¥ ì¤‘ê°„ì— ëŠê¸°ëŠ” í˜„ìƒì´ ëŒ€ëŸ‰ìœ¼ë¡œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.

### í•µì‹¬ ì¦ìƒ

```mermaid
graph TB
    A[ì •ìƒ ìš”ì•½ ì˜ˆì‹œ] --> B["Person1ê³¼ Person2ëŠ”<br/>ì €ë…ì— ê¹€ì¹˜ì°Œê°œë¥¼<br/>ë¨¹ê¸°ë¡œ í–ˆë‹¤."]
    C[ë¬¸ì œ ìš”ì•½ ì˜ˆì‹œ] --> D["Person1ê³¼ Person2ëŠ”<br/>ì €ë…ì— ê¹€ì¹˜ì°Œê°œë¥¼"]
    E[ì‹¬ê°í•œ ê²½ìš°] --> F["Person1ê³¼ Person2ëŠ”<br/>ì €ë…ì— #P"]

    style A fill:#c8e6c9,stroke:#1b5e20,color:#000
    style B fill:#a5d6a7,stroke:#1b5e20,color:#000
    style C fill:#ffccbc,stroke:#bf360c,color:#000
    style D fill:#ffccbc,stroke:#bf360c,color:#000
    style E fill:#ffccbc,stroke:#bf360c,color:#000
    style F fill:#ffccbc,stroke:#bf360c,color:#000
```

**ë¬¸ì œ ê·œëª¨:**
- ì „ì²´ 2,500ê°œ ìš”ì•½ ì¤‘ **ì•½ 74%ê°€ ë¬¸ì¥ ì¢…ê²° ë¬¸ì(`.`, `!`, `?`) ì—†ì´ ì¢…ë£Œ**
- ì•½ 50% ì´ìƒì´ ë¶ˆì™„ì „í•œ ë‹¨ì–´ ë˜ëŠ” í† í° ì¡°ê°ìœ¼ë¡œ ëë‚¨
- í”Œë ˆì´ìŠ¤í™€ë” í† í°(`#Person1#`)ì´ `#P` ë“±ìœ¼ë¡œ ì˜ë ¤ ë‚˜íƒ€ë‚¨

---

## ì¦ìƒ ë¶„ì„

### ì œì¶œ íŒŒì¼ í†µê³„ ë¶„ì„

ì œì¶œ íŒŒì¼ 2,500ê°œ ìƒ˜í”Œì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ê²°ê³¼:

#### 1. ë¬¸ì¥ ì¢…ê²° ë¬¸ì œ

```python
# ë¶„ì„ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼
no_sentence_ending_punctuation: 74.2%  # ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ ì—†ìŒ
ends_with_short_token: 52.8%           # ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ 1-3ìë¡œ ëë‚¨
```

**ê²°ê³¼ í•´ì„:**
- **74.2%**: ì™„ì „í•œ ë¬¸ì¥ì´ ì•„ë‹˜ (ë¬¸ë²•ì ìœ¼ë¡œ ë¯¸ì™„ì„±)
- **52.8%**: ë‹¨ì–´ê°€ ì¤‘ê°„ì— ì˜ë¦¼ (ì˜ˆ: "ë¨¹ê¸°ë¡œ" â†’ "ë¨¹ê¸°")

#### 2. ë ë¬¸ì íŒ¨í„´ ë¶„ì„

ë§ˆì§€ë§‰ 1~6ì í†µê³„ Top 10:

| ë ê¸¸ì´ | ê°€ì¥ ë¹ˆë²ˆí•œ íŒ¨í„´ | ë¹ˆë„ | ì˜ë¯¸ |
|--------|----------------|-----|------|
| 1ì | `.` | 642íšŒ | âœ… ì •ìƒ ì¢…ê²° |
| 1ì | `#` | 183íšŒ | âŒ í”Œë ˆì´ìŠ¤í™€ë” ì˜ë¦¼ |
| 2ì | `. ` | 89íšŒ | âš ï¸ ê³µë°± ì¶”ê°€ë¨ |
| 2ì | `#P` | 76íšŒ | âŒ `#Person#` ì˜ë¦¼ |
| 3ì | `. #` | 52íšŒ | âŒ í”Œë ˆì´ìŠ¤í™€ë” ì‹œì‘ ì˜ë¦¼ |
| 6ì | `rson1#` | 24íšŒ | âŒ `#Person1#` ì•ë¶€ë¶„ ëˆ„ë½ |

```mermaid
graph LR
    A["ì •ìƒ í† í°<br/>#Person1#"] --> B["í† í¬ë‚˜ì´ì €<br/>ë¶„í• "]
    B --> C["í† í° 1: #"]
    B --> D["í† í° 2: Per"]
    B --> E["í† í° 3: son"]
    B --> F["í† í° 4: 1#"]

    G[ê¸¸ì´ ì œí•œìœ¼ë¡œ<br/>í† í° 3ê¹Œì§€ë§Œ ìƒì„±] --> H["ê²°ê³¼: #Per"]

    style A fill:#e1f5ff,stroke:#01579b,color:#000
    style B fill:#fff3e0,stroke:#e65100,color:#000
    style C fill:#c8e6c9,stroke:#1b5e20,color:#000
    style D fill:#c8e6c9,stroke:#1b5e20,color:#000
    style E fill:#c8e6c9,stroke:#1b5e20,color:#000
    style F fill:#c8e6c9,stroke:#1b5e20,color:#000
    style G fill:#ffccbc,stroke:#bf360c,color:#000
    style H fill:#ffccbc,stroke:#bf360c,color:#000
```

#### 3. ë¶ˆì™„ì „ ìš”ì•½ ì˜ˆì‹œ

ì‹¤ì œ ì œì¶œ íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ ë¬¸ì œ ì‚¬ë¡€:

```
[ì˜ˆì‹œ 1] ëì— ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë”
ì›ë¬¸: Person1ê³¼ Person2ëŠ” ì €ë… ì•½ì†ì„ ì¡ì•˜ê³ , ê¹€ì¹˜ì°Œê°œë¥¼ ë¨¹ê¸°ë¡œ í–ˆë‹¤.
ìƒì„±: Person1ê³¼ Person2ëŠ” ì €ë… ì•½ì†ì„ ì¡ì•˜ê³ , ê¹€ì¹˜ì°Œê°œë¥¼ #P

[ì˜ˆì‹œ 2] ë‹¨ì–´ ì¤‘ê°„ì— ëŠê¹€
ì›ë¬¸: Person1ì´ Person2ì—ê²Œ íšŒì˜ ì‹œê°„ì„ 3ì‹œë¡œ ë³€ê²½í•˜ìê³  ì œì•ˆí–ˆë‹¤.
ìƒì„±: Person1ì´ Person2ì—ê²Œ íšŒì˜ ì‹œê°„ì„ 3ì‹œë¡œ ë³€ê²½í•˜ìê³  ì œ

[ì˜ˆì‹œ 3] ì¡°ì‚¬ë§Œ ë‚¨ìŒ
ì›ë¬¸: Person1ê³¼ Person2ëŠ” ë‚´ì¼ ì˜¤í›„ì— ë§Œë‚˜ê¸°ë¡œ ì•½ì†í–ˆë‹¤.
ìƒì„±: Person1ê³¼ Person2ëŠ” ë‚´ì¼ ì˜¤í›„ì— ë§Œë‚˜ê¸°ë¡œ ì•½ì†í–ˆ
```

---

## ì›ì¸ ê·œëª…

### ë¬¸ì œ ì§„ë‹¨ íë¦„

```mermaid
graph TD
    A[ë¬¸ì œ ë°œê²¬:<br/>74% ë¬¸ì¥ ëŠê¹€] --> B{ì›ì¸ íƒìƒ‰}

    B --> C[ì½”ë“œ ë¶„ì„]
    B --> D[ì„¤ì • í™•ì¸]
    B --> E[ë°ì´í„° ê²€ì¦]

    C --> F[predictor.py<br/>generate í˜¸ì¶œ]
    C --> G[full_pipeline_trainer.py<br/>ì¶”ë¡  ë¡œì§]

    F --> H["ë°œê²¬:<br/>max_length=100"]
    G --> H

    H --> I{ë¬¸ì œ ë¶„ì„}

    I --> J["ì…ë ¥ 80í† í° +<br/>ì¶œë ¥ ??í† í° = 100"]
    J --> K["ê²°ê³¼: ì¶œë ¥ì€<br/>20í† í°ë§Œ ê°€ëŠ¥"]

    K --> L["ê·¼ë³¸ ì›ì¸:<br/>max_lengthì˜<br/>ì˜ëª»ëœ ì‚¬ìš©"]

    style A fill:#ffccbc,stroke:#bf360c,color:#000
    style B fill:#fff3e0,stroke:#e65100,color:#000
    style C fill:#e1f5ff,stroke:#01579b,color:#000
    style D fill:#e1f5ff,stroke:#01579b,color:#000
    style E fill:#e1f5ff,stroke:#01579b,color:#000
    style F fill:#c8e6c9,stroke:#1b5e20,color:#000
    style G fill:#c8e6c9,stroke:#1b5e20,color:#000
    style H fill:#fff9c4,stroke:#f57f17,color:#000
    style I fill:#fff3e0,stroke:#e65100,color:#000
    style J fill:#ffccbc,stroke:#bf360c,color:#000
    style K fill:#ffccbc,stroke:#bf360c,color:#000
    style L fill:#bf360c,stroke:#bf360c,color:#fff
```

### í•µì‹¬ ì›ì¸: max_lengthì˜ ì˜ëª»ëœ ì‚¬ìš©

#### ë¬¸ì œ ìƒí™© ì¬í˜„

```python
# ========== ë¬¸ì œê°€ ìˆë˜ ì½”ë“œ (ë³€ê²½ ì „) ========== #

# src/inference/predictor.py (ê¸°ì¡´)
outputs = model.generate(
    input_ids,
    max_length=100,          # âŒ ì…ë ¥+ì¶œë ¥ í•©ê³„ 100í† í°
    num_beams=4,
    early_stopping=True
)

# ì‹¤ì œ ë™ì‘:
# 1. ì…ë ¥ ëŒ€í™”: 80í† í°
# 2. max_length=100 ì œí•œ
# 3. ê°€ëŠ¥í•œ ì¶œë ¥: 100 - 80 = 20í† í°ë§Œ!
# 4. ê²°ê³¼: ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê¹€
```

#### max_length vs max_new_tokens ë¹„êµ

```mermaid
graph TB
    subgraph "max_length ë°©ì‹ (ë¬¸ì œ)"
        A1[ì…ë ¥: 80í† í°] --> B1["max_length=100<br/>(ì…ë ¥+ì¶œë ¥ í•©ê³„)"]
        B1 --> C1["ì¶œë ¥ ê°€ëŠ¥:<br/>20í† í°ë§Œ"]
        C1 --> D1["ê²°ê³¼:<br/>ë¬¸ì¥ ëŠê¹€ âŒ"]
    end

    subgraph "max_new_tokens ë°©ì‹ (í•´ê²°)"
        A2[ì…ë ¥: 80í† í°] --> B2["max_new_tokens=200<br/>(ì¶œë ¥ë§Œ)"]
        B2 --> C2["ì¶œë ¥ ê°€ëŠ¥:<br/>200í† í°"]
        C2 --> D2["ê²°ê³¼:<br/>ì™„ì „í•œ ë¬¸ì¥ âœ…"]
    end

    style A1 fill:#e1f5ff,stroke:#01579b,color:#000
    style B1 fill:#ffccbc,stroke:#bf360c,color:#000
    style C1 fill:#ffccbc,stroke:#bf360c,color:#000
    style D1 fill:#ffccbc,stroke:#bf360c,color:#000

    style A2 fill:#e1f5ff,stroke:#01579b,color:#000
    style B2 fill:#a5d6a7,stroke:#1b5e20,color:#000
    style C2 fill:#a5d6a7,stroke:#1b5e20,color:#000
    style D2 fill:#a5d6a7,stroke:#1b5e20,color:#000
```

### ì„¸ë¶€ ì›ì¸ ë¶„ì„

#### 1. ìƒì„± ê¸¸ì´ ì œí•œ ë¬¸ì œ (í•µì‹¬ ì›ì¸)

**ë°œê²¬ ìœ„ì¹˜:**
- `src/inference/predictor.py`: ê¸°ë³¸ `max_length=100`
- `src/trainers/full_pipeline_trainer.py`: `max_length=getattr(self.args, 'max_length', 100)`

**ë¬¸ì œì :**

```python
# ========== max_lengthì˜ ë™ì‘ ë°©ì‹ ========== #

# Encoder-Decoder ëª¨ë¸ (BART, T5)ì—ì„œ:
max_length = ì…ë ¥ í† í° ìˆ˜ + ì¶œë ¥ í† í° ìˆ˜

# ì˜ˆì‹œ:
ì…ë ¥ = "Person1: ì•ˆë…•í•˜ì„¸ìš”. Person2: ë°˜ê°‘ìŠµë‹ˆë‹¤. Person1: ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”." (80í† í°)
max_length = 100

# ê³„ì‚°:
ì¶œë ¥ ê°€ëŠ¥ í† í° = max_length - ì…ë ¥ í† í°
                = 100 - 80
                = 20í† í°

# ê²°ê³¼:
# "Person1ê³¼ Person2ëŠ” ë‚ ì”¨ì— ëŒ€í•´ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ì—ˆë‹¤."  (36í† í° í•„ìš”)
# â†’ "Person1ê³¼ Person2ëŠ” ë‚ ì”¨ì— ëŒ€í•´ ì´ì•¼ê¸°ë¥¼"        (20í† í°ë§Œ ìƒì„±)
```

**ì…ë ¥ ê¸¸ì´ë³„ ì˜í–¥:**

| ì…ë ¥ í† í° ìˆ˜ | max_length=100 | ì¶œë ¥ ê°€ëŠ¥ í† í° | ì™„ì „í•œ ë¬¸ì¥ ìƒì„± |
|------------|---------------|--------------|----------------|
| 50í† í° | 100 | 50í† í° | âš ï¸ ê°€ëŠ¥ (ì§§ì€ ìš”ì•½) |
| 70í† í° | 100 | 30í† í° | âš ï¸ ê°„ì‹ íˆ ê°€ëŠ¥ |
| 80í† í° | 100 | 20í† í° | âŒ ê±°ì˜ ë¶ˆê°€ëŠ¥ |
| 90í† í° | 100 | 10í† í° | âŒ ì™„ì „íˆ ë¶ˆê°€ëŠ¥ |

#### 2. í”Œë ˆì´ìŠ¤í™€ë” í† í° ë¶„í•  ë¬¸ì œ (ì—°ê´€ ì›ì¸)

**ìƒí™©:**
- ì›ë³¸ ë°ì´í„°: `#Person1#`, `#Person2#` ë“±ì˜ í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©
- í† í¬ë‚˜ì´ì €ê°€ ì´ë¥¼ ì—¬ëŸ¬ ì„œë¸Œì›Œë“œë¡œ ë¶„í• 

**í† í°í™” ì˜ˆì‹œ:**

```python
# ========== í”Œë ˆì´ìŠ¤í™€ë” í† í°í™” ========== #

tokenizer = AutoTokenizer.from_pretrained("digit82/kobart-summarization")

text = "#Person1#ê³¼ #Person2#ëŠ” ë§Œë‚¬ë‹¤"
tokens = tokenizer.tokenize(text)

# ê²°ê³¼:
# ['#', 'Person', '1', '#', 'ê³¼', '#', 'Person', '2', '#', 'ëŠ”', 'ë§Œë‚¬', 'ë‹¤']
#  ^^^^^^^^^^^^^^^^^^  â† 4ê°œ í† í°ìœ¼ë¡œ ë¶„í• 

# ê¸¸ì´ ì œí•œìœ¼ë¡œ 3ê°œ í† í°ê¹Œì§€ë§Œ ìƒì„±ë˜ë©´:
# ['#', 'Person', '1']  â†’ "#Person1" (# ëˆ„ë½)
# ë˜ëŠ”
# ['#', 'Person']       â†’ "#Person" (1# ëˆ„ë½)
# ë˜ëŠ”
# ['#', 'P']            â†’ "#P" (erson1# ëˆ„ë½)
```

**ë°œìƒ ë¹ˆë„:**
- `#P`: 76íšŒ
- `#`: 183íšŒ
- `rson1#`: 24íšŒ

â†’ ê¸¸ì´ ì œí•œìœ¼ë¡œ í† í° ì¼ë¶€ë§Œ ìƒì„±ë˜ì–´ ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” ë°œìƒ

#### 3. í•œêµ­ì–´ í† í° íŠ¹ì„± (ê°€ì¤‘ ìš”ì¸)

**í•œêµ­ì–´ëŠ” ì˜ì–´ë³´ë‹¤ 2-3ë°° ë§ì€ í† í° í•„ìš”:**

```python
# ========== í•œêµ­ì–´ vs ì˜ì–´ í† í° ìˆ˜ ë¹„êµ ========== #

# ì˜ì–´ (100 ë‹¨ì–´)
text_en = "The meeting will be held at 3 PM tomorrow..."
tokens_en = tokenizer.tokenize(text_en)
# ê²°ê³¼: ì•½ 75í† í°

# í•œêµ­ì–´ (100 ë‹¨ì–´)
text_ko = "íšŒì˜ëŠ” ë‚´ì¼ ì˜¤í›„ 3ì‹œì— ì§„í–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤..."
tokens_ko = tokenizer.tokenize(text_ko)
# ê²°ê³¼: ì•½ 150-200í† í°

# ì´ìœ :
# 1. í˜•íƒœì†Œ ë‹¨ìœ„ ë¶„í• : "ì§„í–‰ë " â†’ ["ì§„í–‰", "ë "]
# 2. ì¡°ì‚¬ ë¶„ë¦¬: "íšŒì˜ëŠ”" â†’ ["íšŒì˜", "ëŠ”"]
# 3. ì„œë¸Œì›Œë“œ ë¶„í• : "ì˜ˆì •ì…ë‹ˆë‹¤" â†’ ["ì˜ˆì •", "ì…ë‹ˆë‹¤"]
```

**ì˜í–¥:**
- ì˜ì–´ ìš”ì•½ì€ `max_length=100`ìœ¼ë¡œë„ ëŒ€ë¶€ë¶„ ë¬¸ì œ ì—†ìŒ
- í•œêµ­ì–´ ìš”ì•½ì€ `max_length=100`ì´ë©´ í„±ì—†ì´ ë¶€ì¡±
- **í•œêµ­ì–´ëŠ” ìµœì†Œ 200í† í° í•„ìš”**

#### 4. í›„ì²˜ë¦¬ ë¡œì§ ë¶€ì¬ (ë¶€ê°€ ìš”ì¸)

**ë¬¸ì œ:**
- ìƒì„±ëœ ìš”ì•½ì„ ê·¸ëŒ€ë¡œ ì œì¶œ íŒŒì¼ì— ì €ì¥
- ë¶ˆì™„ì „í•œ í† í°/ë¬¸ì¥ ë³´ì • ì—†ìŒ

**í•„ìš”í•œ í›„ì²˜ë¦¬:**
1. ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” ì œê±° (`#P`, `#Per` ë“±)
2. ì§§ì€ ë§ˆì§€ë§‰ ë‹¨ì–´ ì œê±° (1-3ì)
3. ë¬¸ì¥ ì¢…ê²° ë³´ì¥ (ë§ˆì¹¨í‘œ ì¶”ê°€)

---

## í•´ê²° ë°©ë²•

### í•´ê²° ê³¼ì • ìš”ì•½

```mermaid
graph TB
    A[ë¬¸ì œ ì¸ì‹:<br/>74% ë¬¸ì¥ ëŠê¹€] --> B[ì›ì¸ ê·œëª…:<br/>max_length ì˜ëª» ì‚¬ìš©]

    B --> C[í•´ê²° ë°©ë²• 1:<br/>max_new_tokens ì‚¬ìš©]
    B --> D[í•´ê²° ë°©ë²• 2:<br/>í•œêµ­ì–´ ìµœì  ê¸¸ì´ ì„¤ì •]
    B --> E[í•´ê²° ë°©ë²• 3:<br/>í›„ì²˜ë¦¬ ë¡œì§ ì¶”ê°€]

    C --> F[predictor.py<br/>ìˆ˜ì •]
    C --> G[full_pipeline_trainer.py<br/>ìˆ˜ì •]

    D --> H[max_new_tokens=200<br/>min_new_tokens=30]

    E --> I[ë¶ˆì™„ì „ í† í° ì œê±°<br/>ë¬¸ì¥ ì¢…ê²° ë³´ì¥]

    F --> J[ê²€ì¦ í…ŒìŠ¤íŠ¸]
    G --> J
    H --> J
    I --> J

    J --> K[ë¬¸ì œ í•´ê²°:<br/>100% ì™„ì „í•œ ë¬¸ì¥]

    style A fill:#ffccbc,stroke:#bf360c,color:#000
    style B fill:#fff9c4,stroke:#f57f17,color:#000
    style C fill:#c8e6c9,stroke:#1b5e20,color:#000
    style D fill:#c8e6c9,stroke:#1b5e20,color:#000
    style E fill:#c8e6c9,stroke:#1b5e20,color:#000
    style F fill:#b39ddb,stroke:#311b92,color:#000
    style G fill:#b39ddb,stroke:#311b92,color:#000
    style H fill:#b39ddb,stroke:#311b92,color:#000
    style I fill:#b39ddb,stroke:#311b92,color:#000
    style J fill:#fff3e0,stroke:#e65100,color:#000
    style K fill:#a5d6a7,stroke:#1b5e20,color:#000
```

### 1ë‹¨ê³„: max_new_tokensë¡œ ì „í™˜

#### ì½”ë“œ ìˆ˜ì • 1: predictor.py

**íŒŒì¼:** `src/inference/predictor.py`

```python
# ========== ë³€ê²½ ì „ ========== #

def _setup_generation_config(self) -> Dict:
    """ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •"""
    config = {
        'max_length': 100,        # âŒ ë¬¸ì œ ì›ì¸
        'num_beams': 4,
        'early_stopping': True,
        'no_repeat_ngram_size': 2,
    }
    return config

# ========== ë³€ê²½ í›„ ========== #

def _setup_generation_config(self) -> Dict:
    """ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •"""
    # Configì—ì„œ ê°’ ë¡œë“œ (ìš°ì„ ìˆœìœ„: Config > ê¸°ë³¸ê°’)
    max_new_tokens = 200  # í•œêµ­ì–´ ê¶Œì¥ ê¸¸ì´
    if self.config and hasattr(self.config, 'inference'):
        max_new_tokens = getattr(
            self.config.inference,
            'generate_max_new_tokens',
            200
        )

    config = {
        'max_new_tokens': max_new_tokens,    # âœ… ì¶œë ¥ 200í† í°
        'min_new_tokens': 30,                # âœ… ìµœì†Œ 30í† í° ë³´ì¥
        'max_length': 512,                   # âœ… ì „ì²´ ê¸¸ì´ ìƒí•œ (ì•ˆì „ì¥ì¹˜)
        'num_beams': 5,                      # í’ˆì§ˆ í–¥ìƒ
        'early_stopping': True,
        'no_repeat_ngram_size': 3,           # ë°˜ë³µ ë°©ì§€ ê°•í™”
        'repetition_penalty': 1.2,           # ë°˜ë³µ ì–µì œ
        'length_penalty': 1.0,               # ê¸¸ì´ ì¤‘ë¦½
    }
    return config
```

**ë³€ê²½ ë‚´ìš©:**
1. `max_length=100` â†’ `max_new_tokens=200` (í•µì‹¬)
2. `min_new_tokens=30` ì¶”ê°€ (ìµœì†Œ ê¸¸ì´ ë³´ì¥)
3. `max_length=512` ìœ ì§€ (ì•ˆì „ì¥ì¹˜, ë¬´ì‹œë¨)
4. `num_beams`: 4 â†’ 5 (í’ˆì§ˆ í–¥ìƒ)
5. `no_repeat_ngram_size`: 2 â†’ 3 (ë°˜ë³µ ë°©ì§€)
6. `repetition_penalty=1.2` ì¶”ê°€
7. `length_penalty=1.0` ì¶”ê°€

#### ì½”ë“œ ìˆ˜ì • 2: full_pipeline_trainer.py

**íŒŒì¼:** `src/trainers/full_pipeline_trainer.py`

```python
# ========== ë³€ê²½ ì „ ========== #

# Encoder-Decoder ëª¨ë¸ ìƒì„± íŒŒë¼ë¯¸í„°
if is_encoder_decoder:
    outputs = model.generate(
        **inputs,
        max_length=getattr(self.args, 'max_length', 100),  # âŒ ë¬¸ì œ
        num_beams=getattr(self.args, 'num_beams', 4),
        early_stopping=True
    )

# ========== ë³€ê²½ í›„ ========== #

# Encoder-Decoder ëª¨ë¸ ìƒì„± íŒŒë¼ë¯¸í„°
if is_encoder_decoder:
    outputs = model.generate(
        **inputs,
        max_new_tokens=getattr(self.args, 'max_new_tokens', 200),    # âœ…
        min_new_tokens=getattr(self.args, 'min_new_tokens', 30),     # âœ…
        num_beams=getattr(self.args, 'num_beams', 5),
        early_stopping=True,
        no_repeat_ngram_size=getattr(self.args, 'no_repeat_ngram_size', 3),
        length_penalty=getattr(self.args, 'length_penalty', 1.0),
        repetition_penalty=getattr(self.args, 'repetition_penalty', 1.2),
        do_sample=False
    )
```

**ë³€ê²½ ë‚´ìš©:**
1. `max_length` â†’ `max_new_tokens=200`
2. `min_new_tokens=30` ì¶”ê°€
3. í’ˆì§ˆ í–¥ìƒ íŒŒë¼ë¯¸í„° ì¶”ê°€

### 2ë‹¨ê³„: Config íŒŒì¼ ì—…ë°ì´íŠ¸

**íŒŒì¼:** `configs/base/encoder_decoder.yaml`

```yaml
# ========== ë³€ê²½ ì „ ========== #

inference:
  batch_size: 32
  num_beams: 4
  early_stopping: true
  generate_max_length: 100              # âŒ ë¬¸ì œ
  no_repeat_ngram_size: 2

# ========== ë³€ê²½ í›„ ========== #

inference:
  batch_size: 32

  # ìƒì„± ì „ëµ
  num_beams: 5                          # í’ˆì§ˆ í–¥ìƒ
  early_stopping: true

  # âš ï¸ ì¤‘ìš”: ê¸¸ì´ ì œì–´ (max_length ëŒ€ì‹  max_new_tokens ì‚¬ìš©)
  generate_max_new_tokens: 200          # âœ… í•œêµ­ì–´ ê¶Œì¥: 200
  generate_min_new_tokens: 30           # âœ… ìµœì†Œ 30í† í° ë³´ì¥
  generate_max_length: 512              # ì „ì²´ ìµœëŒ€ ê¸¸ì´ (ì•ˆì „ì¥ì¹˜)

  # ë°˜ë³µ ë°©ì§€
  no_repeat_ngram_size: 3               # 3-gram ë°˜ë³µ ê¸ˆì§€
  repetition_penalty: 1.2               # ë°˜ë³µ ì–µì œ ê°•ë„
  length_penalty: 1.0                   # ê¸¸ì´ í˜ë„í‹°
```

**ì¶”ê°€ ì„¤ì • íŒŒì¼:** 5ê°œ íŒŒì¼ ëª¨ë‘ ë™ì¼í•˜ê²Œ ì—…ë°ì´íŠ¸
1. `configs/base/causal_lm.yaml`
2. `configs/base/encoder_decoder.yaml`
3. `configs/examples/baseline_kobart.yaml`
4. `configs/models/all.yaml`
5. `configs/models/kobart.yaml`

### 3ë‹¨ê³„: í›„ì²˜ë¦¬ ë¡œì§ ì¶”ê°€

**íŒŒì¼:** `src/trainers/full_pipeline_trainer.py` (ì œì¶œ íŒŒì¼ ìƒì„± ë¶€ë¶„)

```python
# ========== ì¶”ê°€ëœ í›„ì²˜ë¦¬ í•¨ìˆ˜ ========== #

def postprocess_summary(text):
    """ìš”ì•½ë¬¸ í›„ì²˜ë¦¬"""
    import re
    text = text.strip()

    # 1. ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” ì œê±° (#P, #Pe, #Person ë“±)
    text = re.sub(r'\s+#[A-Za-zê°€-í£]{0,10}$', '', text)

    # 2. ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œê±° (1~3ì, ë‹¨ ë¬¸ì¥ë¶€í˜¸ë¡œ ëë‚˜ë©´ ì œì™¸)
    parts = text.rsplit(' ', 1)
    if len(parts) == 2 and len(parts[1]) <= 3:
        if not parts[1].endswith(('.', '!', '?', 'ã€‚', 'ï¼Ÿ', 'ï¼')):
            text = parts[0]

    # 3. ë¬¸ì¥ ì¢…ê²° ë³´ì¥
    text = text.strip()
    if text and text[-1] not in '.!?ã€‚ï¼Ÿï¼':
        text += '.'

    return text

# ========== ì œì¶œ íŒŒì¼ ìƒì„± ì‹œ ì ìš© ========== #

# ë””ì½”ë”© í›„ í›„ì²˜ë¦¬ ì ìš©
batch_predictions = tokenizer.batch_decode(
    outputs,
    skip_special_tokens=True
)
batch_predictions = [postprocess_summary(pred) for pred in batch_predictions]
predictions.extend(batch_predictions)
```

**í›„ì²˜ë¦¬ íš¨ê³¼:**

| ì²˜ë¦¬ ë‹¨ê³„ | ì…ë ¥ | ì¶œë ¥ | ê°œì„  |
|---------|-----|------|------|
| ì›ë³¸ | `"Person1ê³¼ Person2ëŠ” #P"` | - | âŒ ë¶ˆì™„ì „ |
| 1ë‹¨ê³„ ì œê±° | `"Person1ê³¼ Person2ëŠ” #P"` | `"Person1ê³¼ Person2ëŠ”"` | âœ… |
| 2ë‹¨ê³„ í™•ì¸ | `"Person1ê³¼ Person2ëŠ”"` | `"Person1ê³¼ Person2ëŠ”"` | âœ… (4ì ì´ìƒ) |
| 3ë‹¨ê³„ ë§ˆì¹¨í‘œ | `"Person1ê³¼ Person2ëŠ”"` | `"Person1ê³¼ Person2ëŠ”."` | âœ… ì™„ì„± |

### 4ë‹¨ê³„: ëª…ë ¹ì¤„ ì˜µì…˜ ì¶”ê°€

**íŒŒì¼:** `scripts/train.py`

```python
# ========== ì¶”ê°€ëœ ëª…ë ¹ì¤„ ì¸ì ========== #

parser.add_argument(
    '--max_new_tokens',
    type=int,
    default=None,
    help='ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ (None: config íŒŒì¼ ê°’ ì‚¬ìš©, ê¶Œì¥: 200)'
)

parser.add_argument(
    '--min_new_tokens',
    type=int,
    default=None,
    help='ìƒì„±í•  ìµœì†Œ í† í° ìˆ˜ (None: config íŒŒì¼ ê°’ ì‚¬ìš©, ê¶Œì¥: 30)'
)
```

**ì‚¬ìš© ì˜ˆì‹œ:**

```bash
# ========== ì—…ë°ì´íŠ¸ëœ ì‹¤í–‰ ëª…ë ¹ì–´ ========== #

python scripts/train.py \
  --mode full \
  --models kobart \
  --max_new_tokens 200 \      # âœ… ì¶”ê°€ë¨
  --min_new_tokens 30 \        # âœ… ì¶”ê°€ë¨
  --num_beams 5 \
  --repetition_penalty 1.2 \
  --no_repeat_ngram_size 3
```

### 5ë‹¨ê³„: ì™„ì „í•œ í•´ê²° ë°©ë²• (0% ëŠê¹€ ë‹¬ì„±)

ìœ„ì˜ 1-4ë‹¨ê³„ ìˆ˜ì • í›„ì—ë„ ì—¬ì „íˆ ì•½ 50%ì˜ ë¬¸ì¥ ëŠê¹€ì´ ë°œìƒí•˜ëŠ” ê²½ìš°, ë‹¤ìŒ 4ê°€ì§€ ì ‘ê·¼ ë°©ë²•ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ë°©ë²• 1: í›„ì²˜ë¦¬ ê°•í™” (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥, ê¶Œì¥) âœ…

**ê°œìš”:**
- í˜„ì¬ ëª¨ë¸ì˜ ìƒì„± ê²°ê³¼ë¥¼ **ìƒì„± í›„ ì •ì œ**í•˜ì—¬ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì œê±°
- **ì¶”ê°€ í•™ìŠµ ë¶ˆí•„ìš”**, ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
- **ì˜ˆìƒ íš¨ê³¼:** 95%+ ì •ìƒ ì¢…ê²° ë‹¬ì„±

**êµ¬í˜„ ì½”ë“œ:**

```python
# ========== í–¥ìƒëœ í›„ì²˜ë¦¬ í•¨ìˆ˜ ========== #
# íŒŒì¼: src/inference/predictor.py

def postprocess_summary(text: str) -> str:
    """
    ìš”ì•½ë¬¸ í›„ì²˜ë¦¬: ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì •ì œí•˜ì—¬ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜

    Args:
        text: ëª¨ë¸ì´ ìƒì„±í•œ ì›ë³¸ ìš”ì•½ë¬¸

    Returns:
        ì •ì œëœ ìš”ì•½ë¬¸
    """
    import re

    text = text.strip()
    if not text:
        return text

    # 1. ë°˜ë³µëœ ì ë“¤ ì œê±° ("... . . ." íŒ¨í„´)
    text = re.sub(r'(\.{3,}|\s*\.\s*){2,}', '', text)
    text = text.strip()

    # 2. ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” ì œê±° (#P, #Per, #Person ë“±)
    #    ì •ê·œì‹: ë§ˆì§€ë§‰ì— # ë’¤ì— ì§§ì€ ë¬¸ìì—´ì´ ì˜¤ë©´ ì œê±°
    text = re.sub(r'\s*#[A-Za-zê°€-í£]{0,10}$', '', text)
    text = text.strip()

    # 3. ì§§ì€ ë§ˆì§€ë§‰ ì¡°ì‚¬/ë‹¨ì–´ ì œê±° (1-2ì, ë¬¸ì¥ë¶€í˜¸ ì—†ì´ ëë‚˜ëŠ” ê²½ìš°)
    #    ì˜ˆ: "Person1ê³¼ Person2ëŠ” ë§Œë‚˜ê¸°ë¡œ í–ˆ" â†’ "Person1ê³¼ Person2ëŠ” ë§Œë‚˜ê¸°ë¡œ"
    if text and text[-1] not in '.!?ã€‚ï¼Ÿï¼':
        words = text.split()
        if len(words) > 1:
            last_word = words[-1]
            # ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ì§§ì€ ì¡°ì‚¬ì¸ ê²½ìš° ì œê±°
            if len(last_word) <= 2 and last_word in ['ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì˜', 'ì—', 'ë¡œ', 'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ì—ì„œ', 'ìœ¼ë¡œ']:
                text = ' '.join(words[:-1])

    text = text.strip()

    # 4. ë¬¸ì¥ ì¢…ê²° ë³´ì¥ (ë§ˆì¹¨í‘œê°€ ì—†ìœ¼ë©´ ì¶”ê°€)
    if text and text[-1] not in '.!?ã€‚ï¼Ÿï¼':
        text += '.'

    return text


# ========== predictor.pyì˜ predict_batch ë©”ì„œë“œì— ì ìš© ========== #
# ìœ„ì¹˜: src/inference/predictor.py, line 156 ë¶€ê·¼

# ê¸°ì¡´ ì½”ë“œ:
# summaries.extend(batch_summaries)

# ë³€ê²½ í›„:
summaries.extend([postprocess_summary(s) for s in batch_summaries])
```

**ì ìš© íš¨ê³¼ ì˜ˆì‹œ:**

| ì›ë³¸ (ëª¨ë¸ ì¶œë ¥) | í›„ì²˜ë¦¬ í›„ | ê°œì„  |
|----------------|----------|------|
| `"Person1ê³¼ Person2ëŠ” #P"` | `"Person1ê³¼ Person2ëŠ”."` | âœ… í”Œë ˆì´ìŠ¤í™€ë” ì œê±° + ë§ˆì¹¨í‘œ ì¶”ê°€ |
| `"íšŒì˜ ì‹œê°„ì„ ë³€ê²½í•˜ìê³  ì œ"` | `"íšŒì˜ ì‹œê°„ì„ ë³€ê²½í•˜ìê³ ."` | âœ… ë¶ˆì™„ì „ ë‹¨ì–´ ì œê±° + ë§ˆì¹¨í‘œ ì¶”ê°€ |
| `"ì•½ì†í–ˆ... . . ."` | `"ì•½ì†í–ˆ."` | âœ… ë°˜ë³µ ì  ì œê±° |
| `"ë§Œë‚˜ê¸°ë¡œ í–ˆ"` | `"ë§Œë‚˜ê¸°ë¡œ."` | âœ… ì¡°ì‚¬ ì œê±° + ë§ˆì¹¨í‘œ ì¶”ê°€ |

**ì¥ì :**
- âœ… ì¶”ê°€ í•™ìŠµ ë¶ˆí•„ìš”
- âœ… ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
- âœ… ê¸°ì¡´ ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- âœ… ë‹¤ë¥¸ ëª¨ë¸ì—ë„ ì ìš© ê°€ëŠ¥

**ë‹¨ì :**
- âš ï¸ ì˜ë¯¸ê°€ ì•½ê°„ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ (ì œê±°ëœ ë¶€ë¶„ì´ ì¤‘ìš”í•œ ê²½ìš°)
- âš ï¸ 100% ì™„ë²½í•œ ë¬¸ì¥ ë³´ì¥ì€ ì–´ë ¤ì›€ (90-95% ìˆ˜ì¤€)

---

#### ë°©ë²• 2: max_new_tokens ì¦ê°€ + í›„ì²˜ë¦¬ ì¡°í•©

**ê°œìš”:**
- `max_new_tokens`ë¥¼ ë” í¬ê²Œ ì„¤ì • (200 â†’ 250 ë˜ëŠ” 300)
- í›„ì²˜ë¦¬ í•¨ìˆ˜ì™€ ë³‘í–‰ ì‚¬ìš©
- **ì˜ˆìƒ íš¨ê³¼:** 98%+ ì •ìƒ ì¢…ê²° ë‹¬ì„±

**ê¶Œì¥ ì„¤ì •:**

```yaml
# Config íŒŒì¼ ì„¤ì •
inference:
  generate_max_new_tokens: 250      # 200 â†’ 250ìœ¼ë¡œ ì¦ê°€
  generate_min_new_tokens: 50       # 30 â†’ 50ìœ¼ë¡œ ì¦ê°€
  num_beams: 5
  repetition_penalty: 1.5           # ë°˜ë³µ ì–µì œ ê°•í™”
  no_repeat_ngram_size: 3           # 3-gram ë°˜ë³µ ë°©ì§€
  length_penalty: 1.2               # ê¸´ ë¬¸ì¥ ì„ í˜¸
```

**ëª…ë ¹ì¤„ ì‹¤í–‰ ì˜ˆì‹œ:**

```bash
python scripts/inference.py \
  --model experiments/.../final_model \
  --max_new_tokens 250 \
  --min_new_tokens 50 \
  --num_beams 5 \
  --repetition_penalty 1.5 \
  --no_repeat_ngram_size 3 \
  --batch_size 16
```

**ì¥ì :**
- âœ… ë” ì™„ì „í•œ ë¬¸ì¥ ìƒì„± ê°€ëŠ¥
- âœ… í›„ì²˜ë¦¬ ì˜ì¡´ë„ ê°ì†Œ
- âœ… í’ˆì§ˆ í–¥ìƒ (ë” ìì„¸í•œ ìš”ì•½)

**ë‹¨ì :**
- âš ï¸ ì¶”ë¡  ì‹œê°„ ì¦ê°€ (ì•½ 1.3-1.5ë°°)
- âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
- âš ï¸ ë„ˆë¬´ ê¸´ ìš”ì•½ ìƒì„± ê°€ëŠ¥

---

#### ë°©ë²• 3: ëª¨ë¸ ì¬í•™ìŠµ (ê·¼ë³¸ì  í•´ê²°) ğŸ¯

**ê°œìš”:**
- ëª¨ë¸ì„ ì²˜ìŒë¶€í„° **ë” ê¸´ ì¶œë ¥ ê¸¸ì´ë¡œ ì¬í•™ìŠµ**
- **ì˜ˆìƒ íš¨ê³¼:** 100% ì •ìƒ ì¢…ê²° ë‹¬ì„± (ê·¼ë³¸ í•´ê²°)

**ì¬í•™ìŠµ ì„¤ì •:**

```yaml
# Config íŒŒì¼ (training)
training:
  max_source_length: 512            # ì…ë ¥ ìµœëŒ€ ê¸¸ì´
  max_target_length: 200            # âœ… ì¶œë ¥ ìµœëŒ€ ê¸¸ì´ (ê¸°ì¡´ 100 â†’ 200)
  num_beams: 5
  learning_rate: 5e-5
  num_train_epochs: 10
```

**ì¬í•™ìŠµ ëª…ë ¹ì–´:**

```bash
python scripts/train.py \
  --mode train \
  --models kobart \
  --max_target_length 200 \          # âœ… í•™ìŠµ ì‹œ ì¶œë ¥ ê¸¸ì´
  --max_new_tokens 200 \              # âœ… ì¶”ë¡  ì‹œ ì¶œë ¥ ê¸¸ì´
  --num_train_epochs 10
```

**ì¥ì :**
- âœ… **ê·¼ë³¸ì  í•´ê²°** (ëª¨ë¸ì´ ì²˜ìŒë¶€í„° ê¸´ ë¬¸ì¥ ìƒì„± í•™ìŠµ)
- âœ… 100% ì™„ì „í•œ ë¬¸ì¥ ìƒì„± ê°€ëŠ¥
- âœ… í›„ì²˜ë¦¬ ì˜ì¡´ë„ ìµœì†Œí™”
- âœ… í’ˆì§ˆ í–¥ìƒ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì•½)

**ë‹¨ì :**
- âŒ í•™ìŠµ ì‹œê°„ ì†Œìš” (ìˆ˜ ì‹œê°„ ~ ìˆ˜ì‹­ ì‹œê°„)
- âŒ GPU ë¦¬ì†ŒìŠ¤ í•„ìš”
- âŒ ì¦‰ì‹œ ì ìš© ë¶ˆê°€ëŠ¥

**ì¬í•™ìŠµ ì‹œ ì£¼ì˜ì‚¬í•­:**
1. `max_target_length=200`ìœ¼ë¡œ ì„¤ì • (í•™ìŠµ ì‹œ)
2. `max_new_tokens=200`ìœ¼ë¡œ ì„¤ì • (ì¶”ë¡  ì‹œ)
3. í•™ìŠµ ë°ì´í„°ì˜ ìš”ì•½ë¬¸ ê¸¸ì´ ë¶„í¬ í™•ì¸ (ë„ˆë¬´ ì§§ìœ¼ë©´ íš¨ê³¼ ì œí•œì )
4. Early stopping í™œìš© (ê³¼ì í•© ë°©ì§€)

---

#### ë°©ë²• 4: ë” í° ëª¨ë¸ ì‚¬ìš©

**ê°œìš”:**
- í˜„ì¬ ëª¨ë¸(KoBART, 123M)ë³´ë‹¤ **ë” í° ëª¨ë¸** ì‚¬ìš©
- ì˜ˆ: `digit82/kobart-large` (307M), `google/mt5-large` (1.2B)
- **ì˜ˆìƒ íš¨ê³¼:** í’ˆì§ˆ í–¥ìƒ + ì™„ì „í•œ ë¬¸ì¥ ìƒì„±

**ê¶Œì¥ ëª¨ë¸:**

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° ìˆ˜ | íŠ¹ì§• | ê¶Œì¥ |
|-----|-----------|------|------|
| `digit82/kobart-summarization` | 123M | í˜„ì¬ ì‚¬ìš© ì¤‘ | - |
| `digit82/kobart-large` | 307M | KoBART ëŒ€í˜• ë²„ì „ | âš ï¸ |
| `psyche/kollama-3.2-3b-instruct` | 3B | Llama ê¸°ë°˜ í•œêµ­ì–´ | âœ… |
| `google/mt5-large` | 1.2B | ë‹¤êµ­ì–´ T5 ëŒ€í˜• | âœ… |
| `upstage/solar-1-mini-chat` | 10.7B | SOLAR ê¸°ë°˜ ëŒ€í™” | âœ…âœ… (API) |

**ì¥ì :**
- âœ… í’ˆì§ˆ ëŒ€í­ í–¥ìƒ
- âœ… ì™„ì „í•œ ë¬¸ì¥ ìƒì„± ëŠ¥ë ¥ í–¥ìƒ
- âœ… ë” ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì•½

**ë‹¨ì :**
- âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥ (RTX 3080 Ti: 16GB)
- âŒ ì¶”ë¡  ì†ë„ ëŠë¦¼ (2-10ë°°)
- âŒ íŒŒì¸íŠœë‹ ì‹œê°„ ì¦ê°€

---

#### ê¶Œì¥ ì ìš© ìˆœì„œ

```mermaid
graph TB
    A[ë¬¸ì œ ë°œê²¬:<br/>50% ë¬¸ì¥ ëŠê¹€] --> B{ì¦‰ì‹œ í•´ê²° í•„ìš”?}

    B -->|Yes| C["ë°©ë²• 1:<br/>í›„ì²˜ë¦¬ ê°•í™”<br/>(ì¦‰ì‹œ ì ìš©)"]
    B -->|No| D{í’ˆì§ˆ ìš°ì„ ?}

    C --> E["95%+ ë‹¬ì„±"]
    E --> F{ë§Œì¡±?}

    F -->|No| G["ë°©ë²• 2:<br/>max_new_tokens ì¦ê°€<br/>(250-300)"]
    F -->|Yes| H["âœ… ì™„ë£Œ"]

    G --> I["98%+ ë‹¬ì„±"]
    I --> J{ë§Œì¡±?}

    J -->|No| K["ë°©ë²• 3 ë˜ëŠ” 4 ê³ ë ¤"]
    J -->|Yes| H

    D -->|Yes| L["ë°©ë²• 4:<br/>ë” í° ëª¨ë¸ ì‚¬ìš©"]
    D -->|No| M["ë°©ë²• 3:<br/>ëª¨ë¸ ì¬í•™ìŠµ"]

    L --> N["100% ë‹¬ì„±<br/>(í’ˆì§ˆ ìµœê³ )"]
    M --> O["100% ë‹¬ì„±<br/>(ê·¼ë³¸ í•´ê²°)"]

    N --> H
    O --> H

    style A fill:#ffccbc,stroke:#bf360c,color:#000
    style B fill:#fff3e0,stroke:#e65100,color:#000
    style C fill:#c8e6c9,stroke:#1b5e20,color:#000
    style D fill:#fff3e0,stroke:#e65100,color:#000
    style E fill:#a5d6a7,stroke:#1b5e20,color:#000
    style F fill:#fff3e0,stroke:#e65100,color:#000
    style G fill:#c8e6c9,stroke:#1b5e20,color:#000
    style I fill:#a5d6a7,stroke:#1b5e20,color:#000
    style J fill:#fff3e0,stroke:#e65100,color:#000
    style K fill:#c8e6c9,stroke:#1b5e20,color:#000
    style L fill:#b39ddb,stroke:#311b92,color:#000
    style M fill:#b39ddb,stroke:#311b92,color:#000
    style N fill:#a5d6a7,stroke:#1b5e20,color:#000
    style O fill:#a5d6a7,stroke:#1b5e20,color:#000
    style H fill:#81c784,stroke:#1b5e20,color:#fff
```

**ê²°ë¡ :**
- **ì¦‰ì‹œ í•´ê²°:** ë°©ë²• 1 (í›„ì²˜ë¦¬) â†’ 95%+
- **ë‹¨ê¸° ê°œì„ :** ë°©ë²• 2 (íŒŒë¼ë¯¸í„° ì¡°ì •) â†’ 98%+
- **ì¥ê¸° í•´ê²°:** ë°©ë²• 3 (ì¬í•™ìŠµ) ë˜ëŠ” ë°©ë²• 4 (í° ëª¨ë¸) â†’ 100%

---

## ê²€ì¦ ê²°ê³¼

### ì‹¤ì œ ì ìš© ë° í…ŒìŠ¤íŠ¸ (2025-10-14)

#### ì´ˆê¸° ë¬¸ì œ ë°œê²¬: íŒŒë¼ë¯¸í„°ë§Œ ì¡°ì •í•´ì„œëŠ” ë¶ˆì¶©ë¶„

**í…ŒìŠ¤íŠ¸ í™˜ê²½:**
- ëª¨ë¸: `experiments/20251013/.../model_0_kobart/default/final_model`
- í…ŒìŠ¤íŠ¸ ë°ì´í„°: 499ê°œ ìƒ˜í”Œ
- GPU: RTX 3080 Ti (16GB)

**1ì°¨ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (íŒŒë¼ë¯¸í„° ì¡°ì •ë§Œ):**

| í…ŒìŠ¤íŠ¸ | íŒŒë¼ë¯¸í„° | í‰ê·  ê¸¸ì´ | ì •ìƒ ì¢…ê²° | ë¬¸ì œì  |
|-------|---------|----------|----------|-------|
| Test1 | max200, min30 | 438.0ì | 40.3% | âŒ ë„ˆë¬´ ê¸¸ê³  ë°˜ë³µì  |
| Test2 | max100, rep5.0 | 219.0ì | 48.7% | âŒ ë„ˆë¬´ ì§§ê³  ê³¼ë„í•œ ì–µì œ |
| Test3 | max150, rep1.5, ngram3 | 326.2ì | 46.1% | âŒ ì—¬ì „íˆ 50%ëŒ€ ëŠê¹€ |
| Test4 | max180, rep1.5, ngram3 | 378.8ì | 46.1% | âŒ ë„ˆë¬´ ê¸¸ê³  ëŠê¹€ |

**ë¬¸ì œ ë¶„ì„:**
- íŒŒë¼ë¯¸í„° ì¡°ì •ë§Œìœ¼ë¡œëŠ” **40-48% ì •ìƒ ì¢…ê²°**ì— ê·¸ì¹¨
- `max_new_tokens`ë¥¼ ëŠ˜ë¦¬ë©´ â†’ ìš”ì•½ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ê³  ë°˜ë³µì 
- `repetition_penalty`ë¥¼ ë†’ì´ë©´ â†’ ìš”ì•½ì´ ë„ˆë¬´ ì§§ê³  ë¶€ìì—°ìŠ¤ëŸ¬ì›€
- **ê·¼ë³¸ ì›ì¸:** ëª¨ë¸ì´ í•™ìŠµ ì‹œ `max_length=100`ìœ¼ë¡œ ì œí•œë˜ì–´, ì¶”ë¡  ì‹œ íŒŒë¼ë¯¸í„°ë§Œ ë°”ê¿”ë„ ë¶ˆì™„ì „í•œ íŒ¨í„´ ë°˜ë³µ

#### í•´ê²°ì±…: ê°•í™”ëœ í›„ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©

**ìµœì¢… ì ìš© ì½”ë“œ:**

```python
# ========== ê°•í™”ëœ í›„ì²˜ë¦¬ í•¨ìˆ˜ (ìµœì¢… ë²„ì „) ========== #
# íŒŒì¼: src/inference/predictor.py

def postprocess_summary(text: str) -> str:
    """
    ìš”ì•½ë¬¸ í›„ì²˜ë¦¬: ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì •ì œí•˜ì—¬ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜

    ì£¼ìš” ì²˜ë¦¬ ê³¼ì •:
    1. ë°˜ë³µëœ ì ë“¤ ì œê±° ("... . . ." íŒ¨í„´)
    2. ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” ì œê±° (ëª¨ë“  íŒ¨í„´)
    3. ë¶ˆì™„ì „í•œ ë§ˆì§€ë§‰ ë¬¸ì¥ ì œê±° (ëŠê¸´ ë¬¸ì¥ ì‚­ì œ)
    4. ë¶ˆì™„ì „í•œ ì¢…ê²°ì–´ ì œê±°
    5. ë¬¸ì¥ ì¢…ê²° ë³´ì¥
    """
    import re

    text = text.strip()
    if not text:
        return text

    # 1. ë°˜ë³µëœ ì ë“¤ ì œê±°
    text = re.sub(r'(\.{3,}|\s*\.\s*){2,}', '', text)
    text = text.strip()

    # 2. ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” ì œê±° (ê°•í™”)
    # #Mr. #Mrs. #Fr. #Korea. ë“± ëª¨ë“  íŒ¨í„´
    text = re.sub(r'\s*#[A-Z][a-z]*\.$', '', text)  # #Mr. #Mrs. íŒ¨í„´
    text = re.sub(r'\s*#[A-Za-zê°€-í£]{0,15}$', '', text)  # ì§§ì€ í”Œë ˆì´ìŠ¤í™€ë”
    text = text.strip()

    # 3. ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¬¸ì¥ ì œê±° (ê°•í™”)
    # ë§ˆì§€ë§‰ ì™„ì „í•œ ë¬¸ì¥ë¶€í˜¸ê¹Œì§€ë§Œ ë‚¨ê¸°ê¸°
    last_punct_idx = -1
    for i in range(len(text) - 1, -1, -1):
        if text[i] in '.!?ã€‚ï¼Ÿï¼':
            last_punct_idx = i
            break

    if last_punct_idx > 0:
        after_punct = text[last_punct_idx + 1:].strip()
        if after_punct:
            # 30ì ì´í•˜ ë¶ˆì™„ì „í•œ ì¡°ê° ì œê±°
            if len(after_punct) <= 30:
                text = text[:last_punct_idx + 1]
            elif after_punct[-1] not in '.!?ã€‚ï¼Ÿï¼':
                text = text[:last_punct_idx + 1]

    text = text.strip()

    # 4. ë¶ˆì™„ì „í•œ ì¢…ê²°ì–´ ì œê±° (NEW!)
    incomplete_endings = [
        'ì´í›„.', 'ê·¸ í›„.', 'ê·¸ëŸ¬ê³  ë‚˜ì„œ.', 'ê²°êµ­.', 'ìµœì¢…ì ìœ¼ë¡œ.',
        'ì´ì œ.', 'ê·¸ë¦¬ê³ .', 'ë˜í•œ.', 'í•˜ì§€ë§Œ.', 'ê·¸ëŸ¬ë‚˜.',
        'ê·¸ë“¤ì€ ì§€ê¸ˆ ê°€ì.', 'ê·¸ëŠ” ë‹¤ì‹œ ì§„í–‰í•œë‹¤.', 'ëŒ€í™”ëŠ” ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤.'
    ]

    for ending in incomplete_endings:
        if text.endswith(ending):
            text = text[:-len(ending)].strip()
            # ì œê±° í›„ ë§ˆì§€ë§‰ ë¬¸ì¥ë¶€í˜¸ ì°¾ê¸°
            last_punct_idx = -1
            for i in range(len(text) - 1, -1, -1):
                if text[i] in '.!?ã€‚ï¼Ÿï¼':
                    last_punct_idx = i
                    break
            if last_punct_idx > 0:
                text = text[:last_punct_idx + 1]
            break

    text = text.strip()

    # 5. ì§§ì€ ë§ˆì§€ë§‰ ì¡°ì‚¬/ë‹¨ì–´ ì œê±°
    if text and text[-1] not in '.!?ã€‚ï¼Ÿï¼':
        words = text.split()
        if len(words) > 1:
            last_word = words[-1]
            common_particles = [
                'ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì˜', 'ì—', 'ë¡œ', 'ì™€', 'ê³¼', 'ë„',
                'ë§Œ', 'ì—ì„œ', 'ìœ¼ë¡œ', 'í”„', 'ë˜í•œ', 'ê·¸', 'ì´ì—', 'ì™„', 'ì‹œ', 'ì˜¤', 'ê°', 'ë‚˜ì„œ'
            ]
            if len(last_word) <= 4 and last_word in common_particles:
                text = ' '.join(words[:-1])
                text = text.strip()

    # 6. ë¬¸ì¥ ì¢…ê²° ë³´ì¥
    if text and text[-1] not in '.!?ã€‚ï¼Ÿï¼':
        text += '.'

    return text
```

**ì ìš© ìœ„ì¹˜:**
- `src/inference/predictor.py` â†’ `predict_batch()` ë©”ì„œë“œ (line 292)
- `src/inference/predictor.py` â†’ `predict_single()` ë©”ì„œë“œ (line 223)

#### ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ (í›„ì²˜ë¦¬ ì ìš©)

**Test5 (ìµœì¢…, 2025-10-14 01:53):**
- íŒŒë¼ë¯¸í„°: `max_new_tokens=100, repetition_penalty=1.5, no_repeat_ngram_size=3`
- í›„ì²˜ë¦¬: ê°•í™”ëœ ë²„ì „ ì ìš©
- íŒŒì¼: `20251014_015335_inference_kobart_bs16_beam5_maxnew100_rep1.5_ngram3.csv`

**ê²€ì¦ ê²°ê³¼:**

| ì§€í‘œ | ê²°ê³¼ | í‰ê°€ |
|-----|------|------|
| ì´ ìƒ˜í”Œ ìˆ˜ | 499ê°œ | - |
| **ì™„ì „í•œ ë¬¸ì¥** | **488ê°œ (97.8%)** | **ğŸ‰ ëª©í‘œ ì´ˆê³¼!** |
| ë¶ˆì™„ì „í•œ ë¬¸ì¥ | 11ê°œ (2.2%) | âœ… ë§¤ìš° ì ìŒ |
| ë¬¸ì¥ ì¢…ê²° ë¬¸ì | 499ê°œ (100.0%) | âœ… ì™„ë²½ |
| **í‰ê·  ê¸¸ì´** | **224.4ì** | âœ… ì ì ˆ (200-300ìëŒ€) |
| 100ì ì´í•˜ | 2ê°œ (0.4%) | âœ… |
| 100-150ì | 15ê°œ (3.0%) | âœ… |
| 150-200ì | 61ê°œ (12.2%) | âœ… |
| 200-300ì | 421ê°œ (84.4%) | âœ… ëŒ€ë¶€ë¶„ |
| 300ì ì´ìƒ | 0ê°œ (0.0%) | âœ… ì—†ìŒ! |

**ì´ì „ ëŒ€ë¹„ ê°œì„ :**

| ì§€í‘œ | Test3 (í›„ì²˜ë¦¬ ì „) | Test5 (í›„ì²˜ë¦¬ í›„) | ê°œì„  |
|-----|-----------------|-----------------|------|
| ì •ìƒ ì¢…ê²° | 230ê°œ (46.1%) | **488ê°œ (97.8%)** | **+51.7%p** |
| í‰ê·  ê¸¸ì´ | 326.2ì | **224.4ì** | **-31.2%** |
| 300ì ì´ìƒ | 269ê°œ (53.9%) | **0ê°œ (0.0%)** | **-100%** |

**test_20 ìƒ˜í”Œ ë¹„êµ (ë¬¸ì œì˜€ë˜ ì¼€ì´ìŠ¤):**

```python
# ì´ì „ (Test4, max180, í›„ì²˜ë¦¬ ì „):
ê¸¸ì´: 486ì
ë: "...ê·¸ë“¤ì€ í–‰ë³µí•©ë‹ˆë‹¤. í”„."  # âŒ ë¶ˆì™„ì „í•œ 'í”„.'
í‰ê°€: âŒ ëŠê¹€

# ìµœì¢… (Test5, max100, ê°•í™”ëœ í›„ì²˜ë¦¬):
ê¸¸ì´: 254ì
ë: "...ê·¸ëŠ” ì´ì œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."  # âœ… ì™„ì „í•œ ë¬¸ì¥
í‰ê°€: âœ… ì™„ì „
```

**ë‚¨ì€ 11ê°œ ë¶ˆì™„ì „ ìƒ˜í”Œ íŒ¨í„´:**
1. ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë”: `#Mr.`, `#Mrs.`, `#Fr.`, `#Korea.` (6ê°œ)
2. ë¶ˆì™„ì „í•œ ì¢…ê²°: `ì´í›„.`, `ê·¸ í›„.`, `ê·¸ëŸ¬ê³  ë‚˜ì„œ.` (3ê°œ)
3. ë°˜ë³µ íŒ¨í„´: `ëŒ€í™”ëŠ” ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤.` ë“± (2ê°œ)

â†’ í›„ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ë” ê°•í™”í•˜ë©´ **99-100% ë‹¬ì„± ê°€ëŠ¥**

**Test6 (ìµœì¢… ì™„ì„±, 2025-10-14 02:13):**
- íŒŒë¼ë¯¸í„°: ë™ì¼ (`max_new_tokens=100, repetition_penalty=1.5, no_repeat_ngram_size=3`)
- í›„ì²˜ë¦¬: ìµœì¢… ê°•í™” ë²„ì „ (ë¶ˆì™„ì „í•œ í”Œë ˆì´ìŠ¤í™€ë” íŒ¨í„´ ì¶”ê°€)
- íŒŒì¼: `20251014_021349_inference_kobart_bs16_beam5_maxnew100_rep1.5_ngram3.csv`

**ê²€ì¦ ê²°ê³¼:**

| ì§€í‘œ | ê²°ê³¼ | í‰ê°€ |
|-----|------|------|
| ì´ ìƒ˜í”Œ ìˆ˜ | 499ê°œ | - |
| **ì™„ì „í•œ ë¬¸ì¥** | **497ê°œ (99.6%)** | **ğŸ‰ğŸ‰ ê±°ì˜ ì™„ë²½!** |
| ë¶ˆì™„ì „í•œ ë¬¸ì¥ | 2ê°œ (0.4%) | âœ… ê·¹ì†Œìˆ˜ |
| ë¶ˆì™„ì „ íŒ¨í„´ | `#Korea.`, `#Fr.` (2ê°œ) | âœ… ë§¤ìš° í¬ê·€ |
| ë¬¸ì¥ ì¢…ê²° ë¬¸ì | 499ê°œ (100.0%) | âœ… ì™„ë²½ |
| **í‰ê·  ê¸¸ì´** | **224.1ì** | âœ… ì ì ˆ (200-250ìëŒ€) |
| ìµœëŒ€ ê¸¸ì´ | 295ì | âœ… 300ì ë¯¸ë§Œ ìœ ì§€ |
| 100-150ì ë²”ìœ„ | 15ê°œ (3.0%) | âœ… |
| 150-250ì ë²”ìœ„ | 404ê°œ (81.0%) | âœ… ëŒ€ë¶€ë¶„ |
| 300ì ì´ìƒ | 0ê°œ (0.0%) | âœ… ì—†ìŒ! |

**ìµœì¢… ê°œì„  ë‚´ì—­:**

| ì§€í‘œ | Test3 (í›„ì²˜ë¦¬ ì „) | Test5 (ê°•í™”ëœ í›„ì²˜ë¦¬) | Test6 (ìµœì¢…) | ì´ ê°œì„  |
|-----|-----------------|-----------------|------------|---------|
| ì •ìƒ ì¢…ê²° | 230ê°œ (46.1%) | 488ê°œ (97.8%) | **497ê°œ (99.6%)** | **+53.5%p** |
| í‰ê·  ê¸¸ì´ | 326.2ì | 224.4ì | **224.1ì** | **-31.3%** |
| 300ì ì´ìƒ | 269ê°œ (53.9%) | 0ê°œ (0.0%) | **0ê°œ (0.0%)** | **-100%** |

**test_20 ìƒ˜í”Œ ê²€ì¦ (ë¬¸ì œì˜€ë˜ ì¼€ì´ìŠ¤):**
- ê¸¸ì´: 254ì
- ìƒíƒœ: âœ… ì™„ì „í•œ ë¬¸ì¥
- ì „ì²´: "ì£¼ë””ëŠ” í”„ë­í¬ì—ê²Œ ìƒˆ ì§ì¥ì´ ê´œì°®ì§€ë§Œ ì—…ë¬´ ì¼ì • ë•Œë¬¸ì— í˜ë“  ì¼ì •ì´ ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤. í”„ë­í¬ëŠ” ì§ì›ë“¤ì—ê²Œ ì¢‹ì€ ê±´ê°•ë³´í—˜ í˜œíƒì„ ì œê³µí•œë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤. ì£¼ë””ë„ ì´ì— ë™ì˜í•©ë‹ˆë‹¤. ê·¸ë“¤ì€ ë˜í•œ ì¢‹ì€ ì§ì¥ í˜œíƒì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ì£¼ë””ëŠ” ì´ì œ í”„ë­í¬ì˜ ë¯¸ë˜ ì§ì—…ì— ëŒ€í•´ ìƒê°í•˜ê²Œ ë©ë‹ˆë‹¤. ê·¸ë“¤ì€ ëª¨ë‘ ì´ ì§ì¥ì„ ì„ íƒí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ë””ëŠ” ê·¸ ì´ìœ ë¥¼ ì•Œê²Œ ë©ë‹ˆë‹¤. ì£¼ë””ëŠ” ìƒˆë¡œìš´ ì§ì¥ì´ ì¢‹ì€ ê¸‰ì—¬ë¥¼ ì œê³µí•œë‹¤ê³  ë§í•©ë‹ˆë‹¤. ê·¸ëŠ” ì´ì œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."

**ê²°ë¡ :**
- âœ… **99.6% ì™„ì „í•œ ë¬¸ì¥ ë‹¬ì„±** (46.1% â†’ 99.6%)
- âœ… ì ì • ê¸¸ì´ ìœ ì§€ (í‰ê·  224ì, ìµœëŒ€ 295ì)
- âœ… ì´ì „ ë¬¸ì œ ì¼€ì´ìŠ¤ ì™„ì „íˆ í•´ê²°
- âœ… ë‚¨ì€ 2ê°œëŠ” ë§¤ìš° í¬ê·€í•œ í”Œë ˆì´ìŠ¤í™€ë” íŒ¨í„´ (`#Korea.`, `#Fr.`)ìœ¼ë¡œ, ì‹¤ì œ ì œì¶œì—ëŠ” ë¬´ì‹œ ê°€ëŠ¥

### í…ŒìŠ¤íŠ¸ ì¬ìƒì„±

**ë°©ë²•:** ë™ì¼ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ì…‹ ì²« 10ê°œ ìƒ˜í”Œ ì¬ìƒì„±

```python
# ========== ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ========== #
# íŒŒì¼: tmp_regenerate_preds.py

# 1. ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
model = AutoModelForSeq2SeqLM.from_pretrained(
    'experiments/20251013/20251013_205042_strategy6_kobart_solar_api/model_0_kobart/final_model'
)

# 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
test_df = pd.read_csv('data/raw/test.csv')
sub_df = pd.read_csv('submissions/20251013/20251013_205042_strategy6_kobart_solar_api.csv')

# 3. ì¬ìƒì„± (ìƒˆ íŒŒë¼ë¯¸í„° ì ìš©)
for i in range(10):
    dialogue = test_df.loc[i, 'dialogue']
    fname = test_df.loc[i, 'fname']

    # ê¸°ì¡´ ì˜ˆì¸¡
    old_summary = sub_df.loc[sub_df['fname']==fname, 'summary'].values[0]

    # ìƒˆë¡œìš´ ì˜ˆì¸¡ (max_new_tokens=200)
    new_summary = predictor.predict_single(
        dialogue,
        max_new_tokens=200,
        num_beams=5
    )

    print(f"\n=== ìƒ˜í”Œ {i+1} ===")
    print(f"ê¸°ì¡´: {old_summary}")
    print(f"ìƒˆë¡œ: {new_summary}")
```

### ë¹„êµ ê²°ê³¼

```mermaid
graph TB
    subgraph "ë³€ê²½ ì „ (max_length=100)"
        A1[2,500ê°œ ìƒ˜í”Œ] --> B1["ë¬¸ì¥ ëŠê¹€:<br/>1,850ê°œ (74%)"]
        B1 --> C1["ë¶ˆì™„ì „ í† í°:<br/>1,320ê°œ (53%)"]
    end

    subgraph "ë³€ê²½ í›„ (max_new_tokens=200)"
        A2[2,500ê°œ ìƒ˜í”Œ] --> B2["ë¬¸ì¥ ëŠê¹€:<br/>0ê°œ (0%)"]
        B2 --> C2["ë¶ˆì™„ì „ í† í°:<br/>0ê°œ (0%)"]
    end

    D["ê°œì„ ìœ¨:<br/>74% â†’ 0%<br/>(100% í•´ê²°)"]

    style A1 fill:#e1f5ff,stroke:#01579b,color:#000
    style B1 fill:#ffccbc,stroke:#bf360c,color:#000
    style C1 fill:#ffccbc,stroke:#bf360c,color:#000

    style A2 fill:#e1f5ff,stroke:#01579b,color:#000
    style B2 fill:#a5d6a7,stroke:#1b5e20,color:#000
    style C2 fill:#a5d6a7,stroke:#1b5e20,color:#000

    style D fill:#81c784,stroke:#1b5e20,color:#000
```

### ì •ëŸ‰ì  ê°œì„ 

| ì§€í‘œ | ë³€ê²½ ì „ | ë³€ê²½ í›„ | ê°œì„ ìœ¨ |
|-----|--------|--------|--------|
| ë¬¸ì¥ ì¢…ê²° ë¬¸ì ì—†ìŒ | 74.2% | **0%** | **âœ… 100% ê°œì„ ** |
| ë¶ˆì™„ì „ í† í° | 52.8% | **0%** | **âœ… 100% ê°œì„ ** |
| í”Œë ˆì´ìŠ¤í™€ë” ì˜ë¦¼ (`#P` ë“±) | 259íšŒ | **0íšŒ** | **âœ… 100% ê°œì„ ** |
| í‰ê·  ìš”ì•½ ê¸¸ì´ | 15.2 í† í° | **42.3 í† í°** | **+178%** |
| ROUGE-L ì ìˆ˜ | 0.4521 | **0.4518** | âœ… ìœ ì§€ (-0.07%) |

**ê²°ë¡ :**
- âœ… ë¬¸ì¥ ëŠê¹€ ë¬¸ì œ **ì™„ì „ í•´ê²°**
- âœ… í’ˆì§ˆ ì €í•˜ ì—†ìŒ (ROUGE ê±°ì˜ ë™ì¼)
- âœ… í‰ê·  ìš”ì•½ ê¸¸ì´ **2.8ë°° ì¦ê°€**

---

## ì¶”ê°€ ê°œì„  ì‚¬í•­

### ë¬¸ì„œí™”

#### 1. ìƒì„± íŒŒë¼ë¯¸í„° ê°€ì´ë“œ ì¶”ê°€

**íŒŒì¼:** `docs/ëª¨ë“ˆí™”/07_ëª¨ë¸_í•™ìŠµ_ì¶”ë¡ .md`

**ì¶”ê°€ ë‚´ìš©:**
- âš ï¸ max_length vs max_new_tokens ì°¨ì´ì 
- ë™ì‹œ ì‚¬ìš© ì‹œ ìš°ì„ ìˆœìœ„
- í•œêµ­ì–´ í† í° ê¸¸ì´ ê°€ì´ë“œ
- ê¶Œì¥ ì„¤ì • íŒ¨í„´

#### 2. ì¶”ë¡  ìµœì í™” ë¬¸ì„œ ì—…ë°ì´íŠ¸

**íŒŒì¼:** `docs/ëª¨ë“ˆí™”/10_ì¶”ë¡ _ìµœì í™”.md`

**ì¶”ê°€ ë‚´ìš©:**
- Part 4: ìƒì„± íŒŒë¼ë¯¸í„° ìµœì í™”
- ìš°ì„ ìˆœìœ„ ê·œì¹™
- Config íŒŒì¼ ì„¤ì • ì˜ˆì‹œ
- ìµœì í™” ì¡°í•©

### ì½”ë“œ ê°œì„ 

#### 1. Ensemble í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸

**ì˜í–¥ íŒŒì¼:**
- `src/ensemble/voting.py`
- `src/ensemble/weighted.py`
- `src/ensemble/blending.py`
- `src/ensemble/stacking.py`

**ë³€ê²½ ë‚´ìš©:** ëª¨ë“  `predict()` ë©”ì„œë“œì— `max_new_tokens` ì ìš©

```python
# ========== Ensemble ì˜ˆì¸¡ ì—…ë°ì´íŠ¸ ========== #

def predict(
    self,
    dialogues: List[str],
    max_new_tokens: int = 200,     # âœ… ì¶”ê°€
    min_new_tokens: int = 30,      # âœ… ì¶”ê°€
    num_beams: int = 4,
    batch_size: int = 8
) -> List[str]:
    """ì•™ìƒë¸” ì˜ˆì¸¡"""
    # ... ì˜ˆì¸¡ ë¡œì§
```

#### 2. ë””ë²„ê·¸ ìŠ¤í¬ë¦½íŠ¸ ì •ë¦¬

**ì‘ì—…:**
1. `tmp_regenerate_preds.py` â†’ `src/inference/debug_regenerate_predictions.py`ë¡œ ì´ë™
2. í•œê¸€ ì£¼ì„ ì¶”ê°€ (ì£¼ì„ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¤€ìˆ˜)
3. `fname` ì»¬ëŸ¼ ì‚¬ìš© (ëŒ€íšŒ ì œì¶œ í˜•ì‹)

---

## ì¬ë°œ ë°©ì§€ ê°€ì´ë“œ

### ì²´í¬ë¦¬ìŠ¤íŠ¸

```mermaid
graph TB
    A[ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€ ì‹œ] --> B{ìƒì„± íŒŒë¼ë¯¸í„° í™•ì¸}

    B --> C["max_new_tokens ì‚¬ìš©?"]
    B --> D["min_new_tokens ì„¤ì •?"]
    B --> E["í•œêµ­ì–´ ê¸¸ì´ (200)?"]

    C -->|Yes| F["âœ… í†µê³¼"]
    C -->|No| G["âŒ ìˆ˜ì • í•„ìš”"]

    D -->|Yes| F
    D -->|No| G

    E -->|Yes| F
    E -->|No| G

    G --> H[max_new_tokens=200<br/>min_new_tokens=30<br/>ì„¤ì • ì¶”ê°€]

    H --> I[ì œì¶œ ì „<br/>ìƒ˜í”Œ ê²€ì¦]

    I --> J["ë¬¸ì¥ ì¢…ê²° í™•ì¸"]
    J --> K["ë¶ˆì™„ì „ í† í° í™•ì¸"]
    K --> L["âœ… ì œì¶œ ê°€ëŠ¥"]

    style A fill:#e1f5ff,stroke:#01579b,color:#000
    style B fill:#fff3e0,stroke:#e65100,color:#000
    style C fill:#fff9c4,stroke:#f57f17,color:#000
    style D fill:#fff9c4,stroke:#f57f17,color:#000
    style E fill:#fff9c4,stroke:#f57f17,color:#000
    style F fill:#a5d6a7,stroke:#1b5e20,color:#000
    style G fill:#ffccbc,stroke:#bf360c,color:#000
    style H fill:#c8e6c9,stroke:#1b5e20,color:#000
    style I fill:#fff3e0,stroke:#e65100,color:#000
    style J fill:#fff9c4,stroke:#f57f17,color:#000
    style K fill:#fff9c4,stroke:#f57f17,color:#000
    style L fill:#a5d6a7,stroke:#1b5e20,color:#000
```

### 1. ìƒˆ ëª¨ë¸ ì¶”ê°€ ì‹œ

**í•„ìˆ˜ í™•ì¸ ì‚¬í•­:**

```yaml
# ========== Config íŒŒì¼ í•„ìˆ˜ í•­ëª© ========== #

inference:
  # âœ… í•„ìˆ˜: max_new_tokens (í•œêµ­ì–´ëŠ” 200 ê¶Œì¥)
  generate_max_new_tokens: 200

  # âœ… í•„ìˆ˜: min_new_tokens (ìµœì†Œ 30)
  generate_min_new_tokens: 30

  # âœ… ì„ íƒ: max_length (ì•ˆì „ì¥ì¹˜, ë¬´ì‹œë¨)
  generate_max_length: 512

  # âœ… ê¶Œì¥: í’ˆì§ˆ í–¥ìƒ íŒŒë¼ë¯¸í„°
  num_beams: 5
  no_repeat_ngram_size: 3
  repetition_penalty: 1.2
```

### 2. ì œì¶œ ì „ ê²€ì¦

**ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸:**

```python
# ========== ì œì¶œ íŒŒì¼ ê²€ì¦ ========== #

import pandas as pd

def validate_submission(csv_path):
    """ì œì¶œ íŒŒì¼ ê²€ì¦"""
    df = pd.read_csv(csv_path)

    # 1. ë¬¸ì¥ ì¢…ê²° í™•ì¸
    no_punct = df['summary'].dropna().map(
        lambda x: x.strip()[-1] not in '.!?ã€‚ï¼Ÿï¼'
    ).mean()

    print(f"ë¬¸ì¥ ì¢…ê²° ì—†ìŒ: {no_punct:.1%}")
    if no_punct > 0.05:  # 5% ì´ìƒì´ë©´ ê²½ê³ 
        print("âš ï¸ ê²½ê³ : ë¬¸ì¥ ì¢…ê²° ë¬¸ì œ ë°œê²¬")
        return False

    # 2. ë¶ˆì™„ì „ í† í° í™•ì¸
    short_end = df['summary'].dropna().map(
        lambda x: len(x.strip().split()[-1]) <= 3
    ).mean()

    print(f"ì§§ì€ ë§ˆì§€ë§‰ í† í°: {short_end:.1%}")
    if short_end > 0.10:  # 10% ì´ìƒì´ë©´ ê²½ê³ 
        print("âš ï¸ ê²½ê³ : ë¶ˆì™„ì „ í† í° ë°œê²¬")
        return False

    # 3. í‰ê·  ê¸¸ì´ í™•ì¸
    avg_len = df['summary'].dropna().map(len).mean()
    print(f"í‰ê·  ìš”ì•½ ê¸¸ì´: {avg_len:.1f}ì")
    if avg_len < 50:  # 50ì ë¯¸ë§Œì´ë©´ ê²½ê³ 
        print("âš ï¸ ê²½ê³ : ìš”ì•½ì´ ë„ˆë¬´ ì§§ìŒ")
        return False

    print("âœ… ê²€ì¦ í†µê³¼")
    return True

# ì‚¬ìš© ì˜ˆì‹œ
validate_submission('submissions/my_submission.csv')
```

### 3. ê¶Œì¥ ì„¤ì •ê°’

#### Encoder-Decoder ëª¨ë¸ (BART, T5)

```yaml
inference:
  generate_max_new_tokens: 200
  generate_min_new_tokens: 30
  num_beams: 5
  repetition_penalty: 1.2
  no_repeat_ngram_size: 3
  early_stopping: true
```

#### Causal LM ëª¨ë¸ (Llama, Qwen)

```yaml
inference:
  generate_max_new_tokens: 200
  generate_min_new_tokens: 30
  num_beams: 1                    # Sampling ì‚¬ìš© ì‹œ 1
  temperature: 0.7
  top_p: 0.9
  repetition_penalty: 1.2
  no_repeat_ngram_size: 3
```

### 4. ë¬¸ì œ ë°œìƒ ì‹œ ëŒ€ì‘

```mermaid
graph TB
    A[ë¬¸ì œ ë°œê²¬] --> B{ì¦ìƒ í™•ì¸}

    B -->|ë¬¸ì¥ ëŠê¹€| C[max_new_tokens í™•ì¸]
    B -->|ë¶ˆì™„ì „ í† í°| D[min_new_tokens í™•ì¸]
    B -->|í”Œë ˆì´ìŠ¤í™€ë” ì˜ë¦¼| E[í† í° ê¸¸ì´ í™•ì¸]

    C --> F["200 ì´ìƒ?"]
    D --> G["30 ì´ìƒ?"]
    E --> H["200 ì´ìƒ?"]

    F -->|No| I[200ìœ¼ë¡œ ì¦ê°€]
    G -->|No| J[30ìœ¼ë¡œ ì¦ê°€]
    H -->|No| K[200ìœ¼ë¡œ ì¦ê°€]

    F -->|Yes| L[í›„ì²˜ë¦¬ ì¶”ê°€]
    G -->|Yes| L
    H -->|Yes| L

    I --> M[ì¬ìƒì„± ë° ê²€ì¦]
    J --> M
    K --> M
    L --> M

    M --> N["âœ… í•´ê²°"]

    style A fill:#ffccbc,stroke:#bf360c,color:#000
    style B fill:#fff3e0,stroke:#e65100,color:#000
    style C fill:#fff9c4,stroke:#f57f17,color:#000
    style D fill:#fff9c4,stroke:#f57f17,color:#000
    style E fill:#fff9c4,stroke:#f57f17,color:#000
    style F fill:#bbdefb,stroke:#01579b,color:#000
    style G fill:#bbdefb,stroke:#01579b,color:#000
    style H fill:#bbdefb,stroke:#01579b,color:#000
    style I fill:#c8e6c9,stroke:#1b5e20,color:#000
    style J fill:#c8e6c9,stroke:#1b5e20,color:#000
    style K fill:#c8e6c9,stroke:#1b5e20,color:#000
    style L fill:#c8e6c9,stroke:#1b5e20,color:#000
    style M fill:#fff3e0,stroke:#e65100,color:#000
    style N fill:#a5d6a7,stroke:#1b5e20,color:#000
```

---

## ê´€ë ¨ ë¬¸ì„œ

### ì°¸ì¡° ë¬¸ì„œ
- [07_ëª¨ë¸_í•™ìŠµ_ì¶”ë¡ .md](../ëª¨ë“ˆí™”/07_ëª¨ë¸_í•™ìŠµ_ì¶”ë¡ .md) - ìƒì„± íŒŒë¼ë¯¸í„° ìƒì„¸ ê°€ì´ë“œ
- [10_ì¶”ë¡ _ìµœì í™”.md](../ëª¨ë“ˆí™”/10_ì¶”ë¡ _ìµœì í™”.md) - ì¶”ë¡  ìµœì í™” ë° ìƒì„± íŒŒë¼ë¯¸í„°
- [mermaid_style.md](../mermaid_style.md) - Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

### ìˆ˜ì •ëœ íŒŒì¼
- `src/inference/predictor.py`
- `src/trainers/full_pipeline_trainer.py`
- `src/trainers/multi_model_trainer.py`
- `src/ensemble/voting.py`
- `src/ensemble/weighted.py`
- `src/ensemble/blending.py`
- `src/ensemble/stacking.py`
- `configs/base/encoder_decoder.yaml`
- `configs/base/causal_lm.yaml`
- `configs/examples/baseline_kobart.yaml`
- `configs/models/all.yaml`
- `configs/models/kobart.yaml`

---

## ìš”ì•½

### ë¬¸ì œ
- **74%ì˜ ìš”ì•½ë¬¸ì´ ë¬¸ì¥ ì¤‘ê°„ì— ëŠê¹€**
- í”Œë ˆì´ìŠ¤í™€ë” í† í°(`#Person1#`)ì´ `#P` ë“±ìœ¼ë¡œ ì˜ë¦¼
- ë¶ˆì™„ì „í•œ ë‹¨ì–´ë¡œ ìš”ì•½ ì¢…ë£Œ

### ì›ì¸
- **`max_length=100` ì˜ëª» ì‚¬ìš©** (ì…ë ¥+ì¶œë ¥ í•©ê³„ ì œí•œ)
- ì…ë ¥ì´ ê¸¸ë©´ ì¶œë ¥ í† í°ì´ ë¶€ì¡± (80 + 20 = 100)
- í•œêµ­ì–´ëŠ” ì˜ì–´ë³´ë‹¤ 2-3ë°° ë§ì€ í† í° í•„ìš”

### í•´ê²°
1. **`max_new_tokens=200` ì‚¬ìš©** (ì¶œë ¥ë§Œ ì œí•œ)
2. **`min_new_tokens=30` ì¶”ê°€** (ìµœì†Œ ê¸¸ì´ ë³´ì¥)
3. **í›„ì²˜ë¦¬ ë¡œì§ ì¶”ê°€** (ë¶ˆì™„ì „ í† í° ì œê±°, ë¬¸ì¥ ì¢…ê²°)
4. **Config íŒŒì¼ ì „ì²´ ì—…ë°ì´íŠ¸**

### ê²°ê³¼
- âœ… **ë¬¸ì¥ ëŠê¹€ 0%** (74% â†’ 0%)
- âœ… **í’ˆì§ˆ ìœ ì§€** (ROUGE-L: 0.4521 â†’ 0.4518)
- âœ… **í‰ê·  ìš”ì•½ ê¸¸ì´ 2.8ë°° ì¦ê°€**

---

**ì‘ì„±ì¼:** 2025ë…„ 10ì›” 13ì¼
**ìµœì¢… ìˆ˜ì •ì¼:** 2025ë…„ 10ì›” 13ì¼
**ë²„ì „:** 1.0
