# Llama-3.2-Korean-Bllossom-3B 모델 설정
# PRD 08: Zero-shot ROUGE Sum 49.52 (1위)

_base_: ../base/causal_lm.yaml

model:
  type: causal_lm
  checkpoint: "Bllossom/llama-3.2-Korean-Bllossom-3B"
  size: "3B"
  dtype: "fp16"  # PyTorch AMP 호환성을 위해 FP16 사용
  chat_template: "llama"

# LoRA 설정 (Llama 최적화)
lora:
  r: 16
  alpha: 32
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  dropout: 0.05
  use_qlora: true

# 학습 설정 (Llama 최적화)
training:
  epochs: 3
  batch_size: 8
  gradient_accumulation_steps: 1
  learning_rate: 2e-5
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  weight_decay: 0.1
  max_grad_norm: 1.2

# LLM Dataset 설정
dataset:
  format_type: "chat"  # Llama는 chat format 사용
  use_instruction_augmentation: false

# 추론 설정 (Llama 최적화)
inference:
  batch_size: 16                                        # 추론 배치 크기

  # HuggingFace 사전학습 모델 보정 (PRD 04, 12)
  pretrained_correction:
    enabled: false                                      # 기본값: 비활성화 (명령행 --use_pretrained_correction으로 활성화)
    models:                                             # 보정에 사용할 HuggingFace 모델 리스트
      - "gogamza/kobart-base-v2"                        # KoBART 사전학습 (일반 요약)
      - "digit82/kobart-summarization"                  # KoBART 요약 특화 (대화 요약)
    strategy: "quality_based"                           # 보정 전략 (quality_based 추천, threshold, voting, weighted)
    threshold: 0.3                                      # 품질 임계값 (0.0~1.0, 낮을수록 엄격)

  # Solar API 앙상블 (PRD 09)
  solar_api:
    enabled: false                                      # 기본값: 비활성화 (명령행 --use_solar_api로 활성화)
    model: "solar-1-mini-chat"                          # Solar 모델 선택
    temperature: 0.2                                    # 생성 온도 (낮을수록 일관성)
    top_p: 0.3                                          # Top-p (낮을수록 일관성)
    batch_size: 10                                      # 배치 크기 (Rate limit 고려)
    delay: 1.0                                          # 배치 간 대기 시간 (초)

# 실험 설정
experiment:
  name: "llama_3.2_3b_qlora"
  tags:
    - "llama"
    - "3b"
    - "qlora"
    - "korean"
