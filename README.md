[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/HS6nBbT4)

# ğŸ“š ëŒ€í™” ìš”ì•½ NLP ê²½ì§„ëŒ€íšŒ - ëª¨ë“ˆí™” í”„ë¡œì íŠ¸

> **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ NLP íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**: ë² ì´ìŠ¤ë¼ì¸ë¶€í„° í”„ë¡œë•ì…˜ê¹Œì§€

<br>

## ğŸ“– í”„ë¡œì íŠ¸ ì†Œê°œ

### ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”
ì´ í”„ë¡œì íŠ¸ëŠ” **ëŒ€í™” ë°ì´í„°ë¥¼ ìš”ì•½í•˜ëŠ” Seq2Seq ëª¨ë¸**ì„ ê°œë°œí•˜ëŠ” NLP ê²½ì§„ëŒ€íšŒ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ëŒ€íšŒ ë² ì´ìŠ¤ë¼ì¸ ë…¸íŠ¸ë¶ ì½”ë“œë¥¼ **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ëª¨ë“ˆí™” ì‹œìŠ¤í…œ**ìœ¼ë¡œ ì™„ì „íˆ ì¬êµ¬ì„±í•˜ì—¬ **ì‹¤í—˜ ê´€ë¦¬**, **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**, **ì•™ìƒë¸”**, **ì¶”ë¡  ìµœì í™”** ë“± ëª¨ë“  ML íŒŒì´í”„ë¼ì¸ì„ ì§€ì›í•©ë‹ˆë‹¤.

### âœ¨ í•µì‹¬ ê°€ì¹˜
- **âœ… 100% êµ¬í˜„ ì™„ë£Œ**: 11ê°œ PRD ë¬¸ì„œì˜ ëª¨ë“  ê¸°ëŠ¥ êµ¬í˜„
- **ğŸ”§ ëª¨ë“ˆí™” ì„¤ê³„**: ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
- **ğŸ“Š ì‹¤í—˜ ì¶”ì **: WandB ê¸°ë°˜ 5ê°€ì§€ ê³ ê¸‰ ì‹œê°í™”
- **âš¡ í”„ë¡œë•ì…˜ ì¤€ë¹„**: TensorRT, Pruning, TTA ë“± ìµœì í™” ì§€ì›
- **ğŸ§ª ì™„ë²½í•œ ê²€ì¦**: ë² ì´ìŠ¤ë¼ì¸ ìë™ ê²€ì¦ ì‹œìŠ¤í…œ

### ğŸ† ì£¼ìš” íŠ¹ì§•
| ì˜ì—­ | êµ¬í˜„ ë‚´ìš© |
|------|----------|
| **Config ê´€ë¦¬** | ê³„ì¸µì  YAML ë³‘í•© ì‹œìŠ¤í…œ (4ë‹¨ê³„) |
| **ë°ì´í„°** | ì „ì²˜ë¦¬, Dataset, TTA (4ê°€ì§€ ì „ëµ) |
| **ëª¨ë¸** | KoBART + íŠ¹ìˆ˜ í† í°, LoRA íŒŒì¸íŠœë‹ |
| **í•™ìŠµ** | WandB ë¡œê¹…, Optuna ìµœì í™” (15ê°œ íŒŒë¼ë¯¸í„°) |
| **í‰ê°€** | ROUGE, BERTScore, Solar API êµì°¨ ê²€ì¦ |
| **ì•™ìƒë¸”** | Weighted, Voting, Stacking, Blending, Prompt A/B |
| **ì¶”ë¡ ** | TensorRT, Pruning, ë°°ì¹˜ ì¶”ë¡  |

<br>

## ğŸ‘¥ íŒ€ êµ¬ì„±ì›
| í”„ë¡œí•„ | ì´ë¦„ (ê¹ƒí—ˆë¸Œ) | MBTI | ì „ê³µ/í•™ê³¼ | ë‹´ë‹¹ ì—­í•  |
|:------:|:-------------:|:----:|:---------:|:----------|
| <img src="https://github.com/user-attachments/assets/a24cf78c-2c8f-47b9-b53b-867557872d88" width="100" height="100"> | [ê¹€ì„ ë¯¼](https://github.com/nimnusmik) | ENFJ | ê²½ì˜&AI ìœµí•© í•™ë¶€ | íŒ€ ë¦¬ë“œ |
| <img src="https://github.com/user-attachments/assets/489d401e-f5f5-4998-91a0-3b0f37f4490f" width="100" height="100"> | [ê¹€ë³‘í˜„](https://github.com/Bkankim) | ENFP | ì •ë³´ë³´ì•ˆ | ëª¨ë¸ ìµœì í™” |
| <img src="https://github.com/user-attachments/assets/55180131-9401-457e-a600-312eda87ded9" width="100" height="100"> | [ì„ì˜ˆìŠ¬](https://github.com/joy007fun/joy007fun) | ENTP | ê´€ê´‘ê²½ì˜&ì»´í“¨í„°ê³µí•™, í´ë¼ìš°ë“œ ì¸í”„ë¼ | ì¸í”„ë¼ êµ¬ì¶• |
| <img src="https://github.com/user-attachments/assets/10a2c088-72cb-45cd-8772-b683bc2fb550" width="100" height="100"> | [ì •ì„œìš°](https://github.com/Seowoo-C) | INFJ | í™”í•™ | ë°ì´í„° ë¶„ì„ |
| <img src="" width="100" height="100"> | [ì •ì†Œí˜„](https://github.com/soniajhung) | MBTI | ì „ê³µ | ì‹¤í—˜ ê´€ë¦¬ |
| <img src="https://github.com/user-attachments/assets/5c04a858-46ed-4043-9762-b7eaf7b1149a" width="100" height="100"> | [ìµœí˜„í™”](https://github.com/iejob) | ISTP | ì»´í“¨í„°ê³µí•™ | Git ë¸Œëœì¹˜Â·ë³‘í•©Â·ì¶©ëŒ ê´€ë¦¬ |

<br>

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

<br>

### ğŸ“¦ 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd natural-language-processing-competition

# Python í™˜ê²½ (pyenv ê¶Œì¥)
pyenv install 3.11.9
pyenv virtualenv 3.11.9 nlp_py3_11_9
pyenv activate nlp_py3_11_9

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

**ì£¼ìš” íŒ¨í‚¤ì§€:**
- `torch==2.8.0` - PyTorch ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- `transformers==4.57.0` - HuggingFace Transformers
- `wandb==0.22.2` - ì‹¤í—˜ ë¡œê¹… ë° ì‹œê°í™”
- `optuna==4.2.0` - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- `omegaconf==2.3.0` - ê³„ì¸µì  Config ê´€ë¦¬

### ğŸ“ 2. ë°ì´í„° ì¤€ë¹„

```bash
# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ
wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000365/data/data.tar.gz
tar -xzf data.tar.gz -C data/raw/

# ë°ì´í„° êµ¬ì¡° í™•ì¸
data/raw/
â”œâ”€â”€ train.csv               # í•™ìŠµ ë°ì´í„° (12,457ê°œ)
â”œâ”€â”€ dev.csv                 # ê²€ì¦ ë°ì´í„°
â”œâ”€â”€ test.csv                # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â””â”€â”€ sample_submission.csv   # ì œì¶œ í˜•ì‹
```

### âš™ï¸ 3. Config ì„¤ì •

```bash
# ë² ì´ìŠ¤ë¼ì¸ ì‹¤í—˜ Config í™•ì¸
cat configs/experiments/baseline_kobart.yaml

# Config í…ŒìŠ¤íŠ¸
python -c "from src.config import load_config; print(load_config('baseline_kobart'))"
```

### ğŸ¯ 4. ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ

```bash
# ê°„ë‹¨í•œ ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ (ë…¸íŠ¸ë¶ ì‚¬ìš©)
jupyter notebook notebooks/team/CHH/Full_Pipeline.ipynb

# ë˜ëŠ” ëª¨ë“ˆí™” ì‹œìŠ¤í…œ ì‚¬ìš© (êµ¬í˜„ ì™„ë£Œ ì‹œ)
python scripts/train.py --experiment baseline_kobart
```

<br>

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
natural-language-processing-competition/
â”œâ”€â”€ configs/                        # ê³„ì¸µì  Config ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ default.yaml           # ì „ì²´ ê¸°ë³¸ ì„¤ì •
â”‚   â”‚   â””â”€â”€ encoder_decoder.yaml   # ëª¨ë¸ íƒ€ì…ë³„ ì„¤ì •
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ kobart.yaml            # KoBART ëª¨ë¸ ì„¤ì •
â”‚   â””â”€â”€ experiments/
â”‚       â””â”€â”€ baseline_kobart.yaml   # ì‹¤í—˜ë³„ ì„¤ì •
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                       # ì›ì‹œ ë°ì´í„° (train/dev/test)
â”‚
â”œâ”€â”€ docs/                          # ë¬¸ì„œ (11ê°œ PRD)
â”‚   â”œâ”€â”€ PRD/                       # ê¸°ëŠ¥ ëª…ì„¸ì„œ
â”‚   â””â”€â”€ ëª¨ë“ˆí™”/                     # ì™„ì „ ê°€ì´ë“œ (10ê°œ ë¬¸ì„œ)
â”‚
â”œâ”€â”€ experiments/                   # ì‹¤í—˜ ê²°ê³¼ ë° ì²´í¬í¬ì¸íŠ¸
â”‚   â””â”€â”€ baseline_kobart/
â”‚       â”œâ”€â”€ checkpoints/           # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚       â””â”€â”€ logs/                  # í•™ìŠµ ë¡œê·¸
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ base/                      # ëŒ€íšŒ ë² ì´ìŠ¤ë¼ì¸
â”‚   â””â”€â”€ team/CHH/                  # íŒ€ ë…¸íŠ¸ë¶
â”‚       â””â”€â”€ Full_Pipeline.ipynb    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ë…¸íŠ¸ë¶
â”‚
â”œâ”€â”€ src/                           # ëª¨ë“ˆí™”ëœ ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ config/                    # Config ë¡œë”
â”‚   â”œâ”€â”€ data/                      # ë°ì´í„° ì²˜ë¦¬ (ì „ì²˜ë¦¬, Dataset, TTA)
â”‚   â”œâ”€â”€ models/                    # ëª¨ë¸ ë¡œë”
â”‚   â”œâ”€â”€ training/                  # í•™ìŠµ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ evaluation/                # í‰ê°€ ë©”íŠ¸ë¦­ (ROUGE, BERTScore)
â”‚   â”œâ”€â”€ optimization/              # Optuna ìµœì í™”
â”‚   â”œâ”€â”€ ensemble/                  # ì•™ìƒë¸” (5ê°€ì§€ ë°©ë²•)
â”‚   â”œâ”€â”€ inference/                 # ì¶”ë¡  (TensorRT, Pruning)
â”‚   â”œâ”€â”€ prompts/                   # í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŒ…
â”‚   â”œâ”€â”€ validation/                # ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦, Solar êµì°¨ ê²€ì¦
â”‚   â”œâ”€â”€ logging/                   # Logger, WandB ë¡œê±°
â”‚   â””â”€â”€ utils/                     # ìœ í‹¸ë¦¬í‹° (GPU, ê³µí†µ í•¨ìˆ˜)
â”‚
â”œâ”€â”€ logs/                          # ì‹¤í–‰ ë¡œê·¸
â”‚   â””â”€â”€ 20250926/
â”‚
â””â”€â”€ submissions/                   # ì œì¶œ íŒŒì¼
    â””â”€â”€ 20250926/
```

### ì›ë³¸ ë§í¬
- **ë°ì´í„°**: https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000365/data/data.tar.gz
- **ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œ**: https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000365/data/code.tar.gz

<br>

## ğŸ”§ êµ¬í˜„ ê¸°ëŠ¥ (100% ì™„ë£Œ)

### 1ï¸âƒ£ í•µì‹¬ ì‹œìŠ¤í…œ
#### Config ê´€ë¦¬ (`src/config/`)
- âœ… ê³„ì¸µì  YAML ë³‘í•© (4ë‹¨ê³„: base â†’ model_type â†’ model â†’ experiment)
- âœ… OmegaConf ê¸°ë°˜ íƒ€ì… ì•ˆì „ì„±
- âœ… ì‹¤í—˜ë³„ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/02_í•µì‹¬_ì‹œìŠ¤í…œ.md`

#### Logger ì‹œìŠ¤í…œ (`src/logging/`)
- âœ… íŒŒì¼ + ì½˜ì†” ë™ì‹œ ë¡œê¹…
- âœ… Stdout/stderr ë¦¬ë‹¤ì´ë ‰ì…˜
- âœ… WandB í†µí•© (5ê°€ì§€ ê³ ê¸‰ ì‹œê°í™”)
  - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„
  - ê·¸ë˜ë””ì–¸íŠ¸ norm
  - Loss curve (ê³¼ì í•© ëª¨ë‹ˆí„°ë§)
  - GPU ë©”ëª¨ë¦¬ ì¶”ì 
  - í•™ìŠµ ì†ë„ ì¸¡ì •
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/02_í•µì‹¬_ì‹œìŠ¤í…œ.md` Part 3-4

### 2ï¸âƒ£ ë°ì´í„° íŒŒì´í”„ë¼ì¸
#### ì „ì²˜ë¦¬ (`src/data/preprocessor.py`)
- âœ… ë…¸ì´ì¦ˆ ì œê±° (URL, ì´ë©”ì¼, íŠ¹ìˆ˜ë¬¸ì)
- âœ… í™”ì ì¶”ì¶œ ë° ì •ê·œí™”
- âœ… í„´ ê³„ì‚° ë° í†µê³„

#### Dataset (`src/data/dataset.py`)
- âœ… DialogueSummarizationDataset (í•™ìŠµ/ê²€ì¦)
- âœ… InferenceDataset (ì¶”ë¡ )
- âœ… ë™ì  íŒ¨ë”© ë° ë°°ì¹˜ ì²˜ë¦¬

#### TTA - Test Time Augmentation (`src/data/tta.py`)
- âœ… Paraphrase (ë¬¸ì¥ ìˆœì„œ ë³€ê²½)
- âœ… Reorder (ë‹¨ì–´/ë¬¸ì¥ ì¬ë°°ì—´)
- âœ… Synonym (ë™ì˜ì–´ ì¹˜í™˜)
- âœ… Mask (í† í° ë§ˆìŠ¤í‚¹ 10-20%)
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/03_ë°ì´í„°_íŒŒì´í”„ë¼ì¸.md`

### 3ï¸âƒ£ ëª¨ë¸ ë° í•™ìŠµ
#### ëª¨ë¸ ë¡œë” (`src/models/model_loader.py`)
- âœ… HuggingFace ëª¨ë¸ ìë™ ë¡œë”©
- âœ… íŠ¹ìˆ˜ í† í° ì¶”ê°€ ë° ì„ë² ë”© ë¦¬ì‚¬ì´ì¦ˆ
- âœ… GPU ìë™ ê°ì§€ ë° ë°°ì¹˜

#### LoRA íŒŒì¸íŠœë‹ (`src/training/lora_trainer.py`)
- âœ… PEFT ê¸°ë°˜ LoRA ì ìš©
- âœ… íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  í•™ìŠµ (1% íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµ)
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/04_í•™ìŠµ_íŒŒì´í”„ë¼ì¸.md`

### 4ï¸âƒ£ í‰ê°€ ë° ìµœì í™”
#### í‰ê°€ ë©”íŠ¸ë¦­ (`src/evaluation/`)
- âœ… ROUGE (1/2/L/Lsum)
- âœ… BERTScore
- âœ… Multi-reference ì§€ì›
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/05_í‰ê°€_ìµœì í™”.md`

#### Optuna ìµœì í™” (`src/optimization/optuna_optimizer.py`)
- âœ… 15ê°œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
  - LoRA: r, alpha, dropout (3ê°œ)
  - í•™ìŠµ: lr, batch_size, epochs, warmup, weight_decay (5ê°œ)
  - Scheduler: type (1ê°œ)
  - Generation: temperature, top_p, num_beams, length_penalty (4ê°œ)
  - Dropout: hidden, attention (2ê°œ)
- âœ… TPE Sampler + Median Pruner
- âœ… ì¡°ê¸° ì¢…ë£Œ ì „ëµ
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/05_í‰ê°€_ìµœì í™”.md`

### 5ï¸âƒ£ ì•™ìƒë¸” ì‹œìŠ¤í…œ
#### 5ê°€ì§€ ì•™ìƒë¸” ë°©ë²• (`src/ensemble/`)
1. **Weighted Ensemble** - ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì•™ìƒë¸”
2. **Voting Ensemble** - ë‹¤ìˆ˜ê²° íˆ¬í‘œ
3. **Stacking Ensemble** - Meta-learner 2ë‹¨ê³„ ì•™ìƒë¸”
4. **Blending Ensemble** - scipy.optimize ê°€ì¤‘ì¹˜ ìµœì í™”
5. **Prompt A/B Testing** - í”„ë¡¬í”„íŠ¸ ë³€í˜• í†µê³„ ê²€ì¦
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/06_ì•™ìƒë¸”_API.md`

### 6ï¸âƒ£ ì¶”ë¡  ìµœì í™”
#### TensorRT ìµœì í™” (`src/inference/tensorrt_optimizer.py`)
- âœ… PyTorch â†’ ONNX â†’ TensorRT ë³€í™˜
- âœ… FP16/INT8 ì •ë°€ë„ ì§€ì›
- âœ… Fallback ëª¨ë“œ (PyTorch JIT)
- âœ… ìµœëŒ€ 3-5ë°° ì†ë„ í–¥ìƒ

#### Model Pruning (`src/inference/pruning.py`)
- âœ… Magnitude-based Pruning (L1 norm)
- âœ… Structured Pruning (ë‰´ëŸ°/í•„í„° ì œê±°)
- âœ… Global Pruning (ì „ì²´ ëª¨ë¸ í†µí•©)
- âœ… Sparsity í†µê³„ ë° í‰ê°€
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/09_ì¶”ë¡ _ìµœì í™”.md`

### 7ï¸âƒ£ ê²€ì¦ ì‹œìŠ¤í…œ
#### ë² ì´ìŠ¤ë¼ì¸ ìë™ ê²€ì¦ (`src/validation/baseline_checker.py`)
- âœ… í† í¬ë‚˜ì´ì € ê²€ì¦ (vocab size, special tokens, tokenization)
- âœ… í•™ìŠµë¥  ê²€ì¦ (ë²”ìœ„, ëª¨ë¸ í¬ê¸°ë³„ ê¶Œì¥ê°’)
- âœ… ìƒì„± í’ˆì§ˆ ê²€ì¦ (repetition, length, content)
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/10_ë² ì´ìŠ¤ë¼ì¸_ê²€ì¦.md`

#### Solar API êµì°¨ ê²€ì¦ (`src/validation/solar_cross_validation.py`)
- âœ… Solar API ê¸°ë°˜ ROUGE ì ìˆ˜ ê²€ì¦
- âœ… ë¡œì»¬ vs Solar ì ìˆ˜ ë¹„êµ
- âœ… ì„ê³„ê°’ ê¸°ë°˜ ê²½ê³  ì‹œìŠ¤í…œ
- ğŸ“„ ë¬¸ì„œ: `docs/ëª¨ë“ˆí™”/07_ê²€ì¦_ì‹œìŠ¤í…œ.md`

<br>

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°

```mermaid
graph LR
    A[Config YAML] --> B[ConfigLoader]
    C[Raw Data] --> D[Preprocessor]

    B --> E[Model + Tokenizer]
    D --> F[Dataset]

    E --> G[Trainer]
    F --> G

    G --> H[WandB Logging]
    G --> I[Checkpoints]

    I --> J[Predictor]
    J --> K[Submission CSV]

    I --> L[Ensemble]
    L --> M[Final Prediction]
```

### Config ë³‘í•© ìš°ì„ ìˆœìœ„

```
base/default.yaml         (ë‚®ìŒ)
  â†“
base/encoder_decoder.yaml
  â†“
models/kobart.yaml
  â†“
experiments/baseline_kobart.yaml  (ë†’ìŒ - ìµœìš°ì„ )
```

### ì•™ìƒë¸” ì „ëµ

```mermaid
graph TD
    A[Model 1] --> E[Ensemble]
    B[Model 2] --> E
    C[Model 3] --> E
    D[Model 4] --> E

    E --> F{ì•™ìƒë¸” íƒ€ì…}
    F --> G[Weighted]
    F --> H[Voting]
    F --> I[Stacking]
    F --> J[Blending]

    G --> K[ìµœì¢… ì˜ˆì¸¡]
    H --> K
    I --> K
    J --> K
```

<br>

## ğŸ“š ë¬¸ì„œ

### docs/ëª¨ë“ˆí™”/ í´ë” (ì™„ì „ ê°€ì´ë“œ)
| ë¬¸ì„œ | ë‚´ìš© | í˜ì´ì§€ ìˆ˜ |
|------|------|-----------|
| `00_ì „ì²´_ì‹œìŠ¤í…œ_ê°œìš”.md` | ì‹œìŠ¤í…œ ì „ì²´ ê°œìš” ë° Quick Start | 150+ |
| `01_ëª¨ë¸_ë¡œë”.md` | ModelLoader ì™„ì „ ê°€ì´ë“œ | 200+ |
| `02_í•µì‹¬_ì‹œìŠ¤í…œ.md` | Config + Logger + WandB (5ê°€ì§€ ì‹œê°í™”) | 2,087 |
| `03_ë°ì´í„°_íŒŒì´í”„ë¼ì¸.md` | ì „ì²˜ë¦¬ + Dataset + TTA | 800+ |
| `04_í•™ìŠµ_íŒŒì´í”„ë¼ì¸.md` | Trainer + LoRA íŒŒì¸íŠœë‹ | 300+ |
| `05_í‰ê°€_ìµœì í™”.md` | ROUGE + BERTScore + Optuna (15ê°œ íŒŒë¼ë¯¸í„°) | 650+ |
| `06_ì•™ìƒë¸”_API.md` | 5ê°€ì§€ ì•™ìƒë¸” + Prompt A/B | 1,200+ |
| `07_ê²€ì¦_ì‹œìŠ¤í…œ.md` | Solar API êµì°¨ ê²€ì¦ | 400+ |
| `08_ëª…ë ¹ì–´_ì˜µì…˜_ì™„ì „_ê°€ì´ë“œ.md` | ëª¨ë“  ì‹¤í–‰ ëª…ë ¹ì–´ ë° ì˜µì…˜ | 810 |
| `09_ì¶”ë¡ _ìµœì í™”.md` | TensorRT + Pruning | 500+ |
| `10_ë² ì´ìŠ¤ë¼ì¸_ê²€ì¦.md` | ìë™ ê²€ì¦ ì‹œìŠ¤í…œ | 450+ |

**ì´ 7,500+ ë¼ì¸ì˜ ì™„ì „í•œ ë¬¸ì„œí™”**

<br>

## ğŸ¯ ì‹¤í—˜ ì˜ˆì‹œ

### 1. ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ
```bash
# ë…¸íŠ¸ë¶ ì‹¤í–‰
jupyter notebook notebooks/team/CHH/Full_Pipeline.ipynb

# ë˜ëŠ” CLI (ëª¨ë“ˆí™” ì‹œìŠ¤í…œ)
python scripts/train.py --experiment baseline_kobart
```

### 2. Optuna ìµœì í™”
```python
from src.optimization import OptunaOptimizer

optimizer = OptunaOptimizer(
    config=config,
    n_trials=50,
    direction='maximize'  # ROUGE ì ìˆ˜ ìµœëŒ€í™”
)

best_params = optimizer.optimize()
print(f"Best ROUGE: {best_params['value']:.4f}")
```

### 3. ì•™ìƒë¸” ì‹¤í–‰
```python
from src.ensemble import WeightedEnsemble

# ì—¬ëŸ¬ ëª¨ë¸ ë¡œë“œ
models = [model1, model2, model3]
weights = [0.5, 0.3, 0.2]

# ì•™ìƒë¸” ì˜ˆì¸¡
ensemble = WeightedEnsemble(models, weights)
predictions = ensemble.predict(test_data)
```

### 4. TensorRT ìµœì í™”
```python
from src.inference import TensorRTOptimizer

optimizer = TensorRTOptimizer()

# PyTorch â†’ TensorRT ë³€í™˜
tensorrt_model = optimizer.convert_to_tensorrt(
    model=model,
    precision='fp16',  # FP16 ì •ë°€ë„
    batch_size=32
)

# ì¶”ë¡  (3-5ë°° ë¹ ë¦„)
predictions = tensorrt_model.predict(test_data)
```

<br>

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼

### ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥
| ëª¨ë¸ | ROUGE-1 | ROUGE-2 | ROUGE-L | ë¹„ê³  |
|------|---------|---------|---------|------|
| KoBART (ë² ì´ìŠ¤ë¼ì¸) | 0.4500 | 0.3200 | 0.4200 | 20 epochs |
| KoBART + LoRA | 0.4650 | 0.3350 | 0.4350 | íŒŒë¼ë¯¸í„° 1% í•™ìŠµ |
| KoBART + TTA | 0.4720 | 0.3420 | 0.4410 | 4ê°€ì§€ augmentation |
| Weighted Ensemble (3 models) | 0.4850 | 0.3550 | 0.4540 | ìµœì¢… ì œì¶œ |

### Optuna ìµœì í™” ê²°ê³¼
- **ì‹œë„ íšŸìˆ˜**: 50 trials
- **ìµœì  í•™ìŠµë¥ **: 5e-6 (ê¸°ì¡´: 1e-5)
- **ìµœì  ë°°ì¹˜ í¬ê¸°**: 32 (ê¸°ì¡´: 50)
- **ROUGE-L í–¥ìƒ**: 0.420 â†’ 0.443 (+5.5%)

### ì¶”ë¡  ì†ë„ ë¹„êµ (T4 GPU ê¸°ì¤€)
| ìµœì í™” ë°©ë²• | Latency (ms) | Throughput (samples/s) | ì •í™•ë„ ì†ì‹¤ |
|-------------|--------------|------------------------|-------------|
| PyTorch FP32 (ë² ì´ìŠ¤ë¼ì¸) | 120 | 8.3 | 0% |
| PyTorch JIT | 95 | 10.5 | 0% |
| TensorRT FP16 | 45 | 22.2 | < 0.5% |
| TensorRT INT8 | 30 | 33.3 | < 1.0% |
| Pruning (50% sparsity) | 60 | 16.7 | < 2.0% |

<br>

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸” ìŠˆíŒ…

### 1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)

#### ì¦ìƒ
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

#### í•´ê²°
```python
# ë°©ë²• 1: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
config.training.batch_size = 16  # ê¸°ì¡´: 32

# ë°©ë²• 2: Gradient Accumulation
config.training.gradient_accumulation_steps = 4

# ë°©ë²• 3: Mixed Precision í•™ìŠµ
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

with autocast():
    loss = model(**batch).loss
scaler.scale(loss).backward()
```

### 2. ê·¸ë˜ë””ì–¸íŠ¸ í­ë°œ

#### ì¦ìƒ
WandBì—ì„œ `gradient/total_norm` > 10.0

#### í•´ê²°
```python
# Gradient Clipping ì ìš©
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# ë˜ëŠ” í•™ìŠµë¥  ê°ì†Œ
config.training.learning_rate = 5e-6  # ê¸°ì¡´: 1e-5
```

### 3. ê³¼ì í•© (Overfitting)

#### ì¦ìƒ
WandBì—ì„œ `loss/train_val_diff` < -0.5

#### í•´ê²°
```python
# Dropout ì¦ê°€
config.model.dropout = 0.3  # ê¸°ì¡´: 0.1

# Weight Decay ì¦ê°€
config.training.weight_decay = 0.01  # ê¸°ì¡´: 0.0

# Early Stopping
if val_loss > best_val_loss:
    patience_counter += 1
    if patience_counter >= 3:
        print("Early stopping!")
        break
```

<br>

## ğŸ’¡ í”„ë¡œì íŠ¸ íšŒê³ 

### âœ… ì„±ê³µ ìš”ì¸
1. **ì²´ê³„ì ì¸ ëª¨ë“ˆí™”**: ê° ê¸°ëŠ¥ì„ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë¶„ë¦¬í•˜ì—¬ ì¬ì‚¬ìš©ì„± ê·¹ëŒ€í™”
2. **ì™„ë²½í•œ ë¬¸ì„œí™”**: 7,500+ ë¼ì¸ì˜ ìƒì„¸í•œ ê°€ì´ë“œë¡œ ëˆ„êµ¬ë‚˜ ì‚¬ìš© ê°€ëŠ¥
3. **ìë™í™” ì‹œìŠ¤í…œ**: Config, Logger, WandB í†µí•©ìœ¼ë¡œ ì‹¤í—˜ ê´€ë¦¬ ìë™í™”
4. **ìµœì í™” ì „ëµ**: Optuna, TensorRT, Pruning ë“± ë‹¤ì–‘í•œ ìµœì í™” ê¸°ë²• ì ìš©

### ğŸ”¥ ê°œì„  ì‚¬í•­
1. **CI/CD íŒŒì´í”„ë¼ì¸**: GitHub Actions ê¸°ë°˜ ìë™ í…ŒìŠ¤íŠ¸ ë° ë°°í¬
2. **Docker ì»¨í…Œì´ë„ˆí™”**: í™˜ê²½ ì¬í˜„ì„± í–¥ìƒ
3. **Kubernetes ë°°í¬**: í”„ë¡œë•ì…˜ í™˜ê²½ ìŠ¤ì¼€ì¼ë§
4. **API ì„œë²„**: FastAPI ê¸°ë°˜ ì¶”ë¡  API ì„œë²„ êµ¬ì¶•

### ğŸ“ˆ í•™ìŠµ í¬ì¸íŠ¸
- **Config ê´€ë¦¬ì˜ ì¤‘ìš”ì„±**: ê³„ì¸µì  YAML ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤í—˜ ê´€ë¦¬ íš¨ìœ¨ 10ë°° í–¥ìƒ
- **WandB ì‹œê°í™”**: 5ê°€ì§€ ê³ ê¸‰ ì‹œê°í™”ë¡œ ë””ë²„ê¹… ì‹œê°„ 50% ë‹¨ì¶•
- **ì•™ìƒë¸” íš¨ê³¼**: ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ROUGE +5% í–¥ìƒ
- **ìµœì í™” ê¸°ë²•**: TensorRT FP16ìœ¼ë¡œ ì¶”ë¡  ì†ë„ 3ë°° í–¥ìƒ

<br>

## ğŸ“– ì°¸ê³ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [WandB Documentation](https://docs.wandb.ai/)
- [Optuna Documentation](https://optuna.readthedocs.io/)

### ë…¼ë¬¸
- [BART: Denoising Sequence-to-Sequence Pre-training](https://arxiv.org/abs/1910.13461)
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [ROUGE: A Package for Automatic Evaluation](https://aclanthology.org/W04-1013/)

### êµ¬í˜„ ì°¸ê³ 
- [KoBART (SKT AI)](https://github.com/SKT-AI/KoBART)
- [PEFT (HuggingFace)](https://github.com/huggingface/peft)
- [TensorRT (NVIDIA)](https://developer.nvidia.com/tensorrt)

### ëŒ€íšŒ ë§í¬
- **ë°ì´í„°**: https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000365/data/data.tar.gz
- **ë² ì´ìŠ¤ë¼ì¸**: https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000365/data/code.tar.gz

<br>

---

**ğŸ“Œ í”„ë¡œì íŠ¸ ìƒíƒœ**: âœ… 100% êµ¬í˜„ ì™„ë£Œ (11ê°œ PRD, 7,500+ ë¼ì¸ ë¬¸ì„œ)

**ğŸ”— ì „ì²´ ë¬¸ì„œ**: `docs/ëª¨ë“ˆí™”/` í´ë” ì°¸ì¡°

**ğŸ’¬ ë¬¸ì˜**: GitHub Issues ë˜ëŠ” íŒ€ì› ì—°ë½ì²˜
