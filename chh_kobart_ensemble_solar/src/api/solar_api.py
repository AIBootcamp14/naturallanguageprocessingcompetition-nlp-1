"""
Solar API í†µí•© v3.9

ëŒ€í­ ê°œì„ ëœ ë²„ì „:
1. í”„ë¡¬í”„íŠ¸ ê°„ì†Œí™” + ê°•ë ¥í•œ ê²½ê³ 
2. Few-shot ì˜ˆì‹œ ì¶”ê°€
3. Post-processing ëŒ€í­ ê°•í™”
4. ì´ë¦„ ìš°ì„ ìˆœìœ„ ê°•ì œ ì ìš©
5. ì¡°ì‚¬ ì²˜ë¦¬ ì™„ì „ ìˆ˜ì •
6. ê³ ë¦½ëœ ì¡°ì‚¬ ì œê±° (v3.8) - "ê°€ Brian" â†’ "Brian"
7. ì¡°ì‚¬ ì—°ì‡„ ë° ë¬¸ì¥ ì¤‘ê°„ ì¡°ì‚¬ ì™„ì „ ì œê±° (v3.9 ì‹ ê·œ)
"""

import os
import re
import time
import hashlib
import pickle
from typing import List, Dict, Optional, Tuple
from pathlib import Path


class SolarAPI:
    """Solar API í´ë¼ì´ì–¸íŠ¸ v3.9 (ì¡°ì‚¬ ì—°ì‡„ ë° ë¬¸ì¥ ì¤‘ê°„ ì¡°ì‚¬ ì™„ì „ ì œê±°)"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        token_limit: int = 512,
        cache_dir: str = "cache/solar",
        logger=None
    ):
        """
        Args:
            api_key: Solar API í‚¤ (Noneì´ë©´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ìŒ)
            token_limit: ëŒ€í™”ë‹¹ ìµœëŒ€ í† í° ìˆ˜
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬
            logger: Logger ì¸ìŠ¤í„´ìŠ¤
        """
        self.api_key = api_key or os.getenv("SOLAR_API_KEY")
        self.token_limit = token_limit
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger

        # ìºì‹œ ë¡œë“œ
        self.cache = self._load_cache()

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Solar API í˜¸í™˜)
        self.client = None
        if self.api_key:
            try:
                from openai import OpenAI
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url="https://api.upstage.ai/v1/solar"
                )
                self._log("Solar API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            except ImportError:
                self._log("âš ï¸  OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ (pip install openai)")
        else:
            self._log("âš ï¸  Solar API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

    def _log(self, msg: str):
        """ë¡œê¹… í—¬í¼"""
        if self.logger:
            self.logger.write(msg)
        else:
            print(msg)

    def _extract_names_from_dialogue(self, dialogue: str) -> List[str]:
        """
        ëŒ€í™”ì—ì„œ ì´ë¦„ ì¶”ì¶œ (ì˜ì–´ ì´ë¦„, í•œê¸€ ì´ë¦„, Mr./Ms./Mrs. í¬í•¨)

        Returns:
            ì¶”ì¶œëœ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        names = []

        # 1. Mr./Ms./Mrs. + ì˜ì–´ ì´ë¦„
        title_name_pattern = r'(Mr\.|Ms\.|Mrs\.)\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)'
        for match in re.finditer(title_name_pattern, dialogue):
            full_name = f"{match.group(1)} {match.group(2)}"
            names.append(full_name)

        # 2. ì˜ì–´ ì´ë¦„ (ëŒ€í™” ì‹œì‘ ë˜ëŠ” : ì•ì— ë‚˜ì˜¤ëŠ” ê²ƒë“¤)
        # ì˜ˆ: "Tom: Hi Mary" â†’ Tom, Mary
        speaker_pattern = r'([A-Z][a-z]+):'
        for match in re.finditer(speaker_pattern, dialogue):
            name = match.group(1)
            if name not in ['Person']:  # Person ì œì™¸
                names.append(name)

        # 3. í•œê¸€ ì´ë¦„ (3-4ê¸€ì, ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„)
        # korean_name_pattern = r'\b([ê°€-í£]{2,4})\b(?=[,\sì”¨ë‹˜])'
        # for match in re.finditer(korean_name_pattern, dialogue):
        #     name = match.group(1)
        #     # ì¼ë°˜ ë‹¨ì–´ ì œì™¸
        #     if name not in ['ì¹œêµ¬', 'ìƒì‚¬', 'ë¹„ì„œ', 'ê³ ê°', 'ì†ë‹˜', 'ì§ì›', 'í•™ìƒ', 'ì„ ìƒ', 'êµìˆ˜', 'í™˜ì', 'ì˜ì‚¬', 'ê°„í˜¸ì‚¬']:
        #         names.append(name)

        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (ê¸´ ì´ë¦„ ìš°ì„ )
        names = list(set(names))
        names.sort(key=len, reverse=True)

        return names

    def _validate_and_fix_summary(self, text: str, dialogue: str) -> str:
        """
        ìš”ì•½ë¬¸ ê²€ì¦ ë° ê°•ì œ ìˆ˜ì • (Post-processing v3.9)

        GPT ë¶„ì„ ê¸°ë°˜ ëŒ€í­ ê°œì„ :
        1. ì´ë¦„ ìš°ì„ ìˆœìœ„ ê°•ì œ ì ìš©
        2. "ì¸+ì¡°ì‚¬" íŒ¨í„´ ì™„ì „ ìˆ˜ì •
        3. "ì¹œêµ¬ A", "ì¹œêµ¬ B" ê°•ì œ ì œê±°
        4. ì—­í• +ì´ë¦„ ì¶©ëŒ í•´ê²°
        5. í”Œë ˆì´ìŠ¤í™€ë” ì™„ì „ ì œê±°
        6. ê³ ë¦½ëœ ì¡°ì‚¬ ì œê±° (v3.8) - "ê°€ Brian" â†’ "Brian"
        7. ì¡°ì‚¬ ì—°ì‡„ ì™„ì „ ì œê±° (v3.9 ì‹ ê·œ) - "ê°€ì—ê²Œ", "ëŠ”ì—ê²Œ" ë“±
        8. í˜•ìš©ì‚¬+ì¡°ì‚¬ íŒ¨í„´ ì œê±° (v3.9 ì‹ ê·œ) - "ë³´ì´ëŠ”ì—ê²Œ" â†’ "ë³´ì´ëŠ” ì‚¬ëŒì—ê²Œ"
        9. ë¬¸ì¥ ì¤‘ê°„ ê³ ë¦½ ì¡°ì‚¬ ì œê±° (v3.9 ì‹ ê·œ) - ". ëŠ”" â†’ ". "

        Args:
            text: Solar API ì¶œë ¥ í…ìŠ¤íŠ¸
            dialogue: ì›ë³¸ ëŒ€í™”

        Returns:
            ê²€ì¦ ë° ìˆ˜ì •ëœ ìš”ì•½ë¬¸
        """
        if not text:
            return text

        original = text
        modified = text

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1: ì´ë¦„ ì¶”ì¶œ ë° ìš°ì„  ì ìš© (ìµœê³  ìš°ì„ ìˆœìœ„!)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        names = self._extract_names_from_dialogue(dialogue)

        # ì´ë¦„ì´ ìˆìœ¼ë©´ ì—­í•  ë‹¨ì–´ë¥¼ ì´ë¦„ìœ¼ë¡œ ì¹˜í™˜
        if names:
            # "ìƒì‚¬ Ms. Dawson" â†’ "Ms. Dawson"
            # "ì¹œêµ¬ Tom" â†’ "Tom"
            for name in names:
                # ì—­í• +ì´ë¦„ íŒ¨í„´ ì œê±° (ì´ë¦„ë§Œ ë‚¨ê¹€)
                role_name_patterns = [
                    (rf'(ì¹œêµ¬|ë™ë£Œ|ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê³ ê°|ì†ë‹˜|í•™ìƒ|ì„ ìƒë‹˜|êµìˆ˜|í™˜ì|ì˜ì‚¬|ê°„í˜¸ì‚¬|ì—°ì¸|ë¶€ëª¨|ìë…€)\s+{re.escape(name)}', name),
                ]

                for pattern, replacement in role_name_patterns:
                    modified = re.sub(pattern, replacement, modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 2: "ì¹œêµ¬ Aì™€ ì¹œêµ¬ B" â†’ "ë‘ ì¹œêµ¬" (ê°•ì œ ë³€í™˜)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # 2-1. "ì¹œêµ¬ Aì™€ ì¹œêµ¬ B" íŒ¨í„´
        same_role_letter_patterns = [
            (r'(ì¹œêµ¬|ë™ë£Œ|ì—°ì¸)\s+[A-D]\s*ì™€\s+\1\s+[A-D]', r'ë‘ \1'),
            (r'(ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê´€ë¦¬ì)\s+[A-D]\s*ì™€\s+\1\s+[A-D]', r'ë‘ \1'),
            (r'(ê³ ê°|ì†ë‹˜|êµ¬ë§¤ì)\s+[A-D]\s*ì™€\s+\1\s+[A-D]', r'ë‘ \1'),
            (r'(í•™ìƒ|ì„ ìƒë‹˜|êµìˆ˜)\s+[A-D]\s*ì™€\s+\1\s+[A-D]', r'ë‘ \1'),
        ]

        for pattern, replacement in same_role_letter_patterns:
            modified = re.sub(pattern, replacement, modified, flags=re.IGNORECASE)

        # 2-2. "ì¹œêµ¬ Aê°€ ì¹œêµ¬ Bì—ê²Œ" â†’ "ë‘ ì¹œêµ¬ê°€" (ëª¨ë“  ë³€í˜•)
        complex_same_role_patterns = [
            (r'(ì¹œêµ¬|ë™ë£Œ)\s+[A-D]\s*ê°€\s+\1\s+[A-D]\s*ì—ê²Œ', r'ë‘ \1ê°€'),
            (r'(ì¹œêµ¬|ë™ë£Œ)\s+[A-D]\s*ì´\s+\1\s+[A-D]\s*ì—ê²Œ', r'ë‘ \1ê°€'),
            (r'(ì¹œêµ¬|ë™ë£Œ)\s+[A-D]\s*ëŠ”\s+\1\s+[A-D]\s*ì—ê²Œ', r'ë‘ \1ëŠ”'),
        ]

        for pattern, replacement in complex_same_role_patterns:
            modified = re.sub(pattern, replacement, modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 3: ì—­í• +ì´ë¦„ íŒ¨í„´ ì œê±° (ì´ë¦„ë§Œ ë‚¨ê¸°ê¸°)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # 3-1. ì—­í•  + ì˜ì–´ ì´ë¦„
        role_english_name_patterns = [
            # "ì¹œêµ¬ Francis" â†’ "Francis"
            r'(ì¹œêµ¬|ë™ë£Œ|ì—°ì¸|ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê³ ê°|ì†ë‹˜)\s+([A-Z][a-z]+)(?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
            # "ìƒì‚¬ Mr. Dawson" â†’ "Mr. Dawson"
            r'(ì¹œêµ¬|ë™ë£Œ|ì—°ì¸|ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê³ ê°|ì†ë‹˜)\s+(Mr\.|Ms\.|Mrs\.)\s+([A-Z][a-z]+)(?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
        ]

        for pattern in role_english_name_patterns:
            def replace_role_name(m):
                if len(m.groups()) == 2:
                    return m.group(2)  # ì´ë¦„ë§Œ
                else:
                    return f"{m.group(2)} {m.group(3)}"  # Mr./Ms. + ì´ë¦„

            modified = re.sub(pattern, replace_role_name, modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 4: í•œê¸€ + ì•ŒíŒŒë²³ ì¡°í•© ì œê±° ("ì¹œêµ¬ A" â†’ "ì¹œêµ¬")
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        korean_letter_patterns = [
            r'(ì¹œêµ¬|ë™ë£Œ|ì—°ì¸|í˜•ì œ|ìë§¤|ë¶€ëª¨|ìë…€|ì¹œì²™)\s+[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
            r'(ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê´€ë¦¬ì|íŒ€ì›|ë¶€í•˜)\s+[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
            r'(ê³ ê°|ì†ë‹˜|êµ¬ë§¤ì|íšŒì›|ë¯¼ì›ì¸)\s+[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
            r'(í™˜ì|ì˜ì‚¬|ê°„í˜¸ì‚¬|ì•½ì‚¬|í•™ìƒ|ì„ ìƒë‹˜|êµìˆ˜|ê°•ì‚¬)\s+[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
            r'(ì‚¬ëŒ|ë‚¨ì|ì—¬ì|ì‚¬ìš©ì|ì¸ë¬¼)\s+[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)',
        ]

        for pattern in korean_letter_patterns:
            modified = re.sub(pattern, r'\1', modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 5: "ì¸+ì¡°ì‚¬" íŒ¨í„´ ìˆ˜ì • (GPT ì œì•ˆ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # 5-1. "ìƒì‚¬ì¸ê°€" â†’ "ìƒì‚¬ê°€" (ì¡°ì‚¬ ê²°í•©)
        particle_fix_patterns = [
            # "ì¸ê°€" â†’ "ê°€"
            (r'(ì¹œêµ¬|ë™ë£Œ|ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê³ ê°|ì†ë‹˜|í•™ìƒ|ì„ ìƒë‹˜|êµìˆ˜|ê´€ë¦¬ì|í™˜ì|ì˜ì‚¬|ê°„í˜¸ì‚¬|ì—°ì¸|í˜•ì œ|ìë§¤|ë¶€ëª¨|ìë…€|ì‚¬ëŒ|ë‚¨ì|ì—¬ì)ì¸(ê°€|ì´)', r'\1\2'),
            # "ì¸ì—ê²Œ" â†’ "ì—ê²Œ"
            (r'(ì¹œêµ¬|ë™ë£Œ|ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê³ ê°|ì†ë‹˜|í•™ìƒ|ì„ ìƒë‹˜|êµìˆ˜|ê´€ë¦¬ì|í™˜ì|ì˜ì‚¬|ê°„í˜¸ì‚¬|ì—°ì¸|í˜•ì œ|ìë§¤|ë¶€ëª¨|ìë…€|ì‚¬ëŒ|ë‚¨ì|ì—¬ì)ì¸(ì—ê²Œ|ì—ì„œ|ì—|í•œí…Œ)', r'\1\2'),
            # "ì¸ì€" â†’ "ì€"
            (r'(ì¹œêµ¬|ë™ë£Œ|ìƒì‚¬|ë¹„ì„œ|ì§ì›|ê³ ê°|ì†ë‹˜|í•™ìƒ|ì„ ìƒë‹˜|êµìˆ˜|ê´€ë¦¬ì|í™˜ì|ì˜ì‚¬|ê°„í˜¸ì‚¬|ì—°ì¸|í˜•ì œ|ìë§¤|ë¶€ëª¨|ìë…€|ì‚¬ëŒ|ë‚¨ì|ì—¬ì)ì¸(ì€|ëŠ”|ì„|ë¥¼|ë„|ë§Œ)', r'\1\2'),
        ]

        for pattern, replacement in particle_fix_patterns:
            modified = re.sub(pattern, replacement, modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 6: êµ¬ë‘ì  ë’¤ í”Œë ˆì´ìŠ¤í™€ë” ì²˜ë¦¬
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # 6-1. "ë¬»ì,AëŠ”" â†’ "ë¬»ì, "
        # 6-2. "ì´ì•¼ê¸°í•¨.AëŠ”" â†’ "ì´ì•¼ê¸°í•¨. "
        punctuation_placeholder_patterns = [
            (r'([,.])\s*[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ])', r'\1 '),
            (r'([,.])[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ])', r'\1 '),
        ]

        for pattern, replacement in punctuation_placeholder_patterns:
            modified = re.sub(pattern, replacement, modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 7: #Person#, ë‹¨ë… ì•ŒíŒŒë²³ ì œê±°
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # 7-1. #Person1#, #Person2# ì œê±°
        placeholder_exact = [
            r'#Person[1-4]#',
            r'#[PFpf]?[AEae]*?person[1-4]#',
            r'#[A-Za-z]*?erson[1-4]#',
        ]

        for pattern in placeholder_exact:
            modified = re.sub(pattern, '', modified, flags=re.IGNORECASE)

        # 7-2. ë‹¨ë… ì•ŒíŒŒë²³ ì œê±° (í›„ìˆœìœ„!)
        modified = re.sub(r'\s+[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|$|,|\.)', '', modified, flags=re.IGNORECASE)
        modified = re.sub(r'^[A-D](?=[ê°€ì´ì™€ê³¼ì—í•œì˜ì€ëŠ”ì„ë¥¼ë„ê»˜ë¶€ê¹Œì„œ]|\s|,|\.)', '', modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 7.5: ì•ŒíŒŒë²³+ì¡°ì‚¬ ì—°ì‡„ ì™„ì „ ì œê±° (v3.8 ì‹ ê·œ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # "Aê°€ Brian" â†’ "Brian"
        # "BëŠ” Tom" â†’ "Tom"
        # ì•ŒíŒŒë²³+ì¡°ì‚¬ë¥¼ ê³µë°±ê³¼ í•¨ê»˜ ì™„ì „ ì œê±°
        alphabet_particle_patterns = [
            r'\b[A-D](ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„|ì—ê²Œ|ì—ì„œ|ì—|í•œí…Œ|ì™€|ê³¼|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€|ê»˜|ê»˜ì„œ|ì˜)\s+',
            r'^[A-D](ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„|ì—ê²Œ|ì—ì„œ|ì—|í•œí…Œ|ì™€|ê³¼|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€|ê»˜|ê»˜ì„œ|ì˜)\s+',
        ]

        for pattern in alphabet_particle_patterns:
            modified = re.sub(pattern, '', modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 7.8: ì¡°ì‚¬ ì—°ì‡„ ì œê±° (v3.9 ì‹ ê·œ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # "ê°€ì—ê²Œ" â†’ ""
        # "ëŠ”ì—ê²Œ" â†’ ""
        # "ê°€ì—ê²Œì˜" â†’ ""
        # "ë¥¼ì—ê²Œ" â†’ ""
        particle_chain_patterns = [
            # ì¡°ì‚¬+ì¡°ì‚¬ ì¡°í•© (2ê°œ)
            r'(ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„)(ì—ê²Œ|ì—ì„œ|ì˜|ì™€|ê³¼|í•œí…Œ)\s*',
            # ì¡°ì‚¬+ì¡°ì‚¬+ì¡°ì‚¬ ì¡°í•© (3ê°œ)
            r'(ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„)(ì—ê²Œ|ì—ì„œ|í•œí…Œ)(ì˜|ì™€|ê³¼)\s*',
        ]

        for pattern in particle_chain_patterns:
            modified = re.sub(pattern, '', modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 7.9: í˜•ìš©ì‚¬/ë™ì‚¬+ì¡°ì‚¬ ì—°ì‡„ ì œê±° (v3.9 ì‹ ê·œ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # "í”¼ê³¤í•´ ë³´ì´ëŠ”ì—ê²Œ" â†’ "í”¼ê³¤í•´ ë³´ì´ëŠ” ì‚¬ëŒì—ê²Œ"
        # "ì´ì›ƒì¸ì™€" â†’ "ì´ì›ƒê³¼"
        adjective_particle_patterns = [
            # "~ëŠ”ì—ê²Œ" â†’ "~ëŠ” ì‚¬ëŒì—ê²Œ"
            (r'([ê°€-í£]+ëŠ”)(ì—ê²Œ|ì—ì„œ|í•œí…Œ)', r'\1 ì‚¬ëŒ\2'),
            # "~ì¸ì™€/ê³¼" â†’ "~ê³¼/ì™€"
            (r'([ê°€-í£]{2,})ì¸(ì™€|ê³¼)', r'\1\2'),
            # "~ì¸ê°€" â†’ "~ê°€"
            (r'([ê°€-í£]{2,})ì¸(ê°€|ì´)(\s)', r'\1\2\3'),
        ]

        for pattern, replacement in adjective_particle_patterns:
            modified = re.sub(pattern, replacement, modified, flags=re.IGNORECASE)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 8: ë¬¸ì¥ ì‹œì‘ì˜ ê³ ë¦½ëœ ì¡°ì‚¬ ì œê±° (v3.8)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # "ê°€ Brianì˜..." â†’ "Brianì˜..."
        # ì£¼ì–´ê°€ ì™„ì „íˆ ì‚¬ë¼ì§€ê³  ì¡°ì‚¬ë§Œ ë‚¨ì€ ê²½ìš° ì œê±°
        isolated_particle_pattern = r'^(ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„|ì—ê²Œ|ì—ì„œ|ì—|í•œí…Œ|ì™€|ê³¼|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€|ê»˜|ê»˜ì„œ|ì˜)\s+'
        modified = re.sub(isolated_particle_pattern, '', modified)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 8.5: ë¬¸ì¥ ì¤‘ê°„ ê³ ë¦½ ì¡°ì‚¬ ì œê±° (v3.9 ì‹ ê·œ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # "ë…¼ì˜í•¨. ëŠ” ìŠ¤íŠ¸ë ˆìŠ¤ê°€" â†’ "ë…¼ì˜í•¨. ìŠ¤íŠ¸ë ˆìŠ¤ê°€"
        # ". ê°€ ë„ì›€ì„" â†’ ". ë„ì›€ì„"
        middle_particle_pattern = r'([.!?])\s+(ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„|ì—ê²Œ|ì—ì„œ|ì˜|ì™€|ê³¼|í•œí…Œ|ë„|ë§Œ)\s+'
        modified = re.sub(middle_particle_pattern, r'\1 ', modified)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 8: ë¬¸ì¥ ì‹œì‘ì˜ ê³ ë¦½ëœ ì¡°ì‚¬ ì œê±° (v3.8)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # "ê°€ Brianì˜..." â†’ "Brianì˜..."
        # ì£¼ì–´ê°€ ì™„ì „íˆ ì‚¬ë¼ì§€ê³  ì¡°ì‚¬ë§Œ ë‚¨ì€ ê²½ìš° ì œê±°
        isolated_particle_pattern = r'^(ê°€|ì´|ëŠ”|ì€|ë¥¼|ì„|ì—ê²Œ|ì—ì„œ|ì—|í•œí…Œ|ì™€|ê³¼|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€|ê»˜|ê»˜ì„œ)\s+'
        modified = re.sub(isolated_particle_pattern, '', modified)

        # ê³µë°± ì •ë¦¬ (ì—°ì† ê³µë°± ì œê±°)
        modified = re.sub(r'\s+', ' ', modified)
        modified = modified.strip()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 10: ì •ë¦¬ (ê³µë°±, êµ¬ë‘ì )
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # ì—°ì† ê³µë°± ì œê±°
        modified = re.sub(r'\s+', ' ', modified)
        # ì•ë’¤ ê³µë°± ì œê±°
        modified = modified.strip()
        # êµ¬ë‘ì  ì• ê³µë°± ì œê±°
        modified = re.sub(r'\s+([,.])', r'\1', modified)
        # êµ¬ë‘ì  ë’¤ ê³µë°± ì¶”ê°€ (ì¼ê´€ì„±)
        modified = re.sub(r'([,.])(?=[ê°€-í£A-Za-z])', r'\1 ', modified)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 11: ê²€ì¦
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # í”Œë ˆì´ìŠ¤í™€ë” ì”ì¡´ í™•ì¸
        placeholder_check = [
            r'\b[A-D]\b',
            r'#Person\d+#',
            r'[ê°€-í£]+\s*[A-D](?=[ê°€ì´ì™€ê³¼])',
        ]

        has_placeholder = any(re.search(p, modified, re.IGNORECASE) for p in placeholder_check)

        if has_placeholder:
            self._log(f"âš ï¸  í”Œë ˆì´ìŠ¤í™€ë” ì”ì¡´: {modified[:80]}...")

        return modified

    def _load_cache(self) -> Dict:
        """ìºì‹œ ë¡œë“œ"""
        cache_file = self.cache_dir / "solar_cache.pkl"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    cache = pickle.load(f)
                self._log(f"ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(cache)}ê°œ í•­ëª©")
                return cache
            except:
                return {}
        return {}

    def _save_cache(self):
        """ìºì‹œ ì €ì¥"""
        cache_file = self.cache_dir / "solar_cache.pkl"
        with open(cache_file, 'wb') as f:
            pickle.dump(self.cache, f)

    def preprocess_dialogue(self, dialogue: str) -> str:
        """ëŒ€í™” ì „ì²˜ë¦¬"""
        dialogue = ' '.join(dialogue.split())
        dialogue = dialogue.replace('#Person1#:', 'A:')
        dialogue = dialogue.replace('#Person2#:', 'B:')
        dialogue = dialogue.replace('#Person3#:', 'C:')
        dialogue = dialogue.replace('#Person4#:', 'D:')
        dialogue = self.smart_truncate(dialogue, self.token_limit)
        return dialogue

    def smart_truncate(self, text: str, max_tokens: int = 512) -> str:
        """ìŠ¤ë§ˆíŠ¸ ì ˆë‹¨"""
        estimated_tokens = self.estimate_tokens(text)
        if estimated_tokens <= max_tokens:
            return text

        sentences = re.split(r'([.!?]\s+)', text)
        truncated = []
        current_tokens = 0

        for i in range(0, len(sentences), 2):
            if i + 1 < len(sentences):
                sentence = sentences[i] + sentences[i + 1]
            else:
                sentence = sentences[i]

            sentence_tokens = self.estimate_tokens(sentence)

            if current_tokens + sentence_tokens > max_tokens:
                break

            truncated.append(sentence)
            current_tokens += sentence_tokens

        result = ''.join(truncated)
        return result if result else text[:int(max_tokens * 2.5)]

    def estimate_tokens(self, text: str) -> int:
        """í† í° ìˆ˜ ì¶”ì •"""
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        other_chars = len(text) - korean_chars - english_chars
        estimated = (korean_chars / 2.5) + (english_chars / 4) + (other_chars / 3)
        return int(estimated)

    def build_few_shot_prompt(
        self,
        dialogue: str,
        example_dialogue: Optional[str] = None,
        example_summary: Optional[str] = None
    ) -> List[Dict[str, str]]:
        """
        Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„± (v3.9 - í¬ê´„ì  ì¡°ì‚¬ ì œê±°)

        Args:
            dialogue: ì…ë ¥ ëŒ€í™”
            example_dialogue: ì˜ˆì‹œ ëŒ€í™”
            example_summary: ì˜ˆì‹œ ìš”ì•½

        Returns:
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        # í”„ë¡¬í”„íŠ¸ ë²„ì „
        PROMPT_VERSION = "v3.9_comprehensive_particle_removal"

        # ê°„ì†Œí™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•µì‹¬ë§Œ!)
        system_prompt = f"""[{PROMPT_VERSION}] ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ğŸš¨ **ì ˆëŒ€ ê¸ˆì§€ (ì¦‰ì‹œ ì‹¤ê²©)**:
1. âŒ A, B, C, D ê°™ì€ ì•ŒíŒŒë²³
2. âŒ #Person1#, #Person2# ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë”
3. âŒ "ì¹œêµ¬ A", "ìƒì‚¬ B" ê°™ì€ í•œê¸€+ì•ŒíŒŒë²³ í˜¼í•©
4. âŒ "ì¹œêµ¬ Aì™€ ì¹œêµ¬ B" - ëŒ€ì‹  "ë‘ ì¹œêµ¬" ì‚¬ìš©!

âœ… **í•„ìˆ˜ ê·œì¹™**:
1. **ì´ë¦„ ìµœìš°ì„ **: ëŒ€í™”ì— ì´ë¦„ì´ ìˆìœ¼ë©´ **ë°˜ë“œì‹œ** ì‚¬ìš©
   - "Ms. Dawson", "Tom", "Mary", "ìŠ¤í‹°ë¸" ë“±
   - âŒ "ìƒì‚¬ê°€ ë¹„ì„œì—ê²Œ" â†’ âœ… "ìƒì‚¬ê°€ Ms. Dawsonì—ê²Œ"

2. **ì´ë¦„ ì—†ìœ¼ë©´ ì—­í•  ì‚¬ìš©**:
   - ì—…ë¬´: "ìƒì‚¬/ë¹„ì„œ", "ê³ ê°/ì§ì›"
   - ì¼ìƒ: "ì¹œêµ¬", "ë™ë£Œ"
   - ë‘ ëª…: "ë‘ ì¹œêµ¬", "ì¹œêµ¬ë“¤"

3. **ê°„ê²°í•˜ê²Œ**: 50-150ì, í•µì‹¬ë§Œ

4. **ë§íˆ¬ í™•ì¸**:
   - ë°˜ë§ â†’ ì¹œêµ¬, ë™ë£Œ
   - ì¡´ëŒ“ë§ â†’ ê³ ê°, ìƒì‚¬, ì§ì›

ì˜ˆì‹œ:
- âŒ "ì¹œêµ¬ Aì™€ ì¹œêµ¬ Bê°€ ì˜í™”ë¥¼ ë³´ê¸°ë¡œ í•¨"
- âœ… "ë‘ ì¹œêµ¬ê°€ ì˜í™”ë¥¼ ë³´ê¸°ë¡œ í•¨"

- âŒ "ìƒì‚¬ê°€ ë¹„ì„œì—ê²Œ ë©”ëª¨ ì‘ì„±ì„ ì§€ì‹œí•¨" (ì´ë¦„ì´ ìˆëŠ”ë°!)
- âœ… "ìƒì‚¬ê°€ Ms. Dawsonì—ê²Œ ë©”ëª¨ ì‘ì„±ì„ ì§€ì‹œí•¨"""

        messages = [
            {"role": "system", "content": system_prompt}
        ]

        # Few-shot ì˜ˆì‹œ ì¶”ê°€ (êµ¬ì²´ì  í•™ìŠµ!)
        if not example_dialogue or not example_summary:
            # ê¸°ë³¸ ì˜ˆì‹œ ì œê³µ
            example_dialogues_and_summaries = [
                # ì˜ˆì‹œ 1: ì´ë¦„ ì‚¬ìš©
                {
                    "dialogue": "A: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. B: ë„¤, ë§ì”€í•˜ì„¸ìš”. A: ì´ê±¸ ì˜¤ëŠ˜ ì˜¤í›„ê¹Œì§€ ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¡œ ë³´ë‚´ì•¼ í•´ìš”.",
                    "summary": "ìƒì‚¬ê°€ Ms. Dawsonì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ ë°°í¬ë¥¼ ì§€ì‹œí•¨."
                },
                # ì˜ˆì‹œ 2: ë‘ ì¹œêµ¬
                {
                    "dialogue": "A: ì˜¤ëŠ˜ ì˜í™” ë³¼ë˜? B: ì¢‹ì•„! ëª‡ ì‹œì—? A: 7ì‹œ ì–´ë•Œ? B: ì™„ë²½í•´!",
                    "summary": "ë‘ ì¹œêµ¬ê°€ ì €ë… 7ì‹œì— ì˜í™” ë³´ê¸°ë¡œ ì•½ì†í•¨."
                },
                # ì˜ˆì‹œ 3: ì´ë¦„ì´ ìˆì„ ë•Œ
                {
                    "dialogue": "Tom: Hi Mary, ì˜¤ëŠ˜ ì €ë…ì— ì‹œê°„ ìˆì–´? Mary: ì‘, ìˆì–´. ì™œ? Tom: ê°™ì´ ì €ë… ë¨¹ì„ë˜?",
                    "summary": "Tomì´ Maryì—ê²Œ ì €ë… ì‹ì‚¬ë¥¼ ì œì•ˆí•¨."
                },
            ]

            for ex in example_dialogues_and_summaries:
                messages.append({
                    "role": "user",
                    "content": f"Dialogue:\n{ex['dialogue']}\n\nSummary:"
                })
                messages.append({
                    "role": "assistant",
                    "content": ex['summary']
                })
        else:
            # ì‚¬ìš©ì ì œê³µ ì˜ˆì‹œ
            messages.append({
                "role": "user",
                "content": f"Dialogue:\n{example_dialogue}\n\nSummary:"
            })
            messages.append({
                "role": "assistant",
                "content": example_summary
            })

        # ì‹¤ì œ ì…ë ¥
        messages.append({
            "role": "user",
            "content": f"""Dialogue:
{dialogue}

Summary:"""
        })

        return messages

    def summarize(
        self,
        dialogue: str,
        example_dialogue: Optional[str] = None,
        example_summary: Optional[str] = None,
        temperature: float = 0.2,
        top_p: float = 0.3,
        max_tokens: int = 200
    ) -> str:
        """ë‹¨ì¼ ëŒ€í™” ìš”ì•½"""
        if not self.client:
            raise RuntimeError("Solar API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")

        # ìºì‹œ í™•ì¸
        PROMPT_VERSION = "v3.9_comprehensive_particle_removal"
        cache_key_string = f"{PROMPT_VERSION}_{dialogue}"
        cache_key = hashlib.md5(cache_key_string.encode()).hexdigest()
        if cache_key in self.cache:
            self._log(f"ìºì‹œ íˆíŠ¸: {cache_key[:8]}")
            return self.cache[cache_key]

        # ì „ì²˜ë¦¬
        processed_dialogue = self.preprocess_dialogue(dialogue)

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        messages = self.build_few_shot_prompt(
            processed_dialogue,
            example_dialogue,
            example_summary
        )

        # API í˜¸ì¶œ
        try:
            response = self.client.chat.completions.create(
                model="solar-1-mini-chat",
                messages=messages,
                temperature=temperature,
                top_p=top_p,
                max_tokens=max_tokens
            )

            summary = response.choices[0].message.content.strip()

            # Post-processing: ê°•ì œ ìˆ˜ì •
            summary = self._validate_and_fix_summary(summary, dialogue)

            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = summary
            self._save_cache()

            return summary

        except Exception as e:
            self._log(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return ""

    def evaluate_summary_quality(self, summary: str, dialogue: str) -> float:
        """ìš”ì•½ë¬¸ í’ˆì§ˆ í‰ê°€"""
        score = 0.0

        # 1. í”Œë ˆì´ìŠ¤í™€ë” ë¯¸ì‚¬ìš© (+30ì )
        placeholder_patterns = [r'\b[A-D]\b', r'#Person\d+#', r'[ê°€-í£]+\s*[A-D]\b']
        has_placeholder = any(re.search(p, summary) for p in placeholder_patterns)
        if not has_placeholder:
            score += 30

        # 2. ì ì ˆí•œ ê¸¸ì´ (+20ì )
        summary_len = len(summary)
        if 50 <= summary_len <= 150:
            score += 20
        elif summary_len < 50:
            score += 5
        else:
            score += 10

        # 3. ì´ë¦„ ì‚¬ìš© í™•ì¸ (+20ì )
        names = self._extract_names_from_dialogue(dialogue)
        if names:
            # ì´ë¦„ì´ ìš”ì•½ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            name_used = any(name in summary for name in names)
            if name_used:
                score += 20
        else:
            score += 20  # ì´ë¦„ ì—†ìœ¼ë©´ ê¸°ë³¸ ì ìˆ˜

        # 4. "ì¹œêµ¬ A", "ì¹œêµ¬ B" ë¯¸ì‚¬ìš© (+30ì )
        forbidden_patterns = [r'ì¹œêµ¬\s+[A-D]', r'ìƒì‚¬\s+[A-D]', r'ë¹„ì„œ\s+[A-D]']
        has_forbidden = any(re.search(p, summary) for p in forbidden_patterns)
        if not has_forbidden:
            score += 30

        return min(100, score)

    def summarize_with_voting(
        self,
        dialogue: str,
        example_dialogue: Optional[str] = None,
        example_summary: Optional[str] = None,
        n_samples: int = 3,
        temperature: float = 0.1,
        top_p: float = 0.3,
        max_tokens: int = 200
    ) -> str:
        """K-Fold ë°©ì‹ ë‹¤ì¤‘ ìƒ˜í”Œë§ ìš”ì•½"""
        if not self.client:
            raise RuntimeError("Solar API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")

        # ìºì‹œ í™•ì¸
        PROMPT_VERSION = "v3.9_comprehensive_particle_removal"
        cache_key_string = f"{PROMPT_VERSION}_voting_{n_samples}_{dialogue}"
        cache_key = hashlib.md5(cache_key_string.encode()).hexdigest()
        if cache_key in self.cache:
            self._log(f"ìºì‹œ íˆíŠ¸ (voting): {cache_key[:8]}")
            return self.cache[cache_key]

        # ì „ì²˜ë¦¬
        processed_dialogue = self.preprocess_dialogue(dialogue)

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        messages = self.build_few_shot_prompt(
            processed_dialogue,
            example_dialogue,
            example_summary
        )

        # NíšŒ ìƒ˜í”Œë§
        summaries = []
        scores = []

        self._log(f"ğŸ”„ Solar API {n_samples}íšŒ ìƒ˜í”Œë§ ì‹œì‘...")

        max_retries = 3

        try:
            for i in range(n_samples):
                success = False
                attempt = 0

                while not success and attempt < max_retries:
                    try:
                        response = self.client.chat.completions.create(
                            model="solar-1-mini-chat",
                            messages=messages,
                            temperature=temperature,
                            top_p=top_p,
                            max_tokens=max_tokens
                        )

                        summary = response.choices[0].message.content.strip()

                        # Post-processing: ê°•ì œ ìˆ˜ì •
                        summary = self._validate_and_fix_summary(summary, dialogue)

                        summaries.append(summary)

                        # í’ˆì§ˆ í‰ê°€
                        score = self.evaluate_summary_quality(summary, dialogue)
                        scores.append(score)

                        self._log(f"  ìƒ˜í”Œ {i+1}/{n_samples}: {score:.1f}ì  | {summary[:50]}...")

                        success = True

                    except Exception as e:
                        error_msg = str(e)

                        if "429" in error_msg or "rate limit" in error_msg.lower():
                            attempt += 1

                            if attempt < max_retries:
                                wait_time = 5 * (2 ** (attempt - 1))
                                self._log(f"  âš ï¸  Rate Limit - {wait_time}ì´ˆ ëŒ€ê¸° ({attempt}/{max_retries})...")
                                time.sleep(wait_time)
                            else:
                                if summaries:
                                    self._log(f"  âš ï¸  ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ - ì´ì „ ìƒ˜í”Œ ì¬ì‚¬ìš©")
                                    summaries.append(summaries[-1])
                                    scores.append(scores[-1])
                                    success = True
                                else:
                                    raise
                        else:
                            raise

                # Rate limit ë°©ì§€
                if i < n_samples - 1:
                    time.sleep(4.0)

            # ìµœê³  ì ìˆ˜ ì„ íƒ
            best_idx = scores.index(max(scores))
            best_summary = summaries[best_idx]
            best_score = scores[best_idx]

            self._log(f"âœ… ìµœì¢… ì„ íƒ: ìƒ˜í”Œ {best_idx+1} ({best_score:.1f}ì )")

            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = best_summary
            self._save_cache()

            return best_summary

        except Exception as e:
            self._log(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return ""

    def summarize_batch(
        self,
        dialogues: List[str],
        example_dialogue: Optional[str] = None,
        example_summary: Optional[str] = None,
        batch_size: int = 10,
        delay: float = 1.0,
        use_voting: bool = False,
        n_samples: int = 3,
        max_tokens: int = 200
    ) -> List[str]:
        """ë°°ì¹˜ ìš”ì•½"""
        summaries = []

        self._log(f"\në°°ì¹˜ ìš”ì•½ ì‹œì‘: {len(dialogues)}ê°œ ëŒ€í™”")
        self._log(f"  - ë°°ì¹˜ í¬ê¸°: {batch_size}")
        self._log(f"  - Rate limit ëŒ€ê¸°: {delay}ì´ˆ")
        if use_voting:
            self._log(f"  - ğŸ”„ K-Fold ë°©ì‹ ìƒ˜í”Œë§: {n_samples}íšŒ")

        try:
            for i in range(0, len(dialogues), batch_size):
                batch = dialogues[i:i + batch_size]
                batch_start = i + 1
                batch_end = min(i + batch_size, len(dialogues))

                self._log(f"[ë°°ì¹˜ {batch_start}-{batch_end}/{len(dialogues)}] ì²˜ë¦¬ ì¤‘...")

                batch_summaries = []
                for idx, dialogue in enumerate(batch):
                    dialogue_idx = i + idx + 1

                    # ëŒ€í™”ë¬¸ ì¶œë ¥ (ì²« 100ì)
                    dialogue_preview = dialogue[:100].replace('\n', ' ')
                    self._log(f"\n[{dialogue_idx}/{len(dialogues)}] ëŒ€í™”: {dialogue_preview}...")

                    if use_voting:
                        summary = self.summarize_with_voting(
                            dialogue,
                            example_dialogue,
                            example_summary,
                            n_samples=n_samples,
                            max_tokens=max_tokens
                        )
                    else:
                        summary = self.summarize(
                            dialogue,
                            example_dialogue,
                            example_summary,
                            max_tokens=max_tokens
                        )
                    batch_summaries.append(summary)

                    # ìš”ì•½ ê²°ê³¼ ì¶œë ¥
                    self._log(f"[{dialogue_idx}/{len(dialogues)}] ìš”ì•½: {summary}")

                summaries.extend(batch_summaries)
                self._log(f"\n  âœ… ë°°ì¹˜ ì™„ë£Œ (ëˆ„ì : {len(summaries)}/{len(dialogues)})")

                if i + batch_size < len(dialogues):
                    time.sleep(delay)

        except Exception as e:
            self._log(f"\nâŒ ë°°ì¹˜ ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self._log(f"  ì§„í–‰ ìƒí™©: {len(summaries)}/{len(dialogues)}ê°œ ì™„ë£Œ")
            if self.logger and hasattr(self.logger, 'write_last_progress'):
                self.logger.write_last_progress()
            raise

        self._log(f"\në°°ì¹˜ ìš”ì•½ ì™„ë£Œ: {len(summaries)}ê°œ")

        return summaries


def create_solar_api(
    api_key: Optional[str] = None,
    token_limit: int = 512,
    cache_dir: str = "cache/solar",
    logger=None
) -> SolarAPI:
    """Solar API ìƒì„±"""
    return SolarAPI(api_key, token_limit, cache_dir, logger)
