# ==================== 실험 정보 (Experiment Information) ==================== #
# 실험명: 베이스라인 KoBART 재현
# 목표: 대회 제공 베이스라인 성능 재현 (ROUGE Sum ≥ 94.51)
# 모델: digit82/kobart-summarization
# 전략: 베이스라인 검증된 파라미터만 사용
# ============================================================================ #

experiment:
  name: "baseline_kobart"
  description: "대회 베이스라인 재현 실험"
  seed: 42


# ==================== WandB 설정 (WandB Configuration) ==================== #
wandb:
  enabled: true
  project: "nlp-competition"
  entity: "ieyeppo"
  tags:
    - "baseline"
    - "kobart"
    - "encoder_decoder"


# ==================== 모델 설정 (Model Configuration) ==================== #
model:
  name: "kobart"
  checkpoint: "digit82/kobart-summarization"
  type: "encoder_decoder"
  architecture: "bart"


# ==================== 토크나이저 설정 (Tokenizer Configuration) ==================== #
tokenizer:
  # ---------------------- 시퀀스 길이 제한 ---------------------- #
  encoder_max_len: 512
  decoder_max_len: 100                                  # 베이스라인 호환: 100

  # ---------------------- 특수 토큰 ---------------------- #
  special_tokens:
    # 화자 토큰
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#Person4#'
    - '#Person5#'
    - '#Person6#'
    - '#Person7#'
    # PII 마스킹 토큰
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'


# ==================== 학습 설정 (Training Configuration) ==================== #
training:
  # ---------------------- 기본 파라미터 ---------------------- #
  num_train_epochs: 5
  learning_rate: 2.0e-05
  per_device_train_batch_size: 50
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 1

  # ---------------------- 최적화 설정 ---------------------- #
  optim: "adamw_torch"
  weight_decay: 0.01
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"

  # ---------------------- 혼합 정밀도 학습 ---------------------- #
  fp16: true
  bf16: false
  gradient_checkpointing: false

  # ---------------------- Early Stopping ---------------------- #
  early_stopping_patience: 3
  early_stopping_threshold: 0.001

  # ---------------------- 체크포인트 저장 ---------------------- #
  save_strategy: "epoch"
  save_total_limit: 2
  load_best_model_at_end: true

  # ---------------------- 평가 및 메트릭 ---------------------- #
  evaluation_strategy: "epoch"
  metric_for_best_model: "rouge_sum"
  greater_is_better: true
  predict_with_generate: true


# ==================== 추론 설정 (Inference Configuration) ==================== #
inference:
  # ---------------------- 배치 처리 ---------------------- #
  batch_size: 32

  # ---------------------- 생성 전략 ---------------------- #
  num_beams: 5                                          # 빔 서치 빔 개수 (품질 향상)
  early_stopping: true                                  # 생성 조기 종료

  # ⚠️ 중요: 길이 제어 (max_length 대신 max_new_tokens 사용)
  generate_max_new_tokens: 100                          # 생성할 최대 토큰 수 (최적값: 100, 적정 길이 유지)
  generate_min_new_tokens: 30                           # 생성할 최소 토큰 수 (문장 끊김 방지)
  generate_max_length: 512                              # 전체 최대 길이 (input+output, 여유있게 설정)

  # ---------------------- 반복 방지 ---------------------- #
  no_repeat_ngram_size: 3                               # 반복 방지 n-gram 크기 (최적값: 3)
  repetition_penalty: 1.5                               # 반복 억제 강도 (최적값: 1.5, 적절한 억제)
  length_penalty: 1.0                                   # 길이 페널티 (1.0=중립)

  # ---------------------- 후처리 ---------------------- #
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'


# ==================== 경로 설정 (Path Configuration) ==================== #
paths:
  # ---------------------- 데이터 경로 ---------------------- #
  train_data: "data/train.csv"
  dev_data: "data/dev.csv"
  test_data: "data/test.csv"

  # ---------------------- 출력 경로 ---------------------- #
  output_dir: "outputs/baseline_kobart"
  model_save_dir: "models/baseline_kobart"
  submission_dir: "submissions/baseline_kobart"


# ==================== 로깅 설정 (Logging Configuration) ==================== #
logging:
  log_level: "INFO"
  log_dir: "logs/baseline_kobart"
  logging_steps: 10


# ==================== 전략 활성화 (Strategy Activation) ==================== #
strategies:
  data_augmentation: false
  cross_validation: false
  ensemble: false
  optuna: false


# ==================== 평가 설정 (Evaluation Configuration) ==================== #
evaluation:
  # ---------------------- 평가 메트릭 ---------------------- #
  metric: "rouge"

  # ---------------------- ROUGE 설정 ---------------------- #
  rouge_types:
    - "rouge1"
    - "rouge2"
    - "rougeL"

  # ---------------------- 토크나이저 ---------------------- #
  use_stemmer: false
  tokenizer: "mecab"


# ==================== 디버깅 설정 (Debug Configuration) ==================== #
debug:
  # ---------------------- 샘플링 ---------------------- #
  use_subset: false
  subset_size: 100

  # ---------------------- 출력 ---------------------- #
  print_sample_predictions: true
  num_samples_to_print: 5


# ============================================================================ #
# 사용 방법 (Usage)
# ============================================================================ #
# 1. 기본 실행:
#    python train.py --config configs/examples/baseline_kobart.yaml
#
# 2. 파라미터 오버라이드:
#    python train.py --config configs/examples/baseline_kobart.yaml \
#        --override training.learning_rate=2e-5 training.num_train_epochs=15
#
# 3. 디버그 모드:
#    python train.py --config configs/examples/baseline_kobart.yaml \
#        --override debug.use_subset=true
# ============================================================================ #


# ============================================================================ #
# 예상 성능 (Expected Performance)
# ============================================================================ #
# ROUGE-1 F1: ~52.0
# ROUGE-2 F1: ~26.5
# ROUGE-L F1: ~47.0
# ROUGE Sum: ~94.5
#
# 학습 시간: ~2-3시간 (RTX 3090 기준)
# GPU 메모리: ~8GB
# ============================================================================ #


# ============================================================================ #
# 주의사항 (Important Notes)
# ============================================================================ #
# 1. 배치 크기 조정:
#    - per_device_train_batch_size=50은 16GB GPU 기준
#    - 메모리 부족 시: 32 또는 16으로 감소
#    - gradient_accumulation_steps로 effective batch size 유지
#
# 2. 토큰 제거 방식:
#    - 반드시 공백으로 치환: summary.replace(token, " ")
#    - 빈 문자열로 치환 금지: summary.replace(token, "")
#
# 3. Learning Rate:
#    - KoBART 최적값: 1e-5
#    - 5e-5 이상 사용 금지
#
# 4. no_repeat_ngram_size:
#    - 베이스라인 최적값: 2
#    - 3 이상 사용 시 요약이 너무 짧아질 수 있음
# ============================================================================ #
