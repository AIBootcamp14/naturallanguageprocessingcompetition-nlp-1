# Prompt v3.0 Story-Aware 업그레이드

## 문제점

### test_28 케이스 분석 (심각한 오류)

**원본 대화** (580자):
```
#Person1#: 바보 같은 여자애 때문에 돈이 이렇게 많이 필요할 줄이야. 이제 ATM에서 돈을 찾아야겠네...
#Person2#: 안녕하세요, 유니버설 은행입니다. 카드를 슬롯에 넣어 주세요.
#Person1#: 카드 넣는 것 정도는 알아, 이 멍청한 기계가 나를 바보로 만드네...
#Person2#: 6자리 비밀번호를 입력하고 우물 정자를 눌러 주세요. 감사합니다. 옵션을 선택해 주세요.
#Person1#: 빨리 처리해, 돈 좀 주라고!
#Person2#: 인출할 금액을 입력해 주세요. 감사합니다. 세계 야생동물 재단으로 10000달러를 이체하고 싶으시면 1번을 눌러 주세요.
#Person1#: 아니, 아니! 이건 아니야! 멍청한 기계, 무슨 짓이야! 그러지 마!
#Person2#: 확인되었습니다. 저희 은행을 이용해 주셔서 감사합니다! 카드를 제거해 주세요. 안녕히 가세요!
#Person1#: 아니, 이게 뭐야! 내 돈 돌려줘!
#Person2#: 위험, 위험! 출입구가 봉쇄되었으며 지역 당국이 도착할 때까지 문이 잠긴 상태로 유지됩니다. 저희 은행을 이용해 주셔서 감사합니다. 좋은 하루 보내세요.
```

**기존 요약** (30자 - v2.0_power_dynamics):
```
고객이 ATM 기계 오작동으로 인해 은행 직원과 대화하며 돈 인출 문제를 겪음
```

**문제점**:
1. ❌ **화자 오인**: ATM 자동 응답 시스템을 "은행 직원"으로 잘못 판단
2. ❌ **핵심 사건 누락**:
   - 실수로 1만 달러 송금 → 누락
   - 취소 시도 실패 → 누락
   - 보안 시스템 발동으로 출입구 봉쇄 → 누락
3. ❌ **길이 부족**: 580자 원본을 30자로 압축 (5% 수준) - 스토리 전개 불가능

**올바른 요약** (120자):
```
한 고객이 ATM을 사용하다가 실수로 세계 야생동물 재단에 1만 달러를 송금하게 된다.
고객은 당황하며 취소를 시도하지만, ATM은 자동 처리 후 '감사합니다'라는 응답만 반복한다.
이어 보안 절차가 발동되어 출입구가 봉쇄되고, 지역 당국이 도착할 때까지 문이 잠긴 상태로 유지된다는 경고가 나온다.
결국 고객은 돈을 잃고 기계에 갇힌 채 분노한다.
```

### 전반적 문제 분석

#### 1. 추론 길이 문제
- **평균 요약 길이**: 52.1자 (너무 짧음)
- **원인**:
  - `max_new_tokens=80` → 실제 출력 50-60자
  - `length_penalty=0.8` → 짧은 출력 선호
  - 프롬프트에 "1-2문장" 고정 지시 → 복잡도 무시

#### 2. 화자 명칭 오류
- **일반 명칭 사용**: "친구 A", "친구 B" 같은 플레이스홀더 여전히 출현
- **비인간 화자 오인**: ATM, 자동 응답 시스템을 사람(직원/상담사)으로 판단
- **역할 오판**: 반말 대화를 "고객-상담사" 관계로 잘못 분류

#### 3. 스토리 구조 미파악
- 시작-문제-시도-결과 4단계 구조 누락
- 핵심 사건 선별 실패
- 시간 순서 전개 무시

---

## 해결 방안

### Prompt v3.0: Story-Aware Architecture

#### 새로운 5단계 분석 체계

**STEP 0: 대화 상대 유형 판별** (최우선!)
- 사람 vs 자동 시스템 구분
- ATM, IVR, 챗봇 등 기계적 응답 감지
- 특징: 맥락 무시, 기계적 반복, 감정 없음

**STEP 1: 역할 구조 분석** (Power Dynamics)
- 기존 방식 유지
- 상하 관계, 수평 관계, 가족 관계 분석

**STEP 2: 말투 분석**
- 기존 방식 유지
- 반말/존댓말 감지

**STEP 3: 명시된 이름/호칭 확인**
- 기존 방식 유지
- 고유명사 우선 사용

**STEP 4: 대화 내용 키워드 분석**
- 기존 방식 유지
- 업무/의료/교육/일상/가족 분류

**STEP 5: 감정 및 성격 분석** (신규!)
- 감정 상태: 분노/당황/기쁨/불안
- 성격 특징: 급함/꼼꼼함/친절/무례
- 명칭에 반영: "당황한 고객", "화난 사용자"

#### 스토리 구조 분석 추가 (Section 3)

**단순 대화** (50-80자, 1-2문장):
- 정보 교환
- 간단한 요청-응답
- 일상 대화

**스토리형 대화** (100-150자, 2-4문장):
- **[1] 시작/배경**: 상황 소개
- **[2] 문제/갈등**: 사고/오류 발생
- **[3] 시도/반응**: 해결 시도
- **[4] 결과/결말**: 최종 결과

⚠️ 중요: 스토리형 대화를 1-2문장으로 압축하면 핵심 사건이 누락됨!

#### 적응형 길이 제한 (Section 7)

**기존**:
```
원본 대화의 30-50% 길이로 요약
1-2문장으로 압축
```

**v3.0**:
```
- 단순 대화: 원본의 30-50% (50-80자, 1-2문장)
- 복잡한 스토리: 원본의 50-70% (100-150자, 2-4문장)
```

#### 금지 사항 강화 (Section 6)

추가된 항목:
- ❌ ATM/자동 시스템을 사람(직원/상담사)으로 표현 금지!
- ❌ 스토리형 대화를 1-2문장으로 과도하게 압축하여 핵심 사건 누락 금지

#### 품질 검증 체크리스트 강화 (Section 8)

추가된 항목:
- [ ] STEP 0: 기계/자동 시스템을 사람으로 착각하지 않았는가?
- [ ] 스토리형 대화의 핵심 사건(시작-문제-시도-결과)이 모두 포함되었는가?
- [ ] 길이가 대화 복잡도에 적절한가? (단순: 50-80자, 복잡: 100-150자)

---

## 추론 파라미터 조정

### 기존 파라미터
```bash
--max_new_tokens 80      # → 실제 출력 50-60자
--min_new_tokens 20
--length_penalty 0.8     # 짧은 출력 선호
--repetition_penalty 1.5
```

### v3.0 권장 파라미터
```bash
--max_new_tokens 120     # 스토리형 대화 지원 (100-150자)
--min_new_tokens 40      # 최소 길이 확보
--length_penalty 0.9     # 중립적 길이 선호
--repetition_penalty 1.3 # 반복 억제 완화
--num_beams 6            # 유지
--no_repeat_ngram_size 3 # 유지
--batch_size 16          # 유지
```

---

## 캐시 무효화

### 캐시 키 업데이트
```python
# src/api/solar_api.py:467
PROMPT_VERSION = "v3.0_story_aware"  # was v2.0_power_dynamics
cache_key_string = f"{PROMPT_VERSION}_{dialogue}"
```

### 영향
- 기존 v2.0 캐시는 자동 무효화됨
- 모든 요약이 v3.0 프롬프트로 재생성됨
- Solar API 실행 시간: 정상 10-15분 예상 (캐시 미적용)

---

## 개선된 상태 (예상)

### test_28 예상 결과
```
한 고객이 ATM 사용 중 실수로 야생동물 재단에 1만 달러를 송금하게 되고,
취소를 시도하지만 ATM은 자동 응답만 반복한다.
이후 보안 절차가 발동되어 출입구가 봉쇄되고, 고객은 돈을 잃고 기계에 갇힌 채로 남는다.
```
(120자, 3문장, 4단계 스토리 구조 완비)

### 전반적 개선 목표
1. **평균 요약 길이**: 52.1자 → 80-100자
2. **ATM/자동 시스템 정확도**: 0% → 100%
3. **스토리 구조 완성도**: 낮음 → 높음 (4단계 포함)
4. **플레이스홀더 사용**: 존재 → 0건

### 추론 명령어 (v3.0)
```bash
python scripts/kfold_ensemble_inference.py \
  --experiment_dir experiments/20251014/20251014_183206_kobart_ultimate_kfold \
  --test_data data/raw/test.csv \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --max_new_tokens 120 \
  --min_new_tokens 40 \
  --length_penalty 0.9 \
  --repetition_penalty 1.3 \
  --num_beams 6 \
  --no_repeat_ngram_size 3 \
  --batch_size 16
```

---

## Phase 2: Solar API Multi-Sampling (✅ 구현 완료!)

### Self-Consistency 기법 구현
```python
# src/api/solar_api.py

def summarize_with_voting(
    self,
    dialogue: str,
    n_samples: int = 3,
    temperature: float = 0.3,
    top_p: float = 0.5
) -> str:
    """K-Fold 방식 다중 샘플링 요약"""

    # N회 샘플링
    summaries = []
    scores = []

    for i in range(n_samples):
        # 요약 생성
        response = self.client.chat.completions.create(...)
        summary = response.choices[0].message.content.strip()
        summaries.append(summary)

        # 품질 평가
        score = self.evaluate_summary_quality(summary, dialogue)
        scores.append(score)

    # 최고 점수 요약 선택
    best_idx = scores.index(max(scores))
    return summaries[best_idx]
```

### 품질 평가 기준 (evaluate_summary_quality)
1. **플레이스홀더 미사용** (+30점)
   - A/B/C/D, #Person1#, "친구 A" 등 감지

2. **적절한 길이** (+20점)
   - 단순: 50-80자 (만점)
   - 복잡: 100-150자 (만점)
   - 중간: 80-100자 (15점)
   - 너무 짧음: <50자 (5점)
   - 너무 김: >150자 (10점)
   - 원본보다 김: -20점 페널티

3. **화자 역할 정확도** (+20점)
   - 반말 대화에 업무 명칭(고객/상담사) 사용 시 감점
   - 업무 맥락 존재 여부 확인

4. **스토리 구조 완성도** (+20점)
   - 복잡한 스토리(400자+): 3문장 이상 (만점)
   - 단순 대화: 1-2문장 (만점)

5. **핵심 사건 포함도** (+10점)
   - 금액, ATM, 예약, 진료 등 중요 키워드 매칭
   - 키워드당 +3점 (최대 10점)

### 사용 방법

**명령어**:
```bash
python scripts/kfold_ensemble_inference.py \
  --experiment_dir experiments/20251014/20251014_183206_kobart_ultimate_kfold \
  --test_data data/raw/test.csv \
  --use_solar_api \
  --solar_model solar-1-mini-chat \
  --solar_use_voting \           # ✅ K-Fold 방식 활성화
  --solar_n_samples 3 \           # ✅ 샘플링 횟수
  --max_new_tokens 120 \
  --min_new_tokens 40 \
  --length_penalty 0.9 \
  --repetition_penalty 1.3 \
  --num_beams 6 \
  --no_repeat_ngram_size 3 \
  --batch_size 16
```

### 예상 효과
- ✅ 품질 안정성 향상 (표준편차 감소)
- ✅ test_28 같은 복잡한 케이스 정확도 향상
- ✅ 플레이스홀더 사용 자동 필터링
- ⏱️ 실행 시간: 10분 → 30-40분 (3배 증가, 품질 향상 대가)

### 실제 동작 예시
```
🔄 Solar API 3회 샘플링 시작...
  샘플 1/3: 75.0점 | 친구가 친구에게 대중교통 이용을 제안함...
  샘플 2/3: 85.0점 | 한 사람이 Carrefour 교차로 근처 교통체증으로 지각하자...
  샘플 3/3: 70.0점 | A가 B에게 출퇴근 시간 교통 문제를 상담함...
✅ 최종 선택: 샘플 2 (85.0점)
```

→ 샘플 3은 플레이스홀더(A/B) 사용으로 낮은 점수
→ 샘플 2가 적절한 길이와 정확한 화자 명칭으로 최고 점수

---

## 변경 이력

### v3.0_story_aware (2025-10-15)
- STEP 0: 비인간 화자 감지 추가
- STEP 5: 감정/성격 분석 추가
- Section 3: 스토리 구조 분석 추가 (4단계 프레임워크)
- Section 7: 적응형 길이 제한 (단순/복잡 구분)
- Section 6: 금지 사항 강화 (ATM 오인 방지)
- Section 8: 품질 검증 강화 (3개 항목 추가)
- 캐시 키 업데이트 (v2.0 → v3.0)

### v2.0_power_dynamics (2025-10-14)
- STEP 1: Power Dynamics 분석 추가
- 역할 구조 기반 화자 명칭 결정
- 플레이스홀더 사용 금지 강화

### v1.0 (초기)
- 기본 요약 규칙
- Few-shot learning
