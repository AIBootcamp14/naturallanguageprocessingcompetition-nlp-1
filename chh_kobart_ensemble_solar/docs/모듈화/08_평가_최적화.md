# 평가 및 최적화 시스템 가이드

> **통합 문서:** 평가 시스템 + K-Fold 교차 검증 + Optuna 최적화

## 📋 목차

### Part 1: 평가 시스템
- [개요](#part-1-평가-시스템)
- [RougeCalculator 클래스](#rougecalculator-클래스)
- [사용 방법](#평가-시스템-사용-방법)
- [Multi-reference 지원](#multi-reference-지원)
- [배치 계산](#배치-계산)
- [HuggingFace Trainer 통합](#huggingface-trainer-통합)

### Part 2: K-Fold 교차 검증
- [개요](#part-2-k-fold-교차-검증)
- [KFoldSplitter](#kfoldsplitter)
- [사용 방법](#교차-검증-사용-방법)
- [실행 명령어](#교차-검증-실행-명령어)

### Part 3: Optuna 최적화
- [개요](#part-3-optuna-최적화)
- [OptunaOptimizer 클래스](#optunaoptimizer-클래스)
- [탐색 공간 정의](#탐색-공간-정의)
- [최적화 전략](#최적화-전략)
- [사용 방법](#optuna-사용-방법)
- [실행 명령어](#optuna-실행-명령어)

---

# 📌 Part 1: 평가 시스템

## 📝 개요

### 목적
- ROUGE 점수 자동 계산 (경진대회 평가 기준)
- Multi-reference 평가 지원
- 배치 계산 및 통계 정보 제공
- 학습/평가 시 자동 통합

### 핵심 기능
- ✅ ROUGE-1/2/L F1 점수 계산
- ✅ ROUGE Sum (경진대회 기준) 자동 계산
- ✅ Multi-reference 지원 (정답이 여러 개인 경우)
- ✅ 배치 계산 및 통계 (평균, 표준편차, 최소/최대)
- ✅ HuggingFace Trainer와 자동 통합

---

## 🏗️ RougeCalculator 클래스

### 파일 위치
```
src/evaluation/metrics.py
```

### 클래스 구조

```python
# ==================== RougeCalculator 클래스 정의 ==================== #
class RougeCalculator:
    # ---------------------- ROUGE 계산기 초기화 ---------------------- #
    def __init__(self, rouge_types=['rouge1', 'rouge2', 'rougeL'], use_stemmer=False):
        """ROUGE 계산기 초기화"""

    # ---------------------- 단일 샘플 ROUGE 계산 ---------------------- #
    def calculate_single(self, prediction: str, reference: Union[str, List[str]]) -> Dict:
        """단일 샘플 ROUGE 계산"""

    # ---------------------- 배치 샘플 ROUGE 평균 계산 ---------------------- #
    def calculate_batch(self, predictions: List[str], references: List[str]) -> Dict:
        """배치 샘플 ROUGE 평균 계산"""

    # ---------------------- 빈 입력에 대한 기본 점수 반환 ---------------------- #
    def _empty_scores(self) -> Dict:
        """빈 입력에 대한 기본 점수 반환"""
```

---

## 💻 평가 시스템 사용 방법

### 1. 기본 사용법 (단일 샘플)

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.evaluation import RougeCalculator

# ---------------------- ROUGE 계산기 초기화 ---------------------- #
calculator = RougeCalculator()

# ---------------------- 단일 샘플 평가 ---------------------- #
prediction = "두 사람이 저녁 약속을 잡았다"        # 예측 요약문
reference = "두 사람이 저녁 식사 약속을 정했다"    # 정답 요약문

# ROUGE 점수 계산
scores = calculator.calculate_single(prediction, reference)

# 결과 출력
print(scores)
# 출력:
# {
#     'rouge1': {'precision': 0.75, 'recall': 0.667, 'fmeasure': 0.706},
#     'rouge2': {'precision': 0.5, 'recall': 0.4, 'fmeasure': 0.444},
#     'rougeL': {'precision': 0.75, 'recall': 0.667, 'fmeasure': 0.706}
# }
```

### 2. 편의 함수 사용

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.evaluation import calculate_rouge_scores

# ---------------------- 단일 샘플 평가 ---------------------- #
scores = calculate_rouge_scores(
    predictions="예측 요약",              # 예측 요약문
    references="정답 요약"                # 정답 요약문
)

# ---------------------- 배치 샘플 평가 ---------------------- #
predictions = ["예측1", "예측2", "예측3"]     # 예측 리스트
references = ["정답1", "정답2", "정답3"]      # 정답 리스트

# 배치 ROUGE 점수 계산
scores = calculate_rouge_scores(predictions, references)
```

### 3. 점수 포맷팅

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.evaluation import calculate_rouge_scores, format_rouge_scores

# ---------------------- ROUGE 점수 계산 및 포맷팅 ---------------------- #
# ROUGE 점수 계산
scores = calculate_rouge_scores(predictions, references)

# 포맷팅된 출력
print(format_rouge_scores(scores))

# 출력:
# ROUGE1:
#   fmeasure: 0.7060
#   std: 0.1200
#   min: 0.5500
#   max: 0.8500
#
# ROUGE2:
#   fmeasure: 0.4440
#   ...
```

---

## 🔄 Multi-reference 지원

### 개요

하나의 대화에 대해 여러 개의 정답 요약이 있을 수 있습니다. Multi-reference 평가는 각 정답에 대해 ROUGE를 계산한 후 **최대 F1 점수**를 선택합니다.

### 사용 방법

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.evaluation import RougeCalculator

# ---------------------- ROUGE 계산기 초기화 ---------------------- #
calculator = RougeCalculator()

# ---------------------- Multi-reference 평가 ---------------------- #
# 단일 예측문
prediction = "두 사람이 저녁 약속을 잡았다"

# 다중 정답문 (여러 개의 가능한 정답)
references = [
    "두 사람이 저녁 식사 약속을 정했다",    # 정답 1
    "저녁에 만나기로 했다",               # 정답 2
    "저녁 약속을 잡았다"                  # 정답 3
]

# 최대 F1 점수를 선택하여 계산
scores = calculator.calculate_single(prediction, references)
```

### 처리 과정

1. **각 정답에 대해 ROUGE 계산**
   ```python
   # 모든 정답에 대해 ROUGE 점수 계산
   for ref in references:
       score = scorer.score(prediction, ref)        # 개별 ROUGE 계산
       all_scores.append(score)                     # 점수 리스트에 추가
   ```

2. **최대 F1 점수 선택**
   ```python
   # ROUGE-1 F1 점수가 가장 높은 정답 선택
   max_score = max(all_scores, key=lambda x: x['rouge1'].fmeasure)
   ```

3. **결과 반환**
   ```python
   {
       'rouge1': {'precision': 1.0, 'recall': 1.0, 'fmeasure': 1.0},  # "저녁 약속을 잡았다"와 완전 일치
       'rouge2': {...},
       'rougeL': {...}
   }
   ```

---

## 📊 배치 계산

### 기본 사용법

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.evaluation import RougeCalculator

# ---------------------- ROUGE 계산기 초기화 ---------------------- #
calculator = RougeCalculator()

# ---------------------- 배치 데이터 준비 ---------------------- #
# 예측 요약문 리스트
predictions = [
    "두 사람이 저녁 약속을 잡았다",
    "회의 시간을 3시로 정했다",
    "내일 점심 메뉴는 김치찌개다"
]

# 정답 요약문 리스트
references = [
    "두 사람이 저녁 식사 약속을 정했다",
    "회의를 오후 3시에 하기로 했다",
    "내일 점심은 김치찌개를 먹기로 했다"
]

# ---------------------- 배치 ROUGE 계산 ---------------------- #
# 평균, 표준편차, 최소/최대 점수 계산
scores = calculator.calculate_batch(predictions, references)
```

### 출력 형식

```python
{
    'rouge1': {
        'fmeasure': 0.7060,      # 평균 F1 점수
        'std': 0.1200,           # 표준편차
        'min': 0.5500,           # 최소값
        'max': 0.8500            # 최대값
    },
    'rouge2': {
        'fmeasure': 0.4440,
        'std': 0.0800,
        'min': 0.3000,
        'max': 0.6000
    },
    'rougeL': {
        'fmeasure': 0.7060,
        'std': 0.1200,
        'min': 0.5500,
        'max': 0.8500
    },
    'rouge_sum': {               # ROUGE-1 + ROUGE-2 + ROUGE-L
        'fmeasure': 1.8560,
        'std': 0.0,
        'min': 0.0,
        'max': 0.0
    }
}
```

### ROUGE Sum (경진대회 기준)

경진대회에서는 ROUGE-1, ROUGE-2, ROUGE-L의 F1 점수 합계를 최종 평가 지표로 사용합니다:

```python
rouge_sum = rouge1_f1 + rouge2_f1 + rougeL_f1
# 예: 0.706 + 0.444 + 0.706 = 1.856
```

---

## 🔗 HuggingFace Trainer 통합

### ModelTrainer에서 자동 사용

`src/training/trainer.py`의 `ModelTrainer` 클래스는 자동으로 ROUGE를 계산합니다:

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.training import create_trainer

# ---------------------- Trainer 생성 ---------------------- #
trainer = create_trainer(
    config=config,                          # 설정 파일
    model=model,                            # 학습할 모델
    tokenizer=tokenizer,                    # 토크나이저
    train_dataset=train_dataset,            # 학습 데이터셋
    eval_dataset=eval_dataset               # 평가 데이터셋
)

# ---------------------- 학습 실행 ---------------------- #
# 학습 중 자동으로 ROUGE 계산
results = trainer.train()

# ---------------------- 평가 결과 출력 ---------------------- #
print(results['eval_metrics'])
# {
#     'eval_rouge1': 0.706,
#     'eval_rouge2': 0.444,
#     'eval_rougeL': 0.706,
#     'eval_rouge_sum': 1.856
# }
```

### compute_metrics 함수

Trainer에서 사용하는 평가 함수:

```python
# ---------------------- 평가 메트릭 계산 함수 ---------------------- #
def compute_metrics(self, eval_preds) -> Dict[str, float]:
    """평가 메트릭 계산 (ROUGE)"""
    # -------------- 예측값과 정답 레이블 추출 -------------- #
    predictions, labels = eval_preds

    # -------------- 레이블 전처리 -------------- #
    # -100을 패딩 토큰으로 변경 (손실 계산에서 무시되는 값)
    labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)

    # -------------- 토큰 디코딩 -------------- #
    # 예측 토큰을 텍스트로 변환
    decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # 정답 토큰을 텍스트로 변환
    decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)

    # -------------- ROUGE 점수 계산 -------------- #
    scores = self.rouge_calculator.calculate_batch(
        decoded_preds,              # 예측 텍스트 리스트
        decoded_labels              # 정답 텍스트 리스트
    )

    # -------------- 결과 포맷팅 -------------- #
    result = {
        'rouge1': scores['rouge1']['fmeasure'],             # ROUGE-1 F1
        'rouge2': scores['rouge2']['fmeasure'],             # ROUGE-2 F1
        'rougeL': scores['rougeL']['fmeasure'],             # ROUGE-L F1
        'rouge_sum': scores['rouge_sum']['fmeasure']        # ROUGE Sum
    }

    return result
```

---

# 📌 Part 2: K-Fold 교차 검증

## 📝 개요

### 목적
- K-Fold 교차 검증으로 모델 일반화 성능 평가
- Stratified K-Fold 지원 (층화 추출)
- Fold 결과 집계 및 통계 분석

### 핵심 기능
- ✅ K-Fold 분할
- ✅ Stratified K-Fold 분할 (대화 길이/토픽 기반)
- ✅ Fold 결과 집계
- ✅ 데이터 무결성 보장

---

## 🏗️ KFoldSplitter

### 파일 위치
```
src/validation/kfold.py
```

### 클래스 구조

```python
# ==================== KFoldSplitter 클래스 정의 ==================== #
class KFoldSplitter:
    # ---------------------- 초기화 함수 ---------------------- #
    def __init__(n_splits=5, shuffle=True, random_state=42, stratified=False)

    # ---------------------- 데이터 분할 함수 ---------------------- #
    def split(data, stratify_column=None)
```

### 주요 기능

#### 1. 기본 K-Fold

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.validation.kfold import KFoldSplitter

# ---------------------- K-Fold Splitter 초기화 ---------------------- #
splitter = KFoldSplitter(
    n_splits=5,                     # 5개 fold로 분할
    shuffle=True,                   # 데이터 셔플
    random_state=42                 # 재현성을 위한 시드
)

# ---------------------- 데이터 분할 실행 ---------------------- #
folds = splitter.split(data)
# 결과: [(train_df1, val_df1), (train_df2, val_df2), ...]
```

**특징:**
- 데이터를 K개 fold로 균등 분할
- 각 fold에서 K-1개는 학습, 1개는 검증
- 모든 데이터가 정확히 한 번씩 검증에 사용됨

**예시 (100개 데이터, 5-Fold):**
```
Fold 1: 학습 80개, 검증 20개 (index 0-19)
Fold 2: 학습 80개, 검증 20개 (index 20-39)
Fold 3: 학습 80개, 검증 20개 (index 40-59)
Fold 4: 학습 80개, 검증 20개 (index 60-79)
Fold 5: 학습 80개, 검증 20개 (index 80-99)
```

---

#### 2. Stratified K-Fold (층화 추출)

```python
# ---------------------- Stratified K-Fold Splitter 초기화 ---------------------- #
splitter = KFoldSplitter(
    n_splits=5,                     # 5개 fold로 분할
    shuffle=True,                   # 데이터 셔플
    random_state=42,                # 재현성을 위한 시드
    stratified=True                 # 층화 추출 활성화
)

# ---------------------- 대화 길이 기반 층화 분할 ---------------------- #
# 대화 길이를 4분위로 나누어 각 fold에 균등 분포
folds = splitter.split(data, stratify_column='length')

# ---------------------- 토픽 기반 층화 분할 ---------------------- #
# 각 토픽이 모든 fold에 균등 분포
folds = splitter.split(data, stratify_column='topic')
```

**층화 기준:**

1. **대화 길이 (`stratify_column='length'`)**
   - 대화 길이를 4분위로 나눔
   - 각 fold에 모든 길이 범위의 데이터 고르게 분포

2. **토픽 (`stratify_column='topic'`)**
   - 데이터에 'topic' 컬럼 존재 시
   - 각 fold에 모든 토픽이 균등하게 분포

**효과:**
- 각 fold가 전체 데이터 분포를 대표
- 검증 결과의 안정성 향상

---

## 💻 교차 검증 사용 방법

### 1. 편의 함수 사용 (추천)

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.validation.kfold import create_kfold_splits
import pandas as pd

# ---------------------- 데이터 로드 ---------------------- #
train_df = pd.read_csv("data/raw/train.csv")

# ---------------------- 5-Fold 분할 생성 ---------------------- #
folds = create_kfold_splits(
    data=train_df,                  # 학습 데이터프레임
    n_splits=5,                     # 5개 fold로 분할
    stratified=False                # 기본 K-Fold (층화 안함)
)

# ---------------------- 각 Fold로 학습 및 평가 ---------------------- #
for fold_idx, (train_fold, val_fold) in enumerate(folds):
    # 현재 fold 정보 출력
    print(f"\n=== Fold {fold_idx + 1}/{len(folds)} ===")
    print(f"학습 데이터: {len(train_fold)}개")
    print(f"검증 데이터: {len(val_fold)}개")

    # 모델 학습
    # model.train(train_fold)

    # 모델 평가
    # metrics = model.evaluate(val_fold)
```

---

### 2. 층화 추출 사용

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.validation.kfold import create_kfold_splits

# ---------------------- 대화 길이 기반 층화 K-Fold ---------------------- #
folds = create_kfold_splits(
    data=train_df,                  # 학습 데이터프레임
    n_splits=5,                     # 5개 fold로 분할
    stratified=True,                # 층화 추출 활성화
    stratify_column='length'        # 대화 길이 기반 층화 (자동으로 4분위 계산)
)
```

---

### 3. Fold 결과 집계

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.validation.kfold import aggregate_fold_results

# ---------------------- 각 Fold 평가 결과 수집 ---------------------- #
fold_results = []                       # 모든 fold 결과 저장 리스트

for fold_idx, (train_fold, val_fold) in enumerate(folds):
    # 모델 학습 및 평가
    metrics = {
        'rouge1': 0.85,                 # ROUGE-1 F1 점수
        'rouge2': 0.75,                 # ROUGE-2 F1 점수
        'rougeL': 0.80                  # ROUGE-L F1 점수
    }
    fold_results.append(metrics)        # 결과 리스트에 추가

# ---------------------- Fold 결과 집계 ---------------------- #
# 평균, 표준편차, 최소/최대 계산
aggregated = aggregate_fold_results(fold_results)

# ---------------------- 집계 결과 출력 ---------------------- #
print(f"ROUGE-1: {aggregated['rouge1_mean']:.4f} (±{aggregated['rouge1_std']:.4f})")
print(f"  - Min: {aggregated['rouge1_min']:.4f}")
print(f"  - Max: {aggregated['rouge1_max']:.4f}")
```

**집계 결과:**
```
{
    'rouge1_mean': 0.8600,
    'rouge1_std': 0.0141,
    'rouge1_min': 0.8400,
    'rouge1_max': 0.8800,
    'rouge2_mean': 0.7600,
    'rouge2_std': 0.0141,
    ...
}
```

---

### 4. 전체 교차 검증 파이프라인

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.config import load_config
from src.validation.kfold import create_kfold_splits, aggregate_fold_results
from src.models.model_loader import load_model_and_tokenizer
from src.data.preprocessor import create_dataset
from src.training.trainer import create_trainer
from src.evaluation.metrics import compute_metrics
import pandas as pd

# ==================== 1. Config 로드 ==================== #
config = load_config("baseline_kobart")

# ==================== 2. 데이터 로드 ==================== #
train_df = pd.read_csv(config.data.train_path)

# ==================== 3. K-Fold 분할 ==================== #
folds = create_kfold_splits(
    data=train_df,                  # 학습 데이터프레임
    n_splits=5,                     # 5개 fold로 분할
    stratified=True,                # 층화 추출 활성화
    stratify_column='length'        # 대화 길이 기반 층화
)

# ==================== 4. 각 Fold로 학습 및 평가 ==================== #
fold_results = []                   # 모든 fold 결과 저장

for fold_idx, (train_fold, val_fold) in enumerate(folds):
    # -------------- 현재 Fold 정보 출력 -------------- #
    print(f"\n{'='*60}")
    print(f"Fold {fold_idx + 1}/{len(folds)}")
    print(f"{'='*60}")

    # -------------- 모델 초기화 -------------- #
    model, tokenizer = load_model_and_tokenizer(config)

    # -------------- Dataset 생성 -------------- #
    # 학습 데이터셋 생성
    train_dataset = create_dataset(
        train_fold['dialogue'].tolist(),        # 대화 리스트
        train_fold['summary'].tolist(),         # 요약 리스트
        tokenizer,                              # 토크나이저
        config                                  # 설정
    )

    # 검증 데이터셋 생성
    val_dataset = create_dataset(
        val_fold['dialogue'].tolist(),          # 대화 리스트
        val_fold['summary'].tolist(),           # 요약 리스트
        tokenizer,                              # 토크나이저
        config                                  # 설정
    )

    # -------------- Trainer 생성 -------------- #
    trainer = create_trainer(
        config,                     # 설정
        model,                      # 모델
        tokenizer,                  # 토크나이저
        train_dataset,              # 학습 데이터셋
        val_dataset                 # 검증 데이터셋
    )

    # -------------- 학습 실행 -------------- #
    trainer.train()

    # -------------- 평가 실행 -------------- #
    eval_results = trainer.evaluate()
    fold_results.append(eval_results)           # 결과 저장

# ==================== 5. 결과 집계 ==================== #
aggregated = aggregate_fold_results(fold_results)

# -------------- 최종 결과 출력 -------------- #
print(f"\n{'='*60}")
print("교차 검증 최종 결과")
print(f"{'='*60}")
print(f"ROUGE-1: {aggregated['rouge1_mean']:.4f} (±{aggregated['rouge1_std']:.4f})")
print(f"ROUGE-2: {aggregated['rouge2_mean']:.4f} (±{aggregated['rouge2_std']:.4f})")
print(f"ROUGE-L: {aggregated['rougeL_mean']:.4f} (±{aggregated['rougeL_std']:.4f})")
```

---

## 🔧 교차 검증 실행 명령어

### Config 설정

**파일:** `configs/experiments/baseline_kobart.yaml`

```yaml
# ------------------------- 교차 검증 설정 ------------------------- #
validation:
  use_kfold: true                               # K-Fold 교차 검증 활성화
  n_splits: 5                                   # 5개 fold로 분할
  stratified: true                              # 층화 추출 활성화
  stratify_column: 'length'                     # 대화 길이 기반 층화
```

---

### 학습 스크립트에 통합

교차 검증을 지원하는 학습 스크립트 (예시):

```bash
# K-Fold 교차 검증 실행
# --experiment: 실험 config 이름
# --mode: kfold 모드
# --n_splits: fold 개수
python scripts/train.py --experiment baseline_kobart --mode kfold --n_splits 5
```

---

# 📌 Part 3: Optuna 최적화

## 📝 개요

### 목적
- Bayesian Optimization을 통한 하이퍼파라미터 자동 최적화
- NLP 특화 탐색 공간 정의 (LoRA, Generation 파라미터 등)
- 조기 종료를 통한 효율적 탐색
- ROUGE 점수 기반 최적화

### 핵심 기능
- ✅ TPE (Tree-structured Parzen Estimator) Sampler
- ✅ Median Pruner를 통한 조기 종료
- ✅ 15개 하이퍼파라미터 동시 탐색
- ✅ 최적 파라미터 자동 저장
- ✅ 시각화 지원 (Plotly)

---

## 🔧 OptunaOptimizer 클래스

### 파일 위치
```
src/optimization/optuna_optimizer.py
```

### 클래스 구조

```python
# ==================== OptunaOptimizer 클래스 정의 ==================== #
class OptunaOptimizer:
    # ---------------------- 초기화 함수 ---------------------- #
    def __init__(config, train_dataset, val_dataset, n_trials, ...)

    # ---------------------- 탐색 공간 생성 ---------------------- #
    def create_search_space(trial)

    # ---------------------- 목적 함수 (최적화 대상) ---------------------- #
    def objective(trial)

    # ---------------------- 최적화 실행 ---------------------- #
    def optimize()

    # ---------------------- 최적 파라미터 조회 ---------------------- #
    def get_best_params()

    # ---------------------- 최적 점수 조회 ---------------------- #
    def get_best_value()

    # ---------------------- 결과 저장 ---------------------- #
    def save_results(output_path)

    # ---------------------- 최적화 히스토리 시각화 ---------------------- #
    def plot_optimization_history(output_path)
```

### 초기화

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.optimization import OptunaOptimizer
from src.data import load_and_preprocess_data

# ==================== 데이터 로드 ==================== #
train_df, val_df = load_and_preprocess_data(
    train_path,                     # 학습 데이터 경로
    split_ratio=0.9                 # 학습:검증 = 9:1
)

# ==================== Config 로드 ==================== #
from src.config import ConfigLoader
config_loader = ConfigLoader()
config = config_loader.load("baseline_kobart")

# ==================== 데이터셋 생성 ==================== #
from src.data import DialogueSummarizationDataset

# 학습 데이터셋 생성
train_dataset = DialogueSummarizationDataset(
    train_df['dialogue'].tolist(),      # 대화 리스트
    train_df['summary'].tolist(),       # 요약 리스트
    tokenizer,                          # 토크나이저
    config                              # 설정
)

# 검증 데이터셋 생성
val_dataset = DialogueSummarizationDataset(
    val_df['dialogue'].tolist(),        # 대화 리스트
    val_df['summary'].tolist(),         # 요약 리스트
    tokenizer,                          # 토크나이저
    config                              # 설정
)

# ==================== Optimizer 초기화 ==================== #
optimizer = OptunaOptimizer(
    config=config,                      # 설정 파일
    train_dataset=train_dataset,        # 학습 데이터셋
    val_dataset=val_dataset,            # 검증 데이터셋
    n_trials=50,                        # 50회 시도
    timeout=None,                       # 무제한 시간
    study_name="kobart_optuna",         # Study 이름
    direction="maximize"                # ROUGE 최대화 목표
)
```

---

## 🔍 탐색 공간 정의 (15개 파라미터)

OptunaOptimizer는 **15개의 하이퍼파라미터**를 동시에 최적화합니다.

### 파라미터 요약 테이블

| 카테고리 | 파라미터 | 탐색 범위 | 타입 | 우선순위 |
|---------|---------|----------|------|---------|
| **LoRA** | lora_r | [8, 16, 32, 64] | Categorical | 높음 |
| **LoRA** | lora_alpha | [16, 32, 64, 128] | Categorical | 높음 |
| **LoRA** | lora_dropout | 0.0 ~ 0.2 | Float | 중간 |
| **학습** | learning_rate | 1e-6 ~ 1e-4 (log) | Float | 매우 높음 |
| **학습** | batch_size | [8, 16, 32, 64] | Categorical | 높음 |
| **학습** | num_epochs | 3 ~ 10 | Integer | 높음 |
| **학습** | warmup_ratio | 0.0 ~ 0.2 | Float | 중간 |
| **학습** | weight_decay | 0.0 ~ 0.1 | Float | 중간 |
| **Scheduler** | scheduler_type | [linear, cosine, cosine_with_restarts, polynomial] | Categorical | 중간 |
| **Generation** | temperature | 0.1 ~ 1.0 | Float | 높음 |
| **Generation** | top_p | 0.5 ~ 1.0 | Float | 중간 |
| **Generation** | num_beams | [2, 4, 6, 8] | Categorical | 매우 높음 |
| **Generation** | length_penalty | 0.5 ~ 2.0 | Float | 높음 |
| **Dropout** | hidden_dropout | 0.0 ~ 0.3 | Float | 낮음 |
| **Dropout** | attention_dropout | 0.0 ~ 0.3 | Float | 낮음 |

---

### 1. LoRA 파라미터 (3개)

| 파라미터 | 탐색 범위 | 설명 | 권장값 |
|---------|----------|------|-------|
| lora_r | [8, 16, 32, 64] | LoRA rank (저차원 행렬 크기) | 16 or 32 |
| lora_alpha | [16, 32, 64, 128] | LoRA scaling factor (α/r이 학습 강도 결정) | 32 or 64 |
| lora_dropout | 0.0 ~ 0.2 | LoRA 레이어의 dropout 비율 | 0.05 ~ 0.1 |

**영향:**
- `lora_r`: 클수록 표현력 증가, 메모리/시간 증가
- `lora_alpha`: 클수록 LoRA 가중치 영향 증가
- `lora_dropout`: 과적합 방지

**코드:**
```python
# 파일: src/optimization/optuna_optimizer.py (96-98번 줄)

# ---------------------- LoRA 파라미터 탐색 ---------------------- #
if config.training.use_lora:
    params['lora_r'] = trial.suggest_categorical('lora_r', [8, 16, 32, 64])                      # LoRA rank
    params['lora_alpha'] = trial.suggest_categorical('lora_alpha', [16, 32, 64, 128])            # LoRA scaling
    params['lora_dropout'] = trial.suggest_float('lora_dropout', 0.0, 0.2)                       # LoRA dropout
```

---

### 2. 학습 파라미터 (5개)

| 파라미터 | 탐색 범위 | 설명 | 권장값 |
|---------|----------|------|-------|
| learning_rate | 1e-6 ~ 1e-4 (log scale) | Optimizer 학습률 | 2e-5 ~ 5e-5 |
| batch_size | [8, 16, 32, 64] | 배치 크기 | 16 or 32 |
| num_epochs | 3 ~ 10 | 전체 에포크 수 | 5 ~ 7 |
| warmup_ratio | 0.0 ~ 0.2 | Learning rate warmup 비율 | 0.05 ~ 0.1 |
| weight_decay | 0.0 ~ 0.1 | L2 정규화 강도 | 0.01 ~ 0.05 |

**영향:**
- `learning_rate`: 가장 중요! 너무 크면 발산, 너무 작으면 느림
- `batch_size`: 클수록 안정적이지만 메모리 많이 사용
- `num_epochs`: 많을수록 성능 향상 가능하지만 과적합 위험
- `warmup_ratio`: 초반 학습 안정성
- `weight_decay`: 과적합 방지

**코드:**
```python
# 파일: src/optimization/optuna_optimizer.py (101-105번 줄)

# ---------------------- 학습 파라미터 탐색 ---------------------- #
params['learning_rate'] = trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True)            # 학습률 (로그 스케일)
params['batch_size'] = trial.suggest_categorical('batch_size', [8, 16, 32, 64])                 # 배치 크기
params['num_epochs'] = trial.suggest_int('num_epochs', 3, 10)                                   # 에포크 수
params['warmup_ratio'] = trial.suggest_float('warmup_ratio', 0.0, 0.2)                          # Warmup 비율
params['weight_decay'] = trial.suggest_float('weight_decay', 0.0, 0.1)                          # 가중치 감쇠
```

**log=True의 의미:**
```python
# 로그 스케일 탐색 (균등하게 작은 값 탐색)
# 1e-6, 3e-6, 1e-5, 3e-5, 1e-4 등
# 일반 스케일은 1e-6, 2.5e-5, 5e-5, 7.5e-5, 1e-4 등으로 큰 값에 편향
```

---

### 3. Scheduler 파라미터 (1개)

| 파라미터 | 탐색 범위 | 설명 | 권장값 |
|---------|----------|------|-------|
| scheduler_type | [linear, cosine, cosine_with_restarts, polynomial] | Learning rate scheduler 종류 | cosine |

**Scheduler 종류 비교:**

| Scheduler | 특징 | 수식 | 권장 사용 |
|-----------|------|------|----------|
| `linear` | 선형 감소 | `lr = lr_init × (1 - step/total)` | 짧은 학습 |
| `cosine` | Cosine 곡선 감소 | `lr = lr_min + 0.5 × (lr_init - lr_min) × (1 + cos(π × step/total))` | **일반적 권장** |
| `cosine_with_restarts` | 주기적 재시작 | Cosine + 주기적으로 lr 증가 | 긴 학습, 다양한 최소값 탐색 |
| `polynomial` | 다항식 감소 | `lr = lr_init × (1 - step/total)^power` | 빠른 초반 감소 |

**코드:**
```python
# 파일: src/optimization/optuna_optimizer.py (108-111번 줄)

# ---------------------- Scheduler 파라미터 탐색 ---------------------- #
params['scheduler_type'] = trial.suggest_categorical(
    'scheduler_type',                                       # Learning rate scheduler 종류
    ['linear', 'cosine', 'cosine_with_restarts', 'polynomial']
)
```

**시각화:**
```
Linear:          ╲
                  ╲
                   ╲

Cosine:          ╲
                  ╲___
                     ╲__

Cosine w/ Restarts: ╲  ╱╲  ╱╲
                     ╲╱  ╲╱  ╲

Polynomial:      ╲___
                    ╲__
                      ╲_
```

---

### 4. Generation 파라미터 (4개)

| 파라미터 | 탐색 범위 | 설명 | 권장값 |
|---------|----------|------|-------|
| temperature | 0.1 ~ 1.0 | 생성 확률 분포 평활화 정도 | 0.7 ~ 0.9 |
| top_p | 0.5 ~ 1.0 | Nucleus sampling (상위 p% 누적 확률 토큰만 사용) | 0.9 ~ 0.95 |
| num_beams | [2, 4, 6, 8] | Beam search 빔 개수 | 4 or 6 |
| length_penalty | 0.5 ~ 2.0 | 생성 길이 패널티 (>1: 길게, <1: 짧게) | 1.0 ~ 1.5 |

**영향:**
- `temperature`:
  - 낮음 (0.1): 결정적 생성 (항상 최고 확률 토큰)
  - 높음 (1.0): 다양한 생성 (확률 분포 그대로)
- `top_p`:
  - 낮음 (0.5): 안전하지만 단조로움
  - 높음 (0.95): 다양하지만 불안정
- `num_beams`:
  - 많을수록 품질 향상, 속도 느림
  - 2: 빠름, 8: 느림
- `length_penalty`:
  - <1.0: 짧은 요약 선호
  - >1.0: 긴 요약 선호

**코드:**
```python
# 파일: src/optimization/optuna_optimizer.py (114-117번 줄)

# ---------------------- Generation 파라미터 탐색 ---------------------- #
params['temperature'] = trial.suggest_float('temperature', 0.1, 1.0)                             # 생성 온도
params['top_p'] = trial.suggest_float('top_p', 0.5, 1.0)                                        # Nucleus sampling
params['num_beams'] = trial.suggest_categorical('num_beams', [2, 4, 6, 8])                      # Beam 개수
params['length_penalty'] = trial.suggest_float('length_penalty', 0.5, 2.0)                      # 길이 패널티
```

**예시:**
```python
# Temperature 효과
# temp=0.3: "두 사람이 저녁 식사 약속을 정했다" (항상 동일)
# temp=1.0: "두 사람은 저녁에 만나기로 했다" (다양한 표현)

# Length penalty 효과
# penalty=0.5: "저녁 약속" (매우 짧음)
# penalty=1.0: "두 사람이 저녁 약속을 정했다" (적절)
# penalty=2.0: "두 사람이 오늘 저녁 식사를 함께 하기로 약속을 정했다" (길음)
```

---

### 5. Dropout 파라미터 (2개)

| 파라미터 | 탐색 범위 | 설명 | 권장값 |
|---------|----------|------|-------|
| hidden_dropout | 0.0 ~ 0.3 | Hidden layer dropout 비율 | 0.1 ~ 0.15 |
| attention_dropout | 0.0 ~ 0.3 | Attention layer dropout 비율 | 0.1 ~ 0.15 |

**영향:**
- 과적합 방지
- 너무 높으면 학습 불안정
- 작은 데이터셋에서 효과적

**코드:**
```python
# 파일: src/optimization/optuna_optimizer.py (121-122번 줄)

# ---------------------- Dropout 파라미터 탐색 ---------------------- #
# 모델이 dropout을 지원하는 경우에만 탐색
if config.model.get('hidden_dropout_prob') is not None:
    params['hidden_dropout'] = trial.suggest_float('hidden_dropout', 0.0, 0.3)                   # Hidden layer dropout
    params['attention_dropout'] = trial.suggest_float('attention_dropout', 0.0, 0.3)             # Attention dropout
```

**Dropout 작동 원리:**
```
입력: [1.0, 2.0, 3.0, 4.0]
dropout=0.2 적용:
→ [1.0, 0.0, 3.0, 4.0]  (20% 확률로 0으로 만듦)
→ [1.25, 0.0, 3.75, 5.0]  (나머지를 1/(1-0.2)배 증폭)
```

---

### 파라미터 우선순위 가이드

최적화 시간이 제한적일 때 탐색 공간 축소 권장:

#### 🔴 필수 (5개) - 항상 최적화
1. `learning_rate` - 가장 중요
2. `num_beams` - 성능에 큰 영향
3. `lora_r` - LoRA 사용 시
4. `lora_alpha` - LoRA 사용 시
5. `batch_size` - 메모리에 따라

#### 🟡 권장 (5개) - 시간 있으면 최적화
6. `temperature` - 생성 품질
7. `num_epochs` - 학습 정도
8. `length_penalty` - 요약 길이
9. `warmup_ratio` - 학습 안정성
10. `scheduler_type` - 학습 곡선

#### 🟢 선택 (5개) - 여유 있으면 최적화
11. `lora_dropout` - 미세 조정
12. `weight_decay` - 정규화
13. `top_p` - 생성 다양성
14. `hidden_dropout` - 과적합 방지
15. `attention_dropout` - 과적합 방지

**빠른 최적화 (5개 파라미터):**
```python
def create_search_space_fast(trial):
    return {
        'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True),
        'num_beams': trial.suggest_categorical('num_beams', [2, 4, 6, 8]),
        'lora_r': trial.suggest_categorical('lora_r', [8, 16, 32, 64]),
        'lora_alpha': trial.suggest_categorical('lora_alpha', [16, 32, 64, 128]),
        'batch_size': trial.suggest_categorical('batch_size', [8, 16, 32, 64])
    }
```

**전체 최적화 (15개 파라미터):**
```python
# src/optimization/optuna_optimizer.py의 create_search_space() 메서드 사용
```

---

## ⚡ 최적화 전략

### 1. Bayesian Optimization (TPE)

**특징:**
- Tree-structured Parzen Estimator
- 이전 trial 결과를 활용하여 다음 탐색 위치 결정
- Random search보다 효율적

**설정:**
```python
# ---------------------- 모듈 임포트 ---------------------- #
from optuna.samplers import TPESampler

# ---------------------- TPE Sampler 생성 ---------------------- #
sampler = TPESampler(seed=42)           # 재현성을 위한 시드 설정
```

---

### 2. Median Pruner (조기 종료)

**특징:**
- 중간 결과가 median보다 낮으면 trial 종료
- 리소스 절약 (불필요한 trial 조기 중단)

**설정:**
```python
# ---------------------- 모듈 임포트 ---------------------- #
from optuna.pruners import MedianPruner

# ---------------------- Median Pruner 생성 ---------------------- #
pruner = MedianPruner(
    n_startup_trials=5,                 # 처음 5개 trial은 pruning 안함
    n_warmup_steps=3,                   # 3 에포크 후부터 체크 시작
    interval_steps=1                    # 매 에포크마다 체크
)
```

**동작 방식:**
```
Trial 0: [에포크1: 0.30] [에포크2: 0.32] [에포크3: 0.35] → 계속
Trial 1: [에포크1: 0.28] [에포크2: 0.29] [에포크3: 0.30] → 계속
Trial 2: [에포크1: 0.25] [에포크2: 0.26] [에포크3: 0.27] → Pruned! (median=0.32보다 낮음)
```

---

### 3. 목적 함수 (Objective Function)

**목표:** ROUGE-L F1 점수 최대화

**흐름:**
1. Trial에서 하이퍼파라미터 샘플링
2. Config 업데이트
3. 모델 로드 및 학습
4. 검증 데이터 평가
5. ROUGE-L F1 반환

**코드:**
```python
# ---------------------- 목적 함수 정의 ---------------------- #
def objective(self, trial: optuna.Trial) -> float:
    # -------------- 1. 하이퍼파라미터 샘플링 -------------- #
    params = self.create_search_space(trial)

    # -------------- 2. Config 업데이트 -------------- #
    config.training.learning_rate = params['learning_rate']         # 학습률 적용
    config.training.batch_size = params['batch_size']               # 배치 크기 적용
    # ... 기타 파라미터 업데이트

    # -------------- 3. 모델 학습 -------------- #
    # 모델 로드
    model_loader = ModelLoader(config)
    model, tokenizer = model_loader.load()

    # Trainer 생성 및 학습 실행
    trainer = ModelTrainer(...)
    trainer.train()

    # -------------- 4. 평가 -------------- #
    metrics = trainer.evaluate()                                    # 검증 데이터 평가
    rouge_l_f1 = metrics['rouge_l_f1']                              # ROUGE-L F1 추출

    # -------------- 5. Pruning 체크 -------------- #
    trial.report(rouge_l_f1, step=config.training.num_epochs)       # 중간 결과 보고
    if trial.should_prune():                                        # Pruning 조건 확인
        raise optuna.TrialPruned()                                  # Trial 조기 종료

    return rouge_l_f1                                               # 최종 점수 반환
```

---

## 💻 Optuna 사용 방법

### 1. 기본 최적화

```python
# ---------------------- 모듈 임포트 ---------------------- #
from src.optimization import OptunaOptimizer
from src.config import ConfigLoader
from src.data import load_and_preprocess_data, DialogueSummarizationDataset

# ==================== Config 로드 ==================== #
config_loader = ConfigLoader()
config = config_loader.load("baseline_kobart")

# ==================== 데이터 로드 ==================== #
train_df, val_df = load_and_preprocess_data(
    "data/raw/train.csv",               # 학습 데이터 경로
    split_ratio=0.9                     # 학습:검증 = 9:1
)

# ==================== 토크나이저 로드 ==================== #
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(config.model.name)

# ==================== 데이터셋 생성 ==================== #
# 학습 데이터셋 생성
train_dataset = DialogueSummarizationDataset(
    train_df['dialogue'].tolist(),      # 대화 리스트
    train_df['summary'].tolist(),       # 요약 리스트
    tokenizer,                          # 토크나이저
    config                              # 설정
)

# 검증 데이터셋 생성
val_dataset = DialogueSummarizationDataset(
    val_df['dialogue'].tolist(),        # 대화 리스트
    val_df['summary'].tolist(),         # 요약 리스트
    tokenizer,                          # 토크나이저
    config                              # 설정
)

# ==================== Optimizer 초기화 ==================== #
optimizer = OptunaOptimizer(
    config=config,                      # 설정 파일
    train_dataset=train_dataset,        # 학습 데이터셋
    val_dataset=val_dataset,            # 검증 데이터셋
    n_trials=50                         # 50회 시도
)

# ==================== 최적화 실행 ==================== #
study = optimizer.optimize()

# ==================== 최적 파라미터 확인 ==================== #
best_params = optimizer.get_best_params()       # 최적 파라미터 조회
best_value = optimizer.get_best_value()         # 최적 점수 조회

# 결과 출력
print(f"최적 ROUGE-L F1: {best_value:.4f}")
print(f"최적 파라미터: {best_params}")
```

---

### 2. 결과 저장

```python
# ---------------------- 결과 저장 ---------------------- #
optimizer.save_results("outputs/optuna_results")

# 저장되는 파일:
# - outputs/optuna_results/best_params.json    : 최적 파라미터
# - outputs/optuna_results/all_trials.csv      : 모든 trial 결과
# - outputs/optuna_results/study_stats.json    : Study 통계
```

**best_params.json 예시:**
```json
{
  "best_params": {
    "learning_rate": 3.5e-05,           // 최적 학습률
    "batch_size": 32,                   // 최적 배치 크기
    "num_epochs": 5,                    // 최적 에포크 수
    "lora_r": 16,                       // 최적 LoRA rank
    "lora_alpha": 32,                   // 최적 LoRA alpha
    "temperature": 0.8,                 // 최적 생성 온도
    "num_beams": 6                      // 최적 beam 개수
  },
  "best_value": 0.4521,                 // 최적 ROUGE-L F1 점수
  "n_trials": 50                        // 총 trial 수
}
```

---

## 🔧 Optuna 실행 명령어

### Optuna 최적화 스크립트 (예시)

**참고:** Optuna 최적화는 `scripts/train.py --mode optuna`로 실행됩니다.

```python
# ---------------------- 모듈 임포트 ---------------------- #
import argparse
from pathlib import Path

from src.config import ConfigLoader
from src.data import load_and_preprocess_data, DialogueSummarizationDataset
from src.optimization import OptunaOptimizer
from transformers import AutoTokenizer


# ==================== 메인 함수 ==================== #
def main():
    # -------------- 명령줄 인자 파싱 -------------- #
    parser = argparse.ArgumentParser()
    parser.add_argument("--experiment", default="baseline_kobart", help="실험 config 이름")
    parser.add_argument("--n_trials", type=int, default=50, help="Trial 횟수")
    parser.add_argument("--timeout", type=int, default=None, help="최대 실행 시간 (초)")
    parser.add_argument("--output_dir", default="outputs/optuna_results", help="결과 저장 경로")
    args = parser.parse_args()

    # -------------- Config 로드 -------------- #
    config_loader = ConfigLoader()
    config = config_loader.load(args.experiment)

    # -------------- 데이터 로드 -------------- #
    train_df, val_df = load_and_preprocess_data(
        "data/raw/train.csv",               # 학습 데이터 경로
        split_ratio=0.9                     # 학습:검증 = 9:1
    )

    # -------------- 토크나이저 로드 -------------- #
    tokenizer = AutoTokenizer.from_pretrained(config.model.name)

    # -------------- 데이터셋 생성 -------------- #
    # 학습 데이터셋 생성
    train_dataset = DialogueSummarizationDataset(
        train_df['dialogue'].tolist(),      # 대화 리스트
        train_df['summary'].tolist(),       # 요약 리스트
        tokenizer,                          # 토크나이저
        config                              # 설정
    )

    # 검증 데이터셋 생성
    val_dataset = DialogueSummarizationDataset(
        val_df['dialogue'].tolist(),        # 대화 리스트
        val_df['summary'].tolist(),         # 요약 리스트
        tokenizer,                          # 토크나이저
        config                              # 설정
    )

    # -------------- Optimizer 초기화 -------------- #
    optimizer = OptunaOptimizer(
        config=config,                              # 설정 파일
        train_dataset=train_dataset,                # 학습 데이터셋
        val_dataset=val_dataset,                    # 검증 데이터셋
        n_trials=args.n_trials,                     # Trial 횟수
        timeout=args.timeout,                       # 최대 실행 시간
        study_name=f"optuna_{args.experiment}"      # Study 이름
    )

    # -------------- 최적화 실행 -------------- #
    study = optimizer.optimize()

    # -------------- 결과 저장 -------------- #
    optimizer.save_results(args.output_dir)

    # -------------- 시각화 -------------- #
    try:
        optimizer.plot_optimization_history(args.output_dir)
    except ImportError:
        print("plotly가 설치되지 않아 시각화를 건너뜁니다")

    # -------------- 최종 결과 출력 -------------- #
    print(f"\n{'='*60}")
    print(f"최적화 완료!")
    print(f"{'='*60}")
    print(f"최적 ROUGE-L F1: {optimizer.get_best_value():.4f}")
    print(f"결과 저장: {args.output_dir}")


# ==================== 메인 실행부 ==================== #
if __name__ == "__main__":
    main()
```

**실행:**
```bash
# ---------------------- 기본 실행 (50 trials) ---------------------- #
python scripts/train.py --experiment baseline_kobart --mode optuna --n_trials 50

# ---------------------- Trial 횟수 조정 ---------------------- #
python scripts/train.py --experiment baseline_kobart --mode optuna --n_trials 100

# ---------------------- 시간 제한 (12시간 = 43200초) ---------------------- #
python scripts/train.py --experiment baseline_kobart --mode optuna --n_trials 50 --timeout 43200

# ---------------------- 결과 디렉토리 지정 ---------------------- #
python scripts/train.py --experiment baseline_kobart --mode optuna --n_trials 50 --output_dir outputs/kobart_optuna
```

---

## 🔗 관련 파일

**소스 코드:**
- `src/evaluation/metrics.py` - RougeCalculator 클래스
- `src/evaluation/__init__.py` - 외부 API
- `src/validation/kfold.py` - K-Fold 시스템
- `src/validation/__init__.py` - 패키지 초기화
- `src/optimization/optuna_optimizer.py` - Optuna optimizer
- `src/optimization/__init__.py` - 패키지 초기화

**테스트:**
- `src/tests/test_metrics.py` - ROUGE 테스트
- `src/tests/test_kfold.py` - K-Fold 테스트
- `src/tests/test_optuna.py` - Optuna 테스트

**통합:**
- `src/training/trainer.py` - Trainer에서 자동 사용

**관련 문서:**
- [01_시작_가이드.md](./01_시작_가이드.md) - 빠른 시작 가이드
- [02_핵심_시스템.md](./02_핵심_시스템.md) - 핵심 시스템 및 Config
- [06_데이터_파이프라인.md](./06_데이터_파이프라인.md) - 데이터 처리 및 증강
- [07_모델_학습_추론.md](./07_모델_학습_추론.md) - 모델 시스템
- [04_명령어_옵션_완전_가이드.md](./04_명령어_옵션_완전_가이드.md) - 전체 명령어 가이드

**Config:**
- `configs/base/default.yaml` - 기본 하이퍼파라미터
- `configs/experiments/*.yaml` - 실험별 Config
