{
  "best_global_step": 5607,
  "best_metric": 1.2381770745079073,
  "best_model_checkpoint": "experiments/20251015/20251015_013734_kobart_balanced_kfold/fold_4/kfold/checkpoint-5607",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 5607,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.045368671417236,
      "learning_rate": 1.80972e-05,
      "loss": 2.0552,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 3.914649248123169,
      "learning_rate": 3.63772e-05,
      "loss": 1.6244,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.771638870239258,
      "learning_rate": 5.4657199999999996e-05,
      "loss": 1.5388,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.7084696292877197,
      "learning_rate": 7.29372e-05,
      "loss": 1.5167,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.680605173110962,
      "learning_rate": 9.12172e-05,
      "loss": 1.5057,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.370373487472534,
      "learning_rate": 8.982083769633509e-05,
      "loss": 1.5084,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4120222330093384,
      "eval_rouge1": 0.40621156876806036,
      "eval_rouge2": 0.2516726494962852,
      "eval_rougeL": 0.3969823585800422,
      "eval_rouge_sum": 1.054866576844388,
      "eval_runtime": 428.2494,
      "eval_samples_per_second": 5.817,
      "eval_steps_per_second": 0.364,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 2.9061245918273926,
      "learning_rate": 8.82257242582897e-05,
      "loss": 1.2643,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 2.8720526695251465,
      "learning_rate": 8.663061082024434e-05,
      "loss": 1.2108,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.2856028079986572,
      "learning_rate": 8.503549738219895e-05,
      "loss": 1.2259,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.2307016849517822,
      "learning_rate": 8.344038394415358e-05,
      "loss": 1.2225,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 4.339393138885498,
      "learning_rate": 8.18452705061082e-05,
      "loss": 1.2274,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.2222089767456055,
      "learning_rate": 8.025015706806283e-05,
      "loss": 1.2502,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3556207418441772,
      "eval_rouge1": 0.43626494593414955,
      "eval_rouge2": 0.27614112774788574,
      "eval_rougeL": 0.4251703220649811,
      "eval_rouge_sum": 1.1375763957470164,
      "eval_runtime": 437.0085,
      "eval_samples_per_second": 5.7,
      "eval_steps_per_second": 0.357,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 6.381958484649658,
      "learning_rate": 7.865504363001744e-05,
      "loss": 1.0131,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 3.0905191898345947,
      "learning_rate": 7.705993019197208e-05,
      "loss": 0.8751,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.117363214492798,
      "learning_rate": 7.546481675392669e-05,
      "loss": 0.8704,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 2.6971137523651123,
      "learning_rate": 7.386970331588133e-05,
      "loss": 0.8799,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.3255255222320557,
      "learning_rate": 7.227458987783596e-05,
      "loss": 0.9047,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.6186118125915527,
      "learning_rate": 7.067947643979058e-05,
      "loss": 0.9002,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.4022278785705566,
      "eval_rouge1": 0.45275010325836407,
      "eval_rouge2": 0.2867816082766875,
      "eval_rougeL": 0.4416817994991297,
      "eval_rouge_sum": 1.1812135110341813,
      "eval_runtime": 433.9151,
      "eval_samples_per_second": 5.741,
      "eval_steps_per_second": 0.36,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 3.435472011566162,
      "learning_rate": 6.90843630017452e-05,
      "loss": 0.8215,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.0562918186187744,
      "learning_rate": 6.748924956369983e-05,
      "loss": 0.5981,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 2.9181621074676514,
      "learning_rate": 6.589413612565445e-05,
      "loss": 0.6136,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 2.9622983932495117,
      "learning_rate": 6.429902268760908e-05,
      "loss": 0.6383,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 2.7642014026641846,
      "learning_rate": 6.27039092495637e-05,
      "loss": 0.6449,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.2186222076416016,
      "learning_rate": 6.110879581151833e-05,
      "loss": 0.6594,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.496817708015442,
      "eval_rouge1": 0.45161320251340087,
      "eval_rouge2": 0.287436066292487,
      "eval_rougeL": 0.43951931437975394,
      "eval_rouge_sum": 1.1785685831856418,
      "eval_runtime": 434.5901,
      "eval_samples_per_second": 5.732,
      "eval_steps_per_second": 0.359,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.4484989643096924,
      "learning_rate": 5.9513682373472944e-05,
      "loss": 0.6369,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 2.908137559890747,
      "learning_rate": 5.7918568935427575e-05,
      "loss": 0.4161,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 2.848815679550171,
      "learning_rate": 5.63234554973822e-05,
      "loss": 0.4361,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 3.0774011611938477,
      "learning_rate": 5.4728342059336824e-05,
      "loss": 0.4441,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 2.8623311519622803,
      "learning_rate": 5.313322862129145e-05,
      "loss": 0.4478,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.054884910583496,
      "learning_rate": 5.153811518324607e-05,
      "loss": 0.4602,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 2.962921142578125,
      "learning_rate": 4.99430017452007e-05,
      "loss": 0.4569,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.5977274179458618,
      "eval_rouge1": 0.47036841786423983,
      "eval_rouge2": 0.3006210994188213,
      "eval_rougeL": 0.4578951070304753,
      "eval_rouge_sum": 1.2288846243135365,
      "eval_runtime": 430.186,
      "eval_samples_per_second": 5.791,
      "eval_steps_per_second": 0.363,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.41440486907959,
      "learning_rate": 4.834788830715533e-05,
      "loss": 0.3138,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 2.7346253395080566,
      "learning_rate": 4.6752774869109946e-05,
      "loss": 0.3,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 2.834183692932129,
      "learning_rate": 4.515766143106457e-05,
      "loss": 0.3106,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 2.555375099182129,
      "learning_rate": 4.3562547993019195e-05,
      "loss": 0.3123,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 2.9856479167938232,
      "learning_rate": 4.196743455497382e-05,
      "loss": 0.3189,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 3.010514974594116,
      "learning_rate": 4.0372321116928443e-05,
      "loss": 0.314,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.6716500520706177,
      "eval_rouge1": 0.46510369955908515,
      "eval_rouge2": 0.296242755081081,
      "eval_rougeL": 0.4532575339188224,
      "eval_rouge_sum": 1.2146039885589885,
      "eval_runtime": 426.7274,
      "eval_samples_per_second": 5.837,
      "eval_steps_per_second": 0.366,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 1.986413836479187,
      "learning_rate": 3.877720767888307e-05,
      "loss": 0.2454,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 1.9647530317306519,
      "learning_rate": 3.718209424083769e-05,
      "loss": 0.2072,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 2.0606884956359863,
      "learning_rate": 3.558698080279232e-05,
      "loss": 0.2107,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 2.5113232135772705,
      "learning_rate": 3.399186736474694e-05,
      "loss": 0.2152,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 2.2772207260131836,
      "learning_rate": 3.2396753926701566e-05,
      "loss": 0.2209,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 2.0435149669647217,
      "learning_rate": 3.080164048865619e-05,
      "loss": 0.2198,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.7307860851287842,
      "eval_rouge1": 0.4690491920460259,
      "eval_rouge2": 0.3006368668432321,
      "eval_rougeL": 0.45710265027608804,
      "eval_rouge_sum": 1.226788709165346,
      "eval_runtime": 423.3543,
      "eval_samples_per_second": 5.884,
      "eval_steps_per_second": 0.368,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 1.9160505533218384,
      "learning_rate": 2.9206527050610818e-05,
      "loss": 0.1885,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 2.179718494415283,
      "learning_rate": 2.7611413612565442e-05,
      "loss": 0.1455,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.08005428314209,
      "learning_rate": 2.6016300174520067e-05,
      "loss": 0.1498,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 1.9696879386901855,
      "learning_rate": 2.442118673647469e-05,
      "loss": 0.1525,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 2.186988592147827,
      "learning_rate": 2.282607329842932e-05,
      "loss": 0.1489,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 2.114725112915039,
      "learning_rate": 2.1230959860383943e-05,
      "loss": 0.1518,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.7888641357421875,
      "eval_rouge1": 0.47098083394935913,
      "eval_rouge2": 0.3010231322864327,
      "eval_rougeL": 0.45689377577354423,
      "eval_rouge_sum": 1.228897742009336,
      "eval_runtime": 402.7433,
      "eval_samples_per_second": 6.185,
      "eval_steps_per_second": 0.387,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 1.47307288646698,
      "learning_rate": 1.963584642233857e-05,
      "loss": 0.1456,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 1.5466364622116089,
      "learning_rate": 1.8040732984293196e-05,
      "loss": 0.1043,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 2.0509796142578125,
      "learning_rate": 1.644561954624782e-05,
      "loss": 0.1038,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 1.8776121139526367,
      "learning_rate": 1.4850506108202444e-05,
      "loss": 0.1075,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 1.7763476371765137,
      "learning_rate": 1.3255392670157069e-05,
      "loss": 0.1056,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 1.9077787399291992,
      "learning_rate": 1.1660279232111693e-05,
      "loss": 0.1062,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 1.7809641361236572,
      "learning_rate": 1.0065165794066318e-05,
      "loss": 0.1067,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.8369140625,
      "eval_rouge1": 0.47515951284314806,
      "eval_rouge2": 0.3018421587323041,
      "eval_rougeL": 0.4611754029324552,
      "eval_rouge_sum": 1.2381770745079073,
      "eval_runtime": 406.4207,
      "eval_samples_per_second": 6.129,
      "eval_steps_per_second": 0.384,
      "step": 5607
    }
  ],
  "logging_steps": 100,
  "max_steps": 6230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.734485094268928e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
