{
  "best_global_step": 5607,
  "best_metric": 1.2076671584951582,
  "best_model_checkpoint": "experiments/20251015/20251015_013734_kobart_balanced_kfold/fold_3/kfold/checkpoint-5607",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 5607,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.035416603088379,
      "learning_rate": 1.80972e-05,
      "loss": 2.0478,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 4.239953517913818,
      "learning_rate": 3.63772e-05,
      "loss": 1.599,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.9472270011901855,
      "learning_rate": 5.4657199999999996e-05,
      "loss": 1.5374,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.790060520172119,
      "learning_rate": 7.29372e-05,
      "loss": 1.5318,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.4843742847442627,
      "learning_rate": 9.12172e-05,
      "loss": 1.5175,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.245954990386963,
      "learning_rate": 8.982083769633509e-05,
      "loss": 1.4901,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4232920408248901,
      "eval_rouge1": 0.387922114132403,
      "eval_rouge2": 0.24568756749645132,
      "eval_rougeL": 0.3809945673182335,
      "eval_rouge_sum": 1.014604248947088,
      "eval_runtime": 403.862,
      "eval_samples_per_second": 6.168,
      "eval_steps_per_second": 0.386,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.3582286834716797,
      "learning_rate": 8.82257242582897e-05,
      "loss": 1.2763,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 4.455452919006348,
      "learning_rate": 8.663061082024434e-05,
      "loss": 1.2201,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.5214297771453857,
      "learning_rate": 8.503549738219895e-05,
      "loss": 1.2304,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 2.934473991394043,
      "learning_rate": 8.344038394415358e-05,
      "loss": 1.206,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 4.211511135101318,
      "learning_rate": 8.18452705061082e-05,
      "loss": 1.2196,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.0448882579803467,
      "learning_rate": 8.025015706806283e-05,
      "loss": 1.2396,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.375260829925537,
      "eval_rouge1": 0.41445964624834153,
      "eval_rouge2": 0.260801557968608,
      "eval_rougeL": 0.40639291025288576,
      "eval_rouge_sum": 1.0816541144698353,
      "eval_runtime": 359.5581,
      "eval_samples_per_second": 6.928,
      "eval_steps_per_second": 0.434,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 2.9213600158691406,
      "learning_rate": 7.865504363001744e-05,
      "loss": 1.0158,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 2.9645509719848633,
      "learning_rate": 7.705993019197208e-05,
      "loss": 0.8659,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.4673843383789062,
      "learning_rate": 7.546481675392669e-05,
      "loss": 0.889,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 3.0304222106933594,
      "learning_rate": 7.386970331588133e-05,
      "loss": 0.8687,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.1289420127868652,
      "learning_rate": 7.227458987783596e-05,
      "loss": 0.8977,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 2.910853624343872,
      "learning_rate": 7.067947643979058e-05,
      "loss": 0.8912,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.4098237752914429,
      "eval_rouge1": 0.42206420600100036,
      "eval_rouge2": 0.26855454924750455,
      "eval_rougeL": 0.41477267695378967,
      "eval_rouge_sum": 1.1053914322022946,
      "eval_runtime": 332.1148,
      "eval_samples_per_second": 7.5,
      "eval_steps_per_second": 0.47,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 2.7424421310424805,
      "learning_rate": 6.90843630017452e-05,
      "loss": 0.7972,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.509894847869873,
      "learning_rate": 6.748924956369983e-05,
      "loss": 0.5999,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 4.322897434234619,
      "learning_rate": 6.589413612565445e-05,
      "loss": 0.6158,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 3.5287036895751953,
      "learning_rate": 6.429902268760908e-05,
      "loss": 0.6265,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 3.2348978519439697,
      "learning_rate": 6.27039092495637e-05,
      "loss": 0.6302,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.0103983879089355,
      "learning_rate": 6.110879581151833e-05,
      "loss": 0.6495,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.4935805797576904,
      "eval_rouge1": 0.4486217368374123,
      "eval_rouge2": 0.29024598270744917,
      "eval_rougeL": 0.4406872614543326,
      "eval_rouge_sum": 1.179554980999194,
      "eval_runtime": 335.0988,
      "eval_samples_per_second": 7.434,
      "eval_steps_per_second": 0.466,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.3463149070739746,
      "learning_rate": 5.9513682373472944e-05,
      "loss": 0.6344,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 2.801440477371216,
      "learning_rate": 5.7918568935427575e-05,
      "loss": 0.4121,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 2.9572272300720215,
      "learning_rate": 5.63234554973822e-05,
      "loss": 0.4308,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 3.3030176162719727,
      "learning_rate": 5.4728342059336824e-05,
      "loss": 0.4391,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 2.5960564613342285,
      "learning_rate": 5.313322862129145e-05,
      "loss": 0.4479,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 2.6499838829040527,
      "learning_rate": 5.153811518324607e-05,
      "loss": 0.4505,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 3.1763360500335693,
      "learning_rate": 4.99430017452007e-05,
      "loss": 0.4565,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6073942184448242,
      "eval_rouge1": 0.44293402153236777,
      "eval_rouge2": 0.28199826529079086,
      "eval_rougeL": 0.43473083022748754,
      "eval_rouge_sum": 1.1596631170506462,
      "eval_runtime": 332.367,
      "eval_samples_per_second": 7.495,
      "eval_steps_per_second": 0.469,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.199693202972412,
      "learning_rate": 4.834788830715533e-05,
      "loss": 0.312,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 2.6315555572509766,
      "learning_rate": 4.6752774869109946e-05,
      "loss": 0.2968,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 2.7056884765625,
      "learning_rate": 4.515766143106457e-05,
      "loss": 0.3014,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 2.511983871459961,
      "learning_rate": 4.3562547993019195e-05,
      "loss": 0.3074,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 2.757821798324585,
      "learning_rate": 4.196743455497382e-05,
      "loss": 0.3152,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 2.8788180351257324,
      "learning_rate": 4.0372321116928443e-05,
      "loss": 0.318,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.6705337762832642,
      "eval_rouge1": 0.45055482279404624,
      "eval_rouge2": 0.29055049003283456,
      "eval_rougeL": 0.44064968680799216,
      "eval_rouge_sum": 1.1817549996348728,
      "eval_runtime": 403.7041,
      "eval_samples_per_second": 6.17,
      "eval_steps_per_second": 0.386,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 2.0208845138549805,
      "learning_rate": 3.877720767888307e-05,
      "loss": 0.2446,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 2.2084391117095947,
      "learning_rate": 3.718209424083769e-05,
      "loss": 0.208,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 1.8786178827285767,
      "learning_rate": 3.558698080279232e-05,
      "loss": 0.212,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 2.269291400909424,
      "learning_rate": 3.399186736474694e-05,
      "loss": 0.2119,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 2.28810715675354,
      "learning_rate": 3.2396753926701566e-05,
      "loss": 0.2146,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 2.432166576385498,
      "learning_rate": 3.080164048865619e-05,
      "loss": 0.2162,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.7491995096206665,
      "eval_rouge1": 0.45702157295261037,
      "eval_rouge2": 0.2941804542003041,
      "eval_rougeL": 0.4484521270920434,
      "eval_rouge_sum": 1.199654154244958,
      "eval_runtime": 402.8713,
      "eval_samples_per_second": 6.183,
      "eval_steps_per_second": 0.387,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 1.8230026960372925,
      "learning_rate": 2.9206527050610818e-05,
      "loss": 0.1905,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 2.1577975749969482,
      "learning_rate": 2.7611413612565442e-05,
      "loss": 0.1438,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 1.940536618232727,
      "learning_rate": 2.6016300174520067e-05,
      "loss": 0.1483,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 2.2261221408843994,
      "learning_rate": 2.442118673647469e-05,
      "loss": 0.1509,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 1.8062381744384766,
      "learning_rate": 2.282607329842932e-05,
      "loss": 0.1515,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 2.52072811126709,
      "learning_rate": 2.1230959860383943e-05,
      "loss": 0.1494,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.8069485425949097,
      "eval_rouge1": 0.4533288041816152,
      "eval_rouge2": 0.2938997906151234,
      "eval_rougeL": 0.4442749902533058,
      "eval_rouge_sum": 1.1915035850500444,
      "eval_runtime": 406.5459,
      "eval_samples_per_second": 6.127,
      "eval_steps_per_second": 0.384,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 1.660768747329712,
      "learning_rate": 1.963584642233857e-05,
      "loss": 0.1464,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 1.4367783069610596,
      "learning_rate": 1.8040732984293196e-05,
      "loss": 0.1041,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 1.6490882635116577,
      "learning_rate": 1.644561954624782e-05,
      "loss": 0.1049,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 1.7106126546859741,
      "learning_rate": 1.4850506108202444e-05,
      "loss": 0.1088,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 1.7130498886108398,
      "learning_rate": 1.3255392670157069e-05,
      "loss": 0.1069,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 1.7856037616729736,
      "learning_rate": 1.1660279232111693e-05,
      "loss": 0.1045,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 1.562135934829712,
      "learning_rate": 1.0065165794066318e-05,
      "loss": 0.1044,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.8544440269470215,
      "eval_rouge1": 0.461430214454143,
      "eval_rouge2": 0.29523202607302135,
      "eval_rougeL": 0.4510049179679937,
      "eval_rouge_sum": 1.2076671584951582,
      "eval_runtime": 437.2782,
      "eval_samples_per_second": 5.697,
      "eval_steps_per_second": 0.357,
      "step": 5607
    }
  ],
  "logging_steps": 100,
  "max_steps": 6230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.734485094268928e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
