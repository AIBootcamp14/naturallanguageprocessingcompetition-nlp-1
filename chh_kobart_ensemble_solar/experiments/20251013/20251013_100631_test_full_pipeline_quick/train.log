2025-10-13 10:06:31 | >> í‘œì¤€ ì¶œë ¥ ë° ì˜¤ë¥˜ë¥¼ ë¡œê·¸ íŒŒì¼ë¡œ ë¦¬ë””ë ‰ì…˜ ì‹œì‘
2025-10-13 10:06:34 | ğŸ“Š FULL ëª¨ë“œ ì‹¤í–‰ ì¤‘...
2025-10-13 10:06:34 | ============================================================
2025-10-13 10:06:34 | = FULL PIPELINE ì‹¤í–‰ ì‹œì‘
2025-10-13 10:06:34 | =ëŒ€ìƒ ëª¨ë¸: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-13 10:06:34 | =ì•™ìƒë¸” ì•™ìƒë¸” ì „ëµ: stacking
2025-10-13 10:06:34 | = TTA ì‚¬ìš©: True
2025-10-13 10:06:34 | ============================================================
2025-10-13 10:06:34 | [1/6] ë°ì´í„° ë¡œë”©...
2025-10-13 10:06:34 | âœ… í•™ìŠµ ë°ì´í„°: 12457ê°œ
2025-10-13 10:06:34 | âœ… ê²€ì¦ ë°ì´í„°: 499ê°œ
2025-10-13 10:06:34 | âš™ï¸ max_train_samples ì ìš©: í•™ìŠµ ë°ì´í„° 6000ê°œë¡œ ì œí•œ
2025-10-13 10:06:34 | [2/6] ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ (6 ëª¨ë¸)...
2025-10-13 10:06:34 | ==================================================
2025-10-13 10:06:34 | ëª¨ë¸ 1/6: kobart
2025-10-13 10:06:34 | ==================================================
2025-10-13 10:06:34 | ëª¨ë¸ íƒ€ì…: encoder_decoder
2025-10-13 10:06:34 | ============================================================
2025-10-13 10:06:34 | ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì‹œì‘
2025-10-13 10:06:34 | ============================================================
2025-10-13 10:06:34 | í† í¬ë‚˜ì´ì € ë¡œë”©: digit82/kobart-summarization
2025-10-13 10:06:35 | ëª¨ë¸ ë¡œë”©: digit82/kobart-summarization
2025-10-13 10:06:35 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-13 10:06:36 | â†’ ë””ë°”ì´ìŠ¤: cuda
2025-10-13 10:06:36 | â†’ ì „ì²´ íŒŒë¼ë¯¸í„°: 123,859,968
2025-10-13 10:06:36 | â†’ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 123,859,968
2025-10-13 10:06:36 | ============================================================
2025-10-13 10:06:36 | âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ
2025-10-13 10:06:36 | ============================================================
2025-10-13 10:06:36 | ============================================================
2025-10-13 10:06:36 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-13 10:06:36 | ============================================================
2025-10-13 10:06:36 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-13 10:06:36 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-13 10:06:37 | 0%|          | 0/750 [00:00<?, ?it/s]
2025-10-13 10:06:37 | 1%|          | 4/750 [00:00<01:47,  6.94it/s]
2025-10-13 10:06:38 | 2%|â–         | 13/750 [00:01<00:41, 17.64it/s]
2025-10-13 10:06:38 | 3%|â–         | 19/750 [00:01<00:34, 21.35it/s]
2025-10-13 10:06:38 | 4%|â–         | 28/750 [00:01<00:30, 23.64it/s]
2025-10-13 10:06:39 | 5%|â–         | 34/750 [00:01<00:29, 24.30it/s]
2025-10-13 10:06:39 | 6%|â–Œ         | 43/750 [00:02<00:28, 24.80it/s]
2025-10-13 10:06:39 | 7%|â–‹         | 49/750 [00:02<00:28, 24.85it/s]
2025-10-13 10:06:39 | 8%|â–Š         | 58/750 [00:02<00:27, 24.99it/s]
2025-10-13 10:06:40 | 9%|â–Š         | 64/750 [00:03<00:27, 25.29it/s]
2025-10-13 10:06:40 | 10%|â–‰         | 73/750 [00:03<00:26, 25.56it/s]
2025-10-13 10:06:40 | 11%|â–ˆ         | 79/750 [00:03<00:27, 24.69it/s]
2025-10-13 10:06:41 | 12%|â–ˆâ–        | 88/750 [00:04<00:26, 25.02it/s]
2025-10-13 10:06:41 | 13%|â–ˆâ–        | 94/750 [00:04<00:26, 24.87it/s]
2025-10-13 10:06:41 | {'loss': 2.7154, 'grad_norm': 9.158895492553711, 'learning_rate': 9.9e-07, 'epoch': 0.13}
2025-10-13 10:06:41 | 13%|â–ˆâ–        | 100/750 [00:04<00:26, 24.82it/s]
2025-10-13 10:06:41 | 14%|â–ˆâ–        | 103/750 [00:04<00:26, 24.57it/s]
2025-10-13 10:06:42 | 15%|â–ˆâ–        | 109/750 [00:04<00:25, 25.18it/s]
2025-10-13 10:06:42 | 16%|â–ˆâ–Œ        | 118/750 [00:05<00:24, 25.41it/s]
2025-10-13 10:06:42 | 17%|â–ˆâ–‹        | 124/750 [00:05<00:24, 25.32it/s]
2025-10-13 10:06:42 | 18%|â–ˆâ–Š        | 133/750 [00:05<00:24, 25.36it/s]
2025-10-13 10:06:43 | 19%|â–ˆâ–Š        | 139/750 [00:06<00:24, 24.99it/s]
2025-10-13 10:06:43 | 20%|â–ˆâ–‰        | 148/750 [00:06<00:23, 25.33it/s]
2025-10-13 10:06:43 | 21%|â–ˆâ–ˆ        | 154/750 [00:06<00:23, 25.11it/s]
2025-10-13 10:06:44 | 22%|â–ˆâ–ˆâ–       | 163/750 [00:07<00:23, 25.47it/s]
2025-10-13 10:06:44 | 23%|â–ˆâ–ˆâ–       | 169/750 [00:07<00:23, 25.07it/s]
2025-10-13 10:06:44 | 24%|â–ˆâ–ˆâ–       | 178/750 [00:07<00:22, 25.33it/s]
2025-10-13 10:06:44 | 25%|â–ˆâ–ˆâ–       | 184/750 [00:07<00:22, 25.21it/s]
2025-10-13 10:06:45 | 26%|â–ˆâ–ˆâ–Œ       | 193/750 [00:08<00:22, 25.15it/s]
2025-10-13 10:06:45 | 27%|â–ˆâ–ˆâ–‹       | 199/750 [00:08<00:22, 24.79it/s]
2025-10-13 10:06:45 | {'loss': 2.0765, 'grad_norm': 6.092968463897705, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.27}
2025-10-13 10:06:45 | 27%|â–ˆâ–ˆâ–‹       | 200/750 [00:08<00:22, 24.79it/s]
2025-10-13 10:06:45 | 28%|â–ˆâ–ˆâ–Š       | 208/750 [00:08<00:21, 24.93it/s]
2025-10-13 10:06:46 | 29%|â–ˆâ–ˆâ–Š       | 214/750 [00:09<00:21, 25.03it/s]
2025-10-13 10:06:46 | 30%|â–ˆâ–ˆâ–‰       | 223/750 [00:09<00:20, 25.36it/s]
2025-10-13 10:06:46 | 31%|â–ˆâ–ˆâ–ˆ       | 229/750 [00:09<00:20, 25.32it/s]
2025-10-13 10:06:47 | 32%|â–ˆâ–ˆâ–ˆâ–      | 238/750 [00:10<00:20, 25.37it/s]
2025-10-13 10:06:47 | 33%|â–ˆâ–ˆâ–ˆâ–      | 244/750 [00:10<00:19, 25.56it/s]
2025-10-13 10:06:47 | 34%|â–ˆâ–ˆâ–ˆâ–      | 253/750 [00:10<00:19, 25.20it/s]
2025-10-13 10:06:47 | 35%|â–ˆâ–ˆâ–ˆâ–      | 259/750 [00:10<00:19, 25.19it/s]
2025-10-13 10:06:48 | 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 268/750 [00:11<00:19, 25.36it/s]
2025-10-13 10:06:48 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 274/750 [00:11<00:18, 25.42it/s]
2025-10-13 10:06:48 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 283/750 [00:11<00:19, 24.43it/s]
2025-10-13 10:06:49 | 39%|â–ˆâ–ˆâ–ˆâ–Š      | 289/750 [00:12<00:18, 24.98it/s]
2025-10-13 10:06:49 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 298/750 [00:12<00:18, 24.81it/s]
2025-10-13 10:06:49 | {'loss': 1.8261, 'grad_norm': 6.38389253616333, 'learning_rate': 2.99e-06, 'epoch': 0.4}
2025-10-13 10:06:49 | 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 300/750 [00:12<00:18, 24.81it/s]
2025-10-13 10:06:49 | 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 304/750 [00:12<00:17, 24.86it/s]
2025-10-13 10:06:50 | 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 313/750 [00:13<00:17, 25.23it/s]
2025-10-13 10:06:50 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 319/750 [00:13<00:17, 25.25it/s]
2025-10-13 10:06:50 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 328/750 [00:13<00:17, 24.75it/s]
2025-10-13 10:06:50 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 334/750 [00:13<00:16, 25.07it/s]
2025-10-13 10:06:51 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 343/750 [00:14<00:16, 25.02it/s]
2025-10-13 10:06:51 | 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 349/750 [00:14<00:16, 24.36it/s]
2025-10-13 10:06:51 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 358/750 [00:14<00:15, 24.71it/s]
2025-10-13 10:06:52 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 364/750 [00:15<00:15, 24.95it/s]
2025-10-13 10:06:52 | 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 373/750 [00:15<00:15, 25.11it/s]
2025-10-13 10:06:52 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 379/750 [00:15<00:14, 24.93it/s]
2025-10-13 10:06:53 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 388/750 [00:16<00:27, 13.04it/s]
2025-10-13 10:06:54 | 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 394/750 [00:17<00:21, 16.88it/s]
2025-10-13 10:06:54 | {'loss': 1.7446, 'grad_norm': 6.942716598510742, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.53}
2025-10-13 10:06:54 | 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 400/750 [00:17<00:18, 19.23it/s]
2025-10-13 10:06:54 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 403/750 [00:17<00:17, 20.05it/s]
2025-10-13 10:06:54 | 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 409/750 [00:17<00:15, 21.43it/s]
2025-10-13 10:06:55 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 418/750 [00:18<00:14, 22.28it/s]
2025-10-13 10:06:55 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 424/750 [00:18<00:13, 23.53it/s]
2025-10-13 10:06:55 | 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 433/750 [00:18<00:13, 23.35it/s]
2025-10-13 10:06:56 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 439/750 [00:18<00:13, 23.48it/s]
2025-10-13 10:06:56 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 448/750 [00:19<00:12, 23.55it/s]
2025-10-13 10:06:56 | 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 454/750 [00:19<00:12, 23.00it/s]
2025-10-13 10:06:57 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 463/750 [00:20<00:12, 22.25it/s]
2025-10-13 10:06:57 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 469/750 [00:20<00:12, 23.12it/s]
2025-10-13 10:06:57 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 478/750 [00:20<00:11, 23.52it/s]
2025-10-13 10:06:57 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 484/750 [00:20<00:11, 23.94it/s]
2025-10-13 10:06:58 | 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 493/750 [00:21<00:11, 23.26it/s]
2025-10-13 10:06:58 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 499/750 [00:21<00:10, 23.22it/s]
2025-10-13 10:06:58 | {'loss': 1.7093, 'grad_norm': 6.41726541519165, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.67}
2025-10-13 10:06:58 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 500/750 [00:21<00:10, 23.22it/s]
2025-10-13 10:06:59 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 508/750 [00:21<00:11, 21.23it/s]
2025-10-13 10:06:59 | 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 514/750 [00:22<00:10, 22.17it/s]
2025-10-13 10:06:59 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 523/750 [00:22<00:10, 22.65it/s]
2025-10-13 10:07:00 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 529/750 [00:22<00:10, 21.59it/s]
2025-10-13 10:07:00 | 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 538/750 [00:23<00:09, 21.98it/s]
2025-10-13 10:07:00 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 544/750 [00:23<00:08, 23.55it/s]
2025-10-13 10:07:01 | 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 553/750 [00:23<00:08, 23.90it/s]
2025-10-13 10:07:01 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 559/750 [00:24<00:07, 24.08it/s]
2025-10-13 10:07:01 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 568/750 [00:24<00:07, 23.99it/s]
2025-10-13 10:07:01 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 574/750 [00:24<00:07, 23.39it/s]
2025-10-13 10:07:02 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 583/750 [00:25<00:07, 22.19it/s]
2025-10-13 10:07:02 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 589/750 [00:25<00:07, 22.57it/s]
2025-10-13 10:07:03 | 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 598/750 [00:25<00:06, 21.81it/s]
2025-10-13 10:07:03 | {'loss': 1.6426, 'grad_norm': 5.970148086547852, 'learning_rate': 3.0200000000000003e-06, 'epoch': 0.8}
2025-10-13 10:07:03 | 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 600/750 [00:25<00:06, 21.81it/s]
2025-10-13 10:07:03 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 604/750 [00:26<00:06, 23.11it/s]
2025-10-13 10:07:03 | 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 613/750 [00:26<00:05, 23.77it/s]
2025-10-13 10:07:03 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 619/750 [00:26<00:05, 24.00it/s]
2025-10-13 10:07:04 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 628/750 [00:27<00:05, 23.29it/s]
2025-10-13 10:07:04 | 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 634/750 [00:27<00:05, 22.73it/s]
2025-10-13 10:07:04 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 643/750 [00:27<00:04, 23.26it/s]
2025-10-13 10:07:05 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 649/750 [00:28<00:04, 22.45it/s]
2025-10-13 10:07:05 | 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 658/750 [00:28<00:04, 22.46it/s]
2025-10-13 10:07:05 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 664/750 [00:28<00:03, 22.57it/s]
2025-10-13 10:07:06 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 673/750 [00:29<00:03, 23.82it/s]
2025-10-13 10:07:06 | 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 679/750 [00:29<00:03, 22.38it/s]
2025-10-13 10:07:06 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 688/750 [00:29<00:02, 21.83it/s]
2025-10-13 10:07:07 | 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 694/750 [00:30<00:02, 21.61it/s]
2025-10-13 10:07:07 | {'loss': 1.5895, 'grad_norm': 6.190375804901123, 'learning_rate': 1.02e-06, 'epoch': 0.93}
2025-10-13 10:07:07 | 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 700/750 [00:30<00:02, 22.07it/s]
2025-10-13 10:07:07 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 703/750 [00:30<00:02, 22.11it/s]
2025-10-13 10:07:07 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 709/750 [00:30<00:01, 21.60it/s]
2025-10-13 10:07:08 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 718/750 [00:31<00:01, 21.83it/s]
2025-10-13 10:07:08 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 724/750 [00:31<00:01, 22.30it/s]
2025-10-13 10:07:08 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 733/750 [00:31<00:00, 23.93it/s]
2025-10-13 10:07:09 | 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 739/750 [00:32<00:00, 24.21it/s]
2025-10-13 10:07:09 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 748/750 [00:32<00:00, 23.46it/s]
2025-10-13 10:07:10 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-13 10:07:10 | [A
2025-10-13 10:07:11 | 3%|â–         | 2/63 [00:00<00:24,  2.51it/s]
2025-10-13 10:07:11 | [A
2025-10-13 10:07:12 | 5%|â–         | 3/63 [00:01<00:32,  1.86it/s]
2025-10-13 10:07:12 | [A
2025-10-13 10:07:13 | 6%|â–‹         | 4/63 [00:02<00:35,  1.66it/s]
2025-10-13 10:07:13 | [A
2025-10-13 10:07:13 | 8%|â–Š         | 5/63 [00:02<00:38,  1.52it/s]
2025-10-13 10:07:13 | [A
2025-10-13 10:07:14 | 10%|â–‰         | 6/63 [00:03<00:38,  1.48it/s]
2025-10-13 10:07:14 | [A
2025-10-13 10:07:15 | 11%|â–ˆ         | 7/63 [00:04<00:38,  1.45it/s]
2025-10-13 10:07:15 | [A
2025-10-13 10:07:15 | 13%|â–ˆâ–        | 8/63 [00:05<00:38,  1.43it/s]
2025-10-13 10:07:15 | [A
2025-10-13 10:07:16 | 14%|â–ˆâ–        | 9/63 [00:05<00:37,  1.42it/s]
2025-10-13 10:07:16 | [A
2025-10-13 10:07:17 | 16%|â–ˆâ–Œ        | 10/63 [00:06<00:37,  1.43it/s]
2025-10-13 10:07:17 | [A
2025-10-13 10:07:18 | 17%|â–ˆâ–‹        | 11/63 [00:07<00:36,  1.42it/s]
2025-10-13 10:07:18 | [A
2025-10-13 10:07:18 | 19%|â–ˆâ–‰        | 12/63 [00:07<00:35,  1.43it/s]
2025-10-13 10:07:18 | [A
2025-10-13 10:07:19 | 21%|â–ˆâ–ˆ        | 13/63 [00:08<00:35,  1.42it/s]
2025-10-13 10:07:19 | [A
2025-10-13 10:07:20 | 22%|â–ˆâ–ˆâ–       | 14/63 [00:09<00:35,  1.39it/s]
2025-10-13 10:07:20 | [A
2025-10-13 10:07:20 | 24%|â–ˆâ–ˆâ–       | 15/63 [00:10<00:35,  1.36it/s]
2025-10-13 10:07:20 | [A
2025-10-13 10:07:21 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:10<00:34,  1.36it/s]
2025-10-13 10:07:21 | [A
2025-10-13 10:07:22 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:11<00:33,  1.37it/s]
2025-10-13 10:07:22 | [A
2025-10-13 10:07:23 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:12<00:32,  1.37it/s]
2025-10-13 10:07:23 | [A
2025-10-13 10:07:23 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:13<00:32,  1.37it/s]
2025-10-13 10:07:23 | [A
2025-10-13 10:07:24 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:13<00:30,  1.39it/s]
2025-10-13 10:07:24 | [A
2025-10-13 10:07:25 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:14<00:29,  1.41it/s]
2025-10-13 10:07:25 | [A
2025-10-13 10:07:26 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:15<00:37,  1.08it/s]
2025-10-13 10:07:26 | [A
2025-10-13 10:07:27 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:16<00:33,  1.18it/s]
2025-10-13 10:07:27 | [A
2025-10-13 10:07:28 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:17<00:31,  1.23it/s]
2025-10-13 10:07:28 | [A
2025-10-13 10:07:28 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [00:51<00:00, 23.46it/s]
2025-10-13 10:07:28 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:17<00:29,  1.31it/s]
2025-10-13 10:07:28 | [A
2025-10-13 10:07:29 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:18<00:27,  1.33it/s]
2025-10-13 10:07:29 | [A
2025-10-13 10:07:30 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:19<00:26,  1.35it/s]
2025-10-13 10:07:30 | [A
2025-10-13 10:07:30 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:20<00:25,  1.35it/s]
2025-10-13 10:07:30 | [A
2025-10-13 10:07:31 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:20<00:24,  1.37it/s]
2025-10-13 10:07:31 | [A
2025-10-13 10:07:32 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:21<00:24,  1.36it/s]
2025-10-13 10:07:32 | [A
2025-10-13 10:07:33 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:22<00:23,  1.36it/s]
2025-10-13 10:07:33 | [A
2025-10-13 10:07:33 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:23<00:22,  1.38it/s]
2025-10-13 10:07:33 | [A
2025-10-13 10:07:34 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:23<00:21,  1.41it/s]
2025-10-13 10:07:34 | [A
2025-10-13 10:07:35 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:24<00:20,  1.41it/s]
2025-10-13 10:07:35 | [A
2025-10-13 10:07:35 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:25<00:20,  1.40it/s]
2025-10-13 10:07:35 | [A
2025-10-13 10:07:36 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:25<00:19,  1.40it/s]
2025-10-13 10:07:36 | [A
2025-10-13 10:07:37 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:26<00:18,  1.42it/s]
2025-10-13 10:07:37 | [A
2025-10-13 10:07:38 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:27<00:17,  1.43it/s]
2025-10-13 10:07:38 | [A
2025-10-13 10:07:38 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:27<00:16,  1.44it/s]
2025-10-13 10:07:38 | [A
2025-10-13 10:07:39 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [00:28<00:15,  1.45it/s]
2025-10-13 10:07:39 | [A
2025-10-13 10:07:40 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [00:29<00:15,  1.44it/s]
2025-10-13 10:07:40 | [A
2025-10-13 10:07:40 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:29<00:14,  1.44it/s]
2025-10-13 10:07:40 | [A
2025-10-13 10:07:41 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [00:30<00:13,  1.45it/s]
2025-10-13 10:07:41 | [A
2025-10-13 10:07:42 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [00:31<00:12,  1.46it/s]
2025-10-13 10:07:42 | [A
2025-10-13 10:07:42 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [00:32<00:12,  1.46it/s]
2025-10-13 10:07:42 | [A
2025-10-13 10:07:43 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [00:32<00:11,  1.43it/s]
2025-10-13 10:07:43 | [A
2025-10-13 10:07:44 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [00:33<00:11,  1.42it/s]
2025-10-13 10:07:44 | [A
2025-10-13 10:07:44 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [00:34<00:10,  1.42it/s]
2025-10-13 10:07:44 | [A
2025-10-13 10:07:45 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [00:34<00:09,  1.44it/s]
2025-10-13 10:07:45 | [A
2025-10-13 10:07:46 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [00:35<00:09,  1.43it/s]
2025-10-13 10:07:46 | [A
2025-10-13 10:07:47 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [00:36<00:08,  1.42it/s]
2025-10-13 10:07:47 | [A
2025-10-13 10:07:47 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [00:36<00:07,  1.43it/s]
2025-10-13 10:07:47 | [A
2025-10-13 10:07:48 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [00:37<00:07,  1.42it/s]
2025-10-13 10:07:48 | [A
2025-10-13 10:07:49 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [00:38<00:06,  1.42it/s]
2025-10-13 10:07:49 | [A
2025-10-13 10:07:49 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [00:39<00:05,  1.42it/s]
2025-10-13 10:07:49 | [A
2025-10-13 10:07:50 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [00:39<00:04,  1.43it/s]
2025-10-13 10:07:50 | [A
2025-10-13 10:07:51 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [00:40<00:04,  1.41it/s]
2025-10-13 10:07:51 | [A
2025-10-13 10:07:51 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [00:41<00:03,  1.43it/s]
2025-10-13 10:07:51 | [A
2025-10-13 10:07:52 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [00:41<00:02,  1.38it/s]
2025-10-13 10:07:52 | [A
2025-10-13 10:07:53 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [00:42<00:02,  1.40it/s]
2025-10-13 10:07:53 | [A
2025-10-13 10:07:54 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [00:43<00:01,  1.37it/s]
2025-10-13 10:07:54 | [A
2025-10-13 10:07:54 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [00:44<00:00,  1.37it/s]
2025-10-13 10:07:54 | [A
2025-10-13 10:07:55 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:44<00:00,  1.40it/s]
2025-10-13 10:07:55 | [A
2025-10-13 10:07:55 | [A
2025-10-13 10:07:55 | {'eval_loss': 1.5233179330825806, 'eval_rouge1': 0.41273764565635696, 'eval_rouge2': 0.26066490055784436, 'eval_rougeL': 0.4040512006792191, 'eval_rouge_sum': 1.0774537468934204, 'eval_runtime': 45.9845, 'eval_samples_per_second': 10.851, 'eval_steps_per_second': 1.37, 'epoch': 1.0}
2025-10-13 10:07:55 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [01:18<00:00, 23.46it/s]
2025-10-13 10:07:55 | [A
2025-10-13 10:07:55 | [A
2025-10-13 10:07:56 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-13 10:07:56 | {'train_runtime': 79.875, 'train_samples_per_second': 75.117, 'train_steps_per_second': 9.39, 'train_loss': 1.8796989135742188, 'epoch': 1.0}
2025-10-13 10:07:56 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [01:19<00:00, 23.46it/s]
2025-10-13 10:07:56 | ìµœì¢… ëª¨ë¸ ì €ì¥ ì¤‘...
2025-10-13 10:07:57 | â†’ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: experiments/20251013/20251013_100631_test_full_pipeline_quick/model_0_kobart/default/final_model
2025-10-13 10:07:57 | ìµœì¢… í‰ê°€ ì¤‘...
2025-10-13 10:07:58 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-13 10:07:59 | 3%|â–         | 2/63 [00:01<00:44,  1.37it/s]
2025-10-13 10:08:00 | 5%|â–         | 3/63 [00:02<00:42,  1.40it/s]
2025-10-13 10:08:01 | 6%|â–‹         | 4/63 [00:02<00:42,  1.39it/s]
2025-10-13 10:08:02 | 8%|â–Š         | 5/63 [00:03<00:41,  1.38it/s]
2025-10-13 10:08:02 | 10%|â–‰         | 6/63 [00:04<00:40,  1.40it/s]
2025-10-13 10:08:03 | 11%|â–ˆ         | 7/63 [00:05<00:40,  1.40it/s]
2025-10-13 10:08:04 | 13%|â–ˆâ–        | 8/63 [00:05<00:39,  1.40it/s]
2025-10-13 10:08:04 | 14%|â–ˆâ–        | 9/63 [00:06<00:38,  1.41it/s]
2025-10-13 10:08:05 | 16%|â–ˆâ–Œ        | 10/63 [00:07<00:37,  1.43it/s]
2025-10-13 10:08:06 | 17%|â–ˆâ–‹        | 11/63 [00:07<00:36,  1.43it/s]
2025-10-13 10:08:06 | 19%|â–ˆâ–‰        | 12/63 [00:08<00:35,  1.45it/s]
2025-10-13 10:08:07 | 21%|â–ˆâ–ˆ        | 13/63 [00:09<00:34,  1.44it/s]
2025-10-13 10:08:08 | 22%|â–ˆâ–ˆâ–       | 14/63 [00:09<00:35,  1.39it/s]
2025-10-13 10:08:09 | 24%|â–ˆâ–ˆâ–       | 15/63 [00:10<00:34,  1.40it/s]
2025-10-13 10:08:09 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:11<00:34,  1.38it/s]
2025-10-13 10:08:10 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:12<00:34,  1.35it/s]
2025-10-13 10:08:11 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:12<00:33,  1.34it/s]
2025-10-13 10:08:12 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:13<00:33,  1.32it/s]
2025-10-13 10:08:12 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:14<00:31,  1.36it/s]
2025-10-13 10:08:13 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:15<00:30,  1.36it/s]
2025-10-13 10:08:14 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:15<00:29,  1.39it/s]
2025-10-13 10:08:14 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:16<00:28,  1.42it/s]
2025-10-13 10:08:15 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:17<00:27,  1.43it/s]
2025-10-13 10:08:16 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:17<00:26,  1.43it/s]
2025-10-13 10:08:17 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:18<00:26,  1.41it/s]
2025-10-13 10:08:17 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:19<00:25,  1.42it/s]
2025-10-13 10:08:18 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:20<00:24,  1.41it/s]
2025-10-13 10:08:19 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:20<00:23,  1.42it/s]
2025-10-13 10:08:19 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:21<00:23,  1.43it/s]
2025-10-13 10:08:20 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:22<00:22,  1.39it/s]
2025-10-13 10:08:21 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:22<00:22,  1.38it/s]
2025-10-13 10:08:22 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:23<00:21,  1.40it/s]
2025-10-13 10:08:22 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:24<00:20,  1.40it/s]
2025-10-13 10:08:23 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:25<00:19,  1.41it/s]
2025-10-13 10:08:24 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:25<00:18,  1.42it/s]
2025-10-13 10:08:24 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:26<00:18,  1.42it/s]
2025-10-13 10:08:25 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:27<00:17,  1.42it/s]
2025-10-13 10:08:26 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:27<00:16,  1.43it/s]
2025-10-13 10:08:26 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [00:28<00:15,  1.44it/s]
2025-10-13 10:08:27 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [00:29<00:15,  1.42it/s]
2025-10-13 10:08:28 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:29<00:14,  1.41it/s]
2025-10-13 10:08:29 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [00:30<00:14,  1.42it/s]
2025-10-13 10:08:29 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [00:31<00:13,  1.42it/s]
2025-10-13 10:08:30 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [00:32<00:12,  1.43it/s]
2025-10-13 10:08:31 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [00:32<00:11,  1.44it/s]
2025-10-13 10:08:32 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [00:34<00:14,  1.09it/s]
2025-10-13 10:08:33 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [00:34<00:12,  1.18it/s]
2025-10-13 10:08:33 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [00:35<00:11,  1.25it/s]
2025-10-13 10:08:34 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [00:36<00:09,  1.31it/s]
2025-10-13 10:08:35 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [00:36<00:08,  1.34it/s]
2025-10-13 10:08:36 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [00:37<00:08,  1.33it/s]
2025-10-13 10:08:36 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [00:38<00:07,  1.35it/s]
2025-10-13 10:08:37 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [00:39<00:06,  1.38it/s]
2025-10-13 10:08:38 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [00:39<00:05,  1.40it/s]
2025-10-13 10:08:38 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [00:40<00:04,  1.41it/s]
2025-10-13 10:08:39 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [00:41<00:04,  1.41it/s]
2025-10-13 10:08:40 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [00:41<00:03,  1.40it/s]
2025-10-13 10:08:40 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [00:42<00:02,  1.42it/s]
2025-10-13 10:08:41 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [00:43<00:02,  1.42it/s]
2025-10-13 10:08:42 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [00:43<00:01,  1.42it/s]
2025-10-13 10:08:43 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [00:44<00:00,  1.43it/s]
2025-10-13 10:08:43 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:45<00:00,  1.44it/s]
2025-10-13 10:08:43 | ìµœì¢… í‰ê°€ ê²°ê³¼:
2025-10-13 10:08:43 | eval_rouge1: 0.4127
2025-10-13 10:08:43 | eval_rouge2: 0.2607
2025-10-13 10:08:43 | eval_rougeL: 0.4041
2025-10-13 10:08:43 | eval_rouge_sum: 1.0775
2025-10-13 10:08:43 | ============================================================
2025-10-13 10:08:43 | âœ… í•™ìŠµ ì™„ë£Œ!
2025-10-13 10:08:43 | ============================================================
2025-10-13 10:08:43 | âœ… kobart í•™ìŠµ ì™„ë£Œ
2025-10-13 10:08:43 | ==================================================
2025-10-13 10:08:43 | ëª¨ë¸ 2/6: llama-3.2-korean-3b
2025-10-13 10:08:43 | ==================================================
2025-10-13 10:08:43 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-13 10:08:43 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-13 10:08:43 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-13 10:08:44 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-13 10:08:44 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-13 10:08:47 | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.02s/it]
2025-10-13 10:08:48 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.77s/it]
2025-10-13 10:08:48 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-13 10:08:49 | íŒ¨ë”© í† í° ì„¤ì •: <|eot_id|>
2025-10-13 10:08:49 | LoRA ì„¤ì • ì ìš© ì¤‘...
2025-10-13 10:08:49 | ğŸ” ìë™ íƒì§€ëœ target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']
2025-10-13 10:08:49 | âœ… LoRA ì ìš© ì™„ë£Œ
2025-10-13 10:08:49 | í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 24,313,856 (0.75%)
2025-10-13 10:08:49 | ì „ì²´ íŒŒë¼ë¯¸í„°: 3,237,063,680
2025-10-13 10:08:49 | Input require grads í™œì„±í™” (LoRA + Gradient Checkpointing)
2025-10-13 10:08:49 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-13 10:08:49 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-13 10:08:49 | ============================================================
2025-10-13 10:08:49 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-13 10:08:49 | ============================================================
2025-10-13 10:08:49 | WandB ë¡œê·¸ì¸ ìƒíƒœ: ieyeppo-job
2025-10-13 10:08:50 | wandb: Currently logged in as: ieyeppo-job (kimsunmin0227-hufs) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
2025-10-13 10:08:50 | wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
2025-10-13 10:08:51 | wandb: setting up run vhyc1nd2
2025-10-13 10:08:51 | wandb: Tracking run with wandb version 0.22.2
2025-10-13 10:08:51 | wandb: Run data is saved locally in /home/ieyeppo/AI_Lab/natural-language-processing-competition/wandb/wandb/run-20251013_100850-vhyc1nd2
wandb: Run `wandb offline` to turn off syncing.
2025-10-13 10:08:51 | wandb: Syncing run 1013-1008-llama_3.2_3b_qlora
2025-10-13 10:08:51 | wandb: â­ï¸ View project at https://wandb.ai/ieyeppo/nlp-competition
2025-10-13 10:08:51 | wandb: ğŸš€ View run at https://wandb.ai/ieyeppo/nlp-competition/runs/vhyc1nd2
2025-10-13 10:08:51 | wandb: Detected [openai] in use.
2025-10-13 10:08:51 | wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
2025-10-13 10:08:51 | wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-10-13 10:08:51 | ğŸ“‹ ì‹¤í—˜ëª…: 1013-1008-llama_3.2_3b_qlora
2025-10-13 10:08:51 | ğŸ”— WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/vhyc1nd2
2025-10-13 10:08:51 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-13 10:08:51 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-13 10:08:51 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-13 10:08:51 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-13 10:08:51 | 0%|          | 0/750 [00:00<?, ?it/s]
2025-10-13 10:09:05 | 1%|          | 4/750 [00:14<44:52,  3.61s/it]
2025-10-13 10:09:26 | {'loss': 1.6067, 'grad_norm': 2.0904722213745117, 'learning_rate': 9e-08, 'epoch': 0.01}
2025-10-13 10:09:26 | 1%|â–         | 10/750 [00:35<42:23,  3.44s/it]
2025-10-13 10:09:33 | 2%|â–         | 12/750 [00:41<40:10,  3.27s/it]
2025-10-13 10:09:55 | 3%|â–         | 19/750 [01:03<38:49,  3.19s/it]
2025-10-13 10:09:59 | {'loss': 1.6723, 'grad_norm': 1.9965585470199585, 'learning_rate': 1.9e-07, 'epoch': 0.03}
2025-10-13 10:09:59 | 3%|â–         | 20/750 [01:07<39:57,  3.28s/it]
2025-10-13 10:10:22 | 4%|â–         | 27/750 [01:30<39:48,  3.30s/it]
2025-10-13 10:10:31 | {'loss': 1.649, 'grad_norm': 1.887860655784607, 'learning_rate': 2.9000000000000003e-07, 'epoch': 0.04}
2025-10-13 10:10:31 | 4%|â–         | 30/750 [01:40<37:54,  3.16s/it]
2025-10-13 10:10:45 | 5%|â–         | 34/750 [01:53<40:03,  3.36s/it]
2025-10-13 10:11:03 | {'loss': 1.6136, 'grad_norm': 1.841176986694336, 'learning_rate': 3.9e-07, 'epoch': 0.05}
2025-10-13 10:11:03 | 5%|â–Œ         | 40/750 [02:11<35:34,  3.01s/it]
2025-10-13 10:11:10 | 6%|â–Œ         | 42/750 [02:18<38:29,  3.26s/it]
2025-10-13 10:11:32 | 7%|â–‹         | 49/750 [02:40<36:34,  3.13s/it]
2025-10-13 10:11:35 | {'loss': 1.636, 'grad_norm': 1.9192255735397339, 'learning_rate': 4.900000000000001e-07, 'epoch': 0.07}
2025-10-13 10:11:35 | 7%|â–‹         | 50/750 [02:44<36:50,  3.16s/it]
2025-10-13 10:11:58 | 8%|â–Š         | 57/750 [03:06<35:25,  3.07s/it]
2025-10-13 10:12:06 | {'loss': 1.6104, 'grad_norm': 1.9077227115631104, 'learning_rate': 5.900000000000001e-07, 'epoch': 0.08}
2025-10-13 10:12:06 | 8%|â–Š         | 60/750 [03:15<33:57,  2.95s/it]
2025-10-13 10:12:18 | 9%|â–Š         | 64/750 [03:27<34:02,  2.98s/it]
2025-10-13 10:12:38 | {'loss': 1.5462, 'grad_norm': 1.7723466157913208, 'learning_rate': 6.900000000000001e-07, 'epoch': 0.09}
2025-10-13 10:12:38 | 9%|â–‰         | 70/750 [03:46<34:13,  3.02s/it]
2025-10-13 10:12:44 | 10%|â–‰         | 72/750 [03:52<35:18,  3.13s/it]
2025-10-13 10:13:07 | 11%|â–ˆ         | 79/750 [04:15<34:51,  3.12s/it]
2025-10-13 10:13:10 | {'loss': 1.5602, 'grad_norm': 1.7908802032470703, 'learning_rate': 7.900000000000001e-07, 'epoch': 0.11}
2025-10-13 10:13:10 | 11%|â–ˆ         | 80/750 [04:18<34:46,  3.11s/it]
2025-10-13 10:13:31 | 12%|â–ˆâ–        | 87/750 [04:39<35:14,  3.19s/it]
2025-10-13 10:13:40 | {'loss': 1.5527, 'grad_norm': 1.8982608318328857, 'learning_rate': 8.900000000000001e-07, 'epoch': 0.12}
2025-10-13 10:13:40 | 12%|â–ˆâ–        | 90/750 [04:49<34:07,  3.10s/it]
2025-10-13 10:13:52 | 13%|â–ˆâ–        | 94/750 [05:01<32:35,  2.98s/it]
2025-10-13 10:14:12 | {'loss': 1.5115, 'grad_norm': 1.6617450714111328, 'learning_rate': 9.9e-07, 'epoch': 0.13}
2025-10-13 10:14:12 | 13%|â–ˆâ–        | 100/750 [05:20<33:49,  3.12s/it]
2025-10-13 10:14:18 | 14%|â–ˆâ–        | 102/750 [05:26<32:31,  3.01s/it]
2025-10-13 10:14:40 | 15%|â–ˆâ–        | 109/750 [05:49<36:24,  3.41s/it]
2025-10-13 10:14:43 | {'loss': 1.5593, 'grad_norm': 1.7247763872146606, 'learning_rate': 1.0900000000000002e-06, 'epoch': 0.15}
2025-10-13 10:14:43 | 15%|â–ˆâ–        | 110/750 [05:52<34:37,  3.25s/it]
2025-10-13 10:15:05 | 16%|â–ˆâ–Œ        | 117/750 [06:13<32:15,  3.06s/it]
2025-10-13 10:15:15 | {'loss': 1.5537, 'grad_norm': 1.9721754789352417, 'learning_rate': 1.19e-06, 'epoch': 0.16}
2025-10-13 10:15:15 | 16%|â–ˆâ–Œ        | 120/750 [06:24<33:54,  3.23s/it]
2025-10-13 10:15:27 | 17%|â–ˆâ–‹        | 124/750 [06:35<31:04,  2.98s/it]
2025-10-13 10:15:46 | {'loss': 1.5346, 'grad_norm': 1.8134406805038452, 'learning_rate': 1.2900000000000001e-06, 'epoch': 0.17}
2025-10-13 10:15:46 | 17%|â–ˆâ–‹        | 130/750 [06:54<33:06,  3.20s/it]
2025-10-13 10:15:51 | 18%|â–ˆâ–Š        | 132/750 [07:00<31:37,  3.07s/it]
2025-10-13 10:16:13 | 19%|â–ˆâ–Š        | 139/750 [07:21<30:13,  2.97s/it]
2025-10-13 10:16:16 | {'loss': 1.5175, 'grad_norm': 1.7022980451583862, 'learning_rate': 1.3900000000000002e-06, 'epoch': 0.19}
2025-10-13 10:16:16 | 19%|â–ˆâ–Š        | 140/750 [07:25<32:58,  3.24s/it]
2025-10-13 10:16:37 | 20%|â–ˆâ–‰        | 147/750 [07:45<29:22,  2.92s/it]
2025-10-13 10:16:46 | {'loss': 1.4684, 'grad_norm': 2.0183608531951904, 'learning_rate': 1.4900000000000001e-06, 'epoch': 0.2}
2025-10-13 10:16:46 | 20%|â–ˆâ–ˆ        | 150/750 [07:54<28:48,  2.88s/it]
2025-10-13 10:16:59 | 21%|â–ˆâ–ˆ        | 154/750 [08:07<31:18,  3.15s/it]
2025-10-13 10:17:22 | {'loss': 1.4761, 'grad_norm': 1.6963934898376465, 'learning_rate': 1.5900000000000002e-06, 'epoch': 0.21}
2025-10-13 10:17:22 | 21%|â–ˆâ–ˆâ–       | 160/750 [08:31<40:37,  4.13s/it]
2025-10-13 10:17:30 | 22%|â–ˆâ–ˆâ–       | 162/750 [08:38<38:41,  3.95s/it]
2025-10-13 10:17:57 | 23%|â–ˆâ–ˆâ–       | 169/750 [09:05<39:27,  4.08s/it]
2025-10-13 10:18:00 | {'loss': 1.45, 'grad_norm': 1.8917884826660156, 'learning_rate': 1.6900000000000003e-06, 'epoch': 0.23}
2025-10-13 10:18:00 | 23%|â–ˆâ–ˆâ–       | 170/750 [09:09<38:20,  3.97s/it]
2025-10-13 10:18:31 | 24%|â–ˆâ–ˆâ–       | 177/750 [09:39<41:13,  4.32s/it]
2025-10-13 10:18:43 | {'loss': 1.396, 'grad_norm': 1.545449137687683, 'learning_rate': 1.79e-06, 'epoch': 0.24}
2025-10-13 10:18:43 | 24%|â–ˆâ–ˆâ–       | 180/750 [09:51<39:23,  4.15s/it]
2025-10-13 10:18:57 | 25%|â–ˆâ–ˆâ–       | 184/750 [10:05<34:56,  3.70s/it]
2025-10-13 10:19:20 | {'loss': 1.4578, 'grad_norm': 1.9536563158035278, 'learning_rate': 1.8900000000000001e-06, 'epoch': 0.25}
2025-10-13 10:19:20 | 25%|â–ˆâ–ˆâ–Œ       | 190/750 [10:28<34:21,  3.68s/it]
2025-10-13 10:19:27 | 26%|â–ˆâ–ˆâ–Œ       | 192/750 [10:35<34:05,  3.67s/it]
2025-10-13 10:19:53 | 27%|â–ˆâ–ˆâ–‹       | 199/750 [11:01<32:25,  3.53s/it]
2025-10-13 10:19:56 | {'loss': 1.4315, 'grad_norm': 1.6504460573196411, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.27}
2025-10-13 10:19:56 | 27%|â–ˆâ–ˆâ–‹       | 200/750 [11:05<32:12,  3.51s/it]
2025-10-13 10:20:21 | 28%|â–ˆâ–ˆâ–Š       | 207/750 [11:30<31:11,  3.45s/it]
2025-10-13 10:20:32 | {'loss': 1.3866, 'grad_norm': 1.884433388710022, 'learning_rate': 2.09e-06, 'epoch': 0.28}
2025-10-13 10:20:32 | 28%|â–ˆâ–ˆâ–Š       | 210/750 [11:40<31:17,  3.48s/it]
2025-10-13 10:20:47 | 29%|â–ˆâ–ˆâ–Š       | 214/750 [11:56<33:51,  3.79s/it]
2025-10-13 10:21:09 | {'loss': 1.344, 'grad_norm': 1.7722502946853638, 'learning_rate': 2.19e-06, 'epoch': 0.29}
2025-10-13 10:21:09 | 29%|â–ˆâ–ˆâ–‰       | 220/750 [12:17<31:50,  3.60s/it]
2025-10-13 10:21:17 | 30%|â–ˆâ–ˆâ–‰       | 222/750 [12:25<33:07,  3.76s/it]
2025-10-13 10:21:40 | 31%|â–ˆâ–ˆâ–ˆ       | 229/750 [12:49<29:37,  3.41s/it]
2025-10-13 10:21:44 | {'loss': 1.3233, 'grad_norm': 1.6390069723129272, 'learning_rate': 2.29e-06, 'epoch': 0.31}
2025-10-13 10:21:44 | 31%|â–ˆâ–ˆâ–ˆ       | 230/750 [12:52<29:16,  3.38s/it]
2025-10-13 10:22:10 | 32%|â–ˆâ–ˆâ–ˆâ–      | 237/750 [13:19<34:31,  4.04s/it]
2025-10-13 10:22:22 | {'loss': 1.3564, 'grad_norm': 1.584446907043457, 'learning_rate': 2.39e-06, 'epoch': 0.32}
2025-10-13 10:22:22 | 32%|â–ˆâ–ˆâ–ˆâ–      | 240/750 [13:30<33:01,  3.89s/it]
2025-10-13 10:22:35 | 33%|â–ˆâ–ˆâ–ˆâ–      | 244/750 [13:44<28:46,  3.41s/it]
2025-10-13 10:22:55 | {'loss': 1.3595, 'grad_norm': 1.9745413064956665, 'learning_rate': 2.4900000000000003e-06, 'epoch': 0.33}
2025-10-13 10:22:55 | 33%|â–ˆâ–ˆâ–ˆâ–      | 250/750 [14:04<28:06,  3.37s/it]
2025-10-13 10:23:02 | 34%|â–ˆâ–ˆâ–ˆâ–      | 252/750 [14:10<27:12,  3.28s/it]
2025-10-13 10:23:27 | 35%|â–ˆâ–ˆâ–ˆâ–      | 259/750 [14:35<31:15,  3.82s/it]
2025-10-13 10:23:31 | {'loss': 1.3141, 'grad_norm': 1.5980799198150635, 'learning_rate': 2.59e-06, 'epoch': 0.35}
2025-10-13 10:23:31 | 35%|â–ˆâ–ˆâ–ˆâ–      | 260/750 [14:39<30:28,  3.73s/it]
2025-10-13 10:23:54 | 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 267/750 [15:03<28:27,  3.53s/it]
2025-10-13 10:24:06 | {'loss': 1.3503, 'grad_norm': 1.9529472589492798, 'learning_rate': 2.6900000000000005e-06, 'epoch': 0.36}
2025-10-13 10:24:06 | 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 270/750 [15:14<28:49,  3.60s/it]
2025-10-13 10:24:19 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 274/750 [15:27<26:47,  3.38s/it]
2025-10-13 10:24:40 | {'loss': 1.2712, 'grad_norm': 1.769500732421875, 'learning_rate': 2.7900000000000004e-06, 'epoch': 0.37}
2025-10-13 10:24:40 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 280/750 [15:48<26:28,  3.38s/it]
2025-10-13 10:24:46 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 282/750 [15:54<25:21,  3.25s/it]
2025-10-13 10:25:10 | 39%|â–ˆâ–ˆâ–ˆâ–Š      | 289/750 [16:18<28:25,  3.70s/it]
2025-10-13 10:25:14 | {'loss': 1.3715, 'grad_norm': 1.8833363056182861, 'learning_rate': 2.89e-06, 'epoch': 0.39}
2025-10-13 10:25:14 | 39%|â–ˆâ–ˆâ–ˆâ–Š      | 290/750 [16:22<28:44,  3.75s/it]
2025-10-13 10:25:37 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 297/750 [16:45<26:07,  3.46s/it]
2025-10-13 10:25:47 | {'loss': 1.2662, 'grad_norm': 1.5957452058792114, 'learning_rate': 2.99e-06, 'epoch': 0.4}
2025-10-13 10:25:47 | 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 300/750 [16:55<24:59,  3.33s/it]
2025-10-13 10:26:00 | 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 304/750 [17:08<24:02,  3.23s/it]
2025-10-13 10:26:24 | {'loss': 1.2837, 'grad_norm': 1.9085322618484497, 'learning_rate': 3.09e-06, 'epoch': 0.41}
2025-10-13 10:26:24 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 310/750 [17:32<27:34,  3.76s/it]
2025-10-13 10:26:30 | 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 312/750 [17:38<25:38,  3.51s/it]
2025-10-13 10:26:58 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 319/750 [18:06<27:45,  3.87s/it]
2025-10-13 10:27:01 | {'loss': 1.2801, 'grad_norm': 1.4109055995941162, 'learning_rate': 3.1900000000000004e-06, 'epoch': 0.43}
2025-10-13 10:27:01 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 320/750 [18:09<26:31,  3.70s/it]
2025-10-13 10:27:26 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 327/750 [18:34<24:52,  3.53s/it]
2025-10-13 10:27:36 | {'loss': 1.2749, 'grad_norm': 1.6189886331558228, 'learning_rate': 3.2900000000000003e-06, 'epoch': 0.44}
2025-10-13 10:27:36 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 330/750 [18:44<23:10,  3.31s/it]
2025-10-13 10:27:49 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 334/750 [18:58<23:50,  3.44s/it]
2025-10-13 10:28:07 | {'loss': 1.3605, 'grad_norm': 1.9082611799240112, 'learning_rate': 3.3900000000000006e-06, 'epoch': 0.45}
2025-10-13 10:28:07 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 340/750 [19:15<20:05,  2.94s/it]
2025-10-13 10:28:13 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 342/750 [19:21<20:52,  3.07s/it]
2025-10-13 10:28:36 | 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 349/750 [19:45<22:24,  3.35s/it]
2025-10-13 10:28:40 | {'loss': 1.3296, 'grad_norm': 1.9930217266082764, 'learning_rate': 3.49e-06, 'epoch': 0.47}
2025-10-13 10:28:40 | 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 350/750 [19:48<22:46,  3.42s/it]
2025-10-13 10:29:02 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 357/750 [20:10<20:12,  3.09s/it]
2025-10-13 10:29:11 | {'loss': 1.3232, 'grad_norm': 1.8341182470321655, 'learning_rate': 3.5900000000000004e-06, 'epoch': 0.48}
2025-10-13 10:29:11 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 360/750 [20:19<19:04,  2.93s/it]
2025-10-13 10:29:22 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 364/750 [20:30<18:31,  2.88s/it]
2025-10-13 10:29:40 | {'loss': 1.2983, 'grad_norm': 2.0631103515625, 'learning_rate': 3.6900000000000002e-06, 'epoch': 0.49}
2025-10-13 10:29:40 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 370/750 [20:48<18:33,  2.93s/it]
2025-10-13 10:29:46 | 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 372/750 [20:54<18:12,  2.89s/it]
2025-10-13 10:30:09 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 379/750 [21:18<21:07,  3.42s/it]
2025-10-13 10:30:12 | {'loss': 1.2425, 'grad_norm': 1.905802607536316, 'learning_rate': 3.79e-06, 'epoch': 0.51}
2025-10-13 10:30:12 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 380/750 [21:21<20:10,  3.27s/it]
2025-10-13 10:30:34 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 387/750 [21:42<19:59,  3.30s/it]
2025-10-13 10:30:44 | {'loss': 1.19, 'grad_norm': 1.7327367067337036, 'learning_rate': 3.89e-06, 'epoch': 0.52}
2025-10-13 10:30:44 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 390/750 [21:52<19:51,  3.31s/it]
2025-10-13 10:30:57 | 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 394/750 [22:05<19:20,  3.26s/it]
2025-10-13 10:31:16 | {'loss': 1.2523, 'grad_norm': 2.5519134998321533, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.53}
2025-10-13 10:31:16 | 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 400/750 [22:25<18:32,  3.18s/it]
2025-10-13 10:31:22 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 402/750 [22:30<17:29,  3.01s/it]
2025-10-13 10:31:45 | 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 409/750 [22:53<19:01,  3.35s/it]
2025-10-13 10:31:49 | {'loss': 1.2944, 'grad_norm': 1.6154648065567017, 'learning_rate': 4.09e-06, 'epoch': 0.55}
2025-10-13 10:31:49 | 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 410/750 [22:57<19:41,  3.47s/it]
2025-10-13 10:32:11 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 417/750 [23:19<18:01,  3.25s/it]
2025-10-13 10:32:23 | {'loss': 1.2092, 'grad_norm': 2.0335118770599365, 'learning_rate': 4.1900000000000005e-06, 'epoch': 0.56}
2025-10-13 10:32:23 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 420/750 [23:31<20:24,  3.71s/it]
2025-10-13 10:32:36 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 424/750 [23:44<17:34,  3.23s/it]
2025-10-13 10:32:56 | {'loss': 1.282, 'grad_norm': 2.1272222995758057, 'learning_rate': 4.2900000000000004e-06, 'epoch': 0.57}
2025-10-13 10:32:56 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 430/750 [24:04<16:47,  3.15s/it]
2025-10-13 10:33:02 | 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 432/750 [24:10<16:12,  3.06s/it]
2025-10-13 10:33:24 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 439/750 [24:32<16:35,  3.20s/it]
2025-10-13 10:33:27 | {'loss': 1.2088, 'grad_norm': 2.1604487895965576, 'learning_rate': 4.39e-06, 'epoch': 0.59}
2025-10-13 10:33:27 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 440/750 [24:35<16:12,  3.14s/it]
2025-10-13 10:33:48 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 447/750 [24:56<15:13,  3.01s/it]
2025-10-13 10:33:58 | {'loss': 1.2217, 'grad_norm': 1.9981695413589478, 'learning_rate': 4.49e-06, 'epoch': 0.6}
2025-10-13 10:33:58 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 450/750 [25:06<15:14,  3.05s/it]
2025-10-13 10:34:09 | 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 454/750 [25:17<14:17,  2.90s/it]
2025-10-13 10:34:27 | {'loss': 1.2504, 'grad_norm': 1.9848891496658325, 'learning_rate': 4.590000000000001e-06, 'epoch': 0.61}
2025-10-13 10:34:27 | 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 460/750 [25:35<15:07,  3.13s/it]
2025-10-13 10:34:33 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 462/750 [25:41<14:23,  3.00s/it]
2025-10-13 10:34:53 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 469/750 [26:01<13:24,  2.86s/it]
2025-10-13 10:34:56 | {'loss': 1.2983, 'grad_norm': 2.018683433532715, 'learning_rate': 4.69e-06, 'epoch': 0.63}
2025-10-13 10:34:56 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 470/750 [26:04<13:22,  2.87s/it]
2025-10-13 10:35:16 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 477/750 [26:25<13:06,  2.88s/it]
2025-10-13 10:35:25 | {'loss': 1.2487, 'grad_norm': 2.0980658531188965, 'learning_rate': 4.79e-06, 'epoch': 0.64}
2025-10-13 10:35:25 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 480/750 [26:33<12:59,  2.89s/it]
2025-10-13 10:35:37 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 484/750 [26:46<13:15,  2.99s/it]
2025-10-13 10:35:54 | {'loss': 1.2102, 'grad_norm': 2.0449211597442627, 'learning_rate': 4.890000000000001e-06, 'epoch': 0.65}
2025-10-13 10:35:54 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 490/750 [27:03<12:26,  2.87s/it]
2025-10-13 10:36:00 | 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 492/750 [27:08<12:20,  2.87s/it]
2025-10-13 10:36:21 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 499/750 [27:29<12:04,  2.89s/it]
2025-10-13 10:36:24 | {'loss': 1.2952, 'grad_norm': 1.9671096801757812, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.67}
2025-10-13 10:36:24 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 500/750 [27:32<11:58,  2.87s/it]
2025-10-13 10:36:45 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 507/750 [27:53<12:05,  2.98s/it]
2025-10-13 10:36:53 | {'loss': 1.2432, 'grad_norm': 2.290065288543701, 'learning_rate': 4.8200000000000004e-06, 'epoch': 0.68}
2025-10-13 10:36:53 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 510/750 [28:01<11:31,  2.88s/it]
2025-10-13 10:37:05 | 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 514/750 [28:13<11:15,  2.86s/it]
2025-10-13 10:37:23 | {'loss': 1.2199, 'grad_norm': 2.143855094909668, 'learning_rate': 4.620000000000001e-06, 'epoch': 0.69}
2025-10-13 10:37:23 | 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 520/750 [28:31<11:06,  2.90s/it]
2025-10-13 10:37:28 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 522/750 [28:37<10:58,  2.89s/it]
2025-10-13 10:37:49 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 529/750 [28:58<11:03,  3.00s/it]
2025-10-13 10:37:52 | {'loss': 1.1998, 'grad_norm': 2.513563871383667, 'learning_rate': 4.42e-06, 'epoch': 0.71}
2025-10-13 10:37:52 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 530/750 [29:00<10:48,  2.95s/it]
2025-10-13 10:38:12 | 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 537/750 [29:20<10:10,  2.87s/it]
2025-10-13 10:38:21 | {'loss': 1.1562, 'grad_norm': 2.562807083129883, 'learning_rate': 4.22e-06, 'epoch': 0.72}
2025-10-13 10:38:21 | 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 540/750 [29:30<10:29,  3.00s/it]
2025-10-13 10:38:33 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 544/750 [29:41<09:52,  2.88s/it]
2025-10-13 10:38:51 | {'loss': 1.173, 'grad_norm': 2.169579029083252, 'learning_rate': 4.0200000000000005e-06, 'epoch': 0.73}
2025-10-13 10:38:51 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 550/750 [29:59<10:27,  3.14s/it]
2025-10-13 10:38:57 | 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 552/750 [30:05<09:53,  3.00s/it]
2025-10-13 10:39:16 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 559/750 [30:25<09:05,  2.86s/it]
2025-10-13 10:39:19 | {'loss': 1.2385, 'grad_norm': 1.9947799444198608, 'learning_rate': 3.820000000000001e-06, 'epoch': 0.75}
2025-10-13 10:39:19 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 560/750 [30:28<09:02,  2.86s/it]
2025-10-13 10:39:40 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 567/750 [30:49<08:44,  2.86s/it]
2025-10-13 10:39:49 | {'loss': 1.2191, 'grad_norm': 2.7087626457214355, 'learning_rate': 3.62e-06, 'epoch': 0.76}
2025-10-13 10:39:49 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 570/750 [30:57<08:32,  2.85s/it]
2025-10-13 10:40:01 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 574/750 [31:10<08:53,  3.03s/it]
2025-10-13 10:40:18 | {'loss': 1.2101, 'grad_norm': 2.3039462566375732, 'learning_rate': 3.4200000000000007e-06, 'epoch': 0.77}
2025-10-13 10:40:18 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 580/750 [31:27<08:05,  2.85s/it]
2025-10-13 10:40:24 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 582/750 [31:32<08:03,  2.88s/it]
2025-10-13 10:40:45 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 589/750 [31:53<07:44,  2.89s/it]
2025-10-13 10:40:48 | {'loss': 1.2057, 'grad_norm': 2.1433985233306885, 'learning_rate': 3.2200000000000005e-06, 'epoch': 0.79}
2025-10-13 10:40:48 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 590/750 [31:56<07:40,  2.88s/it]
2025-10-13 10:41:09 | 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 597/750 [32:17<07:40,  3.01s/it]
2025-10-13 10:41:17 | {'loss': 1.1522, 'grad_norm': 2.2214584350585938, 'learning_rate': 3.0200000000000003e-06, 'epoch': 0.8}
2025-10-13 10:41:17 | 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 600/750 [32:26<07:15,  2.91s/it]
2025-10-13 10:41:29 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 604/750 [32:37<07:08,  2.94s/it]
2025-10-13 10:41:48 | {'loss': 1.2407, 'grad_norm': 2.992375612258911, 'learning_rate': 2.82e-06, 'epoch': 0.81}
2025-10-13 10:41:48 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 610/750 [32:56<06:59,  2.99s/it]
2025-10-13 10:41:54 | 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 612/750 [33:02<06:43,  2.92s/it]
2025-10-13 10:42:15 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 619/750 [33:23<06:33,  3.00s/it]
2025-10-13 10:42:18 | {'loss': 1.0548, 'grad_norm': 2.3859646320343018, 'learning_rate': 2.6200000000000003e-06, 'epoch': 0.83}
2025-10-13 10:42:18 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 620/750 [33:26<06:23,  2.95s/it]
2025-10-13 10:42:38 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 627/750 [33:46<06:03,  2.95s/it]
2025-10-13 10:42:47 | {'loss': 1.1122, 'grad_norm': 2.222219944000244, 'learning_rate': 2.42e-06, 'epoch': 0.84}
2025-10-13 10:42:47 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 630/750 [33:56<06:01,  3.02s/it]
2025-10-13 10:42:59 | 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 634/750 [34:08<05:43,  2.96s/it]
2025-10-13 10:43:18 | {'loss': 1.1962, 'grad_norm': 2.299212694168091, 'learning_rate': 2.2200000000000003e-06, 'epoch': 0.85}
2025-10-13 10:43:18 | 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 640/750 [34:26<05:39,  3.08s/it]
2025-10-13 10:43:23 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 642/750 [34:32<05:20,  2.97s/it]
2025-10-13 10:43:44 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 649/750 [34:52<04:56,  2.94s/it]
2025-10-13 10:43:48 | {'loss': 1.1555, 'grad_norm': 2.0834903717041016, 'learning_rate': 2.02e-06, 'epoch': 0.87}
2025-10-13 10:43:48 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 650/750 [34:56<05:16,  3.16s/it]
2025-10-13 10:44:09 | 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 657/750 [35:17<04:35,  2.96s/it]
2025-10-13 10:44:18 | {'loss': 1.1473, 'grad_norm': 2.3903067111968994, 'learning_rate': 1.8200000000000002e-06, 'epoch': 0.88}
2025-10-13 10:44:18 | 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 660/750 [35:26<04:20,  2.89s/it]
2025-10-13 10:44:30 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 664/750 [35:38<04:14,  2.96s/it]
2025-10-13 10:44:49 | {'loss': 1.2205, 'grad_norm': 2.163768768310547, 'learning_rate': 1.6200000000000002e-06, 'epoch': 0.89}
2025-10-13 10:44:49 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 670/750 [35:57<04:08,  3.11s/it]
2025-10-13 10:44:55 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 672/750 [36:04<04:09,  3.19s/it]
2025-10-13 10:45:16 | 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 679/750 [36:25<03:31,  2.97s/it]
2025-10-13 10:45:19 | {'loss': 1.1752, 'grad_norm': 2.6832528114318848, 'learning_rate': 1.42e-06, 'epoch': 0.91}
2025-10-13 10:45:19 | 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 680/750 [36:28<03:30,  3.00s/it]
2025-10-13 10:45:41 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 687/750 [36:49<03:09,  3.01s/it]
2025-10-13 10:45:50 | {'loss': 1.1921, 'grad_norm': 2.652174472808838, 'learning_rate': 1.2200000000000002e-06, 'epoch': 0.92}
2025-10-13 10:45:50 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 690/750 [36:58<02:59,  3.00s/it]
2025-10-13 10:46:03 | 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 694/750 [37:11<02:55,  3.14s/it]
2025-10-13 10:46:21 | {'loss': 1.1059, 'grad_norm': 2.6294429302215576, 'learning_rate': 1.02e-06, 'epoch': 0.93}
2025-10-13 10:46:21 | 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 700/750 [37:29<02:35,  3.12s/it]
2025-10-13 10:46:27 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 702/750 [37:36<02:31,  3.15s/it]
2025-10-13 10:46:49 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 709/750 [37:57<02:05,  3.07s/it]
2025-10-13 10:46:52 | {'loss': 1.1651, 'grad_norm': 2.2299458980560303, 'learning_rate': 8.200000000000001e-07, 'epoch': 0.95}
2025-10-13 10:46:52 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 710/750 [38:00<02:02,  3.05s/it]
2025-10-13 10:47:14 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 717/750 [38:22<01:40,  3.04s/it]
2025-10-13 10:47:23 | {'loss': 1.1543, 'grad_norm': 2.377122402191162, 'learning_rate': 6.200000000000001e-07, 'epoch': 0.96}
2025-10-13 10:47:23 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 720/750 [38:31<01:29,  2.98s/it]
2025-10-13 10:47:35 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 724/750 [38:43<01:17,  2.98s/it]
2025-10-13 10:47:53 | {'loss': 1.1132, 'grad_norm': 2.0324997901916504, 'learning_rate': 4.2000000000000006e-07, 'epoch': 0.97}
2025-10-13 10:47:53 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 730/750 [39:02<01:00,  3.03s/it]
2025-10-13 10:48:00 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 732/750 [39:08<00:56,  3.15s/it]
2025-10-13 10:48:22 | 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 739/750 [39:30<00:33,  3.05s/it]
2025-10-13 10:48:25 | {'loss': 1.1737, 'grad_norm': 1.8109683990478516, 'learning_rate': 2.2e-07, 'epoch': 0.99}
2025-10-13 10:48:25 | 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 740/750 [39:33<00:30,  3.06s/it]
2025-10-13 10:48:46 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 747/750 [39:54<00:09,  3.21s/it]
2025-10-13 10:48:55 | {'loss': 1.1676, 'grad_norm': 2.3305602073669434, 'learning_rate': 2e-08, 'epoch': 1.0}
2025-10-13 10:48:55 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [40:03<00:00,  3.06s/it]
2025-10-13 10:48:55 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:49:07 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-13 10:49:07 | [A
2025-10-13 10:49:07 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:49:19 | 3%|â–         | 2/63 [00:11<06:02,  5.94s/it]
2025-10-13 10:49:19 | [A
2025-10-13 10:49:19 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:49:32 | 5%|â–         | 3/63 [00:24<08:53,  8.89s/it]
2025-10-13 10:49:32 | [A
2025-10-13 10:49:32 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:49:42 | 6%|â–‹         | 4/63 [00:34<08:59,  9.14s/it]
2025-10-13 10:49:42 | [A
2025-10-13 10:49:42 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:49:54 | 8%|â–Š         | 5/63 [00:46<09:47, 10.13s/it]
2025-10-13 10:49:54 | [A
2025-10-13 10:49:54 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:50:06 | 10%|â–‰         | 6/63 [00:59<10:23, 10.94s/it]
2025-10-13 10:50:06 | [A
2025-10-13 10:50:06 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:50:16 | 11%|â–ˆ         | 7/63 [01:08<09:49, 10.52s/it]
2025-10-13 10:50:16 | [A
2025-10-13 10:50:16 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:50:27 | 13%|â–ˆâ–        | 8/63 [01:19<09:44, 10.62s/it]
2025-10-13 10:50:27 | [A
2025-10-13 10:50:27 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:50:37 | 14%|â–ˆâ–        | 9/63 [01:29<09:24, 10.46s/it]
2025-10-13 10:50:37 | [A
2025-10-13 10:50:37 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:50:52 | 16%|â–ˆâ–Œ        | 10/63 [01:44<10:26, 11.82s/it]
2025-10-13 10:50:52 | [A
2025-10-13 10:50:52 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:52:52 | 17%|â–ˆâ–‹        | 11/63 [03:45<38:58, 44.97s/it]
2025-10-13 10:52:52 | [A
2025-10-13 10:52:52 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:53:05 | 19%|â–ˆâ–‰        | 12/63 [03:57<29:50, 35.10s/it]
2025-10-13 10:53:05 | [A
2025-10-13 10:53:05 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:53:15 | 21%|â–ˆâ–ˆ        | 13/63 [04:07<23:01, 27.64s/it]
2025-10-13 10:53:15 | [A
2025-10-13 10:53:15 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:53:27 | 22%|â–ˆâ–ˆâ–       | 14/63 [04:19<18:44, 22.94s/it]
2025-10-13 10:53:27 | [A
2025-10-13 10:53:27 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:53:36 | 24%|â–ˆâ–ˆâ–       | 15/63 [04:28<14:57, 18.69s/it]
2025-10-13 10:53:36 | [A
2025-10-13 10:53:36 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:53:52 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [04:45<14:04, 17.96s/it]
2025-10-13 10:53:52 | [A
2025-10-13 10:53:52 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:54:06 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [04:59<12:55, 16.87s/it]
2025-10-13 10:54:06 | [A
2025-10-13 10:54:06 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:54:22 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [05:14<12:16, 16.36s/it]
2025-10-13 10:54:22 | [A
2025-10-13 10:54:22 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:54:32 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [05:24<10:36, 14.47s/it]
2025-10-13 10:54:32 | [A
2025-10-13 10:54:32 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:54:42 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [05:34<09:26, 13.18s/it]
2025-10-13 10:54:42 | [A
2025-10-13 10:54:42 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:54:53 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [05:46<08:52, 12.67s/it]
2025-10-13 10:54:53 | [A
2025-10-13 10:54:53 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:55:10 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [06:02<09:24, 13.76s/it]
2025-10-13 10:55:10 | [A
2025-10-13 10:55:10 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:55:24 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [06:16<09:16, 13.90s/it]
2025-10-13 10:55:24 | [A
2025-10-13 10:55:24 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:55:33 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [06:26<08:09, 12.56s/it]
2025-10-13 10:55:33 | [A
2025-10-13 10:55:33 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:55:43 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [06:36<07:25, 11.73s/it]
2025-10-13 10:55:43 | [A
2025-10-13 10:55:43 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:55:57 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [06:50<07:41, 12.46s/it]
2025-10-13 10:55:57 | [A
2025-10-13 10:55:57 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:57:46 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [08:38<24:47, 41.32s/it]
2025-10-13 10:57:46 | [A
2025-10-13 10:57:46 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:57:55 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [08:47<18:27, 31.65s/it]
2025-10-13 10:57:55 | [A
2025-10-13 10:57:55 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:58:09 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [09:02<14:56, 26.38s/it]
2025-10-13 10:58:09 | [A
2025-10-13 10:58:09 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:58:19 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [09:11<11:46, 21.40s/it]
2025-10-13 10:58:19 | [A
2025-10-13 10:58:19 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:58:35 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [09:28<10:35, 19.87s/it]
2025-10-13 10:58:35 | [A
2025-10-13 10:58:35 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:58:48 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [09:40<09:08, 17.69s/it]
2025-10-13 10:58:48 | [A
2025-10-13 10:58:48 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:59:02 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [09:54<08:14, 16.49s/it]
2025-10-13 10:59:02 | [A
2025-10-13 10:59:02 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:59:14 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [10:06<07:21, 15.21s/it]
2025-10-13 10:59:14 | [A
2025-10-13 10:59:14 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:59:27 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [10:19<06:47, 14.54s/it]
2025-10-13 10:59:27 | [A
2025-10-13 10:59:27 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:59:40 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [10:33<06:26, 14.30s/it]
2025-10-13 10:59:40 | [A
2025-10-13 10:59:40 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 10:59:52 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [10:45<05:52, 13.57s/it]
2025-10-13 10:59:52 | [A
2025-10-13 10:59:52 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:00:03 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [10:55<05:18, 12.73s/it]
2025-10-13 11:00:03 | [A
2025-10-13 11:00:03 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:00:23 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [11:15<05:57, 14.90s/it]
2025-10-13 11:00:23 | [A
2025-10-13 11:00:23 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:00:39 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [11:31<05:46, 15.09s/it]
2025-10-13 11:00:39 | [A
2025-10-13 11:00:39 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:00:48 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [11:41<04:56, 13.48s/it]
2025-10-13 11:00:48 | [A
2025-10-13 11:00:48 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:01:01 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [11:53<04:37, 13.23s/it]
2025-10-13 11:01:01 | [A
2025-10-13 11:01:01 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:01:15 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [12:07<04:27, 13.35s/it]
2025-10-13 11:01:15 | [A
2025-10-13 11:01:15 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:01:30 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [12:23<04:27, 14.07s/it]
2025-10-13 11:01:30 | [A
2025-10-13 11:01:30 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:01:37 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [12:30<03:35, 11.98s/it]
2025-10-13 11:01:37 | [A
2025-10-13 11:01:37 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:01:47 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [12:40<03:12, 11.32s/it]
2025-10-13 11:01:47 | [A
2025-10-13 11:01:47 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:01:55 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [12:47<02:43, 10.24s/it]
2025-10-13 11:01:55 | [A
2025-10-13 11:01:55 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:02:04 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [12:57<02:30, 10.01s/it]
2025-10-13 11:02:04 | [A
2025-10-13 11:02:04 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:02:14 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [13:06<02:17,  9.84s/it]
2025-10-13 11:02:14 | [A
2025-10-13 11:02:14 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:02:22 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [13:14<01:59,  9.23s/it]
2025-10-13 11:02:22 | [A
2025-10-13 11:02:22 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:02:40 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [13:33<02:24, 12.03s/it]
2025-10-13 11:02:40 | [A
2025-10-13 11:02:40 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:02:54 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [13:46<02:18, 12.57s/it]
2025-10-13 11:02:54 | [A
2025-10-13 11:02:54 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:03:10 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [14:03<02:16, 13.62s/it]
2025-10-13 11:03:10 | [A
2025-10-13 11:03:10 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:03:19 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [14:12<01:50, 12.25s/it]
2025-10-13 11:03:19 | [A
2025-10-13 11:03:19 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:03:28 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [14:21<01:30, 11.26s/it]
2025-10-13 11:03:28 | [A
2025-10-13 11:03:28 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:03:47 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [14:39<01:34, 13.47s/it]
2025-10-13 11:03:47 | [A
2025-10-13 11:03:47 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:03:57 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [14:50<01:15, 12.57s/it]
2025-10-13 11:03:57 | [A
2025-10-13 11:03:57 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:04:07 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [15:00<00:58, 11.78s/it]
2025-10-13 11:04:07 | [A
2025-10-13 11:04:07 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:04:16 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [15:08<00:43, 10.79s/it]
2025-10-13 11:04:16 | [A
2025-10-13 11:04:16 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:04:35 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [15:27<00:40, 13.38s/it]
2025-10-13 11:04:35 | [A
2025-10-13 11:04:35 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:04:46 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [15:38<00:25, 12.66s/it]
2025-10-13 11:04:46 | [A
2025-10-13 11:04:46 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:05:04 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [15:56<00:14, 14.19s/it]
2025-10-13 11:05:04 | [A
2025-10-13 11:05:04 | A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
2025-10-13 11:05:09 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [16:01<00:00, 11.47s/it]
2025-10-13 11:05:09 | [A
2025-10-13 11:05:09 | âŒ llama-3.2-korean-3b í•™ìŠµ ì‹¤íŒ¨: OverflowError: out of range integral type conversion attempted
2025-10-13 11:05:09 | ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: experiments/20251013/20251013_100631_test_full_pipeline_quick/errors/llama-3.2-korean-3b_error.log
2025-10-13 11:05:09 | ==================================================
2025-10-13 11:05:09 | ëª¨ë¸ 3/6: qwen3-4b
2025-10-13 11:05:09 | ==================================================
2025-10-13 11:05:09 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-13 11:05:09 | Loading Causal LM: Qwen/Qwen3-4B-Instruct-2507
2025-10-13 11:05:09 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-13 11:05:09 | Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2025-10-13 11:05:09 | [A[A
2025-10-13 11:05:11 | Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:02<00:04,  2.21s/it]
2025-10-13 11:05:11 | [A[A
2025-10-13 11:05:14 | Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.22s/it]
2025-10-13 11:05:14 | [A[A
2025-10-13 11:05:14 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.50s/it]
2025-10-13 11:05:14 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-13 11:05:15 | LoRA ì„¤ì • ì ìš© ì¤‘...
2025-10-13 11:05:15 | ğŸ” ìë™ íƒì§€ëœ target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']
2025-10-13 11:05:15 | âœ… LoRA ì ìš© ì™„ë£Œ
2025-10-13 11:05:15 | í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 33,030,144 (0.81%)
2025-10-13 11:05:15 | ì „ì²´ íŒŒë¼ë¯¸í„°: 4,055,498,240
2025-10-13 11:05:15 | Input require grads í™œì„±í™” (LoRA + Gradient Checkpointing)
2025-10-13 11:05:15 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-13 11:05:15 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-13 11:05:15 | ============================================================
2025-10-13 11:05:15 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-13 11:05:15 | ============================================================
2025-10-13 11:05:17 | WandB ë¡œê·¸ì¸ ìƒíƒœ: ieyeppo-job
2025-10-13 11:05:17 | wandb: Finishing previous runs because reinit is set to True.
2025-10-13 11:05:17 | wandb: updating run metadata
2025-10-13 11:05:19 | wandb: uploading summary, console lines 397-409
2025-10-13 11:05:19 | wandb: 
wandb: Run history:
wandb:         train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:   train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:     train/grad_norm â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–„â–ƒâ–ƒâ–‚â–†â–‚â–„â–„â–„â–†â–†â–„â–…â–„â–ˆâ–…â–…â–‡â–†â–†â–…â–…
wandb: train/learning_rate â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–
wandb:          train/loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–…â–†â–†â–…â–„â–…â–„â–…â–„â–…â–„â–„â–…â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:         train/epoch 1
wandb:   train/global_step 750
wandb:     train/grad_norm 2.33056
wandb: train/learning_rate 0.0
wandb:          train/loss 1.1676
wandb:
2025-10-13 11:05:19 | wandb: ğŸš€ View run 1013-1008-llama_3.2_3b_qlora at: https://wandb.ai/ieyeppo/nlp-competition/runs/vhyc1nd2
wandb: â­ï¸ View project at: https://wandb.ai/ieyeppo/nlp-competition
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
2025-10-13 11:05:19 | wandb: Find logs at: ./wandb/wandb/run-20251013_100850-vhyc1nd2/logs
2025-10-13 11:05:20 | wandb: setting up run sdpamw0e
2025-10-13 11:05:20 | wandb: Tracking run with wandb version 0.22.2
2025-10-13 11:05:20 | wandb: Run data is saved locally in /home/ieyeppo/AI_Lab/natural-language-processing-competition/wandb/wandb/run-20251013_110517-sdpamw0e
wandb: Run `wandb offline` to turn off syncing.
2025-10-13 11:05:20 | wandb: Syncing run 1013-1105-qwen3_4b_qlora
2025-10-13 11:05:20 | wandb: â­ï¸ View project at https://wandb.ai/ieyeppo/nlp-competition
2025-10-13 11:05:20 | wandb: ğŸš€ View run at https://wandb.ai/ieyeppo/nlp-competition/runs/sdpamw0e
2025-10-13 11:05:20 | ğŸ“‹ ì‹¤í—˜ëª…: 1013-1105-qwen3_4b_qlora
2025-10-13 11:05:20 | ğŸ”— WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/sdpamw0e
2025-10-13 11:05:20 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-13 11:05:20 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-13 11:05:20 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-13 11:05:20 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
2025-10-13 11:05:20 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [56:28<00:00,  4.52s/it]
2025-10-13 11:05:20 | [A
2025-10-13 11:05:20 | 0%|          | 0/750 [00:00<?, ?it/s]
2025-10-13 11:05:41 | 1%|          | 4/750 [00:21<1:05:49,  5.29s/it]
2025-10-13 11:06:22 | {'loss': 2.5169, 'grad_norm': 6.384832382202148, 'learning_rate': 9e-08, 'epoch': 0.01}
2025-10-13 11:06:22 | 1%|â–         | 10/750 [01:02<1:31:08,  7.39s/it]
2025-10-13 11:06:41 | 2%|â–         | 12/750 [01:20<1:41:42,  8.27s/it]
2025-10-13 11:07:44 | 3%|â–         | 19/750 [02:23<1:50:19,  9.06s/it]
2025-10-13 11:07:53 | {'loss': 2.6644, 'grad_norm': 4.389631748199463, 'learning_rate': 1.9e-07, 'epoch': 0.03}
2025-10-13 11:07:53 | 3%|â–         | 20/750 [02:32<1:48:57,  8.96s/it]
2025-10-13 11:08:56 | 4%|â–         | 27/750 [03:36<1:48:31,  9.01s/it]
2025-10-13 11:09:23 | {'loss': 2.6082, 'grad_norm': 4.653611660003662, 'learning_rate': 2.9000000000000003e-07, 'epoch': 0.04}
2025-10-13 11:09:23 | 4%|â–         | 30/750 [04:02<1:47:52,  8.99s/it]
2025-10-13 11:09:59 | 5%|â–         | 34/750 [04:38<1:47:02,  8.97s/it]
2025-10-13 11:10:53 | {'loss': 2.6846, 'grad_norm': 4.022918224334717, 'learning_rate': 3.9e-07, 'epoch': 0.05}
2025-10-13 11:10:53 | 5%|â–Œ         | 40/750 [05:32<1:47:12,  9.06s/it]
2025-10-13 11:11:11 | 6%|â–Œ         | 42/750 [05:50<1:47:07,  9.08s/it]
2025-10-13 11:12:20 | 7%|â–‹         | 49/750 [06:59<1:55:43,  9.91s/it]
2025-10-13 11:12:31 | {'loss': 2.5624, 'grad_norm': 4.087717533111572, 'learning_rate': 4.900000000000001e-07, 'epoch': 0.07}
2025-10-13 11:12:31 | 7%|â–‹         | 50/750 [07:10<1:59:40, 10.26s/it]
2025-10-13 11:13:42 | 8%|â–Š         | 57/750 [08:22<2:01:29, 10.52s/it]
2025-10-13 11:14:23 | {'loss': 2.5576, 'grad_norm': 4.949262619018555, 'learning_rate': 5.900000000000001e-07, 'epoch': 0.08}
2025-10-13 11:14:23 | 8%|â–Š         | 60/750 [09:03<2:24:42, 12.58s/it]
2025-10-13 11:15:16 | >> ë¡œê·¸ ë¦¬ë””ë ‰ì…˜ ì¤‘ë£Œ.
