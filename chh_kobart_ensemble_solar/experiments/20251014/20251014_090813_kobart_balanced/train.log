2025-10-14 09:08:13 | >> 표준 출력 및 오류를 로그 파일로 리디렉션 시작
2025-10-14 09:08:17 | 📊 KFOLD 모드 실행 중...
2025-10-14 09:08:17 | ============================================================
2025-10-14 09:08:17 | 🔄 K-FOLD 교차검증 모드 학습 시작
2025-10-14 09:08:17 | 📋 K-Folds: 5
2025-10-14 09:08:17 | 📋 모델: kobart
2025-10-14 09:08:17 | 📋 Fold Seed: 42
2025-10-14 09:08:17 | ============================================================
2025-10-14 09:08:17 | [1/3] 전체 데이터 로딩...
2025-10-14 09:08:17 | ✅ 학습 데이터: 12457개
2025-10-14 09:08:17 | ✅ 검증 데이터: 499개
2025-10-14 09:08:17 | ✅ 전체 데이터: 12457개
2025-10-14 09:08:17 | [2/3] Config 로딩...
2025-10-14 09:08:17 | ✅ Config 로드 완료: kobart
2025-10-14 09:08:17 | [3/3] K-Fold 교차검증 실행...
2025-10-14 09:08:17 | ========================================
2025-10-14 09:08:17 | ========================================
2025-10-14 09:08:17 | 학습: 9965개
2025-10-14 09:08:17 | 검증: 2492개
2025-10-14 09:08:17 | 모델 타입: encoder_decoder
2025-10-14 09:08:18 | ============================================================
2025-10-14 09:08:18 | 모델 및 토크나이저 로딩 시작
2025-10-14 09:08:18 | ============================================================
2025-10-14 09:08:18 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-14 09:08:18 | 모델 로딩: digit82/kobart-summarization
2025-10-14 09:08:18 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-14 09:08:20 | → 디바이스: cuda
2025-10-14 09:08:20 | → 전체 파라미터: 123,859,968
2025-10-14 09:08:20 | → 학습 가능 파라미터: 123,859,968
2025-10-14 09:08:20 | ============================================================
2025-10-14 09:08:20 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-14 09:08:20 | ============================================================
2025-10-14 09:08:20 | ============================================================
2025-10-14 09:08:20 | 모델 학습 시작
2025-10-14 09:08:20 | ============================================================
2025-10-14 09:08:20 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:253: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-14 09:08:20 | 학습 진행 중...
2025-10-14 09:08:40 | {'loss': 2.1531, 'grad_norm': 4.489185810089111, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.16}
2025-10-14 09:09:00 | {'loss': 1.6514, 'grad_norm': 3.7915103435516357, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.32}
2025-10-14 09:09:20 | {'loss': 1.5723, 'grad_norm': 4.011915683746338, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.48}
2025-10-14 09:09:38 | {'loss': 1.5336, 'grad_norm': 3.339083194732666, 'learning_rate': 3.99e-05, 'epoch': 0.64}
2025-10-14 09:09:58 | {'loss': 1.4978, 'grad_norm': 3.9378459453582764, 'learning_rate': 4.99e-05, 'epoch': 0.8}
2025-10-14 09:10:17 | {'loss': 1.4464, 'grad_norm': 3.7429141998291016, 'learning_rate': 4.944036178631996e-05, 'epoch': 0.96}
2025-10-14 09:15:17 | {'eval_loss': 1.392896056175232, 'eval_rouge1': 0.39583326629121923, 'eval_rouge2': 0.24555791702206087, 'eval_rougeL': 0.3875504756578239, 'eval_rouge_sum': 1.028941658971104, 'eval_runtime': 294.3602, 'eval_samples_per_second': 8.466, 'eval_steps_per_second': 0.53, 'epoch': 1.0}
2025-10-14 09:15:35 | {'loss': 1.314, 'grad_norm': 3.6839802265167236, 'learning_rate': 4.887507066139062e-05, 'epoch': 1.12}
2025-10-14 09:15:54 | {'loss': 1.2675, 'grad_norm': 3.2839434146881104, 'learning_rate': 4.830977953646128e-05, 'epoch': 1.28}
2025-10-14 09:16:14 | {'loss': 1.2493, 'grad_norm': 3.7500452995300293, 'learning_rate': 4.774448841153194e-05, 'epoch': 1.44}
2025-10-14 09:16:35 | {'loss': 1.2833, 'grad_norm': 3.9722676277160645, 'learning_rate': 4.71791972866026e-05, 'epoch': 1.61}
2025-10-14 09:16:54 | {'loss': 1.2366, 'grad_norm': 3.352959632873535, 'learning_rate': 4.661390616167327e-05, 'epoch': 1.77}
2025-10-14 09:17:14 | {'loss': 1.2517, 'grad_norm': 3.9990293979644775, 'learning_rate': 4.604861503674392e-05, 'epoch': 1.93}
2025-10-14 09:22:34 | {'eval_loss': 1.3375699520111084, 'eval_rouge1': 0.40962063130718634, 'eval_rouge2': 0.2620776594134463, 'eval_rougeL': 0.4029189658100632, 'eval_rouge_sum': 1.0746172565306957, 'eval_runtime': 311.9451, 'eval_samples_per_second': 7.989, 'eval_steps_per_second': 0.5, 'epoch': 2.0}
2025-10-14 09:22:48 | {'loss': 1.0911, 'grad_norm': 2.910457134246826, 'learning_rate': 4.5483323911814584e-05, 'epoch': 2.09}
2025-10-14 09:23:07 | {'loss': 0.9631, 'grad_norm': 3.0870282649993896, 'learning_rate': 4.491803278688525e-05, 'epoch': 2.25}
2025-10-14 09:23:27 | {'loss': 0.985, 'grad_norm': 3.932147979736328, 'learning_rate': 4.435274166195591e-05, 'epoch': 2.41}
2025-10-14 09:23:49 | {'loss': 0.9919, 'grad_norm': 3.2362172603607178, 'learning_rate': 4.378745053702657e-05, 'epoch': 2.57}
2025-10-14 09:24:08 | {'loss': 0.9972, 'grad_norm': 3.571103096008301, 'learning_rate': 4.322215941209723e-05, 'epoch': 2.73}
2025-10-14 09:24:28 | {'loss': 0.9922, 'grad_norm': 3.2972359657287598, 'learning_rate': 4.2656868287167893e-05, 'epoch': 2.89}
2025-10-14 09:30:02 | {'eval_loss': 1.344132661819458, 'eval_rouge1': 0.4316859420707987, 'eval_rouge2': 0.2747540685384241, 'eval_rougeL': 0.42300971984341956, 'eval_rouge_sum': 1.1294497304526423, 'eval_runtime': 320.2133, 'eval_samples_per_second': 7.782, 'eval_steps_per_second': 0.487, 'epoch': 3.0}
2025-10-14 09:30:11 | {'loss': 0.9398, 'grad_norm': 3.5688228607177734, 'learning_rate': 4.2091577162238555e-05, 'epoch': 3.05}
2025-10-14 09:30:31 | {'loss': 0.7645, 'grad_norm': 3.608423948287964, 'learning_rate': 4.152628603730922e-05, 'epoch': 3.21}
2025-10-14 09:30:51 | {'loss': 0.7675, 'grad_norm': 3.7278053760528564, 'learning_rate': 4.096099491237988e-05, 'epoch': 3.37}
2025-10-14 09:31:11 | {'loss': 0.7706, 'grad_norm': 3.097214698791504, 'learning_rate': 4.039570378745054e-05, 'epoch': 3.53}
2025-10-14 09:31:31 | {'loss': 0.7777, 'grad_norm': 3.4168243408203125, 'learning_rate': 3.98304126625212e-05, 'epoch': 3.69}
2025-10-14 09:31:52 | {'loss': 0.7897, 'grad_norm': 3.4093806743621826, 'learning_rate': 3.926512153759186e-05, 'epoch': 3.85}
2025-10-14 09:37:27 | {'eval_loss': 1.4103279113769531, 'eval_rouge1': 0.44529357263304176, 'eval_rouge2': 0.2826772605058427, 'eval_rougeL': 0.4355270611302739, 'eval_rouge_sum': 1.1634978942691583, 'eval_runtime': 316.2495, 'eval_samples_per_second': 7.88, 'eval_steps_per_second': 0.493, 'epoch': 4.0}
2025-10-14 09:37:31 | {'loss': 0.7726, 'grad_norm': 2.9626846313476562, 'learning_rate': 3.8699830412662526e-05, 'epoch': 4.01}
2025-10-14 09:37:52 | {'loss': 0.5841, 'grad_norm': 4.1365437507629395, 'learning_rate': 3.813453928773318e-05, 'epoch': 4.17}
2025-10-14 09:38:11 | {'loss': 0.5981, 'grad_norm': 4.459263801574707, 'learning_rate': 3.756924816280384e-05, 'epoch': 4.33}
2025-10-14 09:38:32 | {'loss': 0.596, 'grad_norm': 3.432373046875, 'learning_rate': 3.700395703787451e-05, 'epoch': 4.49}
2025-10-14 09:38:52 | {'loss': 0.6139, 'grad_norm': 6.0225911140441895, 'learning_rate': 3.6438665912945167e-05, 'epoch': 4.65}
2025-10-14 09:39:12 | {'loss': 0.6229, 'grad_norm': 3.086092233657837, 'learning_rate': 3.587337478801583e-05, 'epoch': 4.82}
2025-10-14 09:39:32 | {'loss': 0.6301, 'grad_norm': 3.342611789703369, 'learning_rate': 3.530808366308649e-05, 'epoch': 4.98}
2025-10-14 09:45:02 | {'eval_loss': 1.47602379322052, 'eval_rouge1': 0.44185717686542875, 'eval_rouge2': 0.2786862883267776, 'eval_rougeL': 0.43153257418375585, 'eval_rouge_sum': 1.1520760393759621, 'eval_runtime': 326.4902, 'eval_samples_per_second': 7.633, 'eval_steps_per_second': 0.478, 'epoch': 5.0}
2025-10-14 09:45:21 | {'loss': 0.4864, 'grad_norm': 3.312227725982666, 'learning_rate': 3.474279253815715e-05, 'epoch': 5.14}
2025-10-14 09:45:41 | {'loss': 0.4667, 'grad_norm': 3.0194363594055176, 'learning_rate': 3.4177501413227814e-05, 'epoch': 5.3}
2025-10-14 09:50:04 | {'loss': 0.4813, 'grad_norm': 3.3658955097198486, 'learning_rate': 3.3612210288298476e-05, 'epoch': 5.46}
2025-10-14 09:50:24 | {'loss': 0.4782, 'grad_norm': 3.7881274223327637, 'learning_rate': 3.304691916336914e-05, 'epoch': 5.62}
2025-10-14 09:50:44 | {'loss': 0.4825, 'grad_norm': 3.570544958114624, 'learning_rate': 3.24816280384398e-05, 'epoch': 5.78}
2025-10-14 09:51:05 | {'loss': 0.4926, 'grad_norm': 3.6214921474456787, 'learning_rate': 3.191633691351046e-05, 'epoch': 5.94}
2025-10-14 09:57:03 | {'eval_loss': 1.5393247604370117, 'eval_rouge1': 0.4391882478944783, 'eval_rouge2': 0.2820638949170777, 'eval_rougeL': 0.4308145088905421, 'eval_rouge_sum': 1.152066651702098, 'eval_runtime': 348.3504, 'eval_samples_per_second': 7.154, 'eval_steps_per_second': 0.448, 'epoch': 6.0}
2025-10-14 09:57:20 | {'loss': 0.4095, 'grad_norm': 3.1918914318084717, 'learning_rate': 3.1351045788581116e-05, 'epoch': 6.1}
2025-10-14 09:57:40 | {'loss': 0.3628, 'grad_norm': 3.0745151042938232, 'learning_rate': 3.0785754663651785e-05, 'epoch': 6.26}
2025-10-14 09:58:01 | {'loss': 0.3828, 'grad_norm': 2.846791982650757, 'learning_rate': 3.0220463538722443e-05, 'epoch': 6.42}
2025-10-14 09:58:22 | {'loss': 0.3818, 'grad_norm': 2.7377655506134033, 'learning_rate': 2.96551724137931e-05, 'epoch': 6.58}
2025-10-14 09:58:42 | {'loss': 0.3874, 'grad_norm': 3.4611546993255615, 'learning_rate': 2.9089881288863767e-05, 'epoch': 6.74}
2025-10-14 09:59:03 | {'loss': 0.3802, 'grad_norm': 2.8316755294799805, 'learning_rate': 2.852459016393443e-05, 'epoch': 6.9}
2025-10-14 10:05:23 | {'eval_loss': 1.6151819229125977, 'eval_rouge1': 0.45581088982766105, 'eval_rouge2': 0.2891347298781442, 'eval_rougeL': 0.4441621204397436, 'eval_rouge_sum': 1.189107740145549, 'eval_runtime': 366.3939, 'eval_samples_per_second': 6.801, 'eval_steps_per_second': 0.426, 'epoch': 7.0}
2025-10-14 10:05:35 | {'loss': 0.3465, 'grad_norm': 2.3611669540405273, 'learning_rate': 2.7959299039005087e-05, 'epoch': 7.06}
2025-10-14 10:05:54 | {'loss': 0.29, 'grad_norm': 2.750584602355957, 'learning_rate': 2.739400791407575e-05, 'epoch': 7.22}
2025-10-14 10:06:15 | {'loss': 0.2977, 'grad_norm': 2.9528920650482178, 'learning_rate': 2.6828716789146414e-05, 'epoch': 7.38}
2025-10-14 10:06:35 | {'loss': 0.3011, 'grad_norm': 3.5012831687927246, 'learning_rate': 2.6263425664217072e-05, 'epoch': 7.54}
2025-10-14 10:06:56 | {'loss': 0.3003, 'grad_norm': 2.7560012340545654, 'learning_rate': 2.5698134539287734e-05, 'epoch': 7.7}
2025-10-14 10:07:17 | {'loss': 0.3065, 'grad_norm': 2.9484691619873047, 'learning_rate': 2.51328434143584e-05, 'epoch': 7.87}
2025-10-14 10:13:29 | {'eval_loss': 1.67362642288208, 'eval_rouge1': 0.44733159642073517, 'eval_rouge2': 0.2872476069874094, 'eval_rougeL': 0.4369426349848502, 'eval_rouge_sum': 1.1715218383929948, 'eval_runtime': 354.8039, 'eval_samples_per_second': 7.024, 'eval_steps_per_second': 0.44, 'epoch': 8.0}
2025-10-14 10:13:35 | {'loss': 0.296, 'grad_norm': 5.490448951721191, 'learning_rate': 2.4567552289429058e-05, 'epoch': 8.03}
2025-10-14 10:13:56 | {'loss': 0.2238, 'grad_norm': 2.4418323040008545, 'learning_rate': 2.4002261164499716e-05, 'epoch': 8.19}
2025-10-14 10:14:16 | {'loss': 0.2348, 'grad_norm': 2.7151408195495605, 'learning_rate': 2.343697003957038e-05, 'epoch': 8.35}
2025-10-14 10:14:38 | {'loss': 0.2374, 'grad_norm': 3.213239908218384, 'learning_rate': 2.287167891464104e-05, 'epoch': 8.51}
2025-10-14 10:14:58 | {'loss': 0.2423, 'grad_norm': 3.0437374114990234, 'learning_rate': 2.2306387789711702e-05, 'epoch': 8.67}
2025-10-14 10:15:20 | {'loss': 0.2473, 'grad_norm': 2.816304922103882, 'learning_rate': 2.1741096664782364e-05, 'epoch': 8.83}
2025-10-14 10:15:41 | {'loss': 0.2467, 'grad_norm': 2.639594793319702, 'learning_rate': 2.1175805539853025e-05, 'epoch': 8.99}
2025-10-14 10:21:39 | {'eval_loss': 1.7135964632034302, 'eval_rouge1': 0.46230180004178956, 'eval_rouge2': 0.29788742317738104, 'eval_rougeL': 0.4507008890779583, 'eval_rouge_sum': 1.210890112297129, 'eval_runtime': 356.3885, 'eval_samples_per_second': 6.992, 'eval_steps_per_second': 0.438, 'epoch': 9.0}
2025-10-14 10:22:02 | {'loss': 0.1884, 'grad_norm': 2.4778997898101807, 'learning_rate': 2.0610514414923687e-05, 'epoch': 9.15}
2025-10-14 10:22:24 | {'loss': 0.1924, 'grad_norm': 2.6228678226470947, 'learning_rate': 2.0045223289994346e-05, 'epoch': 9.31}
2025-10-14 10:22:44 | {'loss': 0.1869, 'grad_norm': 2.3802731037139893, 'learning_rate': 1.947993216506501e-05, 'epoch': 9.47}
2025-10-14 10:23:05 | {'loss': 0.193, 'grad_norm': 2.1081719398498535, 'learning_rate': 1.891464104013567e-05, 'epoch': 9.63}
2025-10-14 10:23:27 | {'loss': 0.193, 'grad_norm': 2.3111860752105713, 'learning_rate': 1.834934991520633e-05, 'epoch': 9.79}
2025-10-14 10:23:47 | {'loss': 0.1969, 'grad_norm': 2.428452968597412, 'learning_rate': 1.7784058790276993e-05, 'epoch': 9.95}
2025-10-14 10:29:49 | {'eval_loss': 1.7667138576507568, 'eval_rouge1': 0.4567754285325296, 'eval_rouge2': 0.2911703795306811, 'eval_rougeL': 0.4467762700227013, 'eval_rouge_sum': 1.194722078085912, 'eval_runtime': 355.8531, 'eval_samples_per_second': 7.003, 'eval_steps_per_second': 0.438, 'epoch': 10.0}
2025-10-14 10:30:07 | {'loss': 0.1627, 'grad_norm': 2.3005788326263428, 'learning_rate': 1.7218767665347655e-05, 'epoch': 10.11}
2025-10-14 10:30:26 | {'loss': 0.1505, 'grad_norm': 2.728832721710205, 'learning_rate': 1.6653476540418316e-05, 'epoch': 10.27}
2025-10-14 10:30:48 | {'loss': 0.1535, 'grad_norm': 2.4417247772216797, 'learning_rate': 1.6088185415488978e-05, 'epoch': 10.43}
2025-10-14 10:31:08 | {'loss': 0.1568, 'grad_norm': 2.572190999984741, 'learning_rate': 1.552289429055964e-05, 'epoch': 10.59}
2025-10-14 10:31:30 | {'loss': 0.1587, 'grad_norm': 2.1269900798797607, 'learning_rate': 1.4957603165630298e-05, 'epoch': 10.75}
2025-10-14 10:31:51 | {'loss': 0.1593, 'grad_norm': 2.272793769836426, 'learning_rate': 1.4392312040700962e-05, 'epoch': 10.91}
2025-10-14 10:37:22 | {'eval_loss': 1.807669997215271, 'eval_rouge1': 0.4630051794830225, 'eval_rouge2': 0.2930134862637478, 'eval_rougeL': 0.45148830220035874, 'eval_rouge_sum': 1.207506967947129, 'eval_runtime': 320.9287, 'eval_samples_per_second': 7.765, 'eval_steps_per_second': 0.486, 'epoch': 11.0}
2025-10-14 10:37:34 | {'loss': 0.1434, 'grad_norm': 2.0203866958618164, 'learning_rate': 1.3827020915771624e-05, 'epoch': 11.08}
2025-10-14 10:37:54 | {'loss': 0.1279, 'grad_norm': 2.0377004146575928, 'learning_rate': 1.3261729790842284e-05, 'epoch': 11.24}
2025-10-14 10:38:13 | {'loss': 0.1263, 'grad_norm': 2.0124855041503906, 'learning_rate': 1.2696438665912946e-05, 'epoch': 11.4}
2025-10-14 10:38:34 | {'loss': 0.1283, 'grad_norm': 1.7988698482513428, 'learning_rate': 1.2131147540983608e-05, 'epoch': 11.56}
2025-10-14 10:38:53 | {'loss': 0.1296, 'grad_norm': 1.9415769577026367, 'learning_rate': 1.156585641605427e-05, 'epoch': 11.72}
2025-10-14 10:39:14 | {'loss': 0.1299, 'grad_norm': 2.387305736541748, 'learning_rate': 1.100056529112493e-05, 'epoch': 11.88}
2025-10-14 10:44:46 | {'eval_loss': 1.840354323387146, 'eval_rouge1': 0.4684592708472068, 'eval_rouge2': 0.2978512075108336, 'eval_rougeL': 0.45696769011361227, 'eval_rouge_sum': 1.2232781684716527, 'eval_runtime': 317.5151, 'eval_samples_per_second': 7.848, 'eval_steps_per_second': 0.491, 'epoch': 12.0}
2025-10-14 10:44:53 | {'loss': 0.1249, 'grad_norm': 1.9434139728546143, 'learning_rate': 1.0435274166195591e-05, 'epoch': 12.04}
2025-10-14 10:45:14 | {'loss': 0.106, 'grad_norm': 1.9816396236419678, 'learning_rate': 9.869983041266251e-06, 'epoch': 12.2}
2025-10-14 10:45:33 | {'loss': 0.1064, 'grad_norm': 1.6186896562576294, 'learning_rate': 9.304691916336913e-06, 'epoch': 12.36}
2025-10-14 10:45:53 | {'loss': 0.1089, 'grad_norm': 2.3329484462738037, 'learning_rate': 8.739400791407577e-06, 'epoch': 12.52}
2025-10-14 10:46:12 | {'loss': 0.1075, 'grad_norm': 1.8710182905197144, 'learning_rate': 8.174109666478237e-06, 'epoch': 12.68}
2025-10-14 10:46:33 | {'loss': 0.11, 'grad_norm': 2.1796677112579346, 'learning_rate': 7.608818541548899e-06, 'epoch': 12.84}
2025-10-14 10:52:11 | {'eval_loss': 1.8683029413223267, 'eval_rouge1': 0.46359066599431, 'eval_rouge2': 0.2965332173114022, 'eval_rougeL': 0.45189439238913676, 'eval_rouge_sum': 1.212018275694849, 'eval_runtime': 317.6461, 'eval_samples_per_second': 7.845, 'eval_steps_per_second': 0.491, 'epoch': 13.0}
2025-10-14 10:52:14 | {'loss': 0.1073, 'grad_norm': 1.8532130718231201, 'learning_rate': 7.04352741661956e-06, 'epoch': 13.0}
2025-10-14 10:52:34 | {'loss': 0.0954, 'grad_norm': 1.8036068677902222, 'learning_rate': 6.478236291690221e-06, 'epoch': 13.16}
2025-10-14 10:52:53 | {'loss': 0.0939, 'grad_norm': 1.8107554912567139, 'learning_rate': 5.912945166760882e-06, 'epoch': 13.32}
2025-10-14 10:53:14 | {'loss': 0.0927, 'grad_norm': 2.0503406524658203, 'learning_rate': 5.347654041831543e-06, 'epoch': 13.48}
2025-10-14 10:53:34 | {'loss': 0.0944, 'grad_norm': 2.370595693588257, 'learning_rate': 4.782362916902205e-06, 'epoch': 13.64}
2025-10-14 10:53:53 | {'loss': 0.0909, 'grad_norm': 1.7384443283081055, 'learning_rate': 4.217071791972866e-06, 'epoch': 13.8}
2025-10-14 10:54:14 | {'loss': 0.0949, 'grad_norm': 1.6027328968048096, 'learning_rate': 3.651780667043528e-06, 'epoch': 13.96}
2025-10-14 10:59:33 | {'eval_loss': 1.8891512155532837, 'eval_rouge1': 0.46097921811283604, 'eval_rouge2': 0.29392765272135696, 'eval_rougeL': 0.4498180781048314, 'eval_rouge_sum': 1.2047249489390244, 'eval_runtime': 314.7035, 'eval_samples_per_second': 7.919, 'eval_steps_per_second': 0.496, 'epoch': 14.0}
2025-10-14 10:59:51 | {'loss': 0.0866, 'grad_norm': 1.6524708271026611, 'learning_rate': 3.086489542114189e-06, 'epoch': 14.13}
2025-10-14 11:00:10 | {'loss': 0.084, 'grad_norm': 1.676949381828308, 'learning_rate': 2.5211984171848503e-06, 'epoch': 14.29}
2025-10-14 11:00:31 | {'loss': 0.0842, 'grad_norm': 1.745793104171753, 'learning_rate': 1.9559072922555117e-06, 'epoch': 14.45}
2025-10-14 11:00:52 | {'loss': 0.0828, 'grad_norm': 1.860117793083191, 'learning_rate': 1.390616167326173e-06, 'epoch': 14.61}
2025-10-14 11:01:11 | {'loss': 0.0839, 'grad_norm': 1.5867588520050049, 'learning_rate': 8.253250423968344e-07, 'epoch': 14.77}
2025-10-14 11:01:31 | {'loss': 0.0824, 'grad_norm': 1.7275705337524414, 'learning_rate': 2.600339174674958e-07, 'epoch': 14.93}
2025-10-14 11:06:55 | {'eval_loss': 1.9005203247070312, 'eval_rouge1': 0.460669848912978, 'eval_rouge2': 0.29329732811199555, 'eval_rougeL': 0.4494088960040154, 'eval_rouge_sum': 1.203376073028989, 'eval_runtime': 315.3576, 'eval_samples_per_second': 7.902, 'eval_steps_per_second': 0.495, 'epoch': 15.0}
2025-10-14 11:06:58 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-14 11:06:58 | {'train_runtime': 7117.7509, 'train_samples_per_second': 21.0, 'train_steps_per_second': 1.313, 'train_loss': 0.49458812644227806, 'epoch': 15.0}
2025-10-14 11:06:58 | 최종 모델 저장 중...
2025-10-14 11:07:00 | → 모델 저장 위치: experiments/20251014/20251014_090813_kobart_balanced/fold_1/default/final_model
2025-10-14 11:07:00 | 최종 평가 중...
2025-10-14 11:12:14 | 최종 평가 결과:
2025-10-14 11:12:14 | eval_rouge1: 0.4685
2025-10-14 11:12:14 | eval_rouge2: 0.2979
2025-10-14 11:12:14 | eval_rougeL: 0.4570
2025-10-14 11:12:14 | eval_rouge_sum: 1.2233
2025-10-14 11:12:14 | ============================================================
2025-10-14 11:12:14 | ✅ 학습 완료!
2025-10-14 11:12:14 | ============================================================
2025-10-14 11:12:14 | ========================================
2025-10-14 11:12:14 | ========================================
2025-10-14 11:12:14 | 학습: 9965개
2025-10-14 11:12:14 | 검증: 2492개
2025-10-14 11:12:14 | 모델 타입: encoder_decoder
2025-10-14 11:12:14 | ============================================================
2025-10-14 11:12:14 | 모델 및 토크나이저 로딩 시작
2025-10-14 11:12:14 | ============================================================
2025-10-14 11:12:14 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-14 11:12:15 | 모델 로딩: digit82/kobart-summarization
2025-10-14 11:12:15 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-14 11:12:17 | → 디바이스: cuda
2025-10-14 11:12:17 | → 전체 파라미터: 123,859,968
2025-10-14 11:12:17 | → 학습 가능 파라미터: 123,859,968
2025-10-14 11:12:17 | ============================================================
2025-10-14 11:12:17 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-14 11:12:17 | ============================================================
2025-10-14 11:12:18 | ============================================================
2025-10-14 11:12:18 | 모델 학습 시작
2025-10-14 11:12:18 | ============================================================
2025-10-14 11:12:18 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:253: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-14 11:12:18 | 학습 진행 중...
2025-10-14 11:12:40 | {'loss': 2.1531, 'grad_norm': 5.2561445236206055, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.16}
2025-10-14 11:12:59 | {'loss': 1.6606, 'grad_norm': 4.699923038482666, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.32}
2025-10-14 11:13:20 | {'loss': 1.5422, 'grad_norm': 3.527829170227051, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.48}
2025-10-14 11:13:39 | {'loss': 1.525, 'grad_norm': 3.8381850719451904, 'learning_rate': 3.99e-05, 'epoch': 0.64}
2025-10-14 11:14:00 | {'loss': 1.4971, 'grad_norm': 3.2452187538146973, 'learning_rate': 4.99e-05, 'epoch': 0.8}
2025-10-14 11:14:20 | {'loss': 1.4735, 'grad_norm': 4.194812297821045, 'learning_rate': 4.944036178631996e-05, 'epoch': 0.96}
2025-10-14 11:19:44 | {'eval_loss': 1.4006688594818115, 'eval_rouge1': 0.39324629779240255, 'eval_rouge2': 0.2514010371929978, 'eval_rougeL': 0.38655282709141825, 'eval_rouge_sum': 1.0312001620768185, 'eval_runtime': 319.2127, 'eval_samples_per_second': 7.807, 'eval_steps_per_second': 0.489, 'epoch': 1.0}
2025-10-14 11:20:03 | {'loss': 1.3023, 'grad_norm': 4.102224349975586, 'learning_rate': 4.887507066139062e-05, 'epoch': 1.12}
2025-10-14 11:20:22 | {'loss': 1.2461, 'grad_norm': 3.726137638092041, 'learning_rate': 4.830977953646128e-05, 'epoch': 1.28}
2025-10-14 11:20:43 | {'loss': 1.2589, 'grad_norm': 3.5481085777282715, 'learning_rate': 4.774448841153194e-05, 'epoch': 1.44}
2025-10-14 11:21:03 | {'loss': 1.2574, 'grad_norm': 3.1859331130981445, 'learning_rate': 4.71791972866026e-05, 'epoch': 1.61}
2025-10-14 11:21:23 | {'loss': 1.2697, 'grad_norm': 3.1904406547546387, 'learning_rate': 4.661390616167327e-05, 'epoch': 1.77}
2025-10-14 11:21:43 | {'loss': 1.2433, 'grad_norm': 3.4772472381591797, 'learning_rate': 4.604861503674392e-05, 'epoch': 1.93}
2025-10-14 11:27:10 | {'eval_loss': 1.3496073484420776, 'eval_rouge1': 0.4080423609077036, 'eval_rouge2': 0.26043452513042503, 'eval_rougeL': 0.39943160246898496, 'eval_rouge_sum': 1.0679084885071137, 'eval_runtime': 317.8294, 'eval_samples_per_second': 7.841, 'eval_steps_per_second': 0.491, 'epoch': 2.0}
2025-10-14 11:27:22 | {'loss': 1.0908, 'grad_norm': 3.4605956077575684, 'learning_rate': 4.5483323911814584e-05, 'epoch': 2.09}
2025-10-14 11:27:43 | {'loss': 0.9528, 'grad_norm': 3.4797115325927734, 'learning_rate': 4.491803278688525e-05, 'epoch': 2.25}
2025-10-14 11:28:02 | {'loss': 0.9684, 'grad_norm': 3.2387893199920654, 'learning_rate': 4.435274166195591e-05, 'epoch': 2.41}
2025-10-14 11:28:23 | {'loss': 0.9798, 'grad_norm': 3.3345117568969727, 'learning_rate': 4.378745053702657e-05, 'epoch': 2.57}
2025-10-14 11:28:42 | {'loss': 1.003, 'grad_norm': 3.5576274394989014, 'learning_rate': 4.322215941209723e-05, 'epoch': 2.73}
2025-10-14 11:29:02 | {'loss': 0.9893, 'grad_norm': 3.3942227363586426, 'learning_rate': 4.2656868287167893e-05, 'epoch': 2.89}
2025-10-14 11:34:34 | {'eval_loss': 1.368067979812622, 'eval_rouge1': 0.4373247677725314, 'eval_rouge2': 0.2776389653530335, 'eval_rougeL': 0.42827914139993645, 'eval_rouge_sum': 1.1432428745255014, 'eval_runtime': 317.3668, 'eval_samples_per_second': 7.852, 'eval_steps_per_second': 0.492, 'epoch': 3.0}
2025-10-14 11:34:42 | {'loss': 0.9243, 'grad_norm': 3.4638242721557617, 'learning_rate': 4.2091577162238555e-05, 'epoch': 3.05}
2025-10-14 11:35:03 | {'loss': 0.7436, 'grad_norm': 3.5735902786254883, 'learning_rate': 4.152628603730922e-05, 'epoch': 3.21}
2025-10-14 11:35:22 | {'loss': 0.7567, 'grad_norm': 3.232393264770508, 'learning_rate': 4.096099491237988e-05, 'epoch': 3.37}
2025-10-14 11:35:43 | {'loss': 0.7664, 'grad_norm': 3.2060296535491943, 'learning_rate': 4.039570378745054e-05, 'epoch': 3.53}
2025-10-14 11:36:03 | {'loss': 0.7882, 'grad_norm': 3.122283458709717, 'learning_rate': 3.98304126625212e-05, 'epoch': 3.69}
2025-10-14 11:36:23 | {'loss': 0.7728, 'grad_norm': 3.3828539848327637, 'learning_rate': 3.926512153759186e-05, 'epoch': 3.85}
2025-10-14 11:42:01 | {'eval_loss': 1.4339382648468018, 'eval_rouge1': 0.4650835088741048, 'eval_rouge2': 0.2906803780020088, 'eval_rougeL': 0.45201786889030976, 'eval_rouge_sum': 1.2077817557664234, 'eval_runtime': 318.6032, 'eval_samples_per_second': 7.822, 'eval_steps_per_second': 0.49, 'epoch': 4.0}
2025-10-14 11:42:06 | {'loss': 0.7724, 'grad_norm': 2.6578595638275146, 'learning_rate': 3.8699830412662526e-05, 'epoch': 4.01}
2025-10-14 11:42:26 | {'loss': 0.5791, 'grad_norm': 3.264491319656372, 'learning_rate': 3.813453928773318e-05, 'epoch': 4.17}
2025-10-14 11:42:47 | {'loss': 0.5912, 'grad_norm': 3.669292688369751, 'learning_rate': 3.756924816280384e-05, 'epoch': 4.33}
2025-10-14 11:43:06 | {'loss': 0.606, 'grad_norm': 3.336945056915283, 'learning_rate': 3.700395703787451e-05, 'epoch': 4.49}
2025-10-14 11:43:27 | {'loss': 0.6086, 'grad_norm': 3.572202682495117, 'learning_rate': 3.6438665912945167e-05, 'epoch': 4.65}
2025-10-14 11:43:48 | {'loss': 0.6162, 'grad_norm': 3.7970798015594482, 'learning_rate': 3.587337478801583e-05, 'epoch': 4.82}
2025-10-14 11:44:07 | {'loss': 0.6164, 'grad_norm': 2.990370512008667, 'learning_rate': 3.530808366308649e-05, 'epoch': 4.98}
2025-10-14 11:49:32 | {'eval_loss': 1.5000213384628296, 'eval_rouge1': 0.44051911247092457, 'eval_rouge2': 0.27913773046525847, 'eval_rougeL': 0.4323495561396409, 'eval_rouge_sum': 1.152006399075824, 'eval_runtime': 322.1582, 'eval_samples_per_second': 7.735, 'eval_steps_per_second': 0.484, 'epoch': 5.0}
2025-10-14 11:49:53 | {'loss': 0.4727, 'grad_norm': 3.3002817630767822, 'learning_rate': 3.474279253815715e-05, 'epoch': 5.14}
2025-10-14 11:50:13 | {'loss': 0.4578, 'grad_norm': 3.33638334274292, 'learning_rate': 3.4177501413227814e-05, 'epoch': 5.3}
2025-10-14 11:50:33 | {'loss': 0.4673, 'grad_norm': 2.989382028579712, 'learning_rate': 3.3612210288298476e-05, 'epoch': 5.46}
2025-10-14 11:50:53 | {'loss': 0.4776, 'grad_norm': 4.244324207305908, 'learning_rate': 3.304691916336914e-05, 'epoch': 5.62}
2025-10-14 11:51:14 | {'loss': 0.4812, 'grad_norm': 3.3879714012145996, 'learning_rate': 3.24816280384398e-05, 'epoch': 5.78}
2025-10-14 11:51:34 | {'loss': 0.4948, 'grad_norm': 3.7506861686706543, 'learning_rate': 3.191633691351046e-05, 'epoch': 5.94}
2025-10-14 11:57:03 | {'eval_loss': 1.5549668073654175, 'eval_rouge1': 0.45168943717690924, 'eval_rouge2': 0.28790744570896437, 'eval_rougeL': 0.4414237013966749, 'eval_rouge_sum': 1.1810205842825485, 'eval_runtime': 320.7371, 'eval_samples_per_second': 7.77, 'eval_steps_per_second': 0.486, 'epoch': 6.0}
2025-10-14 11:57:18 | {'loss': 0.4059, 'grad_norm': 2.8419480323791504, 'learning_rate': 3.1351045788581116e-05, 'epoch': 6.1}
2025-10-14 11:57:39 | {'loss': 0.3576, 'grad_norm': 2.6977412700653076, 'learning_rate': 3.0785754663651785e-05, 'epoch': 6.26}
2025-10-14 11:57:58 | {'loss': 0.3688, 'grad_norm': 3.1269333362579346, 'learning_rate': 3.0220463538722443e-05, 'epoch': 6.42}
2025-10-14 11:58:18 | {'loss': 0.3738, 'grad_norm': 3.4320013523101807, 'learning_rate': 2.96551724137931e-05, 'epoch': 6.58}
2025-10-14 11:58:38 | {'loss': 0.3793, 'grad_norm': 3.212376832962036, 'learning_rate': 2.9089881288863767e-05, 'epoch': 6.74}
2025-10-14 11:58:59 | {'loss': 0.3854, 'grad_norm': 2.702244520187378, 'learning_rate': 2.852459016393443e-05, 'epoch': 6.9}
2025-10-14 12:04:27 | {'eval_loss': 1.6097424030303955, 'eval_rouge1': 0.45238939177796295, 'eval_rouge2': 0.28906698936276126, 'eval_rougeL': 0.44247347079641985, 'eval_rouge_sum': 1.183929851937144, 'eval_runtime': 315.9294, 'eval_samples_per_second': 7.888, 'eval_steps_per_second': 0.494, 'epoch': 7.0}
2025-10-14 12:04:29 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-14 12:04:29 | {'train_runtime': 3130.3655, 'train_samples_per_second': 47.75, 'train_steps_per_second': 2.985, 'train_loss': 0.8694636002234214, 'epoch': 7.0}
2025-10-14 12:04:29 | 최종 모델 저장 중...
2025-10-14 12:04:30 | → 모델 저장 위치: experiments/20251014/20251014_090813_kobart_balanced/fold_2/default/final_model
2025-10-14 12:04:30 | 최종 평가 중...
2025-10-14 12:09:42 | 최종 평가 결과:
2025-10-14 12:09:42 | eval_rouge1: 0.4651
2025-10-14 12:09:42 | eval_rouge2: 0.2907
2025-10-14 12:09:42 | eval_rougeL: 0.4520
2025-10-14 12:09:42 | eval_rouge_sum: 1.2078
2025-10-14 12:09:42 | ============================================================
2025-10-14 12:09:42 | ✅ 학습 완료!
2025-10-14 12:09:42 | ============================================================
2025-10-14 12:09:42 | ========================================
2025-10-14 12:09:42 | ========================================
2025-10-14 12:09:42 | 학습: 9966개
2025-10-14 12:09:42 | 검증: 2491개
2025-10-14 12:09:42 | 모델 타입: encoder_decoder
2025-10-14 12:09:42 | ============================================================
2025-10-14 12:09:42 | 모델 및 토크나이저 로딩 시작
2025-10-14 12:09:42 | ============================================================
2025-10-14 12:09:42 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-14 12:09:43 | 모델 로딩: digit82/kobart-summarization
2025-10-14 12:09:43 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-14 12:09:45 | → 디바이스: cuda
2025-10-14 12:09:45 | → 전체 파라미터: 123,859,968
2025-10-14 12:09:45 | → 학습 가능 파라미터: 123,859,968
2025-10-14 12:09:45 | ============================================================
2025-10-14 12:09:45 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-14 12:09:45 | ============================================================
2025-10-14 12:09:45 | ============================================================
2025-10-14 12:09:45 | 모델 학습 시작
2025-10-14 12:09:45 | ============================================================
2025-10-14 12:09:45 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:253: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-14 12:09:45 | 학습 진행 중...
2025-10-14 12:10:07 | {'loss': 2.1503, 'grad_norm': 4.314073085784912, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.16}
2025-10-14 12:10:27 | {'loss': 1.6416, 'grad_norm': 4.289769172668457, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.32}
2025-10-14 12:10:47 | {'loss': 1.5598, 'grad_norm': 4.612136363983154, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.48}
2025-10-14 12:11:07 | {'loss': 1.5346, 'grad_norm': 3.9981653690338135, 'learning_rate': 3.99e-05, 'epoch': 0.64}
2025-10-14 12:11:27 | {'loss': 1.5059, 'grad_norm': 3.4102582931518555, 'learning_rate': 4.99e-05, 'epoch': 0.8}
2025-10-14 12:11:47 | {'loss': 1.4629, 'grad_norm': 3.5190682411193848, 'learning_rate': 4.944036178631996e-05, 'epoch': 0.96}
2025-10-14 12:17:06 | {'eval_loss': 1.391784906387329, 'eval_rouge1': 0.40044381042512794, 'eval_rouge2': 0.25002921848558846, 'eval_rougeL': 0.39318764084677915, 'eval_rouge_sum': 1.0436606697574955, 'eval_runtime': 313.8759, 'eval_samples_per_second': 7.936, 'eval_steps_per_second': 0.497, 'epoch': 1.0}
2025-10-14 12:17:24 | {'loss': 1.306, 'grad_norm': 3.410689115524292, 'learning_rate': 4.887507066139062e-05, 'epoch': 1.12}
2025-10-14 12:17:45 | {'loss': 1.263, 'grad_norm': 3.970885992050171, 'learning_rate': 4.830977953646128e-05, 'epoch': 1.28}
2025-10-14 12:18:04 | {'loss': 1.2653, 'grad_norm': 3.8668227195739746, 'learning_rate': 4.774448841153194e-05, 'epoch': 1.44}
2025-10-14 12:18:25 | {'loss': 1.2287, 'grad_norm': 16.553613662719727, 'learning_rate': 4.71791972866026e-05, 'epoch': 1.61}
2025-10-14 12:18:44 | {'loss': 1.2452, 'grad_norm': 4.41334342956543, 'learning_rate': 4.661390616167327e-05, 'epoch': 1.77}
2025-10-14 12:19:05 | {'loss': 1.2591, 'grad_norm': 3.4679551124572754, 'learning_rate': 4.604861503674392e-05, 'epoch': 1.93}
2025-10-14 12:24:28 | {'eval_loss': 1.3371732234954834, 'eval_rouge1': 0.41421705585439367, 'eval_rouge2': 0.2624120112984969, 'eval_rougeL': 0.4062799192369652, 'eval_rouge_sum': 1.0829089863898558, 'eval_runtime': 313.6644, 'eval_samples_per_second': 7.942, 'eval_steps_per_second': 0.497, 'epoch': 2.0}
2025-10-14 12:24:40 | {'loss': 1.085, 'grad_norm': 3.2149977684020996, 'learning_rate': 4.5483323911814584e-05, 'epoch': 2.09}
2025-10-14 12:25:01 | {'loss': 0.9752, 'grad_norm': 3.2011401653289795, 'learning_rate': 4.491803278688525e-05, 'epoch': 2.25}
2025-10-14 12:25:21 | {'loss': 0.9953, 'grad_norm': 3.3737547397613525, 'learning_rate': 4.435274166195591e-05, 'epoch': 2.41}
2025-10-14 12:25:42 | {'loss': 0.9646, 'grad_norm': 3.306830883026123, 'learning_rate': 4.378745053702657e-05, 'epoch': 2.57}
2025-10-14 12:26:01 | {'loss': 0.9944, 'grad_norm': 3.182112216949463, 'learning_rate': 4.322215941209723e-05, 'epoch': 2.73}
2025-10-14 12:26:22 | {'loss': 0.9873, 'grad_norm': 3.212055206298828, 'learning_rate': 4.2656868287167893e-05, 'epoch': 2.89}
2025-10-14 12:31:49 | {'eval_loss': 1.3487823009490967, 'eval_rouge1': 0.4288564500587998, 'eval_rouge2': 0.274424365278506, 'eval_rougeL': 0.42085119371765933, 'eval_rouge_sum': 1.1241320090549651, 'eval_runtime': 313.2191, 'eval_samples_per_second': 7.953, 'eval_steps_per_second': 0.498, 'epoch': 3.0}
2025-10-14 12:31:58 | {'loss': 0.9034, 'grad_norm': 3.025322198867798, 'learning_rate': 4.2091577162238555e-05, 'epoch': 3.05}
2025-10-14 12:32:19 | {'loss': 0.7452, 'grad_norm': 3.68784236907959, 'learning_rate': 4.152628603730922e-05, 'epoch': 3.21}
2025-10-14 12:32:38 | {'loss': 0.7551, 'grad_norm': 3.9345579147338867, 'learning_rate': 4.096099491237988e-05, 'epoch': 3.37}
2025-10-14 12:32:59 | {'loss': 0.7686, 'grad_norm': 3.77604079246521, 'learning_rate': 4.039570378745054e-05, 'epoch': 3.53}
2025-10-14 12:33:18 | {'loss': 0.7685, 'grad_norm': 3.256580352783203, 'learning_rate': 3.98304126625212e-05, 'epoch': 3.69}
2025-10-14 12:33:39 | {'loss': 0.7931, 'grad_norm': 3.1612887382507324, 'learning_rate': 3.926512153759186e-05, 'epoch': 3.85}
2025-10-14 12:39:12 | {'eval_loss': 1.4079314470291138, 'eval_rouge1': 0.4434460874243459, 'eval_rouge2': 0.28203746947729713, 'eval_rougeL': 0.43396161909047953, 'eval_rouge_sum': 1.1594451759921225, 'eval_runtime': 314.398, 'eval_samples_per_second': 7.923, 'eval_steps_per_second': 0.496, 'epoch': 4.0}
2025-10-14 12:39:17 | {'loss': 0.7779, 'grad_norm': 2.7055463790893555, 'learning_rate': 3.8699830412662526e-05, 'epoch': 4.01}
2025-10-14 12:39:38 | {'loss': 0.5743, 'grad_norm': 3.4591715335845947, 'learning_rate': 3.813453928773318e-05, 'epoch': 4.17}
2025-10-14 12:39:57 | {'loss': 0.5909, 'grad_norm': 3.3411507606506348, 'learning_rate': 3.756924816280384e-05, 'epoch': 4.33}
2025-10-14 12:40:18 | {'loss': 0.6, 'grad_norm': 3.5047287940979004, 'learning_rate': 3.700395703787451e-05, 'epoch': 4.49}
2025-10-14 12:40:37 | {'loss': 0.6077, 'grad_norm': 3.050433874130249, 'learning_rate': 3.6438665912945167e-05, 'epoch': 4.65}
2025-10-14 12:40:58 | {'loss': 0.6107, 'grad_norm': 3.0760626792907715, 'learning_rate': 3.587337478801583e-05, 'epoch': 4.82}
2025-10-14 12:41:19 | {'loss': 0.6213, 'grad_norm': 3.199930191040039, 'learning_rate': 3.530808366308649e-05, 'epoch': 4.98}
2025-10-14 12:46:35 | {'eval_loss': 1.4835114479064941, 'eval_rouge1': 0.4450022204854732, 'eval_rouge2': 0.2849970861073512, 'eval_rougeL': 0.43578431001266826, 'eval_rouge_sum': 1.1657836166054927, 'eval_runtime': 313.2818, 'eval_samples_per_second': 7.951, 'eval_steps_per_second': 0.498, 'epoch': 5.0}
2025-10-14 12:46:56 | {'loss': 0.4753, 'grad_norm': 2.85304594039917, 'learning_rate': 3.474279253815715e-05, 'epoch': 5.14}
2025-10-14 12:47:15 | {'loss': 0.4558, 'grad_norm': 3.181858777999878, 'learning_rate': 3.4177501413227814e-05, 'epoch': 5.3}
2025-10-14 12:47:36 | {'loss': 0.4632, 'grad_norm': 3.152881383895874, 'learning_rate': 3.3612210288298476e-05, 'epoch': 5.46}
2025-10-14 12:47:55 | {'loss': 0.4721, 'grad_norm': 3.110886335372925, 'learning_rate': 3.304691916336914e-05, 'epoch': 5.62}
2025-10-14 12:48:16 | {'loss': 0.4839, 'grad_norm': 3.1620185375213623, 'learning_rate': 3.24816280384398e-05, 'epoch': 5.78}
2025-10-14 12:48:37 | {'loss': 0.4864, 'grad_norm': 2.928189992904663, 'learning_rate': 3.191633691351046e-05, 'epoch': 5.94}
2025-10-14 12:53:59 | {'eval_loss': 1.5503826141357422, 'eval_rouge1': 0.44297111386274846, 'eval_rouge2': 0.2857012153235078, 'eval_rougeL': 0.43351994813123995, 'eval_rouge_sum': 1.1621922773174962, 'eval_runtime': 315.2383, 'eval_samples_per_second': 7.902, 'eval_steps_per_second': 0.495, 'epoch': 6.0}
2025-10-14 12:54:15 | {'loss': 0.4039, 'grad_norm': 3.065396308898926, 'learning_rate': 3.1351045788581116e-05, 'epoch': 6.1}
2025-10-14 12:54:35 | {'loss': 0.3587, 'grad_norm': 2.5986571311950684, 'learning_rate': 3.0785754663651785e-05, 'epoch': 6.26}
2025-10-14 12:54:56 | {'loss': 0.3657, 'grad_norm': 2.7397758960723877, 'learning_rate': 3.0220463538722443e-05, 'epoch': 6.42}
2025-10-14 12:55:17 | {'loss': 0.367, 'grad_norm': 3.2426137924194336, 'learning_rate': 2.96551724137931e-05, 'epoch': 6.58}
2025-10-14 12:55:36 | {'loss': 0.3753, 'grad_norm': 3.1636335849761963, 'learning_rate': 2.9089881288863767e-05, 'epoch': 6.74}
2025-10-14 12:55:57 | {'loss': 0.3784, 'grad_norm': 4.25323486328125, 'learning_rate': 2.852459016393443e-05, 'epoch': 6.9}
2025-10-14 13:01:27 | {'eval_loss': 1.6250367164611816, 'eval_rouge1': 0.44665727679084966, 'eval_rouge2': 0.2829208789860473, 'eval_rougeL': 0.4371173623424355, 'eval_rouge_sum': 1.1666955181193326, 'eval_runtime': 318.3748, 'eval_samples_per_second': 7.824, 'eval_steps_per_second': 0.49, 'epoch': 7.0}
2025-10-14 13:01:37 | {'loss': 0.3457, 'grad_norm': 3.4123950004577637, 'learning_rate': 2.7959299039005087e-05, 'epoch': 7.06}
2025-10-14 13:01:56 | {'loss': 0.2775, 'grad_norm': 2.6170945167541504, 'learning_rate': 2.739400791407575e-05, 'epoch': 7.22}
2025-10-14 13:02:17 | {'loss': 0.2903, 'grad_norm': 2.5443294048309326, 'learning_rate': 2.6828716789146414e-05, 'epoch': 7.38}
2025-10-14 13:02:38 | {'loss': 0.2936, 'grad_norm': 3.6643435955047607, 'learning_rate': 2.6263425664217072e-05, 'epoch': 7.54}
2025-10-14 13:02:58 | {'loss': 0.2965, 'grad_norm': 3.010754346847534, 'learning_rate': 2.5698134539287734e-05, 'epoch': 7.7}
2025-10-14 13:03:19 | {'loss': 0.3014, 'grad_norm': 3.5431289672851562, 'learning_rate': 2.51328434143584e-05, 'epoch': 7.87}
2025-10-14 13:08:52 | {'eval_loss': 1.6782944202423096, 'eval_rouge1': 0.46159756552782866, 'eval_rouge2': 0.29304189362371896, 'eval_rougeL': 0.4509144146040165, 'eval_rouge_sum': 1.205553873755564, 'eval_runtime': 316.6439, 'eval_samples_per_second': 7.867, 'eval_steps_per_second': 0.493, 'epoch': 8.0}
2025-10-14 13:08:58 | {'loss': 0.2924, 'grad_norm': 2.2987189292907715, 'learning_rate': 2.4567552289429058e-05, 'epoch': 8.03}
2025-10-14 13:09:18 | {'loss': 0.2256, 'grad_norm': 2.3798601627349854, 'learning_rate': 2.4002261164499716e-05, 'epoch': 8.19}
2025-10-14 13:09:38 | {'loss': 0.2274, 'grad_norm': 2.5452301502227783, 'learning_rate': 2.343697003957038e-05, 'epoch': 8.35}
2025-10-14 13:09:59 | {'loss': 0.236, 'grad_norm': 2.785989284515381, 'learning_rate': 2.287167891464104e-05, 'epoch': 8.51}
2025-10-14 13:10:18 | {'loss': 0.234, 'grad_norm': 2.870187520980835, 'learning_rate': 2.2306387789711702e-05, 'epoch': 8.67}
2025-10-14 13:10:39 | {'loss': 0.235, 'grad_norm': 2.638998508453369, 'learning_rate': 2.1741096664782364e-05, 'epoch': 8.83}
2025-10-14 13:11:00 | {'loss': 0.2373, 'grad_norm': 2.5254387855529785, 'learning_rate': 2.1175805539853025e-05, 'epoch': 8.99}
2025-10-14 13:16:18 | {'eval_loss': 1.7276428937911987, 'eval_rouge1': 0.44875898994537267, 'eval_rouge2': 0.28688052066283587, 'eval_rougeL': 0.4391322086016937, 'eval_rouge_sum': 1.1747717192099023, 'eval_runtime': 316.5262, 'eval_samples_per_second': 7.87, 'eval_steps_per_second': 0.493, 'epoch': 9.0}
2025-10-14 13:16:40 | {'loss': 0.1836, 'grad_norm': 2.6843554973602295, 'learning_rate': 2.0610514414923687e-05, 'epoch': 9.15}
2025-10-14 13:16:59 | {'loss': 0.1848, 'grad_norm': 2.6541688442230225, 'learning_rate': 2.0045223289994346e-05, 'epoch': 9.31}
2025-10-14 13:17:20 | {'loss': 0.1868, 'grad_norm': 2.6224987506866455, 'learning_rate': 1.947993216506501e-05, 'epoch': 9.47}
2025-10-14 13:17:41 | {'loss': 0.1891, 'grad_norm': 2.642625093460083, 'learning_rate': 1.891464104013567e-05, 'epoch': 9.63}
2025-10-14 13:18:00 | {'loss': 0.1924, 'grad_norm': 2.4269328117370605, 'learning_rate': 1.834934991520633e-05, 'epoch': 9.79}
2025-10-14 13:18:21 | {'loss': 0.1883, 'grad_norm': 2.5876662731170654, 'learning_rate': 1.7784058790276993e-05, 'epoch': 9.95}
2025-10-14 13:23:44 | {'eval_loss': 1.7849719524383545, 'eval_rouge1': 0.4673043028189116, 'eval_rouge2': 0.2994002589605897, 'eval_rougeL': 0.45603496740355653, 'eval_rouge_sum': 1.2227395291830578, 'eval_runtime': 317.0691, 'eval_samples_per_second': 7.856, 'eval_steps_per_second': 0.492, 'epoch': 10.0}
2025-10-14 13:24:02 | {'loss': 0.158, 'grad_norm': 2.531646490097046, 'learning_rate': 1.7218767665347655e-05, 'epoch': 10.11}
2025-10-14 13:24:21 | {'loss': 0.151, 'grad_norm': 2.8234705924987793, 'learning_rate': 1.6653476540418316e-05, 'epoch': 10.27}
2025-10-14 13:24:42 | {'loss': 0.1522, 'grad_norm': 2.039577007293701, 'learning_rate': 1.6088185415488978e-05, 'epoch': 10.43}
2025-10-14 13:25:03 | {'loss': 0.1541, 'grad_norm': 1.9757193326950073, 'learning_rate': 1.552289429055964e-05, 'epoch': 10.59}
2025-10-14 13:25:22 | {'loss': 0.1538, 'grad_norm': 2.2070846557617188, 'learning_rate': 1.4957603165630298e-05, 'epoch': 10.75}
2025-10-14 13:25:44 | {'loss': 0.1525, 'grad_norm': 2.4647605419158936, 'learning_rate': 1.4392312040700962e-05, 'epoch': 10.91}
2025-10-14 13:31:13 | {'eval_loss': 1.8239377737045288, 'eval_rouge1': 0.4693847868789896, 'eval_rouge2': 0.2991398235849619, 'eval_rougeL': 0.45787105438508446, 'eval_rouge_sum': 1.226395664849036, 'eval_runtime': 318.9602, 'eval_samples_per_second': 7.81, 'eval_steps_per_second': 0.489, 'epoch': 11.0}
2025-10-14 13:31:25 | {'loss': 0.1399, 'grad_norm': 2.3594610691070557, 'learning_rate': 1.3827020915771624e-05, 'epoch': 11.08}
2025-10-14 13:31:46 | {'loss': 0.1219, 'grad_norm': 2.068671226501465, 'learning_rate': 1.3261729790842284e-05, 'epoch': 11.24}
2025-10-14 13:32:05 | {'loss': 0.1243, 'grad_norm': 1.6963233947753906, 'learning_rate': 1.2696438665912946e-05, 'epoch': 11.4}
2025-10-14 13:32:26 | {'loss': 0.1245, 'grad_norm': 2.1291587352752686, 'learning_rate': 1.2131147540983608e-05, 'epoch': 11.56}
2025-10-14 13:32:45 | {'loss': 0.1263, 'grad_norm': 2.1927554607391357, 'learning_rate': 1.156585641605427e-05, 'epoch': 11.72}
2025-10-14 13:33:06 | {'loss': 0.1271, 'grad_norm': 2.226623058319092, 'learning_rate': 1.100056529112493e-05, 'epoch': 11.88}
2025-10-14 13:38:40 | {'eval_loss': 1.8572896718978882, 'eval_rouge1': 0.4656085481156391, 'eval_rouge2': 0.2971952251765783, 'eval_rougeL': 0.4555747494840285, 'eval_rouge_sum': 1.218378522776246, 'eval_runtime': 319.2591, 'eval_samples_per_second': 7.802, 'eval_steps_per_second': 0.489, 'epoch': 12.0}
2025-10-14 13:38:49 | {'loss': 0.1209, 'grad_norm': 2.14213228225708, 'learning_rate': 1.0435274166195591e-05, 'epoch': 12.04}
2025-10-14 13:39:09 | {'loss': 0.1042, 'grad_norm': 2.113856792449951, 'learning_rate': 9.869983041266251e-06, 'epoch': 12.2}
2025-10-14 13:39:30 | {'loss': 0.106, 'grad_norm': 1.7449593544006348, 'learning_rate': 9.304691916336913e-06, 'epoch': 12.36}
2025-10-14 13:39:51 | {'loss': 0.1037, 'grad_norm': 1.7783935070037842, 'learning_rate': 8.739400791407577e-06, 'epoch': 12.52}
2025-10-14 13:40:11 | {'loss': 0.1086, 'grad_norm': 1.967507004737854, 'learning_rate': 8.174109666478237e-06, 'epoch': 12.68}
2025-10-14 13:40:32 | {'loss': 0.1082, 'grad_norm': 2.184154748916626, 'learning_rate': 7.608818541548899e-06, 'epoch': 12.84}
2025-10-14 13:46:11 | {'eval_loss': 1.88104248046875, 'eval_rouge1': 0.46145367845182395, 'eval_rouge2': 0.29554030591293723, 'eval_rougeL': 0.4515227756358736, 'eval_rouge_sum': 1.2085167600006348, 'eval_runtime': 319.7931, 'eval_samples_per_second': 7.789, 'eval_steps_per_second': 0.488, 'epoch': 13.0}
2025-10-14 13:46:13 | {'loss': 0.1056, 'grad_norm': 1.8251198530197144, 'learning_rate': 7.04352741661956e-06, 'epoch': 13.0}
2025-10-14 13:46:34 | {'loss': 0.0902, 'grad_norm': 2.072206497192383, 'learning_rate': 6.478236291690221e-06, 'epoch': 13.16}
2025-10-14 13:46:54 | {'loss': 0.0904, 'grad_norm': 1.7051960229873657, 'learning_rate': 5.912945166760882e-06, 'epoch': 13.32}
2025-10-14 13:47:15 | {'loss': 0.0912, 'grad_norm': 1.5238585472106934, 'learning_rate': 5.347654041831543e-06, 'epoch': 13.48}
2025-10-14 13:47:34 | {'loss': 0.0899, 'grad_norm': 2.3466975688934326, 'learning_rate': 4.782362916902205e-06, 'epoch': 13.64}
2025-10-14 13:47:55 | {'loss': 0.0919, 'grad_norm': 2.0059802532196045, 'learning_rate': 4.217071791972866e-06, 'epoch': 13.8}
2025-10-14 13:48:16 | {'loss': 0.0909, 'grad_norm': 1.7821807861328125, 'learning_rate': 3.651780667043528e-06, 'epoch': 13.96}
2025-10-14 13:53:38 | {'eval_loss': 1.9057300090789795, 'eval_rouge1': 0.46703948851962085, 'eval_rouge2': 0.3020785924054995, 'eval_rougeL': 0.45634664548433396, 'eval_rouge_sum': 1.2254647264094543, 'eval_runtime': 317.9351, 'eval_samples_per_second': 7.835, 'eval_steps_per_second': 0.491, 'epoch': 14.0}
2025-10-14 13:53:40 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-14 13:53:40 | {'train_runtime': 6234.5675, 'train_samples_per_second': 23.978, 'train_steps_per_second': 1.499, 'train_loss': 0.5188182055253114, 'epoch': 14.0}
2025-10-14 13:53:40 | 최종 모델 저장 중...
2025-10-14 13:53:42 | → 모델 저장 위치: experiments/20251014/20251014_090813_kobart_balanced/fold_3/default/final_model
2025-10-14 13:53:42 | 최종 평가 중...
2025-10-14 13:59:23 | 최종 평가 결과:
2025-10-14 13:59:23 | eval_rouge1: 0.4694
2025-10-14 13:59:23 | eval_rouge2: 0.2991
2025-10-14 13:59:23 | eval_rougeL: 0.4579
2025-10-14 13:59:23 | eval_rouge_sum: 1.2264
2025-10-14 13:59:23 | ============================================================
2025-10-14 13:59:23 | ✅ 학습 완료!
2025-10-14 13:59:23 | ============================================================
2025-10-14 13:59:23 | ========================================
2025-10-14 13:59:23 | ========================================
2025-10-14 13:59:23 | 학습: 9966개
2025-10-14 13:59:23 | 검증: 2491개
2025-10-14 13:59:23 | 모델 타입: encoder_decoder
2025-10-14 13:59:23 | ============================================================
2025-10-14 13:59:23 | 모델 및 토크나이저 로딩 시작
2025-10-14 13:59:23 | ============================================================
2025-10-14 13:59:23 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-14 13:59:24 | 모델 로딩: digit82/kobart-summarization
2025-10-14 13:59:24 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-14 13:59:26 | → 디바이스: cuda
2025-10-14 13:59:26 | → 전체 파라미터: 123,859,968
2025-10-14 13:59:26 | → 학습 가능 파라미터: 123,859,968
2025-10-14 13:59:26 | ============================================================
2025-10-14 13:59:26 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-14 13:59:26 | ============================================================
2025-10-14 13:59:26 | ============================================================
2025-10-14 13:59:26 | 모델 학습 시작
2025-10-14 13:59:26 | ============================================================
2025-10-14 13:59:26 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:253: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-14 13:59:26 | 학습 진행 중...
2025-10-14 13:59:48 | {'loss': 2.1629, 'grad_norm': 4.328639507293701, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.16}
2025-10-14 14:00:10 | {'loss': 1.6676, 'grad_norm': 4.451586723327637, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.32}
2025-10-14 14:00:32 | {'loss': 1.5605, 'grad_norm': 3.8663547039031982, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.48}
2025-10-14 14:00:53 | {'loss': 1.5225, 'grad_norm': 3.718086004257202, 'learning_rate': 3.99e-05, 'epoch': 0.64}
2025-10-14 14:01:15 | {'loss': 1.4943, 'grad_norm': 4.088637828826904, 'learning_rate': 4.99e-05, 'epoch': 0.8}
2025-10-14 14:01:37 | {'loss': 1.4856, 'grad_norm': 3.5218002796173096, 'learning_rate': 4.944036178631996e-05, 'epoch': 0.96}
2025-10-14 14:07:02 | {'eval_loss': 1.3936502933502197, 'eval_rouge1': 0.3900423208406374, 'eval_rouge2': 0.242841558240863, 'eval_rougeL': 0.38222969849459515, 'eval_rouge_sum': 1.0151135775760955, 'eval_runtime': 319.9269, 'eval_samples_per_second': 7.786, 'eval_steps_per_second': 0.488, 'epoch': 1.0}
2025-10-14 14:07:21 | {'loss': 1.2957, 'grad_norm': 3.025428056716919, 'learning_rate': 4.887507066139062e-05, 'epoch': 1.12}
2025-10-14 14:07:42 | {'loss': 1.253, 'grad_norm': 3.2348172664642334, 'learning_rate': 4.830977953646128e-05, 'epoch': 1.28}
2025-10-14 14:08:01 | {'loss': 1.2466, 'grad_norm': 3.6316773891448975, 'learning_rate': 4.774448841153194e-05, 'epoch': 1.44}
2025-10-14 14:08:22 | {'loss': 1.2595, 'grad_norm': 3.319521903991699, 'learning_rate': 4.71791972866026e-05, 'epoch': 1.61}
2025-10-14 14:08:42 | {'loss': 1.2544, 'grad_norm': 3.2523269653320312, 'learning_rate': 4.661390616167327e-05, 'epoch': 1.77}
2025-10-14 14:09:03 | {'loss': 1.2776, 'grad_norm': 3.4113781452178955, 'learning_rate': 4.604861503674392e-05, 'epoch': 1.93}
2025-10-14 14:14:35 | {'eval_loss': 1.3308420181274414, 'eval_rouge1': 0.4338896627769586, 'eval_rouge2': 0.27485882342477674, 'eval_rougeL': 0.42332694469305426, 'eval_rouge_sum': 1.1320754308947896, 'eval_runtime': 323.0547, 'eval_samples_per_second': 7.711, 'eval_steps_per_second': 0.483, 'epoch': 2.0}
2025-10-14 14:14:49 | {'loss': 1.0804, 'grad_norm': 3.624814510345459, 'learning_rate': 4.5483323911814584e-05, 'epoch': 2.09}
2025-10-14 14:15:10 | {'loss': 0.9763, 'grad_norm': 3.297778844833374, 'learning_rate': 4.491803278688525e-05, 'epoch': 2.25}
2025-10-14 14:15:30 | {'loss': 0.9646, 'grad_norm': 3.608116865158081, 'learning_rate': 4.435274166195591e-05, 'epoch': 2.41}
2025-10-14 14:15:50 | {'loss': 0.9743, 'grad_norm': 2.895113229751587, 'learning_rate': 4.378745053702657e-05, 'epoch': 2.57}
2025-10-14 14:16:11 | {'loss': 0.9929, 'grad_norm': 3.2810819149017334, 'learning_rate': 4.322215941209723e-05, 'epoch': 2.73}
2025-10-14 14:16:31 | {'loss': 0.9835, 'grad_norm': 3.471489667892456, 'learning_rate': 4.2656868287167893e-05, 'epoch': 2.89}
2025-10-14 14:22:09 | {'eval_loss': 1.3492239713668823, 'eval_rouge1': 0.4344960771799422, 'eval_rouge2': 0.2807464680820718, 'eval_rougeL': 0.42674231278924823, 'eval_rouge_sum': 1.1419848580512624, 'eval_runtime': 323.8543, 'eval_samples_per_second': 7.692, 'eval_steps_per_second': 0.482, 'epoch': 3.0}
2025-10-14 14:22:18 | {'loss': 0.9274, 'grad_norm': 4.020814418792725, 'learning_rate': 4.2091577162238555e-05, 'epoch': 3.05}
2025-10-14 14:22:38 | {'loss': 0.7359, 'grad_norm': 3.3748931884765625, 'learning_rate': 4.152628603730922e-05, 'epoch': 3.21}
2025-10-14 14:22:59 | {'loss': 0.7472, 'grad_norm': 3.360471248626709, 'learning_rate': 4.096099491237988e-05, 'epoch': 3.37}
2025-10-14 14:23:20 | {'loss': 0.7766, 'grad_norm': 3.4647486209869385, 'learning_rate': 4.039570378745054e-05, 'epoch': 3.53}
2025-10-14 14:23:40 | {'loss': 0.774, 'grad_norm': 3.2959911823272705, 'learning_rate': 3.98304126625212e-05, 'epoch': 3.69}
2025-10-14 14:24:00 | {'loss': 0.7954, 'grad_norm': 3.7131943702697754, 'learning_rate': 3.926512153759186e-05, 'epoch': 3.85}
2025-10-14 14:29:47 | {'eval_loss': 1.412736177444458, 'eval_rouge1': 0.4499980934230757, 'eval_rouge2': 0.28566049790740655, 'eval_rougeL': 0.43756343523525437, 'eval_rouge_sum': 1.1732220265657367, 'eval_runtime': 327.6965, 'eval_samples_per_second': 7.602, 'eval_steps_per_second': 0.476, 'epoch': 4.0}
2025-10-14 14:29:51 | {'loss': 0.7736, 'grad_norm': 2.888242244720459, 'learning_rate': 3.8699830412662526e-05, 'epoch': 4.01}
2025-10-14 14:30:12 | {'loss': 0.5731, 'grad_norm': 3.200859308242798, 'learning_rate': 3.813453928773318e-05, 'epoch': 4.17}
2025-10-14 14:30:32 | {'loss': 0.5922, 'grad_norm': 3.4119462966918945, 'learning_rate': 3.756924816280384e-05, 'epoch': 4.33}
2025-10-14 14:30:53 | {'loss': 0.5975, 'grad_norm': 3.3940823078155518, 'learning_rate': 3.700395703787451e-05, 'epoch': 4.49}
2025-10-14 14:31:14 | {'loss': 0.605, 'grad_norm': 3.1590332984924316, 'learning_rate': 3.6438665912945167e-05, 'epoch': 4.65}
2025-10-14 14:31:34 | {'loss': 0.6222, 'grad_norm': 3.5258777141571045, 'learning_rate': 3.587337478801583e-05, 'epoch': 4.82}
2025-10-14 14:31:55 | {'loss': 0.6137, 'grad_norm': 3.2095141410827637, 'learning_rate': 3.530808366308649e-05, 'epoch': 4.98}
2025-10-14 14:37:29 | {'eval_loss': 1.492132306098938, 'eval_rouge1': 0.4625684013097557, 'eval_rouge2': 0.29584446133314507, 'eval_rougeL': 0.44776875613746414, 'eval_rouge_sum': 1.206181618780365, 'eval_runtime': 330.6041, 'eval_samples_per_second': 7.535, 'eval_steps_per_second': 0.472, 'epoch': 5.0}
2025-10-14 14:37:49 | {'loss': 0.4724, 'grad_norm': 3.0265748500823975, 'learning_rate': 3.474279253815715e-05, 'epoch': 5.14}
2025-10-14 14:38:10 | {'loss': 0.4627, 'grad_norm': 3.2384159564971924, 'learning_rate': 3.4177501413227814e-05, 'epoch': 5.3}
2025-10-14 14:38:30 | {'loss': 0.4734, 'grad_norm': 3.5412185192108154, 'learning_rate': 3.3612210288298476e-05, 'epoch': 5.46}
2025-10-14 14:38:50 | {'loss': 0.4734, 'grad_norm': 3.067727565765381, 'learning_rate': 3.304691916336914e-05, 'epoch': 5.62}
2025-10-14 14:39:12 | {'loss': 0.4865, 'grad_norm': 3.571559190750122, 'learning_rate': 3.24816280384398e-05, 'epoch': 5.78}
2025-10-14 14:39:33 | {'loss': 0.481, 'grad_norm': 3.6559104919433594, 'learning_rate': 3.191633691351046e-05, 'epoch': 5.94}
2025-10-14 14:45:12 | {'eval_loss': 1.5466996431350708, 'eval_rouge1': 0.45739694076083864, 'eval_rouge2': 0.29167333494616643, 'eval_rougeL': 0.44661933417135974, 'eval_rouge_sum': 1.195689609878365, 'eval_runtime': 330.7368, 'eval_samples_per_second': 7.532, 'eval_steps_per_second': 0.472, 'epoch': 6.0}
2025-10-14 14:45:27 | {'loss': 0.4065, 'grad_norm': 2.5939784049987793, 'learning_rate': 3.1351045788581116e-05, 'epoch': 6.1}
2025-10-14 14:45:48 | {'loss': 0.3563, 'grad_norm': 2.961459159851074, 'learning_rate': 3.0785754663651785e-05, 'epoch': 6.26}
2025-10-14 14:46:08 | {'loss': 0.3685, 'grad_norm': 3.3761112689971924, 'learning_rate': 3.0220463538722443e-05, 'epoch': 6.42}
2025-10-14 14:46:29 | {'loss': 0.3709, 'grad_norm': 3.391608238220215, 'learning_rate': 2.96551724137931e-05, 'epoch': 6.58}
2025-10-14 14:46:49 | {'loss': 0.3814, 'grad_norm': 3.112426280975342, 'learning_rate': 2.9089881288863767e-05, 'epoch': 6.74}
2025-10-14 14:47:10 | {'loss': 0.3821, 'grad_norm': 3.0274438858032227, 'learning_rate': 2.852459016393443e-05, 'epoch': 6.9}
2025-10-14 14:52:54 | {'eval_loss': 1.6207855939865112, 'eval_rouge1': 0.4613149703599126, 'eval_rouge2': 0.2961810632696011, 'eval_rougeL': 0.4496483809226929, 'eval_rouge_sum': 1.2071444145522066, 'eval_runtime': 331.2834, 'eval_samples_per_second': 7.519, 'eval_steps_per_second': 0.471, 'epoch': 7.0}
2025-10-14 14:53:04 | {'loss': 0.3433, 'grad_norm': 2.7114572525024414, 'learning_rate': 2.7959299039005087e-05, 'epoch': 7.06}
2025-10-14 14:53:25 | {'loss': 0.2813, 'grad_norm': 2.9396777153015137, 'learning_rate': 2.739400791407575e-05, 'epoch': 7.22}
2025-10-14 14:53:45 | {'loss': 0.2898, 'grad_norm': 2.9981260299682617, 'learning_rate': 2.6828716789146414e-05, 'epoch': 7.38}
2025-10-14 14:54:06 | {'loss': 0.2955, 'grad_norm': 2.6565287113189697, 'learning_rate': 2.6263425664217072e-05, 'epoch': 7.54}
2025-10-14 14:54:27 | {'loss': 0.2933, 'grad_norm': 2.6825435161590576, 'learning_rate': 2.5698134539287734e-05, 'epoch': 7.7}
2025-10-14 14:54:47 | {'loss': 0.3033, 'grad_norm': 3.015878677368164, 'learning_rate': 2.51328434143584e-05, 'epoch': 7.87}
2025-10-14 15:00:35 | {'eval_loss': 1.6720725297927856, 'eval_rouge1': 0.46885379839274993, 'eval_rouge2': 0.3026880446712482, 'eval_rougeL': 0.4564478796973685, 'eval_rouge_sum': 1.2279897227613668, 'eval_runtime': 330.5402, 'eval_samples_per_second': 7.536, 'eval_steps_per_second': 0.472, 'epoch': 8.0}
2025-10-14 15:00:41 | {'loss': 0.2922, 'grad_norm': 2.317526340484619, 'learning_rate': 2.4567552289429058e-05, 'epoch': 8.03}
2025-10-14 15:01:02 | {'loss': 0.2273, 'grad_norm': 2.419520139694214, 'learning_rate': 2.4002261164499716e-05, 'epoch': 8.19}
2025-10-14 15:01:23 | {'loss': 0.2285, 'grad_norm': 2.883922815322876, 'learning_rate': 2.343697003957038e-05, 'epoch': 8.35}
2025-10-14 15:01:43 | {'loss': 0.2356, 'grad_norm': 2.6958703994750977, 'learning_rate': 2.287167891464104e-05, 'epoch': 8.51}
2025-10-14 15:02:04 | {'loss': 0.2342, 'grad_norm': 2.8900105953216553, 'learning_rate': 2.2306387789711702e-05, 'epoch': 8.67}
2025-10-14 15:02:24 | {'loss': 0.24, 'grad_norm': 2.7898001670837402, 'learning_rate': 2.1741096664782364e-05, 'epoch': 8.83}
2025-10-14 15:02:45 | {'loss': 0.2411, 'grad_norm': 2.974248170852661, 'learning_rate': 2.1175805539853025e-05, 'epoch': 8.99}
2025-10-14 15:08:20 | {'eval_loss': 1.7214535474777222, 'eval_rouge1': 0.469228917501182, 'eval_rouge2': 0.29802000385790983, 'eval_rougeL': 0.45574774268318397, 'eval_rouge_sum': 1.2229966640422758, 'eval_runtime': 333.6428, 'eval_samples_per_second': 7.466, 'eval_steps_per_second': 0.468, 'epoch': 9.0}
2025-10-14 15:08:42 | {'loss': 0.1831, 'grad_norm': 2.2281577587127686, 'learning_rate': 2.0610514414923687e-05, 'epoch': 9.15}
2025-10-14 15:09:02 | {'loss': 0.189, 'grad_norm': 3.2785067558288574, 'learning_rate': 2.0045223289994346e-05, 'epoch': 9.31}
2025-10-14 15:09:23 | {'loss': 0.1834, 'grad_norm': 2.0083837509155273, 'learning_rate': 1.947993216506501e-05, 'epoch': 9.47}
2025-10-14 15:09:44 | {'loss': 0.1901, 'grad_norm': 2.3687846660614014, 'learning_rate': 1.891464104013567e-05, 'epoch': 9.63}
2025-10-14 15:10:04 | {'loss': 0.1967, 'grad_norm': 2.5102391242980957, 'learning_rate': 1.834934991520633e-05, 'epoch': 9.79}
2025-10-14 15:10:25 | {'loss': 0.189, 'grad_norm': 2.2071218490600586, 'learning_rate': 1.7784058790276993e-05, 'epoch': 9.95}
2025-10-14 15:16:05 | {'eval_loss': 1.7765341997146606, 'eval_rouge1': 0.4723193027565001, 'eval_rouge2': 0.303826890023047, 'eval_rougeL': 0.45905334367292117, 'eval_rouge_sum': 1.2351995364524684, 'eval_runtime': 333.8197, 'eval_samples_per_second': 7.462, 'eval_steps_per_second': 0.467, 'epoch': 10.0}
2025-10-14 15:16:22 | {'loss': 0.1618, 'grad_norm': 2.391961097717285, 'learning_rate': 1.7218767665347655e-05, 'epoch': 10.11}
2025-10-14 15:16:43 | {'loss': 0.1508, 'grad_norm': 1.9941773414611816, 'learning_rate': 1.6653476540418316e-05, 'epoch': 10.27}
2025-10-14 15:17:03 | {'loss': 0.1504, 'grad_norm': 2.734686851501465, 'learning_rate': 1.6088185415488978e-05, 'epoch': 10.43}
2025-10-14 15:17:24 | {'loss': 0.1541, 'grad_norm': 2.3555290699005127, 'learning_rate': 1.552289429055964e-05, 'epoch': 10.59}
2025-10-14 15:17:44 | {'loss': 0.1549, 'grad_norm': 2.4065043926239014, 'learning_rate': 1.4957603165630298e-05, 'epoch': 10.75}
2025-10-14 15:18:05 | {'loss': 0.1551, 'grad_norm': 2.296760320663452, 'learning_rate': 1.4392312040700962e-05, 'epoch': 10.91}
2025-10-14 15:23:52 | {'eval_loss': 1.818512201309204, 'eval_rouge1': 0.46161808313451425, 'eval_rouge2': 0.29579135976236015, 'eval_rougeL': 0.44963628620775126, 'eval_rouge_sum': 1.2070457291046257, 'eval_runtime': 336.2162, 'eval_samples_per_second': 7.409, 'eval_steps_per_second': 0.464, 'epoch': 11.0}
2025-10-14 15:24:04 | {'loss': 0.1428, 'grad_norm': 2.4399943351745605, 'learning_rate': 1.3827020915771624e-05, 'epoch': 11.08}
2025-10-14 15:24:25 | {'loss': 0.1257, 'grad_norm': 2.0716874599456787, 'learning_rate': 1.3261729790842284e-05, 'epoch': 11.24}
2025-10-14 15:24:46 | {'loss': 0.1254, 'grad_norm': 2.4214584827423096, 'learning_rate': 1.2696438665912946e-05, 'epoch': 11.4}
2025-10-14 15:25:06 | {'loss': 0.1258, 'grad_norm': 2.431931734085083, 'learning_rate': 1.2131147540983608e-05, 'epoch': 11.56}
2025-10-14 15:25:27 | {'loss': 0.1241, 'grad_norm': 1.9574096202850342, 'learning_rate': 1.156585641605427e-05, 'epoch': 11.72}
2025-10-14 15:25:48 | {'loss': 0.1272, 'grad_norm': 2.5467538833618164, 'learning_rate': 1.100056529112493e-05, 'epoch': 11.88}
2025-10-14 15:31:43 | {'eval_loss': 1.8507388830184937, 'eval_rouge1': 0.4718162579334613, 'eval_rouge2': 0.30325617979939756, 'eval_rougeL': 0.4597417895336052, 'eval_rouge_sum': 1.234814227266464, 'eval_runtime': 340.2212, 'eval_samples_per_second': 7.322, 'eval_steps_per_second': 0.459, 'epoch': 12.0}
2025-10-14 15:31:51 | {'loss': 0.1212, 'grad_norm': 1.8760606050491333, 'learning_rate': 1.0435274166195591e-05, 'epoch': 12.04}
2025-10-14 15:32:12 | {'loss': 0.1027, 'grad_norm': 2.0425732135772705, 'learning_rate': 9.869983041266251e-06, 'epoch': 12.2}
2025-10-14 15:32:32 | {'loss': 0.1038, 'grad_norm': 1.9503788948059082, 'learning_rate': 9.304691916336913e-06, 'epoch': 12.36}
2025-10-14 15:32:53 | {'loss': 0.1083, 'grad_norm': 2.2031195163726807, 'learning_rate': 8.739400791407577e-06, 'epoch': 12.52}
2025-10-14 15:33:14 | {'loss': 0.1068, 'grad_norm': 2.284879684448242, 'learning_rate': 8.174109666478237e-06, 'epoch': 12.68}
2025-10-14 15:33:34 | {'loss': 0.1068, 'grad_norm': 1.5691760778427124, 'learning_rate': 7.608818541548899e-06, 'epoch': 12.84}
2025-10-14 15:39:35 | {'eval_loss': 1.8847378492355347, 'eval_rouge1': 0.4723163405940721, 'eval_rouge2': 0.30192508042527194, 'eval_rougeL': 0.45918008728122794, 'eval_rouge_sum': 1.233421508300572, 'eval_runtime': 340.4662, 'eval_samples_per_second': 7.316, 'eval_steps_per_second': 0.458, 'epoch': 13.0}
2025-10-14 15:39:38 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-14 15:39:38 | {'train_runtime': 6011.7266, 'train_samples_per_second': 24.866, 'train_steps_per_second': 1.554, 'train_loss': 0.5530209839822393, 'epoch': 13.0}
2025-10-14 15:39:38 | 최종 모델 저장 중...
2025-10-14 15:39:40 | → 모델 저장 위치: experiments/20251014/20251014_090813_kobart_balanced/fold_4/default/final_model
2025-10-14 15:39:40 | 최종 평가 중...
2025-10-14 15:45:20 | 최종 평가 결과:
2025-10-14 15:45:20 | eval_rouge1: 0.4723
2025-10-14 15:45:20 | eval_rouge2: 0.3038
2025-10-14 15:45:20 | eval_rougeL: 0.4591
2025-10-14 15:45:20 | eval_rouge_sum: 1.2352
2025-10-14 15:45:20 | ============================================================
2025-10-14 15:45:20 | ✅ 학습 완료!
2025-10-14 15:45:20 | ============================================================
2025-10-14 15:45:20 | ========================================
2025-10-14 15:45:20 | ========================================
2025-10-14 15:45:20 | 학습: 9966개
2025-10-14 15:45:20 | 검증: 2491개
2025-10-14 15:45:20 | 모델 타입: encoder_decoder
2025-10-14 15:45:20 | ============================================================
2025-10-14 15:45:20 | 모델 및 토크나이저 로딩 시작
2025-10-14 15:45:20 | ============================================================
2025-10-14 15:45:20 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-14 15:45:21 | 모델 로딩: digit82/kobart-summarization
2025-10-14 15:45:21 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-14 15:45:22 | → 디바이스: cuda
2025-10-14 15:45:22 | → 전체 파라미터: 123,859,968
2025-10-14 15:45:22 | → 학습 가능 파라미터: 123,859,968
2025-10-14 15:45:22 | ============================================================
2025-10-14 15:45:22 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-14 15:45:22 | ============================================================
2025-10-14 15:45:23 | ============================================================
2025-10-14 15:45:23 | 모델 학습 시작
2025-10-14 15:45:23 | ============================================================
2025-10-14 15:45:23 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:253: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-14 15:45:23 | 학습 진행 중...
2025-10-14 15:45:44 | {'loss': 2.1403, 'grad_norm': 4.651334285736084, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.16}
2025-10-14 15:46:05 | {'loss': 1.638, 'grad_norm': 4.068536281585693, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.32}
2025-10-14 15:46:26 | {'loss': 1.5847, 'grad_norm': 3.6712734699249268, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.48}
2025-10-14 15:46:47 | {'loss': 1.5251, 'grad_norm': 3.8082823753356934, 'learning_rate': 3.99e-05, 'epoch': 0.64}
2025-10-14 15:47:07 | {'loss': 1.4886, 'grad_norm': 3.929732322692871, 'learning_rate': 4.99e-05, 'epoch': 0.8}
2025-10-14 15:47:28 | {'loss': 1.4626, 'grad_norm': 3.6515393257141113, 'learning_rate': 4.944036178631996e-05, 'epoch': 0.96}
2025-10-14 15:53:18 | {'eval_loss': 1.3998587131500244, 'eval_rouge1': 0.40913237620947773, 'eval_rouge2': 0.25859741770338934, 'eval_rougeL': 0.40028080109699093, 'eval_rouge_sum': 1.068010595009858, 'eval_runtime': 344.5778, 'eval_samples_per_second': 7.229, 'eval_steps_per_second': 0.453, 'epoch': 1.0}
2025-10-14 15:53:37 | {'loss': 1.3098, 'grad_norm': 3.510146379470825, 'learning_rate': 4.887507066139062e-05, 'epoch': 1.12}
2025-10-14 15:53:58 | {'loss': 1.2431, 'grad_norm': 3.542646884918213, 'learning_rate': 4.830977953646128e-05, 'epoch': 1.28}
2025-10-14 15:54:19 | {'loss': 1.2531, 'grad_norm': 3.5275816917419434, 'learning_rate': 4.774448841153194e-05, 'epoch': 1.44}
2025-10-14 15:54:39 | {'loss': 1.2658, 'grad_norm': 3.16302490234375, 'learning_rate': 4.71791972866026e-05, 'epoch': 1.61}
2025-10-14 15:55:00 | {'loss': 1.2408, 'grad_norm': 3.0322582721710205, 'learning_rate': 4.661390616167327e-05, 'epoch': 1.77}
2025-10-14 15:55:21 | {'loss': 1.2444, 'grad_norm': 3.275099039077759, 'learning_rate': 4.604861503674392e-05, 'epoch': 1.93}
2025-10-14 16:01:15 | {'eval_loss': 1.3382233381271362, 'eval_rouge1': 0.4101297059949803, 'eval_rouge2': 0.2592480728047338, 'eval_rougeL': 0.4018269951702185, 'eval_rouge_sum': 1.0712047739699326, 'eval_runtime': 344.4336, 'eval_samples_per_second': 7.232, 'eval_steps_per_second': 0.453, 'epoch': 2.0}
2025-10-14 16:01:32 | {'loss': 1.0858, 'grad_norm': 3.424136161804199, 'learning_rate': 4.5483323911814584e-05, 'epoch': 2.09}
2025-10-14 16:01:52 | {'loss': 0.9686, 'grad_norm': 3.2489113807678223, 'learning_rate': 4.491803278688525e-05, 'epoch': 2.25}
2025-10-14 16:02:13 | {'loss': 0.9691, 'grad_norm': 3.9313442707061768, 'learning_rate': 4.435274166195591e-05, 'epoch': 2.41}
2025-10-14 16:02:34 | {'loss': 0.9765, 'grad_norm': 3.651634693145752, 'learning_rate': 4.378745053702657e-05, 'epoch': 2.57}
2025-10-14 16:02:55 | {'loss': 0.9841, 'grad_norm': 3.4265055656433105, 'learning_rate': 4.322215941209723e-05, 'epoch': 2.73}
2025-10-14 16:03:16 | {'loss': 0.9803, 'grad_norm': 3.771947145462036, 'learning_rate': 4.2656868287167893e-05, 'epoch': 2.89}
2025-10-14 16:09:16 | {'eval_loss': 1.356278419494629, 'eval_rouge1': 0.44150569841261716, 'eval_rouge2': 0.28178241603476883, 'eval_rougeL': 0.4311062624024268, 'eval_rouge_sum': 1.1543943768498126, 'eval_runtime': 345.2262, 'eval_samples_per_second': 7.216, 'eval_steps_per_second': 0.452, 'epoch': 3.0}
2025-10-14 16:09:28 | {'loss': 0.929, 'grad_norm': 3.424267292022705, 'learning_rate': 4.2091577162238555e-05, 'epoch': 3.05}
2025-10-14 16:09:49 | {'loss': 0.7397, 'grad_norm': 3.1767051219940186, 'learning_rate': 4.152628603730922e-05, 'epoch': 3.21}
2025-10-14 16:10:09 | {'loss': 0.7546, 'grad_norm': 3.1695756912231445, 'learning_rate': 4.096099491237988e-05, 'epoch': 3.37}
2025-10-14 16:10:30 | {'loss': 0.7722, 'grad_norm': 3.207671642303467, 'learning_rate': 4.039570378745054e-05, 'epoch': 3.53}
2025-10-14 16:10:51 | {'loss': 0.7728, 'grad_norm': 3.2666022777557373, 'learning_rate': 3.98304126625212e-05, 'epoch': 3.69}
2025-10-14 16:11:12 | {'loss': 0.7784, 'grad_norm': 3.40486741065979, 'learning_rate': 3.926512153759186e-05, 'epoch': 3.85}
2025-10-14 16:17:18 | {'eval_loss': 1.4181015491485596, 'eval_rouge1': 0.43582177856475013, 'eval_rouge2': 0.2740778066378397, 'eval_rougeL': 0.4253992638633854, 'eval_rouge_sum': 1.1352988490659752, 'eval_runtime': 346.6002, 'eval_samples_per_second': 7.187, 'eval_steps_per_second': 0.45, 'epoch': 4.0}
2025-10-14 16:17:22 | {'loss': 0.7749, 'grad_norm': 3.3860244750976562, 'learning_rate': 3.8699830412662526e-05, 'epoch': 4.01}
2025-10-14 16:17:43 | {'loss': 0.5892, 'grad_norm': 3.5742759704589844, 'learning_rate': 3.813453928773318e-05, 'epoch': 4.17}
2025-10-14 16:18:04 | {'loss': 0.5859, 'grad_norm': 3.080670118331909, 'learning_rate': 3.756924816280384e-05, 'epoch': 4.33}
2025-10-14 16:18:25 | {'loss': 0.602, 'grad_norm': 2.806656837463379, 'learning_rate': 3.700395703787451e-05, 'epoch': 4.49}
2025-10-14 16:18:45 | {'loss': 0.5981, 'grad_norm': 3.8350155353546143, 'learning_rate': 3.6438665912945167e-05, 'epoch': 4.65}
2025-10-14 16:19:07 | {'loss': 0.6072, 'grad_norm': 3.282836675643921, 'learning_rate': 3.587337478801583e-05, 'epoch': 4.82}
2025-10-14 16:19:28 | {'loss': 0.6247, 'grad_norm': 3.863685131072998, 'learning_rate': 3.530808366308649e-05, 'epoch': 4.98}
2025-10-14 16:25:20 | {'eval_loss': 1.4948773384094238, 'eval_rouge1': 0.4398370735889078, 'eval_rouge2': 0.27859549848076726, 'eval_rougeL': 0.42989015062147773, 'eval_rouge_sum': 1.1483227226911528, 'eval_runtime': 348.8782, 'eval_samples_per_second': 7.14, 'eval_steps_per_second': 0.447, 'epoch': 5.0}
2025-10-14 16:25:41 | {'loss': 0.4791, 'grad_norm': 2.8160595893859863, 'learning_rate': 3.474279253815715e-05, 'epoch': 5.14}
2025-10-14 16:26:02 | {'loss': 0.4674, 'grad_norm': 3.2989814281463623, 'learning_rate': 3.4177501413227814e-05, 'epoch': 5.3}
2025-10-14 16:26:23 | {'loss': 0.4659, 'grad_norm': 3.078261375427246, 'learning_rate': 3.3612210288298476e-05, 'epoch': 5.46}
2025-10-14 16:26:43 | {'loss': 0.4725, 'grad_norm': 2.5509228706359863, 'learning_rate': 3.304691916336914e-05, 'epoch': 5.62}
2025-10-14 16:27:05 | {'loss': 0.4844, 'grad_norm': 3.040972948074341, 'learning_rate': 3.24816280384398e-05, 'epoch': 5.78}
2025-10-14 16:27:26 | {'loss': 0.4872, 'grad_norm': 3.133127450942993, 'learning_rate': 3.191633691351046e-05, 'epoch': 5.94}
2025-10-14 16:33:32 | {'eval_loss': 1.5592522621154785, 'eval_rouge1': 0.44377602069770394, 'eval_rouge2': 0.28322468010121066, 'eval_rougeL': 0.43440008452963436, 'eval_rouge_sum': 1.1614007853285488, 'eval_runtime': 358.2797, 'eval_samples_per_second': 6.953, 'eval_steps_per_second': 0.435, 'epoch': 6.0}
2025-10-14 16:33:49 | {'loss': 0.4022, 'grad_norm': 2.884824275970459, 'learning_rate': 3.1351045788581116e-05, 'epoch': 6.1}
2025-10-14 16:34:10 | {'loss': 0.3626, 'grad_norm': 3.315859794616699, 'learning_rate': 3.0785754663651785e-05, 'epoch': 6.26}
2025-10-14 16:34:31 | {'loss': 0.3661, 'grad_norm': 3.0668561458587646, 'learning_rate': 3.0220463538722443e-05, 'epoch': 6.42}
2025-10-14 16:34:53 | {'loss': 0.3722, 'grad_norm': 3.339646339416504, 'learning_rate': 2.96551724137931e-05, 'epoch': 6.58}
2025-10-14 16:35:14 | {'loss': 0.3791, 'grad_norm': 3.0659148693084717, 'learning_rate': 2.9089881288863767e-05, 'epoch': 6.74}
2025-10-14 16:35:36 | {'loss': 0.3852, 'grad_norm': 3.237544536590576, 'learning_rate': 2.852459016393443e-05, 'epoch': 6.9}
2025-10-14 16:41:52 | {'eval_loss': 1.6221129894256592, 'eval_rouge1': 0.4432917519014602, 'eval_rouge2': 0.28382998038676926, 'eval_rougeL': 0.43274912253019404, 'eval_rouge_sum': 1.1598708548184236, 'eval_runtime': 363.344, 'eval_samples_per_second': 6.856, 'eval_steps_per_second': 0.429, 'epoch': 7.0}
2025-10-14 16:42:03 | {'loss': 0.3457, 'grad_norm': 2.774444580078125, 'learning_rate': 2.7959299039005087e-05, 'epoch': 7.06}
2025-10-14 16:42:25 | {'loss': 0.2851, 'grad_norm': 3.346095085144043, 'learning_rate': 2.739400791407575e-05, 'epoch': 7.22}
2025-10-14 16:42:46 | {'loss': 0.2904, 'grad_norm': 2.974510669708252, 'learning_rate': 2.6828716789146414e-05, 'epoch': 7.38}
2025-10-14 16:43:08 | {'loss': 0.2925, 'grad_norm': 3.0178279876708984, 'learning_rate': 2.6263425664217072e-05, 'epoch': 7.54}
2025-10-14 16:43:29 | {'loss': 0.3007, 'grad_norm': 2.9425601959228516, 'learning_rate': 2.5698134539287734e-05, 'epoch': 7.7}
2025-10-14 16:43:51 | {'loss': 0.3035, 'grad_norm': 3.7797744274139404, 'learning_rate': 2.51328434143584e-05, 'epoch': 7.87}
2025-10-14 16:50:15 | {'eval_loss': 1.6891127824783325, 'eval_rouge1': 0.4479867599550867, 'eval_rouge2': 0.28508454102381375, 'eval_rougeL': 0.4364823829532349, 'eval_rouge_sum': 1.1695536839321354, 'eval_runtime': 366.8707, 'eval_samples_per_second': 6.79, 'eval_steps_per_second': 0.425, 'epoch': 8.0}
2025-10-14 16:50:22 | {'loss': 0.2909, 'grad_norm': 2.3665239810943604, 'learning_rate': 2.4567552289429058e-05, 'epoch': 8.03}
2025-10-14 16:50:44 | {'loss': 0.227, 'grad_norm': 2.200967311859131, 'learning_rate': 2.4002261164499716e-05, 'epoch': 8.19}
2025-10-14 16:51:06 | {'loss': 0.2316, 'grad_norm': 2.4560112953186035, 'learning_rate': 2.343697003957038e-05, 'epoch': 8.35}
2025-10-14 16:51:27 | {'loss': 0.2393, 'grad_norm': 2.8689870834350586, 'learning_rate': 2.287167891464104e-05, 'epoch': 8.51}
2025-10-14 16:51:49 | {'loss': 0.2379, 'grad_norm': 3.240206718444824, 'learning_rate': 2.2306387789711702e-05, 'epoch': 8.67}
2025-10-14 16:52:10 | {'loss': 0.237, 'grad_norm': 2.474205493927002, 'learning_rate': 2.1741096664782364e-05, 'epoch': 8.83}
2025-10-14 16:52:31 | {'loss': 0.2399, 'grad_norm': 2.855858087539673, 'learning_rate': 2.1175805539853025e-05, 'epoch': 8.99}
2025-10-14 16:58:44 | {'eval_loss': 1.7172625064849854, 'eval_rouge1': 0.44733482248803397, 'eval_rouge2': 0.28554395891273243, 'eval_rougeL': 0.4375388275493617, 'eval_rouge_sum': 1.1704176089501281, 'eval_runtime': 371.4192, 'eval_samples_per_second': 6.707, 'eval_steps_per_second': 0.42, 'epoch': 9.0}
2025-10-14 16:59:08 | {'loss': 0.186, 'grad_norm': 2.5248165130615234, 'learning_rate': 2.0610514414923687e-05, 'epoch': 9.15}
2025-10-14 16:59:29 | {'loss': 0.1864, 'grad_norm': 2.8135576248168945, 'learning_rate': 2.0045223289994346e-05, 'epoch': 9.31}
2025-10-14 16:59:50 | {'loss': 0.1899, 'grad_norm': 2.8073832988739014, 'learning_rate': 1.947993216506501e-05, 'epoch': 9.47}
2025-10-14 17:00:11 | {'loss': 0.1871, 'grad_norm': 2.4601972103118896, 'learning_rate': 1.891464104013567e-05, 'epoch': 9.63}
2025-10-14 17:00:32 | {'loss': 0.1938, 'grad_norm': 2.2433629035949707, 'learning_rate': 1.834934991520633e-05, 'epoch': 9.79}
2025-10-14 17:00:53 | {'loss': 0.1912, 'grad_norm': 2.637812376022339, 'learning_rate': 1.7784058790276993e-05, 'epoch': 9.95}
2025-10-14 17:07:00 | {'eval_loss': 1.7730377912521362, 'eval_rouge1': 0.4583364033586011, 'eval_rouge2': 0.29052875768750047, 'eval_rougeL': 0.44697696435634166, 'eval_rouge_sum': 1.1958421254024432, 'eval_runtime': 360.8038, 'eval_samples_per_second': 6.904, 'eval_steps_per_second': 0.432, 'epoch': 10.0}
2025-10-14 17:07:19 | {'loss': 0.1581, 'grad_norm': 2.2762510776519775, 'learning_rate': 1.7218767665347655e-05, 'epoch': 10.11}
2025-10-14 17:07:40 | {'loss': 0.1515, 'grad_norm': 1.8716620206832886, 'learning_rate': 1.6653476540418316e-05, 'epoch': 10.27}
2025-10-14 17:08:01 | {'loss': 0.1526, 'grad_norm': 2.1104094982147217, 'learning_rate': 1.6088185415488978e-05, 'epoch': 10.43}
2025-10-14 17:08:22 | {'loss': 0.1527, 'grad_norm': 2.7101898193359375, 'learning_rate': 1.552289429055964e-05, 'epoch': 10.59}
2025-10-14 17:08:43 | {'loss': 0.1583, 'grad_norm': 2.2953414916992188, 'learning_rate': 1.4957603165630298e-05, 'epoch': 10.75}
2025-10-14 17:09:04 | {'loss': 0.1555, 'grad_norm': 2.319990396499634, 'learning_rate': 1.4392312040700962e-05, 'epoch': 10.91}
2025-10-14 17:15:14 | {'eval_loss': 1.8171112537384033, 'eval_rouge1': 0.45878016050964276, 'eval_rouge2': 0.29277581663375396, 'eval_rougeL': 0.44542844624093075, 'eval_rouge_sum': 1.1969844233843274, 'eval_runtime': 358.7712, 'eval_samples_per_second': 6.943, 'eval_steps_per_second': 0.435, 'epoch': 11.0}
2025-10-14 17:15:28 | {'loss': 0.1461, 'grad_norm': 2.6244499683380127, 'learning_rate': 1.3827020915771624e-05, 'epoch': 11.08}
2025-10-14 17:15:49 | {'loss': 0.1258, 'grad_norm': 2.5422866344451904, 'learning_rate': 1.3261729790842284e-05, 'epoch': 11.24}
2025-10-14 17:16:10 | {'loss': 0.1265, 'grad_norm': 2.0110700130462646, 'learning_rate': 1.2696438665912946e-05, 'epoch': 11.4}
2025-10-14 17:16:31 | {'loss': 0.1272, 'grad_norm': 2.008241891860962, 'learning_rate': 1.2131147540983608e-05, 'epoch': 11.56}
2025-10-14 17:16:53 | {'loss': 0.1268, 'grad_norm': 2.1403377056121826, 'learning_rate': 1.156585641605427e-05, 'epoch': 11.72}
2025-10-14 17:17:14 | {'loss': 0.1295, 'grad_norm': 1.962826132774353, 'learning_rate': 1.100056529112493e-05, 'epoch': 11.88}
2025-10-14 17:23:29 | {'eval_loss': 1.8521900177001953, 'eval_rouge1': 0.4615091211783212, 'eval_rouge2': 0.29599805686718206, 'eval_rougeL': 0.45002981524326585, 'eval_rouge_sum': 1.2075369932887692, 'eval_runtime': 358.8294, 'eval_samples_per_second': 6.942, 'eval_steps_per_second': 0.435, 'epoch': 12.0}
2025-10-14 17:23:38 | {'loss': 0.1203, 'grad_norm': 1.8925241231918335, 'learning_rate': 1.0435274166195591e-05, 'epoch': 12.04}
2025-10-14 17:24:01 | {'loss': 0.1039, 'grad_norm': 1.7057799100875854, 'learning_rate': 9.869983041266251e-06, 'epoch': 12.2}
2025-10-14 17:24:23 | {'loss': 0.1072, 'grad_norm': 1.58173406124115, 'learning_rate': 9.304691916336913e-06, 'epoch': 12.36}
2025-10-14 17:24:46 | {'loss': 0.1061, 'grad_norm': 2.6454057693481445, 'learning_rate': 8.739400791407577e-06, 'epoch': 12.52}
2025-10-14 17:25:08 | {'loss': 0.1066, 'grad_norm': 1.7071812152862549, 'learning_rate': 8.174109666478237e-06, 'epoch': 12.68}
2025-10-14 17:25:30 | {'loss': 0.1068, 'grad_norm': 1.4906007051467896, 'learning_rate': 7.608818541548899e-06, 'epoch': 12.84}
2025-10-14 17:32:00 | {'eval_loss': 1.8820487260818481, 'eval_rouge1': 0.459836719158535, 'eval_rouge2': 0.2937429650229863, 'eval_rougeL': 0.4466348971962156, 'eval_rouge_sum': 1.200214581377737, 'eval_runtime': 368.1129, 'eval_samples_per_second': 6.767, 'eval_steps_per_second': 0.424, 'epoch': 13.0}
2025-10-14 17:32:04 | {'loss': 0.1066, 'grad_norm': 1.8438055515289307, 'learning_rate': 7.04352741661956e-06, 'epoch': 13.0}
2025-10-14 17:32:27 | {'loss': 0.0904, 'grad_norm': 1.5557790994644165, 'learning_rate': 6.478236291690221e-06, 'epoch': 13.16}
2025-10-14 17:32:50 | {'loss': 0.0904, 'grad_norm': 2.1772122383117676, 'learning_rate': 5.912945166760882e-06, 'epoch': 13.32}
2025-10-14 17:33:13 | {'loss': 0.0923, 'grad_norm': 2.190145254135132, 'learning_rate': 5.347654041831543e-06, 'epoch': 13.48}
2025-10-14 17:33:36 | {'loss': 0.0932, 'grad_norm': 2.218510389328003, 'learning_rate': 4.782362916902205e-06, 'epoch': 13.64}
2025-10-14 17:33:59 | {'loss': 0.0928, 'grad_norm': 2.088303565979004, 'learning_rate': 4.217071791972866e-06, 'epoch': 13.8}
2025-10-14 17:34:21 | {'loss': 0.0939, 'grad_norm': 2.2563624382019043, 'learning_rate': 3.651780667043528e-06, 'epoch': 13.96}
2025-10-14 17:40:28 | {'eval_loss': 1.8983361721038818, 'eval_rouge1': 0.46125105305728764, 'eval_rouge2': 0.29491027934016295, 'eval_rougeL': 0.449110074383162, 'eval_rouge_sum': 1.2052714067806125, 'eval_runtime': 361.8474, 'eval_samples_per_second': 6.884, 'eval_steps_per_second': 0.431, 'epoch': 14.0}
2025-10-14 17:40:50 | {'loss': 0.0844, 'grad_norm': 1.795458197593689, 'learning_rate': 3.086489542114189e-06, 'epoch': 14.13}
2025-10-14 17:41:12 | {'loss': 0.0852, 'grad_norm': 1.6400394439697266, 'learning_rate': 2.5211984171848503e-06, 'epoch': 14.29}
2025-10-14 17:41:35 | {'loss': 0.0819, 'grad_norm': 1.4690757989883423, 'learning_rate': 1.9559072922555117e-06, 'epoch': 14.45}
2025-10-14 17:41:57 | {'loss': 0.0805, 'grad_norm': 1.6822501420974731, 'learning_rate': 1.390616167326173e-06, 'epoch': 14.61}
2025-10-14 17:42:20 | {'loss': 0.0818, 'grad_norm': 1.551696538925171, 'learning_rate': 8.253250423968344e-07, 'epoch': 14.77}
2025-10-14 17:42:43 | {'loss': 0.0847, 'grad_norm': 1.9204100370407104, 'learning_rate': 2.600339174674958e-07, 'epoch': 14.93}
2025-10-14 17:48:54 | {'eval_loss': 1.9089410305023193, 'eval_rouge1': 0.4585439994600708, 'eval_rouge2': 0.2926865870453542, 'eval_rougeL': 0.4466008612910911, 'eval_rouge_sum': 1.1978314477965162, 'eval_runtime': 361.3998, 'eval_samples_per_second': 6.893, 'eval_steps_per_second': 0.432, 'epoch': 15.0}
2025-10-14 17:48:58 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-14 17:48:58 | {'train_runtime': 7414.6063, 'train_samples_per_second': 20.162, 'train_steps_per_second': 1.26, 'train_loss': 0.49037025777205484, 'epoch': 15.0}
2025-10-14 17:48:58 | 최종 모델 저장 중...
2025-10-14 17:49:00 | → 모델 저장 위치: experiments/20251014/20251014_090813_kobart_balanced/fold_5/default/final_model
2025-10-14 17:49:00 | 최종 평가 중...
2025-10-14 17:55:04 | 최종 평가 결과:
2025-10-14 17:55:04 | eval_rouge1: 0.4615
2025-10-14 17:55:04 | eval_rouge2: 0.2960
2025-10-14 17:55:04 | eval_rougeL: 0.4500
2025-10-14 17:55:04 | eval_rouge_sum: 1.2075
2025-10-14 17:55:04 | ============================================================
2025-10-14 17:55:04 | ✅ 학습 완료!
2025-10-14 17:55:04 | ============================================================
2025-10-14 17:55:04 | ============================================================
2025-10-14 17:55:04 | ✅ K-FOLD 교차검증 완료!
2025-10-14 17:55:04 | 📊 평균 성능:
2025-10-14 17:55:04 | ============================================================
2025-10-14 17:55:04 | 💾 결과 저장: experiments/20251014/20251014_090813_kobart_balanced/kfold_results.json
2025-10-14 17:55:04 | ============================================================
2025-10-14 17:55:04 | ✅ 학습 완료!
2025-10-14 17:55:04 | 📁 결과 저장: experiments/20251014/20251014_090813_kobart_balanced
2025-10-14 17:55:04 | ============================================================
2025-10-14 17:55:04 | >> 로그 리디렉션 중료.
