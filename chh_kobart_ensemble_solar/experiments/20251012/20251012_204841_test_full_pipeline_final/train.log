2025-10-12 20:48:41 | >> í‘œì¤€ ì¶œë ¥ ë° ì˜¤ë¥˜ë¥¼ ë¡œê·¸ íŒŒì¼ë¡œ ë¦¬ë””ë ‰ì…˜ ì‹œì‘
2025-10-12 20:48:46 | ğŸ“Š FULL ëª¨ë“œ ì‹¤í–‰ ì¤‘...
2025-10-12 20:48:46 | ============================================================
2025-10-12 20:48:46 | = FULL PIPELINE ì‹¤í–‰ ì‹œì‘
2025-10-12 20:48:46 | =ëŒ€ìƒ ëª¨ë¸: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-12 20:48:46 | =ì•™ìƒë¸” ì•™ìƒë¸” ì „ëµ: stacking
2025-10-12 20:48:46 | = TTA ì‚¬ìš©: False
2025-10-12 20:48:46 | ============================================================
2025-10-12 20:48:46 | [1/6] ë°ì´í„° ë¡œë”©...
2025-10-12 20:48:46 | âœ… í•™ìŠµ ë°ì´í„°: 12457ê°œ
2025-10-12 20:48:46 | âœ… ê²€ì¦ ë°ì´í„°: 499ê°œ
2025-10-12 20:48:46 | [2/6] ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ (6 ëª¨ë¸)...
2025-10-12 20:48:46 | ==================================================
2025-10-12 20:48:46 | ëª¨ë¸ 1/6: kobart
2025-10-12 20:48:46 | ==================================================
2025-10-12 20:48:46 | ëª¨ë¸ íƒ€ì…: encoder_decoder
2025-10-12 20:48:46 | ============================================================
2025-10-12 20:48:46 | ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì‹œì‘
2025-10-12 20:48:46 | ============================================================
2025-10-12 20:48:46 | í† í¬ë‚˜ì´ì € ë¡œë”©: digit82/kobart-summarization
2025-10-12 20:48:46 | ëª¨ë¸ ë¡œë”©: digit82/kobart-summarization
2025-10-12 20:48:47 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 20:48:50 | â†’ ë””ë°”ì´ìŠ¤: cuda
2025-10-12 20:48:50 | â†’ ì „ì²´ íŒŒë¼ë¯¸í„°: 123,859,968
2025-10-12 20:48:50 | â†’ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 123,859,968
2025-10-12 20:48:50 | ============================================================
2025-10-12 20:48:50 | âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ
2025-10-12 20:48:50 | ============================================================
2025-10-12 20:48:50 | ============================================================
2025-10-12 20:48:50 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:48:50 | ============================================================
2025-10-12 20:48:50 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:48:50 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:48:50 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 20:48:51 | 1%|          | 9/1558 [00:01<02:20, 11.05it/s]
2025-10-12 20:48:52 | 2%|â–         | 25/1558 [00:02<01:32, 16.52it/s]
2025-10-12 20:48:53 | 3%|â–         | 39/1558 [00:02<01:25, 17.72it/s]
2025-10-12 20:48:54 | 4%|â–         | 55/1558 [00:03<01:24, 17.72it/s]
2025-10-12 20:48:55 | 5%|â–         | 71/1558 [00:04<01:23, 17.89it/s]
2025-10-12 20:48:56 | 6%|â–Œ         | 87/1558 [00:05<01:27, 16.88it/s]
2025-10-12 20:48:57 | {'loss': 2.747, 'grad_norm': 8.182331085205078, 'learning_rate': 9.9e-07, 'epoch': 0.06}
2025-10-12 20:48:57 | 6%|â–‹         | 100/1558 [00:06<01:42, 14.24it/s]
2025-10-12 20:48:57 | 7%|â–‹         | 103/1558 [00:06<01:49, 13.30it/s]
2025-10-12 20:48:58 | 8%|â–Š         | 117/1558 [00:07<01:59, 12.05it/s]
2025-10-12 20:48:59 | 9%|â–Š         | 133/1558 [00:09<02:02, 11.62it/s]
2025-10-12 20:49:01 | 10%|â–‰         | 149/1558 [00:10<01:58, 11.89it/s]
2025-10-12 20:49:02 | 11%|â–ˆ         | 165/1558 [00:12<01:58, 11.79it/s]
2025-10-12 20:49:04 | 12%|â–ˆâ–        | 181/1558 [00:13<01:56, 11.78it/s]
2025-10-12 20:49:05 | 13%|â–ˆâ–        | 195/1558 [00:14<01:53, 11.97it/s]
2025-10-12 20:49:05 | {'loss': 2.0335, 'grad_norm': 9.968262672424316, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.13}
2025-10-12 20:49:05 | 13%|â–ˆâ–        | 200/1558 [00:15<01:53, 11.94it/s]
2025-10-12 20:49:06 | 14%|â–ˆâ–        | 211/1558 [00:15<01:53, 11.88it/s]
2025-10-12 20:49:08 | 15%|â–ˆâ–        | 227/1558 [00:17<02:03, 10.74it/s]
2025-10-12 20:49:09 | 16%|â–ˆâ–Œ        | 243/1558 [00:19<01:47, 12.19it/s]
2025-10-12 20:49:11 | 17%|â–ˆâ–‹        | 259/1558 [00:20<01:43, 12.60it/s]
2025-10-12 20:49:12 | 18%|â–ˆâ–Š        | 273/1558 [00:21<01:48, 11.82it/s]
2025-10-12 20:49:13 | 19%|â–ˆâ–Š        | 289/1558 [00:22<01:45, 12.07it/s]
2025-10-12 20:49:14 | {'loss': 1.8539, 'grad_norm': 6.356421947479248, 'learning_rate': 2.99e-06, 'epoch': 0.19}
2025-10-12 20:49:14 | 19%|â–ˆâ–‰        | 300/1558 [00:23<01:43, 12.20it/s]
2025-10-12 20:49:14 | 20%|â–ˆâ–‰        | 305/1558 [00:24<01:42, 12.24it/s]
2025-10-12 20:49:16 | 21%|â–ˆâ–ˆ        | 321/1558 [00:25<01:39, 12.38it/s]
2025-10-12 20:49:17 | 22%|â–ˆâ–ˆâ–       | 335/1558 [00:26<01:42, 11.93it/s]
2025-10-12 20:49:18 | 23%|â–ˆâ–ˆâ–       | 351/1558 [00:28<01:37, 12.32it/s]
2025-10-12 20:49:20 | 24%|â–ˆâ–ˆâ–       | 367/1558 [00:29<01:38, 12.15it/s]
2025-10-12 20:49:21 | 25%|â–ˆâ–ˆâ–       | 383/1558 [00:30<01:40, 11.75it/s]
2025-10-12 20:49:22 | 26%|â–ˆâ–ˆâ–Œ       | 399/1558 [00:32<01:36, 12.01it/s]
2025-10-12 20:49:22 | {'loss': 1.7595, 'grad_norm': 6.685025215148926, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.26}
2025-10-12 20:49:22 | 26%|â–ˆâ–ˆâ–Œ       | 400/1558 [00:32<01:36, 12.01it/s]
2025-10-12 20:49:23 | 27%|â–ˆâ–ˆâ–‹       | 413/1558 [00:33<01:35, 11.94it/s]
2025-10-12 20:49:25 | 28%|â–ˆâ–ˆâ–Š       | 429/1558 [00:34<01:32, 12.22it/s]
2025-10-12 20:49:26 | 29%|â–ˆâ–ˆâ–Š       | 445/1558 [00:35<01:37, 11.43it/s]
2025-10-12 20:49:28 | 30%|â–ˆâ–ˆâ–‰       | 461/1558 [00:37<01:42, 10.69it/s]
2025-10-12 20:49:29 | 31%|â–ˆâ–ˆâ–ˆ       | 477/1558 [00:38<01:29, 12.13it/s]
2025-10-12 20:49:30 | 32%|â–ˆâ–ˆâ–ˆâ–      | 491/1558 [00:39<01:28, 12.00it/s]
2025-10-12 20:49:31 | {'loss': 1.6645, 'grad_norm': 5.705896377563477, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.32}
2025-10-12 20:49:31 | 32%|â–ˆâ–ˆâ–ˆâ–      | 500/1558 [00:40<01:31, 11.53it/s]
2025-10-12 20:49:31 | 33%|â–ˆâ–ˆâ–ˆâ–      | 507/1558 [00:41<01:28, 11.87it/s]
2025-10-12 20:49:33 | 34%|â–ˆâ–ˆâ–ˆâ–      | 523/1558 [00:42<01:23, 12.45it/s]
2025-10-12 20:49:34 | 35%|â–ˆâ–ˆâ–ˆâ–      | 539/1558 [00:43<01:21, 12.58it/s]
2025-10-12 20:49:35 | 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 555/1558 [00:45<01:24, 11.83it/s]
2025-10-12 20:49:37 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 569/1558 [00:46<01:19, 12.39it/s]
2025-10-12 20:49:38 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 585/1558 [00:47<01:16, 12.71it/s]
2025-10-12 20:49:39 | {'loss': 1.6316, 'grad_norm': 6.63378381729126, 'learning_rate': 4.532136105860114e-06, 'epoch': 0.39}
2025-10-12 20:49:39 | 39%|â–ˆâ–ˆâ–ˆâ–Š      | 600/1558 [00:48<01:15, 12.68it/s]
2025-10-12 20:49:41 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 617/1558 [00:50<01:20, 11.68it/s]
2025-10-12 20:49:42 | 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 631/1558 [00:51<01:15, 12.23it/s]
2025-10-12 20:49:43 | 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 647/1558 [00:53<01:11, 12.72it/s]
2025-10-12 20:49:45 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 663/1558 [00:54<01:10, 12.75it/s]
2025-10-12 20:49:46 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 679/1558 [00:55<01:12, 12.20it/s]
2025-10-12 20:49:47 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 695/1558 [00:56<01:08, 12.66it/s]
2025-10-12 20:49:48 | {'loss': 1.6049, 'grad_norm': 7.676779270172119, 'learning_rate': 4.059546313799622e-06, 'epoch': 0.45}
2025-10-12 20:49:48 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 700/1558 [00:57<01:07, 12.70it/s]
2025-10-12 20:49:48 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 709/1558 [00:58<01:06, 12.71it/s]
2025-10-12 20:49:50 | 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 725/1558 [00:59<01:07, 12.29it/s]
2025-10-12 20:49:51 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 741/1558 [01:00<01:04, 12.72it/s]
2025-10-12 20:49:52 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 757/1558 [01:01<01:03, 12.69it/s]
2025-10-12 20:49:53 | 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 773/1558 [01:03<01:02, 12.65it/s]
2025-10-12 20:49:54 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 787/1558 [01:04<01:00, 12.68it/s]
2025-10-12 20:49:55 | {'loss': 1.5707, 'grad_norm': 5.510678291320801, 'learning_rate': 3.5869565217391305e-06, 'epoch': 0.51}
2025-10-12 20:49:55 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 800/1558 [01:05<00:59, 12.66it/s]
2025-10-12 20:49:56 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 803/1558 [01:05<00:59, 12.68it/s]
2025-10-12 20:49:57 | 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 819/1558 [01:06<00:58, 12.71it/s]
2025-10-12 20:49:58 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 835/1558 [01:08<00:56, 12.71it/s]
2025-10-12 20:49:59 | 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 851/1558 [01:09<00:55, 12.71it/s]
2025-10-12 20:50:01 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 865/1558 [01:10<00:55, 12.45it/s]
2025-10-12 20:50:02 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 881/1558 [01:11<00:53, 12.58it/s]
2025-10-12 20:50:03 | 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 897/1558 [01:12<00:52, 12.55it/s]
2025-10-12 20:50:03 | {'loss': 1.5792, 'grad_norm': 6.096556663513184, 'learning_rate': 3.114366729678639e-06, 'epoch': 0.58}
2025-10-12 20:50:03 | 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 900/1558 [01:13<00:52, 12.61it/s]
2025-10-12 20:50:04 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 913/1558 [01:14<00:50, 12.65it/s]
2025-10-12 20:50:06 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 929/1558 [01:15<00:49, 12.72it/s]
2025-10-12 20:50:07 | 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 943/1558 [01:16<00:48, 12.69it/s]
2025-10-12 20:50:08 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 959/1558 [01:17<00:50, 11.75it/s]
2025-10-12 20:50:09 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 975/1558 [01:19<00:48, 12.13it/s]
2025-10-12 20:50:11 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 991/1558 [01:20<00:45, 12.59it/s]
2025-10-12 20:50:11 | {'loss': 1.5577, 'grad_norm': 5.246335506439209, 'learning_rate': 2.641776937618148e-06, 'epoch': 0.64}
2025-10-12 20:50:11 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1000/1558 [01:21<00:43, 12.70it/s]
2025-10-12 20:50:12 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1005/1558 [01:21<00:43, 12.69it/s]
2025-10-12 20:50:14 | 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1021/1558 [01:23<00:47, 11.31it/s]
2025-10-12 20:50:15 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1037/1558 [01:24<00:41, 12.52it/s]
2025-10-12 20:50:16 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1053/1558 [01:26<00:40, 12.39it/s]
2025-10-12 20:50:18 | 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1069/1558 [01:27<00:39, 12.32it/s]
2025-10-12 20:50:19 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1083/1558 [01:28<00:38, 12.23it/s]
2025-10-12 20:50:20 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1099/1558 [01:29<00:36, 12.44it/s]
2025-10-12 20:50:20 | {'loss': 1.5503, 'grad_norm': 5.73559045791626, 'learning_rate': 2.169187145557656e-06, 'epoch': 0.71}
2025-10-12 20:50:20 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1100/1558 [01:29<00:36, 12.44it/s]
2025-10-12 20:50:21 | 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1115/1558 [01:31<00:42, 10.42it/s]
2025-10-12 20:50:23 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1131/1558 [01:32<00:41, 10.38it/s]
2025-10-12 20:50:24 | 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1147/1558 [01:34<00:36, 11.22it/s]
2025-10-12 20:50:26 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1161/1558 [01:35<00:31, 12.59it/s]
2025-10-12 20:50:27 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1177/1558 [01:36<00:30, 12.41it/s]
2025-10-12 20:50:28 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1193/1558 [01:37<00:29, 12.53it/s]
2025-10-12 20:50:29 | {'loss': 1.5246, 'grad_norm': 4.479743003845215, 'learning_rate': 1.6965973534971647e-06, 'epoch': 0.77}
2025-10-12 20:50:29 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1200/1558 [01:38<00:28, 12.45it/s]
2025-10-12 20:50:29 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1209/1558 [01:39<00:28, 12.16it/s]
2025-10-12 20:50:31 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1225/1558 [01:40<00:27, 11.97it/s]
2025-10-12 20:50:32 | 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1239/1558 [01:41<00:25, 12.36it/s]
2025-10-12 20:50:33 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1255/1558 [01:42<00:24, 12.56it/s]
2025-10-12 20:50:34 | 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1271/1558 [01:44<00:23, 12.43it/s]
2025-10-12 20:50:36 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1287/1558 [01:45<00:21, 12.65it/s]
2025-10-12 20:50:37 | {'loss': 1.5154, 'grad_norm': 5.4030561447143555, 'learning_rate': 1.224007561436673e-06, 'epoch': 0.83}
2025-10-12 20:50:37 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1300/1558 [01:46<00:21, 11.86it/s]
2025-10-12 20:50:37 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1301/1558 [01:46<00:21, 11.97it/s]
2025-10-12 20:50:38 | 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1317/1558 [01:47<00:19, 12.26it/s]
2025-10-12 20:50:39 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1333/1558 [01:49<00:18, 12.37it/s]
2025-10-12 20:50:41 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1349/1558 [01:50<00:16, 12.67it/s]
2025-10-12 20:50:42 | 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1365/1558 [01:51<00:15, 12.59it/s]
2025-10-12 20:50:43 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1379/1558 [01:52<00:14, 12.40it/s]
2025-10-12 20:50:44 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1395/1558 [01:54<00:12, 12.55it/s]
2025-10-12 20:50:45 | {'loss': 1.5504, 'grad_norm': 5.752111911773682, 'learning_rate': 7.514177693761815e-07, 'epoch': 0.9}
2025-10-12 20:50:45 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1400/1558 [01:55<00:12, 12.61it/s]
2025-10-12 20:50:46 | 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1411/1558 [01:56<00:14, 10.42it/s]
2025-10-12 20:50:48 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1427/1558 [01:57<00:10, 12.18it/s]
2025-10-12 20:50:49 | 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1443/1558 [01:58<00:09, 12.32it/s]
2025-10-12 20:50:50 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1457/1558 [01:59<00:08, 12.47it/s]
2025-10-12 20:50:51 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1473/1558 [02:01<00:06, 12.32it/s]
2025-10-12 20:50:53 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1489/1558 [02:02<00:05, 12.31it/s]
2025-10-12 20:50:53 | {'loss': 1.5458, 'grad_norm': 4.620223522186279, 'learning_rate': 2.7882797731569e-07, 'epoch': 0.96}
2025-10-12 20:50:53 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1500/1558 [02:03<00:04, 12.60it/s]
2025-10-12 20:50:54 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1505/1558 [02:03<00:04, 12.62it/s]
2025-10-12 20:50:55 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1521/1558 [02:04<00:02, 12.61it/s]
2025-10-12 20:50:56 | 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1535/1558 [02:06<00:01, 12.71it/s]
2025-10-12 20:50:57 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1551/1558 [02:07<00:00, 12.69it/s]
2025-10-12 20:51:00 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 20:51:00 | [A
2025-10-12 20:51:01 | 3%|â–         | 2/63 [00:01<00:37,  1.64it/s]
2025-10-12 20:51:01 | [A
2025-10-12 20:51:02 | 5%|â–         | 3/63 [00:02<00:54,  1.10it/s]
2025-10-12 20:51:02 | [A
2025-10-12 20:51:04 | 6%|â–‹         | 4/63 [00:03<01:03,  1.08s/it]
2025-10-12 20:51:04 | [A
2025-10-12 20:51:05 | 8%|â–Š         | 5/63 [00:05<01:08,  1.18s/it]
2025-10-12 20:51:05 | [A
2025-10-12 20:51:06 | 10%|â–‰         | 6/63 [00:06<01:09,  1.23s/it]
2025-10-12 20:51:06 | [A
2025-10-12 20:51:08 | 11%|â–ˆ         | 7/63 [00:07<01:10,  1.27s/it]
2025-10-12 20:51:08 | [A
2025-10-12 20:51:09 | 13%|â–ˆâ–        | 8/63 [00:09<01:11,  1.29s/it]
2025-10-12 20:51:09 | [A
2025-10-12 20:51:10 | 14%|â–ˆâ–        | 9/63 [00:10<01:10,  1.31s/it]
2025-10-12 20:51:10 | [A
2025-10-12 20:51:12 | 16%|â–ˆâ–Œ        | 10/63 [00:12<01:10,  1.34s/it]
2025-10-12 20:51:12 | [A
2025-10-12 20:51:12 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1558/1558 [02:22<00:00, 12.81it/s]
2025-10-12 20:51:13 | 17%|â–ˆâ–‹        | 11/63 [00:13<01:09,  1.34s/it]
2025-10-12 20:51:13 | [A
2025-10-12 20:51:14 | 19%|â–ˆâ–‰        | 12/63 [00:14<01:08,  1.33s/it]
2025-10-12 20:51:14 | [A
2025-10-12 20:51:16 | 21%|â–ˆâ–ˆ        | 13/63 [00:16<01:06,  1.33s/it]
2025-10-12 20:51:16 | [A
2025-10-12 20:51:17 | 22%|â–ˆâ–ˆâ–       | 14/63 [00:17<01:04,  1.32s/it]
2025-10-12 20:51:17 | [A
2025-10-12 20:51:19 | 24%|â–ˆâ–ˆâ–       | 15/63 [00:19<01:10,  1.48s/it]
2025-10-12 20:51:19 | [A
2025-10-12 20:51:20 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:20<01:07,  1.44s/it]
2025-10-12 20:51:20 | [A
2025-10-12 20:51:22 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:21<01:05,  1.42s/it]
2025-10-12 20:51:22 | [A
2025-10-12 20:51:23 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:23<01:02,  1.39s/it]
2025-10-12 20:51:23 | [A
2025-10-12 20:51:24 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:24<01:00,  1.37s/it]
2025-10-12 20:51:24 | [A
2025-10-12 20:51:26 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:25<00:58,  1.35s/it]
2025-10-12 20:51:26 | [A
2025-10-12 20:51:27 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:27<00:55,  1.33s/it]
2025-10-12 20:51:27 | [A
2025-10-12 20:51:28 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:28<00:54,  1.32s/it]
2025-10-12 20:51:28 | [A
2025-10-12 20:51:29 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:29<00:52,  1.30s/it]
2025-10-12 20:51:29 | [A
2025-10-12 20:51:31 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:30<00:50,  1.29s/it]
2025-10-12 20:51:31 | [A
2025-10-12 20:51:32 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:32<00:49,  1.31s/it]
2025-10-12 20:51:32 | [A
2025-10-12 20:51:33 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:33<00:48,  1.31s/it]
2025-10-12 20:51:33 | [A
2025-10-12 20:51:35 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:34<00:46,  1.30s/it]
2025-10-12 20:51:35 | [A
2025-10-12 20:51:36 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:36<00:44,  1.29s/it]
2025-10-12 20:51:36 | [A
2025-10-12 20:51:37 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:37<00:42,  1.26s/it]
2025-10-12 20:51:37 | [A
2025-10-12 20:51:38 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:38<00:41,  1.25s/it]
2025-10-12 20:51:38 | [A
2025-10-12 20:51:40 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:39<00:39,  1.24s/it]
2025-10-12 20:51:40 | [A
2025-10-12 20:51:41 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:41<00:38,  1.23s/it]
2025-10-12 20:51:41 | [A
2025-10-12 20:51:42 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:42<00:38,  1.27s/it]
2025-10-12 20:51:42 | [A
2025-10-12 20:51:44 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:43<00:37,  1.31s/it]
2025-10-12 20:51:44 | [A
2025-10-12 20:51:45 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:44<00:34,  1.24s/it]
2025-10-12 20:51:45 | [A
2025-10-12 20:51:46 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:46<00:33,  1.26s/it]
2025-10-12 20:51:46 | [A
2025-10-12 20:51:47 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:47<00:32,  1.25s/it]
2025-10-12 20:51:47 | [A
2025-10-12 20:51:48 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:48<00:31,  1.25s/it]
2025-10-12 20:51:48 | [A
2025-10-12 20:51:50 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:49<00:29,  1.25s/it]
2025-10-12 20:51:50 | [A
2025-10-12 20:51:51 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [00:51<00:32,  1.43s/it]
2025-10-12 20:51:51 | [A
2025-10-12 20:51:53 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [00:53<00:30,  1.38s/it]
2025-10-12 20:51:53 | [A
2025-10-12 20:51:54 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:54<00:28,  1.35s/it]
2025-10-12 20:51:54 | [A
2025-10-12 20:51:55 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [00:55<00:26,  1.32s/it]
2025-10-12 20:51:55 | [A
2025-10-12 20:51:57 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [00:56<00:24,  1.30s/it]
2025-10-12 20:51:57 | [A
2025-10-12 20:51:58 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [00:58<00:23,  1.28s/it]
2025-10-12 20:51:58 | [A
2025-10-12 20:51:59 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [00:59<00:21,  1.27s/it]
2025-10-12 20:51:59 | [A
2025-10-12 20:52:00 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:00<00:19,  1.25s/it]
2025-10-12 20:52:00 | [A
2025-10-12 20:52:01 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:01<00:18,  1.24s/it]
2025-10-12 20:52:01 | [A
2025-10-12 20:52:03 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:02<00:17,  1.24s/it]
2025-10-12 20:52:03 | [A
2025-10-12 20:52:04 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:04<00:16,  1.23s/it]
2025-10-12 20:52:04 | [A
2025-10-12 20:52:05 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:05<00:14,  1.24s/it]
2025-10-12 20:52:05 | [A
2025-10-12 20:52:06 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:06<00:13,  1.24s/it]
2025-10-12 20:52:06 | [A
2025-10-12 20:52:08 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:07<00:12,  1.24s/it]
2025-10-12 20:52:08 | [A
2025-10-12 20:52:09 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:09<00:11,  1.25s/it]
2025-10-12 20:52:09 | [A
2025-10-12 20:52:10 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:10<00:09,  1.25s/it]
2025-10-12 20:52:10 | [A
2025-10-12 20:52:11 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:11<00:08,  1.25s/it]
2025-10-12 20:52:11 | [A
2025-10-12 20:52:13 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:12<00:07,  1.25s/it]
2025-10-12 20:52:13 | [A
2025-10-12 20:52:14 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:14<00:06,  1.25s/it]
2025-10-12 20:52:14 | [A
2025-10-12 20:52:15 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:15<00:04,  1.25s/it]
2025-10-12 20:52:15 | [A
2025-10-12 20:52:16 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:16<00:03,  1.24s/it]
2025-10-12 20:52:16 | [A
2025-10-12 20:52:18 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:17<00:02,  1.24s/it]
2025-10-12 20:52:18 | [A
2025-10-12 20:52:19 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:19<00:01,  1.25s/it]
2025-10-12 20:52:19 | [A
2025-10-12 20:52:20 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:20<00:00,  1.24s/it]
2025-10-12 20:52:20 | [A
2025-10-12 20:52:20 | [A
2025-10-12 20:52:20 | {'eval_loss': 1.4561823606491089, 'eval_rouge1': 0.41327704171428237, 'eval_rouge2': 0.25485074356001697, 'eval_rougeL': 0.40613363999411095, 'eval_rouge_sum': 1.0742614252684102, 'eval_runtime': 82.0787, 'eval_samples_per_second': 6.08, 'eval_steps_per_second': 0.768, 'epoch': 1.0}
2025-10-12 20:52:20 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1558/1558 [03:29<00:00, 12.81it/s]
2025-10-12 20:52:20 | [A
2025-10-12 20:52:20 | [A
2025-10-12 20:52:22 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-12 20:52:22 | {'train_runtime': 212.2607, 'train_samples_per_second': 58.687, 'train_steps_per_second': 7.34, 'train_loss': 1.707339736096207, 'epoch': 1.0}
2025-10-12 20:52:22 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1558/1558 [03:32<00:00, 12.81it/s]
2025-10-12 20:52:22 | ìµœì¢… ëª¨ë¸ ì €ì¥ ì¤‘...
2025-10-12 20:52:24 | â†’ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: experiments/20251012/20251012_204841_test_full_pipeline_final/model_0_kobart/default/final_model
2025-10-12 20:52:24 | ìµœì¢… í‰ê°€ ì¤‘...
2025-10-12 20:52:25 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 20:52:26 | 3%|â–         | 2/63 [00:00<00:22,  2.69it/s]
2025-10-12 20:52:27 | 5%|â–         | 3/63 [00:01<00:33,  1.81it/s]
2025-10-12 20:52:28 | 6%|â–‹         | 4/63 [00:02<00:38,  1.53it/s]
2025-10-12 20:52:28 | 8%|â–Š         | 5/63 [00:03<00:41,  1.40it/s]
2025-10-12 20:52:29 | 10%|â–‰         | 6/63 [00:04<00:42,  1.34it/s]
2025-10-12 20:52:30 | 11%|â–ˆ         | 7/63 [00:04<00:42,  1.32it/s]
2025-10-12 20:52:31 | 13%|â–ˆâ–        | 8/63 [00:05<00:43,  1.26it/s]
2025-10-12 20:52:32 | 14%|â–ˆâ–        | 9/63 [00:06<00:42,  1.26it/s]
2025-10-12 20:52:32 | 16%|â–ˆâ–Œ        | 10/63 [00:07<00:42,  1.26it/s]
2025-10-12 20:52:33 | 17%|â–ˆâ–‹        | 11/63 [00:08<00:41,  1.26it/s]
2025-10-12 20:52:34 | 19%|â–ˆâ–‰        | 12/63 [00:08<00:40,  1.27it/s]
2025-10-12 20:52:35 | 21%|â–ˆâ–ˆ        | 13/63 [00:09<00:39,  1.27it/s]
2025-10-12 20:52:36 | 22%|â–ˆâ–ˆâ–       | 14/63 [00:10<00:37,  1.30it/s]
2025-10-12 20:52:36 | 24%|â–ˆâ–ˆâ–       | 15/63 [00:11<00:35,  1.34it/s]
2025-10-12 20:52:37 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:11<00:34,  1.37it/s]
2025-10-12 20:52:38 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:12<00:34,  1.35it/s]
2025-10-12 20:52:38 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:13<00:33,  1.34it/s]
2025-10-12 20:52:39 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:14<00:33,  1.31it/s]
2025-10-12 20:52:40 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:14<00:33,  1.28it/s]
2025-10-12 20:52:41 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:15<00:32,  1.28it/s]
2025-10-12 20:52:42 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:16<00:32,  1.25it/s]
2025-10-12 20:52:43 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:17<00:33,  1.19it/s]
2025-10-12 20:52:44 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:18<00:35,  1.09it/s]
2025-10-12 20:52:45 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:19<00:35,  1.08it/s]
2025-10-12 20:52:46 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:20<00:35,  1.05it/s]
2025-10-12 20:52:47 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:21<00:33,  1.06it/s]
2025-10-12 20:52:48 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:22<00:34,  1.02it/s]
2025-10-12 20:52:49 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:23<00:33,  1.03it/s]
2025-10-12 20:52:50 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:24<00:31,  1.04it/s]
2025-10-12 20:52:51 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:25<00:31,  1.03it/s]
2025-10-12 20:52:52 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:26<00:30,  1.01it/s]
2025-10-12 20:52:52 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:27<00:28,  1.04it/s]
2025-10-12 20:52:53 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:28<00:28,  1.02it/s]
2025-10-12 20:52:54 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:29<00:27,  1.03it/s]
2025-10-12 20:52:55 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:30<00:26,  1.03it/s]
2025-10-12 20:52:57 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:31<00:30,  1.15s/it]
2025-10-12 20:52:58 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:32<00:27,  1.12s/it]
2025-10-12 20:52:59 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:34<00:27,  1.14s/it]
2025-10-12 20:53:00 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [00:35<00:27,  1.18s/it]
2025-10-12 20:53:02 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [00:36<00:26,  1.21s/it]
2025-10-12 20:53:03 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:37<00:26,  1.24s/it]
2025-10-12 20:53:04 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [00:39<00:25,  1.27s/it]
2025-10-12 20:53:06 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [00:40<00:24,  1.27s/it]
2025-10-12 20:53:07 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [00:41<00:22,  1.28s/it]
2025-10-12 20:53:08 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [00:43<00:21,  1.27s/it]
2025-10-12 20:53:09 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [00:44<00:20,  1.26s/it]
2025-10-12 20:53:11 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [00:45<00:18,  1.25s/it]
2025-10-12 20:53:12 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [00:46<00:17,  1.25s/it]
2025-10-12 20:53:13 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [00:48<00:16,  1.26s/it]
2025-10-12 20:53:14 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [00:49<00:15,  1.25s/it]
2025-10-12 20:53:16 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [00:50<00:13,  1.24s/it]
2025-10-12 20:53:17 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [00:51<00:12,  1.25s/it]
2025-10-12 20:53:18 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [00:53<00:11,  1.24s/it]
2025-10-12 20:53:19 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [00:54<00:10,  1.26s/it]
2025-10-12 20:53:21 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [00:55<00:08,  1.27s/it]
2025-10-12 20:53:22 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [00:56<00:07,  1.26s/it]
2025-10-12 20:53:23 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [00:58<00:06,  1.25s/it]
2025-10-12 20:53:25 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [00:59<00:04,  1.25s/it]
2025-10-12 20:53:26 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:00<00:03,  1.26s/it]
2025-10-12 20:53:27 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:01<00:02,  1.26s/it]
2025-10-12 20:53:28 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:03<00:01,  1.26s/it]
2025-10-12 20:53:30 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:05<00:00,  1.45s/it]
2025-10-12 20:53:30 | ìµœì¢… í‰ê°€ ê²°ê³¼:
2025-10-12 20:53:30 | eval_rouge1: 0.4133
2025-10-12 20:53:30 | eval_rouge2: 0.2549
2025-10-12 20:53:30 | eval_rougeL: 0.4061
2025-10-12 20:53:30 | eval_rouge_sum: 1.0743
2025-10-12 20:53:30 | ============================================================
2025-10-12 20:53:30 | âœ… í•™ìŠµ ì™„ë£Œ!
2025-10-12 20:53:30 | ============================================================
2025-10-12 20:53:30 | âœ… kobart í•™ìŠµ ì™„ë£Œ
2025-10-12 20:53:30 | ==================================================
2025-10-12 20:53:30 | ëª¨ë¸ 2/6: llama-3.2-korean-3b
2025-10-12 20:53:30 | ==================================================
2025-10-12 20:53:30 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-12 20:53:30 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-12 20:53:30 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-12 20:53:31 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-12 20:53:31 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-12 20:53:42 | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:11<00:11, 11.14s/it]
2025-10-12 20:53:45 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  6.72s/it]
2025-10-12 20:53:46 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-12 20:53:47 | íŒ¨ë”© í† í° ì„¤ì •: <|eot_id|>
2025-10-12 20:53:47 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-12 20:53:47 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-12 20:53:47 | ============================================================
2025-10-12 20:53:47 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:53:47 | ============================================================
2025-10-12 20:53:47 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:53:47 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 20:53:47 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:53:47 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-12 20:53:47 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 20:54:22 | âŒ llama-3.2-korean-3b í•™ìŠµ ì‹¤íŒ¨: ValueError: Attempting to unscale FP16 gradients.
2025-10-12 20:54:22 | ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: experiments/20251012/20251012_204841_test_full_pipeline_final/errors/llama-3.2-korean-3b_error.log
2025-10-12 20:54:22 | ==================================================
2025-10-12 20:54:22 | ëª¨ë¸ 3/6: qwen3-4b
2025-10-12 20:54:22 | ==================================================
2025-10-12 20:54:22 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-12 20:54:22 | Loading Causal LM: Qwen/Qwen3-4B-Instruct-2507
2025-10-12 20:54:22 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-12 20:54:22 | Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2025-10-12 20:54:22 | [A
2025-10-12 20:54:26 | Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:03<00:07,  3.78s/it]
2025-10-12 20:54:26 | [A
2025-10-12 20:54:30 | Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:08<00:04,  4.10s/it]
2025-10-12 20:54:30 | [A
2025-10-12 20:54:30 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.28s/it]
2025-10-12 20:54:30 | [A
2025-10-12 20:54:30 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.74s/it]
2025-10-12 20:54:31 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-12 20:54:32 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-12 20:54:32 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-12 20:54:32 | ============================================================
2025-10-12 20:54:32 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:54:32 | ============================================================
2025-10-12 20:54:32 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:54:32 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 20:54:32 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:54:32 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
2025-10-12 20:54:32 | 0%|          | 0/1558 [00:44<?, ?it/s]
2025-10-12 20:54:48 | âŒ qwen3-4b í•™ìŠµ ì‹¤íŒ¨: ValueError: Attempting to unscale FP16 gradients.
2025-10-12 20:54:48 | ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: experiments/20251012/20251012_204841_test_full_pipeline_final/errors/qwen3-4b_error.log
2025-10-12 20:54:48 | ==================================================
2025-10-12 20:54:48 | ëª¨ë¸ 4/6: solar-10.7b
2025-10-12 20:54:48 | ==================================================
2025-10-12 20:54:48 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-12 20:54:48 | Loading Causal LM: upstage/solar-10.7b-instruct-v1.0
2025-10-12 20:54:48 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-12 20:54:48 | Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
2025-10-12 20:54:48 | [A
2025-10-12 20:55:05 | Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:16<01:04, 16.23s/it]
2025-10-12 20:55:05 | [A
2025-10-12 20:55:19 | Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:30<00:45, 15.23s/it]
2025-10-12 20:55:19 | [A
2025-10-12 20:55:29 | Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:40<00:25, 12.78s/it]
2025-10-12 20:55:29 | [A
2025-10-12 20:55:30 | Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:42<00:08,  8.29s/it]
2025-10-12 20:55:30 | [A
2025-10-12 20:55:30 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:42<00:00,  8.41s/it]
2025-10-12 20:55:31 | WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.
2025-10-12 20:55:31 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-12 20:55:32 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-12 20:55:32 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-12 20:55:33 | ============================================================
2025-10-12 20:55:33 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:55:33 | ============================================================
2025-10-12 20:55:33 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:55:33 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 20:55:33 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:55:33 | 0%|          | 0/1558 [01:00<?, ?it/s]
