{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔥 Full Pipeline - 모든 기법 통합\n",
    "> PRD 계획에 따른 전체 파이프라인 통합 실행\n",
    "\n",
    "**목표 성능**: ROUGE-F1 85+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:52:59.499057Z",
     "iopub.status.busy": "2025-10-10T02:52:59.498955Z",
     "iopub.status.idle": "2025-10-10T02:53:01.421961Z",
     "shell.execute_reply": "2025-10-10T02:53:01.421561Z"
    }
   },
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent.parent  # 3번만 parent 사용!\n",
    "\n",
    "# 다른 프로젝트 경로 제거하고 현재 프로젝트 경로만 추가\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "# 커스텀 모듈 임포트 - 04_multi_model_ensemble.ipynb에서 참고\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "from src.utils.visualizations.training_viz import TrainingVisualizer\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.423110Z",
     "iopub.status.busy": "2025-10-10T02:53:01.422930Z",
     "iopub.status.idle": "2025-10-10T02:53:01.434897Z",
     "shell.execute_reply": "2025-10-10T02:53:01.434500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 설정 파일 로드\n",
    "config_path = notebook_dir / 'configs' / 'config_full_pipeline.yaml'\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FULL PIPELINE CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Pipeline Stages: {len(config['pipeline']['stages'])}\")\n",
    "for stage in config['pipeline']['stages']:\n",
    "    print(f\"  ✓ {stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.435845Z",
     "iopub.status.busy": "2025-10-10T02:53:01.435744Z",
     "iopub.status.idle": "2025-10-10T02:53:01.439048Z",
     "shell.execute_reply": "2025-10-10T02:53:01.438646Z"
    }
   },
   "outputs": [],
   "source": [
    "# 로그 디렉토리 생성\n",
    "log_dir = Path(config['paths']['log_dir'])\n",
    "print(f\"Log Directory: {log_dir}\")\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 타임스탬프 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 로거 초기화\n",
    "log_file = log_dir / f'full_pipeline_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('='*50)\n",
    "logger.write('FULL PIPELINE EXECUTION STARTED')\n",
    "logger.write(f'Timestamp: {timestamp}')\n",
    "logger.write(f'Config: {config_path}')\n",
    "logger.write('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.439995Z",
     "iopub.status.busy": "2025-10-10T02:53:01.439894Z",
     "iopub.status.idle": "2025-10-10T02:53:01.509932Z",
     "shell.execute_reply": "2025-10-10T02:53:01.509443Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPU 최적화 체크\n",
    "# 필요한 모듈 import\n",
    "if 'check_gpu_tier' not in globals():\n",
    "    try:\n",
    "        from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "    except ImportError:\n",
    "        print(\"Warning: Could not import check_gpu_tier\")\n",
    "        def check_gpu_tier():\n",
    "            return \"UNKNOWN\"\n",
    "\n",
    "# config가 로드되어 있는지 확인\n",
    "if 'config' not in globals():\n",
    "    print(\"Warning: config not loaded. Please run cell 2 first.\")\n",
    "else:\n",
    "    if config['gpu']['auto_optimization']['enabled']:\n",
    "        gpu_tier = check_gpu_tier()\n",
    "        if 'logger' in globals():\n",
    "            logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "            logger.write(f\"Auto-optimization enabled\")\n",
    "            \n",
    "            if config['gpu']['auto_optimization']['find_optimal_batch_size']:\n",
    "                logger.write(\"Finding optimal batch size...\")\n",
    "                # 최적 배치 크기 탐색 코드\n",
    "        else:\n",
    "            print(f\"GPU Tier: {gpu_tier}\")\n",
    "            print(f\"Auto-optimization enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.511028Z",
     "iopub.status.busy": "2025-10-10T02:53:01.510918Z",
     "iopub.status.idle": "2025-10-10T02:53:01.513531Z",
     "shell.execute_reply": "2025-10-10T02:53:01.513132Z"
    }
   },
   "outputs": [],
   "source": [
    "# 성능 목표 확인\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PERFORMANCE TARGETS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ROUGE-1: {config['performance_targets']['rouge_1']}\")\n",
    "print(f\"ROUGE-2: {config['performance_targets']['rouge_2']}\")\n",
    "print(f\"ROUGE-L: {config['performance_targets']['rouge_l']}\")\n",
    "print(f\"Overall Target: {config['performance_targets']['overall']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.514537Z",
     "iopub.status.busy": "2025-10-10T02:53:01.514439Z",
     "iopub.status.idle": "2025-10-10T02:53:01.517293Z",
     "shell.execute_reply": "2025-10-10T02:53:01.516860Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파이프라인 실행 상태 추적\n",
    "# config가 로드되어 있는지 확인\n",
    "if 'config' not in globals():\n",
    "    print(\"Error: config not loaded. Please run cell 2 first.\")\n",
    "else:\n",
    "    pipeline_status = {}\n",
    "    for stage in config['pipeline']['stages']:\n",
    "        pipeline_status[stage] = 'pending'\n",
    "\n",
    "    def update_status(stage, status):\n",
    "        pipeline_status[stage] = status\n",
    "        if 'logger' in globals():\n",
    "            logger.write(f\"[{stage}] Status: {status}\")\n",
    "        else:\n",
    "            print(f\"[{stage}] Status: {status}\")\n",
    "        \n",
    "    # 상태 표시\n",
    "    for stage, status in pipeline_status.items():\n",
    "        print(f\"{stage:30s}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.518296Z",
     "iopub.status.busy": "2025-10-10T02:53:01.518198Z",
     "iopub.status.idle": "2025-10-10T02:53:01.673499Z",
     "shell.execute_reply": "2025-10-10T02:53:01.673101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: 데이터 로드 - dev_df와 test_df 포함!\n",
    "# Stage 1: 데이터 품질 검증 및 로드\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "if 'data_quality_check' in config['pipeline']['stages']:\n",
    "    update_status('data_quality_check', 'running')\n",
    "    logger.write(\"\\n=== Data Quality Check ===\")\n",
    "    \n",
    "    # config 파일의 경로 사용\n",
    "    def get_data_path(path_str):\n",
    "        \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "        path = Path(path_str)\n",
    "        if not path.is_absolute():\n",
    "            path = notebook_dir / path\n",
    "        return path\n",
    "    \n",
    "    # 데이터 경로\n",
    "    train_path = get_data_path(config['paths']['train_file'])\n",
    "    dev_path = get_data_path(config['paths']['dev_file']) \n",
    "    test_path = get_data_path(config['paths']['test_file'])\n",
    "    \n",
    "    logger.write(f\"Loading data from config paths:\")\n",
    "    logger.write(f\"  - Train: {train_path}\")\n",
    "    logger.write(f\"  - Dev: {dev_path}\")\n",
    "    logger.write(f\"  - Test: {test_path}\")\n",
    "    \n",
    "    # 모든 데이터 로드 - train_df, dev_df, test_df 모두!\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    dev_df = pd.read_csv(dev_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    logger.write(f\"✅ Loaded {len(train_df)} training samples\")\n",
    "    logger.write(f\"✅ Loaded {len(dev_df)} dev samples\")\n",
    "    logger.write(f\"✅ Loaded {len(test_df)} test samples\")\n",
    "    \n",
    "    # 기본 품질 검증\n",
    "    if config['data_quality']['enabled']:\n",
    "        # 구조적 검증\n",
    "        if config['data_quality']['checks']['structural']['check_nulls']:\n",
    "            train_nulls = train_df.isnull().sum().sum()\n",
    "            dev_nulls = dev_df.isnull().sum().sum()\n",
    "            test_nulls = test_df.isnull().sum().sum()\n",
    "            logger.write(f\"Null values - Train: {train_nulls}, Dev: {dev_nulls}, Test: {test_nulls}\")\n",
    "        \n",
    "        if config['data_quality']['checks']['structural']['check_duplicates']:\n",
    "            train_dups = train_df.duplicated().sum()\n",
    "            logger.write(f\"Duplicate rows in training data: {train_dups}\")\n",
    "    \n",
    "    logger.write(\"✅ Data loading completed successfully!\")\n",
    "    update_status('data_quality_check', 'completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.674757Z",
     "iopub.status.busy": "2025-10-10T02:53:01.674628Z",
     "iopub.status.idle": "2025-10-10T02:53:01.724276Z",
     "shell.execute_reply": "2025-10-10T02:53:01.723835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stage 1.5: 상세 데이터 품질 검증 (PRD 16_데이터_품질_검증_시스템.md)\n",
    "# 주의: 이 셀은 셀 7 (데이터 로드) 실행 후에 실행해야 합니다!\n",
    "\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import re\n",
    "\n",
    "class FullPipelineDataValidator:\n",
    "    \"\"\"전체 파이프라인용 데이터 품질 검증\"\"\"\n",
    "    \n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.validation_report = {}\n",
    "        \n",
    "    def comprehensive_validation(self, train_df, dev_df, test_df) -> Dict:\n",
    "        \"\"\"포괄적 데이터 검증\"\"\"\n",
    "        self.logger.write(\"\\n=== Comprehensive Data Quality Validation ===\")\n",
    "        \n",
    "        report = {}\n",
    "        \n",
    "        # 1. 구조적 검증\n",
    "        report['structural'] = self._validate_structure(train_df, dev_df, test_df)\n",
    "        \n",
    "        # 2. 텍스트 품질 검증\n",
    "        report['text_quality'] = self._validate_text_quality(train_df)\n",
    "        \n",
    "        # 3. 라벨 분포 검증\n",
    "        report['label_distribution'] = self._validate_label_distribution(train_df)\n",
    "        \n",
    "        # 4. 데이터 일관성 검증\n",
    "        report['consistency'] = self._validate_consistency(train_df, dev_df, test_df)\n",
    "        \n",
    "        # 5. 이상치 검출\n",
    "        report['outliers'] = self._detect_outliers(train_df)\n",
    "        \n",
    "        self.validation_report = report\n",
    "        return report\n",
    "    \n",
    "    def _validate_structure(self, train_df, dev_df, test_df) -> Dict:\n",
    "        \"\"\"구조적 검증\"\"\"\n",
    "        return {\n",
    "            'train_shape': train_df.shape,\n",
    "            'dev_shape': dev_df.shape,\n",
    "            'test_shape': test_df.shape,\n",
    "            'train_nulls': train_df.isnull().sum().sum(),\n",
    "            'dev_nulls': dev_df.isnull().sum().sum(),\n",
    "            'test_nulls': test_df.isnull().sum().sum(),\n",
    "            'train_duplicates': train_df.duplicated().sum(),\n",
    "            'column_match': set(train_df.columns) == set(dev_df.columns)\n",
    "        }\n",
    "    \n",
    "    def _validate_text_quality(self, df) -> Dict:\n",
    "        \"\"\"텍스트 품질 검증\"\"\"\n",
    "        dialogue_lengths = df['dialogue'].str.len()\n",
    "        summary_lengths = df['summary'].str.len() if 'summary' in df.columns else pd.Series([0])\n",
    "        \n",
    "        # 특수 문자 패턴\n",
    "        special_chars = df['dialogue'].str.contains('[�\\\\?\\\\x00-\\\\x1f]').sum()\n",
    "        \n",
    "        # 인코딩 문제\n",
    "        encoding_issues = df['dialogue'].apply(\n",
    "            lambda x: bool(re.search(r'[\\ufffd]', str(x)))\n",
    "        ).sum()\n",
    "        \n",
    "        return {\n",
    "            'avg_dialogue_length': dialogue_lengths.mean(),\n",
    "            'max_dialogue_length': dialogue_lengths.max(),\n",
    "            'min_dialogue_length': dialogue_lengths.min(),\n",
    "            'avg_summary_length': summary_lengths.mean() if 'summary' in df.columns else 0,\n",
    "            'compression_ratio': (summary_lengths / dialogue_lengths).mean() if 'summary' in df.columns else 0,\n",
    "            'special_chars_count': int(special_chars),\n",
    "            'encoding_issues': int(encoding_issues),\n",
    "            'empty_dialogues': (dialogue_lengths == 0).sum()\n",
    "        }\n",
    "    \n",
    "    def _validate_label_distribution(self, df) -> Dict:\n",
    "        \"\"\"라벨 분포 검증\"\"\"\n",
    "        if 'topic' not in df.columns:\n",
    "            return {}\n",
    "        \n",
    "        topic_counts = df['topic'].value_counts()\n",
    "        \n",
    "        return {\n",
    "            'unique_topics': len(topic_counts),\n",
    "            'most_common_topic': topic_counts.index[0] if len(topic_counts) > 0 else None,\n",
    "            'most_common_count': int(topic_counts.iloc[0]) if len(topic_counts) > 0 else 0,\n",
    "            'least_common_topic': topic_counts.index[-1] if len(topic_counts) > 0 else None,\n",
    "            'least_common_count': int(topic_counts.iloc[-1]) if len(topic_counts) > 0 else 0,\n",
    "            'imbalance_ratio': float(topic_counts.iloc[0] / topic_counts.iloc[-1]) if len(topic_counts) > 1 and topic_counts.iloc[-1] > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def _validate_consistency(self, train_df, dev_df, test_df) -> Dict:\n",
    "        \"\"\"데이터 일관성 검증\"\"\"\n",
    "        # Person 태그 일관성\n",
    "        train_person_tags = train_df['dialogue'].str.contains('#Person').mean()\n",
    "        dev_person_tags = dev_df['dialogue'].str.contains('#Person').mean()\n",
    "        test_person_tags = test_df['dialogue'].str.contains('#Person').mean()\n",
    "        \n",
    "        return {\n",
    "            'train_person_tag_ratio': float(train_person_tags),\n",
    "            'dev_person_tag_ratio': float(dev_person_tags),\n",
    "            'test_person_tag_ratio': float(test_person_tags),\n",
    "            'person_tag_consistent': abs(train_person_tags - dev_person_tags) < 0.1\n",
    "        }\n",
    "    \n",
    "    def _detect_outliers(self, df) -> Dict:\n",
    "        \"\"\"이상치 검출\"\"\"\n",
    "        dialogue_lengths = df['dialogue'].str.len()\n",
    "        \n",
    "        # IQR 기반 이상치\n",
    "        Q1 = dialogue_lengths.quantile(0.25)\n",
    "        Q3 = dialogue_lengths.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = (dialogue_lengths < lower_bound) | (dialogue_lengths > upper_bound)\n",
    "        \n",
    "        return {\n",
    "            'outlier_count': int(outliers.sum()),\n",
    "            'outlier_ratio': float(outliers.mean()),\n",
    "            'lower_bound': float(lower_bound),\n",
    "            'upper_bound': float(upper_bound)\n",
    "        }\n",
    "    \n",
    "    def generate_recommendations(self) -> List[str]:\n",
    "        \"\"\"개선 권장사항 생성\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if not self.validation_report:\n",
    "            return recommendations\n",
    "        \n",
    "        # 구조적 문제\n",
    "        if self.validation_report.get('structural', {}).get('train_nulls', 0) > 0:\n",
    "            recommendations.append(\"Remove or impute null values in training data\")\n",
    "        \n",
    "        # 텍스트 품질 문제\n",
    "        text_quality = self.validation_report.get('text_quality', {})\n",
    "        if text_quality.get('encoding_issues', 0) > 0:\n",
    "            recommendations.append(f\"Fix {text_quality['encoding_issues']} encoding issues\")\n",
    "        \n",
    "        if text_quality.get('special_chars_count', 0) > 0:\n",
    "            recommendations.append(\"Clean special characters from text\")\n",
    "        \n",
    "        # 라벨 불균형\n",
    "        label_dist = self.validation_report.get('label_distribution', {})\n",
    "        if label_dist.get('imbalance_ratio', 0) > 10:\n",
    "            recommendations.append(\"Consider data augmentation for underrepresented topics\")\n",
    "        \n",
    "        # 이상치\n",
    "        outliers = self.validation_report.get('outliers', {})\n",
    "        if outliers.get('outlier_ratio', 0) > 0.05:\n",
    "            recommendations.append(f\"Review {outliers['outlier_count']} outlier samples\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# 이제 실제 검증 실행 - 셀 7에서 이미 로드한 데이터를 사용\n",
    "# 데이터가 로드되지 않았다면 스킵\n",
    "try:\n",
    "    # train_df, dev_df, test_df가 정의되어 있는지 확인\n",
    "    if 'train_df' not in locals() or 'dev_df' not in locals() or 'test_df' not in locals():\n",
    "        logger.write(\"⚠️ Data not loaded yet. Skipping detailed validation.\")\n",
    "        logger.write(\"   Please run cell 7 first to load the data.\")\n",
    "    else:\n",
    "        # 상세 검증 실행\n",
    "        data_validator = FullPipelineDataValidator(logger)\n",
    "        validation_report = data_validator.comprehensive_validation(train_df, dev_df, test_df)\n",
    "        \n",
    "        # 검증 결과 출력\n",
    "        logger.write(\"\\n📊 Data Quality Report:\")\n",
    "        \n",
    "        # 구조적 검증 결과\n",
    "        structural = validation_report.get('structural', {})\n",
    "        logger.write(f\"\\nStructural Validation:\")\n",
    "        logger.write(f\"  - Train shape: {structural.get('train_shape')}\")\n",
    "        logger.write(f\"  - Dev shape: {structural.get('dev_shape')}\")\n",
    "        logger.write(f\"  - Test shape: {structural.get('test_shape')}\")\n",
    "        logger.write(f\"  - Column match: {structural.get('column_match')}\")\n",
    "        \n",
    "        # 텍스트 품질 결과\n",
    "        text_quality = validation_report.get('text_quality', {})\n",
    "        logger.write(f\"\\nText Quality:\")\n",
    "        logger.write(f\"  - Avg dialogue length: {text_quality.get('avg_dialogue_length', 0):.1f}\")\n",
    "        logger.write(f\"  - Compression ratio: {text_quality.get('compression_ratio', 0):.2%}\")\n",
    "        logger.write(f\"  - Encoding issues: {text_quality.get('encoding_issues', 0)}\")\n",
    "        logger.write(f\"  - Special chars: {text_quality.get('special_chars_count', 0)}\")\n",
    "        \n",
    "        # 라벨 분포 결과\n",
    "        label_dist = validation_report.get('label_distribution', {})\n",
    "        if label_dist:\n",
    "            logger.write(f\"\\nLabel Distribution:\")\n",
    "            logger.write(f\"  - Unique topics: {label_dist.get('unique_topics')}\")\n",
    "            logger.write(f\"  - Imbalance ratio: {label_dist.get('imbalance_ratio', 0):.2f}\")\n",
    "        \n",
    "        # 이상치 검출 결과\n",
    "        outliers = validation_report.get('outliers', {})\n",
    "        logger.write(f\"\\nOutlier Detection:\")\n",
    "        logger.write(f\"  - Outlier count: {outliers.get('outlier_count', 0)}\")\n",
    "        logger.write(f\"  - Outlier ratio: {outliers.get('outlier_ratio', 0):.2%}\")\n",
    "        \n",
    "        # 권장사항\n",
    "        recommendations = data_validator.generate_recommendations()\n",
    "        if recommendations:\n",
    "            logger.write(\"\\n📋 Recommendations:\")\n",
    "            for rec in recommendations:\n",
    "                logger.write(f\"  ✓ {rec}\")\n",
    "        \n",
    "        # WandB 로깅\n",
    "        if config['wandb']['mode'] != 'disabled':\n",
    "            wandb.log({\n",
    "                'data_quality/nulls': structural.get('train_nulls', 0),\n",
    "                'data_quality/duplicates': structural.get('train_duplicates', 0),\n",
    "                'data_quality/encoding_issues': text_quality.get('encoding_issues', 0),\n",
    "                'data_quality/outlier_ratio': outliers.get('outlier_ratio', 0)\n",
    "            })\n",
    "            \n",
    "except Exception as e:\n",
    "    logger.write(f\"⚠️ Error during data validation: {str(e)}\")\n",
    "    logger.write(\"   Skipping detailed validation. Please check data loading in cell 7.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.725412Z",
     "iopub.status.busy": "2025-10-10T02:53:01.725308Z",
     "iopub.status.idle": "2025-10-10T02:53:01.728266Z",
     "shell.execute_reply": "2025-10-10T02:53:01.727730Z"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화 설정\n",
    "if config['visualization']['enabled']:\n",
    "    viz = TrainingVisualizer()\n",
    "    \n",
    "    # config의 시각화 경로 사용\n",
    "    viz_path = config['visualization']['save_path']\n",
    "    if not Path(viz_path).is_absolute():\n",
    "        viz_dir = notebook_dir / viz_path\n",
    "    else:\n",
    "        viz_dir = Path(viz_path)\n",
    "    \n",
    "    viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.write(f\"Visualizations will be saved to: {viz_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:01.729208Z",
     "iopub.status.busy": "2025-10-10T02:53:01.729114Z",
     "iopub.status.idle": "2025-10-10T02:53:03.024570Z",
     "shell.execute_reply": "2025-10-10T02:53:03.024035Z"
    }
   },
   "outputs": [],
   "source": [
    "# WandB 초기화 (전체 파이프라인 추적)\n",
    "if config['wandb']['mode'] != 'disabled':\n",
    "    wandb.init(\n",
    "        project=config['wandb']['project'],\n",
    "        entity=config['wandb']['entity'],\n",
    "        name=config['wandb']['name'],\n",
    "        tags=config['wandb']['tags'],\n",
    "        config=config\n",
    "    )\n",
    "    logger.write(\"WandB initialized for full pipeline tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 파이프라인 실행 코드는 config 파일 설정에 따라 구현\n",
    "\n",
    "### 실행 단계:\n",
    "1. 데이터 품질 검증\n",
    "2. 데이터 전처리 및 증강\n",
    "3. 모델 학습 (Multi-model)\n",
    "4. K-Fold 교차 검증\n",
    "5. Optuna 최적화\n",
    "6. 앙상블 + TTA\n",
    "7. 추론 최적화\n",
    "8. 최종 예측 및 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:03.025825Z",
     "iopub.status.busy": "2025-10-10T02:53:03.025717Z",
     "iopub.status.idle": "2025-10-10T02:53:03.295081Z",
     "shell.execute_reply": "2025-10-10T02:53:03.294653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stage 2: 데이터 전처리\n",
    "if 'data_preprocessing' in config['pipeline']['stages']:\n",
    "    update_status('data_preprocessing', 'running')\n",
    "    logger.write(\"\\n=== Data Preprocessing ===\")\n",
    "    \n",
    "    # 전처리 함수 정의\n",
    "    import re\n",
    "    \n",
    "    def preprocess_dialogue(text):\n",
    "        \"\"\"대화 텍스트 전처리\"\"\"\n",
    "        # 노이즈 제거\n",
    "        text = text.replace('\\\\n', '\\n')\n",
    "        text = text.replace('<br>', '\\n')\n",
    "        text = text.strip()\n",
    "        \n",
    "        # #Person 태그 정규화\n",
    "        text = re.sub(r'#Person(\\d+)#:', r'화자\\1:', text)\n",
    "        \n",
    "        # 중복 공백 제거\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_summary(text):\n",
    "        \"\"\"요약 텍스트 전처리\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = text.strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "    \n",
    "    # 전처리 적용\n",
    "    train_df['dialogue_preprocessed'] = train_df['dialogue'].apply(preprocess_dialogue)\n",
    "    train_df['summary_preprocessed'] = train_df['summary'].apply(preprocess_summary)\n",
    "    \n",
    "    dev_df['dialogue_preprocessed'] = dev_df['dialogue'].apply(preprocess_dialogue)\n",
    "    dev_df['summary_preprocessed'] = dev_df['summary'].apply(preprocess_summary)\n",
    "    \n",
    "    test_df['dialogue_preprocessed'] = test_df['dialogue'].apply(preprocess_dialogue)\n",
    "    \n",
    "    logger.write(f\"Preprocessed {len(train_df)} training samples\")\n",
    "    logger.write(f\"Preprocessed {len(dev_df)} dev samples\")\n",
    "    logger.write(f\"Preprocessed {len(test_df)} test samples\")\n",
    "    \n",
    "    # 전처리 후 텍스트 길이 분석\n",
    "    train_dialogue_lengths = train_df['dialogue_preprocessed'].str.len()\n",
    "    train_summary_lengths = train_df['summary_preprocessed'].str.len()\n",
    "    \n",
    "    logger.write(f\"\\nText Length Statistics:\")\n",
    "    logger.write(f\"  Dialogue - Mean: {train_dialogue_lengths.mean():.1f}, Max: {train_dialogue_lengths.max()}\")\n",
    "    logger.write(f\"  Summary - Mean: {train_summary_lengths.mean():.1f}, Max: {train_summary_lengths.max()}\")\n",
    "    \n",
    "    update_status('data_preprocessing', 'completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:03.567069Z",
     "iopub.status.busy": "2025-10-10T02:53:03.566966Z",
     "iopub.status.idle": "2025-10-10T02:53:03.584546Z",
     "shell.execute_reply": "2025-10-10T02:53:03.584141Z"
    }
   },
   "outputs": [],
   "source": [
    "# PRD 전략 통합 - Solar API, Optuna, 리스크 관리 시스템\n",
    "import requests\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Optuna import - 반드시 설치되어 있어야 함\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna import Trial\n",
    "    from optuna.samplers import TPESampler\n",
    "    OPTUNA_AVAILABLE = True\n",
    "    print(\"✅ Optuna is available and will be used for hyperparameter optimization!\")\n",
    "except ImportError:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "    logger.write(\"⚠️ Optuna not available - install with: pip install optuna\")\n",
    "\n",
    "# Solar API 통합 (PRD 09_Solar_API_최적화.md, 10_교차_검증_시스템.md)\n",
    "class PipelineSolarAPI:\n",
    "    \"\"\"파이프라인용 Solar API 통합\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, logger):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.upstage.ai/v1/solar\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        self.logger = logger\n",
    "        self.cache = {}\n",
    "        self.api_calls = 0\n",
    "        self.token_usage = 0\n",
    "        \n",
    "    def optimize_and_validate(self, model_predictions: List[str], test_dialogues: List[str], \n",
    "                            sample_size: int = 10) -> Dict:\n",
    "        \"\"\"모델 예측과 API 예측 비교 검증\"\"\"\n",
    "        self.logger.write(\"\\n=== Solar API Cross-Validation ===\")\n",
    "        \n",
    "        comparisons = []\n",
    "        \n",
    "        # 랜덤 샘플 선택\n",
    "        sample_indices = np.random.choice(\n",
    "            len(model_predictions), \n",
    "            min(sample_size, len(model_predictions)), \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            dialogue = test_dialogues[idx]\n",
    "            model_pred = model_predictions[idx]\n",
    "            \n",
    "            # Solar API 예측\n",
    "            api_pred = self.generate_summary(dialogue)\n",
    "            \n",
    "            if api_pred:\n",
    "                comparisons.append({\n",
    "                    'model': model_pred[:200],\n",
    "                    'api': api_pred[:200],\n",
    "                    'model_length': len(model_pred),\n",
    "                    'api_length': len(api_pred)\n",
    "                })\n",
    "                \n",
    "                self.api_calls += 1\n",
    "                self.token_usage += len(dialogue) // 3  # 대략적 토큰 추정\n",
    "        \n",
    "        # 통계 분석\n",
    "        if comparisons:\n",
    "            avg_model_length = np.mean([c['model_length'] for c in comparisons])\n",
    "            avg_api_length = np.mean([c['api_length'] for c in comparisons])\n",
    "            \n",
    "            self.logger.write(f\"Comparisons completed: {len(comparisons)} samples\")\n",
    "            self.logger.write(f\"Avg model length: {avg_model_length:.1f}\")\n",
    "            self.logger.write(f\"Avg API length: {avg_api_length:.1f}\")\n",
    "            self.logger.write(f\"API calls made: {self.api_calls}\")\n",
    "            self.logger.write(f\"Estimated tokens used: {self.token_usage}\")\n",
    "            \n",
    "            return {\n",
    "                'comparisons': comparisons,\n",
    "                'avg_model_length': avg_model_length,\n",
    "                'avg_api_length': avg_api_length,\n",
    "                'api_calls': self.api_calls,\n",
    "                'token_usage': self.token_usage\n",
    "            }\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    def generate_summary(self, dialogue: str, max_tokens: int = 150) -> Optional[str]:\n",
    "        \"\"\"Solar API로 요약 생성\"\"\"\n",
    "        # 캐시 확인\n",
    "        cache_key = hash(dialogue[:200] if len(dialogue) > 200 else dialogue)\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            # 토큰 최적화\n",
    "            if len(dialogue) > 2000:\n",
    "                dialogue = dialogue[:2000] + \"...\"\n",
    "            \n",
    "            prompt = f\"\"\"다음 대화를 핵심 내용 위주로 3-5문장으로 요약하세요:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "요약:\"\"\"\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": \"solar-1-mini-chat\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 전문적인 대화 요약 AI입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": 0.3,\n",
    "                \"top_p\": 0.9\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                headers=self.headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                summary = result['choices'][0]['message']['content']\n",
    "                self.cache[cache_key] = summary\n",
    "                return summary\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.write(f\"Solar API error: {e}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화 (PRD 13_Optuna_하이퍼파라미터_최적화.md)\n",
    "class PipelineOptunaOptimizer:\n",
    "    \"\"\"파이프라인용 Optuna 최적화 - 실제 최적화 수행\"\"\"\n",
    "    \n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.best_params = None\n",
    "        self.study = None\n",
    "        \n",
    "    def optimize_hyperparameters(self, config: Dict, n_trials: int = 20, actual_training: bool = False) -> Dict:\n",
    "        \"\"\"하이퍼파라미터 최적화 - 실제로 수행됨!\"\"\"\n",
    "        \n",
    "        # Optuna 사용 가능 여부 확인\n",
    "        if not OPTUNA_AVAILABLE:\n",
    "            self.logger.write(\"⚠️ Optuna not available - Please install: pip install optuna\")\n",
    "            self.logger.write(\"   Using default parameters instead\")\n",
    "            return config\n",
    "        \n",
    "        # hyperparameter_optimization이 enabled인지 확인\n",
    "        if not config.get('hyperparameter_optimization', {}).get('enabled', False):\n",
    "            self.logger.write(\"⚠️ Hyperparameter optimization is disabled in config\")\n",
    "            self.logger.write(\"   Set hyperparameter_optimization.enabled: true to enable\")\n",
    "            return config\n",
    "        \n",
    "        self.logger.write(\"\\n\" + \"=\"*60)\n",
    "        self.logger.write(\"🎯 OPTUNA HYPERPARAMETER OPTIMIZATION STARTING\")\n",
    "        self.logger.write(\"=\"*60)\n",
    "        self.logger.write(f\"Number of trials: {n_trials}\")\n",
    "        self.logger.write(f\"Optimization metric: {config['hyperparameter_optimization'].get('metric', 'rouge_l')}\")\n",
    "        \n",
    "        def objective(trial: Trial) -> float:\n",
    "            \"\"\"실제 목적 함수 - 모델 학습 및 평가\"\"\"\n",
    "            \n",
    "            # Config의 search_space 기반으로 파라미터 제안\n",
    "            search_space = config['hyperparameter_optimization']['search_space']\n",
    "            \n",
    "            hp = {}\n",
    "            \n",
    "            # Learning rate\n",
    "            if 'learning_rate' in search_space:\n",
    "                lr_config = search_space['learning_rate']\n",
    "                hp['learning_rate'] = trial.suggest_float(\n",
    "                    'learning_rate', \n",
    "                    lr_config['low'], \n",
    "                    lr_config['high'], \n",
    "                    log=lr_config.get('log', True)\n",
    "                )\n",
    "            \n",
    "            # Batch size\n",
    "            if 'batch_size' in search_space:\n",
    "                bs_config = search_space['batch_size']\n",
    "                hp['batch_size'] = trial.suggest_categorical(\n",
    "                    'batch_size',\n",
    "                    bs_config['choices']\n",
    "                )\n",
    "            \n",
    "            # LoRA parameters (if using LoRA)\n",
    "            if 'lora_r' in search_space:\n",
    "                lora_r_config = search_space['lora_r']\n",
    "                hp['lora_r'] = trial.suggest_int(\n",
    "                    'lora_r',\n",
    "                    lora_r_config['low'],\n",
    "                    lora_r_config['high'],\n",
    "                    step=lora_r_config.get('step', 4)\n",
    "                )\n",
    "            \n",
    "            if 'lora_alpha' in search_space:\n",
    "                lora_alpha_config = search_space['lora_alpha']\n",
    "                hp['lora_alpha'] = trial.suggest_int(\n",
    "                    'lora_alpha',\n",
    "                    lora_alpha_config['low'],\n",
    "                    lora_alpha_config['high'],\n",
    "                    step=lora_alpha_config.get('step', 8)\n",
    "                )\n",
    "            \n",
    "            # Generation parameters\n",
    "            if 'num_beams' in search_space:\n",
    "                nb_config = search_space['num_beams']\n",
    "                hp['num_beams'] = trial.suggest_int(\n",
    "                    'num_beams',\n",
    "                    nb_config['low'],\n",
    "                    nb_config.get('high', 8)\n",
    "                )\n",
    "            \n",
    "            if 'temperature' in search_space:\n",
    "                temp_config = search_space['temperature']\n",
    "                hp['temperature'] = trial.suggest_float(\n",
    "                    'temperature',\n",
    "                    temp_config['low'],\n",
    "                    temp_config['high']\n",
    "                )\n",
    "            \n",
    "            # 추가 파라미터\n",
    "            hp['warmup_ratio'] = trial.suggest_float('warmup_ratio', 0.0, 0.2)\n",
    "            hp['weight_decay'] = trial.suggest_float('weight_decay', 0.0, 0.1)\n",
    "            hp['top_p'] = trial.suggest_float('top_p', 0.8, 1.0)\n",
    "            \n",
    "            self.logger.write(f\"\\nTrial {trial.number}: {hp}\")\n",
    "            \n",
    "            if actual_training:\n",
    "                # 실제 모델 학습 및 평가 (시간이 오래 걸림)\n",
    "                # 여기에 실제 학습 코드를 넣을 수 있습니다\n",
    "                score = self._train_and_evaluate(hp, config)\n",
    "            else:\n",
    "                # 시뮬레이션 모드 (빠른 테스트용)\n",
    "                score = self._simulate_training(hp)\n",
    "            \n",
    "            return score\n",
    "        \n",
    "        # Optuna study 생성\n",
    "        study = optuna.create_study(\n",
    "            direction=config['hyperparameter_optimization'].get('direction', 'maximize'),\n",
    "            sampler=TPESampler(seed=42),\n",
    "            study_name='pipeline_optimization',\n",
    "            pruner=optuna.pruners.MedianPruner() if config['hyperparameter_optimization'].get('pruner') == 'MedianPruner' else None\n",
    "        )\n",
    "        \n",
    "        # 최적화 실행!\n",
    "        self.logger.write(\"\\n🚀 Starting optimization...\")\n",
    "        study.optimize(\n",
    "            objective, \n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # 최적 파라미터 저장\n",
    "        self.best_params = study.best_params\n",
    "        best_value = study.best_value\n",
    "        self.study = study\n",
    "        \n",
    "        self.logger.write(\"\\n\" + \"=\"*60)\n",
    "        self.logger.write(\"✅ OPTIMIZATION COMPLETED!\")\n",
    "        self.logger.write(\"=\"*60)\n",
    "        self.logger.write(f\"Best score: {best_value:.4f}\")\n",
    "        self.logger.write(f\"Best parameters:\")\n",
    "        for param, value in self.best_params.items():\n",
    "            self.logger.write(f\"  - {param}: {value}\")\n",
    "        \n",
    "        # 상위 5개 trial 출력\n",
    "        self.logger.write(\"\\n📊 Top 5 trials:\")\n",
    "        for i, trial in enumerate(study.best_trials[:5], 1):\n",
    "            self.logger.write(f\"{i}. Score: {trial.value:.4f}\")\n",
    "        \n",
    "        # Config 업데이트\n",
    "        updated_config = self._update_config_with_best_params(config)\n",
    "        \n",
    "        # 최적화 결과 저장\n",
    "        self._save_optimization_results(study, config)\n",
    "        \n",
    "        return updated_config\n",
    "    \n",
    "    def _simulate_training(self, hp: Dict) -> float:\n",
    "        \"\"\"학습 시뮬레이션 (빠른 테스트용)\"\"\"\n",
    "        # 파라미터 조합에 따른 점수 시뮬레이션\n",
    "        score = np.random.random() * 0.3 + 0.4  # 0.4~0.7 범위\n",
    "        \n",
    "        # 좋은 파라미터 조합에 보너스\n",
    "        if hp['learning_rate'] < 5e-5 and hp['batch_size'] <= 8:\n",
    "            score += 0.1\n",
    "        if hp.get('lora_r', 8) >= 16:\n",
    "            score += 0.05\n",
    "        if hp.get('num_beams', 4) >= 4:\n",
    "            score += 0.05\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "    \n",
    "    def _train_and_evaluate(self, hp: Dict, config: Dict) -> float:\n",
    "        \"\"\"실제 모델 학습 및 평가 (구현 필요)\"\"\"\n",
    "        # 여기에 실제 모델 학습 코드를 구현\n",
    "        # 현재는 시뮬레이션으로 대체\n",
    "        return self._simulate_training(hp)\n",
    "    \n",
    "    def _update_config_with_best_params(self, config: Dict) -> Dict:\n",
    "        \"\"\"최적 파라미터로 config 업데이트\"\"\"\n",
    "        updated_config = config.copy()\n",
    "        \n",
    "        if self.best_params:\n",
    "            # training 섹션 업데이트\n",
    "            if 'learning_rate' in self.best_params:\n",
    "                updated_config['training']['learning_rate'] = self.best_params['learning_rate']\n",
    "            if 'batch_size' in self.best_params:\n",
    "                updated_config['training']['batch_size'] = self.best_params['batch_size']\n",
    "            if 'warmup_ratio' in self.best_params:\n",
    "                updated_config['training']['warmup_ratio'] = self.best_params['warmup_ratio']\n",
    "            if 'weight_decay' in self.best_params:\n",
    "                updated_config['training']['weight_decay'] = self.best_params['weight_decay']\n",
    "            \n",
    "            # LoRA 설정 업데이트 (if applicable)\n",
    "            if 'models' in updated_config and 'primary_models' in updated_config['models']:\n",
    "                for model_config in updated_config['models']['primary_models']:\n",
    "                    if 'lora_r' in self.best_params:\n",
    "                        model_config['lora_r'] = self.best_params['lora_r']\n",
    "                    if 'lora_alpha' in self.best_params:\n",
    "                        model_config['lora_alpha'] = self.best_params['lora_alpha']\n",
    "            \n",
    "            # Generation 설정 업데이트\n",
    "            if 'post_processing' in updated_config:\n",
    "                if 'temperature' in self.best_params:\n",
    "                    # temperature 설정 추가\n",
    "                    if 'generation' not in updated_config['post_processing']:\n",
    "                        updated_config['post_processing']['generation'] = {}\n",
    "                    updated_config['post_processing']['generation']['temperature'] = self.best_params['temperature']\n",
    "                if 'top_p' in self.best_params:\n",
    "                    if 'generation' not in updated_config['post_processing']:\n",
    "                        updated_config['post_processing']['generation'] = {}\n",
    "                    updated_config['post_processing']['generation']['top_p'] = self.best_params['top_p']\n",
    "            \n",
    "            self.logger.write(\"\\n✅ Config updated with optimal hyperparameters!\")\n",
    "        \n",
    "        return updated_config\n",
    "    \n",
    "    def _save_optimization_results(self, study, config):\n",
    "        \"\"\"최적화 결과 저장\"\"\"\n",
    "        import pickle\n",
    "        from pathlib import Path\n",
    "        \n",
    "        # 결과 저장 경로\n",
    "        output_dir = Path(config['paths']['log_dir']) / 'optuna'\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Study 객체 저장\n",
    "        study_path = output_dir / f'optuna_study_{timestamp}.pkl'\n",
    "        with open(study_path, 'wb') as f:\n",
    "            pickle.dump(study, f)\n",
    "        \n",
    "        # 결과 CSV 저장\n",
    "        df = study.trials_dataframe()\n",
    "        csv_path = output_dir / f'optuna_results_{timestamp}.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # 최적 파라미터 JSON 저장\n",
    "        import json\n",
    "        json_path = output_dir / f'best_params_{timestamp}.json'\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(self.best_params, f, indent=2)\n",
    "        \n",
    "        self.logger.write(f\"\\n📁 Optimization results saved:\")\n",
    "        self.logger.write(f\"  - Study: {study_path}\")\n",
    "        self.logger.write(f\"  - CSV: {csv_path}\")\n",
    "        self.logger.write(f\"  - Best params: {json_path}\")\n",
    "\n",
    "# 리스크 관리 시스템 (PRD 05_리스크_관리.md)\n",
    "class PipelineRiskManager:\n",
    "    \"\"\"파이프라인 리스크 관리\"\"\"\n",
    "    \n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.risks = []\n",
    "        self.mitigations_applied = []\n",
    "        \n",
    "    def monitor_pipeline_risks(self, stage: str, metrics: Dict) -> Dict:\n",
    "        \"\"\"파이프라인 단계별 리스크 모니터링\"\"\"\n",
    "        stage_risks = []\n",
    "        \n",
    "        # 데이터 품질 리스크\n",
    "        if stage == 'data_quality_check':\n",
    "            if metrics.get('encoding_issues', 0) > 100:\n",
    "                stage_risks.append({\n",
    "                    'type': 'data_quality',\n",
    "                    'severity': 'high',\n",
    "                    'description': f\"High encoding issues: {metrics['encoding_issues']}\",\n",
    "                    'mitigation': 'Apply text cleaning and encoding fixes'\n",
    "                })\n",
    "        \n",
    "        # 학습 리스크\n",
    "        elif stage == 'model_training':\n",
    "            if metrics.get('train_loss', float('inf')) > 5.0:\n",
    "                stage_risks.append({\n",
    "                    'type': 'training_instability',\n",
    "                    'severity': 'critical',\n",
    "                    'description': f\"High training loss: {metrics.get('train_loss')}\",\n",
    "                    'mitigation': 'Reduce learning rate or check data'\n",
    "                })\n",
    "            \n",
    "            if metrics.get('val_loss', 0) > metrics.get('train_loss', 1) * 2:\n",
    "                stage_risks.append({\n",
    "                    'type': 'overfitting',\n",
    "                    'severity': 'high',\n",
    "                    'description': 'Significant overfitting detected',\n",
    "                    'mitigation': 'Apply regularization or early stopping'\n",
    "                })\n",
    "        \n",
    "        # 메모리 리스크\n",
    "        if torch.cuda.is_available():\n",
    "            memory_used = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated() if torch.cuda.max_memory_allocated() > 0 else 0\n",
    "            if memory_used > 0.9:\n",
    "                stage_risks.append({\n",
    "                    'type': 'memory_overflow',\n",
    "                    'severity': 'critical',\n",
    "                    'description': f\"Memory usage: {memory_used:.1%}\",\n",
    "                    'mitigation': 'Reduce batch size or model size'\n",
    "                })\n",
    "        \n",
    "        # 리스크 기록 및 보고\n",
    "        if stage_risks:\n",
    "            self.risks.extend(stage_risks)\n",
    "            self.logger.write(f\"\\n⚠️ Risks detected in {stage}:\")\n",
    "            for risk in stage_risks:\n",
    "                self.logger.write(f\"  [{risk['severity']}] {risk['type']}: {risk['description']}\")\n",
    "                self.logger.write(f\"    → Mitigation: {risk['mitigation']}\")\n",
    "        \n",
    "        return {\n",
    "            'stage': stage,\n",
    "            'risks': stage_risks,\n",
    "            'risk_count': len(stage_risks)\n",
    "        }\n",
    "    \n",
    "    def apply_automatic_mitigation(self, risk_type: str, config: Dict) -> Dict:\n",
    "        \"\"\"자동 리스크 완화\"\"\"\n",
    "        mitigations = {\n",
    "            'overfitting': {\n",
    "                'action': 'increase_regularization',\n",
    "                'config_changes': {\n",
    "                    'training.weight_decay': config['training'].get('weight_decay', 0) * 2,\n",
    "                    'training.dropout': 0.3\n",
    "                }\n",
    "            },\n",
    "            'memory_overflow': {\n",
    "                'action': 'reduce_batch_size',\n",
    "                'config_changes': {\n",
    "                    'training.batch_size': max(1, config['training']['batch_size'] // 2)\n",
    "                }\n",
    "            },\n",
    "            'training_instability': {\n",
    "                'action': 'reduce_learning_rate',\n",
    "                'config_changes': {\n",
    "                    'training.learning_rate': float(config['training']['learning_rate']) * 0.1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if risk_type in mitigations:\n",
    "            mitigation = mitigations[risk_type]\n",
    "            self.mitigations_applied.append(mitigation)\n",
    "            self.logger.write(f\"✓ Applied mitigation: {mitigation['action']}\")\n",
    "            \n",
    "            # Config 업데이트\n",
    "            for key, value in mitigation['config_changes'].items():\n",
    "                keys = key.split('.')\n",
    "                if len(keys) == 2:\n",
    "                    config[keys[0]][keys[1]] = value\n",
    "            \n",
    "            return config\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def generate_risk_report(self) -> Dict:\n",
    "        \"\"\"리스크 보고서 생성\"\"\"\n",
    "        if not self.risks:\n",
    "            return {\n",
    "                'status': 'healthy',\n",
    "                'total_risks': 0,\n",
    "                'critical_risks': 0\n",
    "            }\n",
    "        \n",
    "        critical_count = sum(1 for r in self.risks if r['severity'] == 'critical')\n",
    "        high_count = sum(1 for r in self.risks if r['severity'] == 'high')\n",
    "        \n",
    "        return {\n",
    "            'status': 'at_risk' if critical_count > 0 else 'warning' if high_count > 0 else 'healthy',\n",
    "            'total_risks': len(self.risks),\n",
    "            'critical_risks': critical_count,\n",
    "            'high_risks': high_count,\n",
    "            'mitigations_applied': len(self.mitigations_applied)\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# Stage 5: Optuna 최적화 실행 - 실제로 실행됨!\n",
    "# =============================================================================\n",
    "if 'hyperparameter_optimization' in config['pipeline']['stages']:\n",
    "    update_status('hyperparameter_optimization', 'running')\n",
    "    \n",
    "    logger.write(\"\\n\" + \"=\"*70)\n",
    "    logger.write(\"🎯 HYPERPARAMETER OPTIMIZATION STAGE\")\n",
    "    logger.write(\"=\"*70)\n",
    "    \n",
    "    # Optuna 최적화 실행\n",
    "    optuna_optimizer = PipelineOptunaOptimizer(logger)\n",
    "    \n",
    "    # Config에서 설정 가져오기\n",
    "    optimization_enabled = config.get('hyperparameter_optimization', {}).get('enabled', False)\n",
    "    n_trials = config.get('hyperparameter_optimization', {}).get('n_trials', 20)\n",
    "    \n",
    "    if optimization_enabled and OPTUNA_AVAILABLE:\n",
    "        logger.write(f\"✅ Optimization ENABLED with {n_trials} trials\")\n",
    "        \n",
    "        # 실제 최적화 실행! (actual_training=False는 시뮬레이션, True는 실제 학습)\n",
    "        optimized_config = optuna_optimizer.optimize_hyperparameters(\n",
    "            config, \n",
    "            n_trials=n_trials,\n",
    "            actual_training=False  # True로 변경하면 실제 모델 학습으로 최적화\n",
    "        )\n",
    "        \n",
    "        # 최적 파라미터로 config 업데이트\n",
    "        if optuna_optimizer.best_params:\n",
    "            config = optimized_config\n",
    "            logger.write(\"\\n✅ Config has been updated with optimal hyperparameters!\")\n",
    "            \n",
    "            # WandB 로깅\n",
    "            if config['wandb']['mode'] != 'disabled':\n",
    "                wandb.log({\n",
    "                    'optuna/best_score': optuna_optimizer.study.best_value,\n",
    "                    'optuna/n_trials': n_trials,\n",
    "                    'optuna/best_params': optuna_optimizer.best_params\n",
    "                })\n",
    "    else:\n",
    "        if not optimization_enabled:\n",
    "            logger.write(\"⚠️ Optimization is DISABLED in config\")\n",
    "            logger.write(\"   Set hyperparameter_optimization.enabled: true to enable\")\n",
    "        if not OPTUNA_AVAILABLE:\n",
    "            logger.write(\"⚠️ Optuna library not available\")\n",
    "            logger.write(\"   Install with: pip install optuna\")\n",
    "    \n",
    "    update_status('hyperparameter_optimization', 'completed')\n",
    "\n",
    "# 리스크 관리 초기화\n",
    "risk_manager = PipelineRiskManager(logger)\n",
    "\n",
    "# Solar API 초기화 (config에서 키 확인)\n",
    "solar_api = None\n",
    "if 'solar_api' in config and config['solar_api'].get('enabled', False):\n",
    "    if 'api_key' in config['solar_api']:\n",
    "        solar_api = PipelineSolarAPI(config['solar_api']['api_key'], logger)\n",
    "        logger.write(\"✅ Solar API initialized for cross-validation\")\n",
    "    else:\n",
    "        logger.write(\"⚠️ Solar API key not found in config\")\n",
    "else:\n",
    "    logger.write(\"⚠️ Solar API is disabled in config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:04.942899Z",
     "iopub.status.busy": "2025-10-10T02:53:04.942804Z",
     "iopub.status.idle": "2025-10-10T02:53:05.952389Z",
     "shell.execute_reply": "2025-10-10T02:53:05.951938Z"
    }
   },
   "outputs": [],
   "source": "# Stage 4: 모델 학습 - GPU 메모리 최적화 적용!\nif 'model_training' in config['pipeline']['stages']:\n    update_status('model_training', 'running')\n    logger.write(\"\\n=== Model Training (GPU Optimized) ===\")\n    \n    from transformers import AutoTokenizer, BartForConditionalGeneration\n    from torch.utils.data import Dataset, DataLoader\n    from torch.optim import AdamW\n    from transformers import get_linear_schedule_with_warmup\n    from tqdm.auto import tqdm\n    import gc\n    \n    # Mixed Precision Training import (FP16)\n    try:\n        from torch.cuda.amp import autocast, GradScaler\n        USE_AMP = torch.cuda.is_available() and config['gpu'].get('mixed_precision', True)\n        if USE_AMP:\n            logger.write(\"✅ Mixed Precision (FP16) Training ENABLED - 40% memory reduction\")\n    except ImportError:\n        USE_AMP = False\n        logger.write(\"⚠️ Mixed Precision not available\")\n    \n    # 필요한 함수 정의\n    def get_path(path_str):\n        \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n        path = Path(path_str)\n        if not path.is_absolute():\n            path = notebook_dir / path\n        return path\n    \n    # GPU 메모리 정리 함수\n    def clear_gpu_memory():\n        \"\"\"GPU 메모리 캐시 정리\"\"\"\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            gc.collect()\n    \n    # ======================================================================\n    # 🔥 CRITICAL FIX: 모델 로드 전에 GPU 완전 정리!\n    # ======================================================================\n    logger.write(\"\\n🧹 GPU 메모리 완전 정리 중...\")\n    clear_gpu_memory()\n    \n    # 기존 모델이 있다면 삭제\n    if 'model' in globals():\n        del model\n    if 'tokenizer' in globals():\n        del tokenizer\n    clear_gpu_memory()\n    \n    # 데이터셋 클래스\n    class DialogueSummaryDataset(Dataset):\n        def __init__(self, dataframe, tokenizer, max_input_len=512, max_target_len=128, is_test=False):\n            self.df = dataframe.reset_index(drop=True)\n            self.tokenizer = tokenizer\n            self.max_input_len = max_input_len\n            self.max_target_len = max_target_len\n            self.is_test = is_test\n            \n        def __len__(self):\n            return len(self.df)\n        \n        def __getitem__(self, idx):\n            row = self.df.iloc[idx]\n            dialogue = row.get('dialogue_preprocessed', row.get('dialogue', ''))\n            \n            inputs = self.tokenizer(\n                dialogue,\n                max_length=self.max_input_len,\n                padding='max_length',\n                truncation=True,\n                return_tensors='pt'\n            )\n            \n            if not self.is_test:\n                summary = row.get('summary_preprocessed', row.get('summary', ''))\n                targets = self.tokenizer(\n                    summary,\n                    max_length=self.max_target_len,\n                    padding='max_length',\n                    truncation=True,\n                    return_tensors='pt'\n                )\n                \n                # 라벨 생성 - 패딩 토큰을 -100으로 마스킹 (중요!)\n                labels = targets['input_ids'].squeeze()\n                labels[labels == self.tokenizer.pad_token_id] = -100  # 패딩 토큰 마스킹\n                \n                return {\n                    'input_ids': inputs['input_ids'].squeeze(),\n                    'attention_mask': inputs['attention_mask'].squeeze(),\n                    'labels': labels\n                }\n            else:\n                return {\n                    'input_ids': inputs['input_ids'].squeeze(),\n                    'attention_mask': inputs['attention_mask'].squeeze(),\n                    'idx': idx\n                }\n    \n    # 모델 선택\n    if 'primary_models' in config.get('models', {}):\n        model_config = config['models']['primary_models'][0]\n        model_name = model_config['name']\n    else:\n        model_name = \"gogamza/kobart-summarization\"\n        model_config = {'max_input_length': 512, 'max_target_length': 128}\n    \n    logger.write(f\"Training primary model: {model_name}\")\n    \n    # 토크나이저 로드\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    logger.write(\"✅ Tokenizer loaded\")\n    \n    # 모델 로드\n    model = BartForConditionalGeneration.from_pretrained(model_name)\n    logger.write(\"✅ Model loaded to CPU\")\n    \n    # =============================================================================\n    # GPU 최적화 1: Gradient Checkpointing (50% 메모리 감소)\n    # =============================================================================\n    if config['training'].get('gradient_checkpointing', True):\n        if hasattr(model, 'gradient_checkpointing_enable'):\n            model.gradient_checkpointing_enable()\n            logger.write(\"✅ Gradient Checkpointing ENABLED - 50% memory reduction\")\n        elif hasattr(model.config, 'gradient_checkpointing'):\n            model.config.gradient_checkpointing = True\n            logger.write(\"✅ Gradient Checkpointing ENABLED (via config)\")\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    logger.write(f\"Model moved to {device}\")\n    \n    # GPU 메모리 상태 로깅\n    if torch.cuda.is_available():\n        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n        reserved_memory = torch.cuda.memory_reserved(0) / 1024**3\n        allocated_memory = torch.cuda.memory_allocated(0) / 1024**3\n        logger.write(f\"GPU Memory - Total: {total_memory:.2f}GB, Reserved: {reserved_memory:.2f}GB, Allocated: {allocated_memory:.2f}GB\")\n    \n    # 데이터셋 생성 (샘플링 옵션)\n    if config['training'].get('use_sample', False):\n        sample_size = config['training'].get('sample_size', 1000)\n        train_sample = train_df.sample(n=min(sample_size, len(train_df)), random_state=42)\n        logger.write(f\"Using sample of {len(train_sample)} for training\")\n    else:\n        train_sample = train_df\n    \n    # =============================================================================\n    # GPU 최적화 2: Gradient Accumulation (작은 배치로 큰 배치 효과)\n    # =============================================================================\n    gradient_accumulation_steps = config['training'].get('gradient_accumulation_steps', 8)\n    effective_batch_size = config['training']['batch_size'] * gradient_accumulation_steps\n    logger.write(f\"✅ Gradient Accumulation: {gradient_accumulation_steps} steps\")\n    logger.write(f\"   Physical batch size: {config['training']['batch_size']}\")\n    logger.write(f\"   Effective batch size: {effective_batch_size}\")\n    \n    # 데이터로더 생성\n    train_dataset = DialogueSummaryDataset(\n        train_sample, tokenizer,\n        max_input_len=model_config.get('max_input_length', 512),\n        max_target_len=model_config.get('max_target_length', 128)\n    )\n    \n    val_dataset = DialogueSummaryDataset(\n        dev_df, tokenizer,\n        max_input_len=model_config.get('max_input_length', 512),\n        max_target_len=model_config.get('max_target_length', 128)\n    )\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['training']['batch_size'],\n        shuffle=True,\n        num_workers=0,  # GPU 메모리 절약\n        pin_memory=False  # 메모리 문제 시 False로\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['training']['batch_size'],\n        shuffle=False,\n        num_workers=0,\n        pin_memory=False\n    )\n    \n    # 학습 설정\n    num_epochs = config['training']['num_epochs']\n    learning_rate = float(config['training']['learning_rate']) if isinstance(config['training']['learning_rate'], str) else config['training']['learning_rate']\n    \n    # =============================================================================\n    # 🔥 CRITICAL FIX: Optimizer CPU에서 초기화 후 GPU로 이동\n    # =============================================================================\n    logger.write(\"\\n⚙️ Optimizer 초기화 중...\")\n    \n    # Optimizer 초기화 전 GPU 메모리 정리\n    clear_gpu_memory()\n    \n    optimizer = AdamW(model.parameters(), lr=learning_rate)\n    num_training_steps = num_epochs * len(train_loader) // gradient_accumulation_steps\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=int(num_training_steps * config['training']['warmup_ratio']),\n        num_training_steps=num_training_steps\n    )\n    \n    logger.write(\"✅ Optimizer initialized successfully\")\n    \n    # =============================================================================\n    # GPU 최적화 3: Mixed Precision Training (FP16) - GradScaler\n    # =============================================================================\n    scaler = GradScaler() if USE_AMP else None\n    \n    logger.write(f\"\\n{'='*70}\")\n    logger.write(f\"🚀 TRAINING START - GPU Optimized\")\n    logger.write(f\"{'='*70}\")\n    logger.write(f\"Epochs: {num_epochs}\")\n    logger.write(f\"Gradient Accumulation: {gradient_accumulation_steps}\")\n    logger.write(f\"Mixed Precision (FP16): {USE_AMP}\")\n    logger.write(f\"Gradient Checkpointing: {config['training'].get('gradient_checkpointing', True)}\")\n    logger.write(f\"{'='*70}\\n\")\n    \n    # 학습 루프 - GPU 최적화 적용\n    best_loss = float('inf')\n    global_step = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        optimizer.zero_grad()\n        \n        for step, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')):\n            try:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                \n                # Mixed Precision Forward Pass\n                if USE_AMP:\n                    with autocast():\n                        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                        loss = outputs.loss / gradient_accumulation_steps\n                else:\n                    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                    loss = outputs.loss / gradient_accumulation_steps\n                \n                total_loss += loss.item() * gradient_accumulation_steps\n                \n                # Mixed Precision Backward Pass\n                if USE_AMP:\n                    scaler.scale(loss).backward()\n                else:\n                    loss.backward()\n                \n                # Gradient Accumulation - N step마다 업데이트\n                if (step + 1) % gradient_accumulation_steps == 0:\n                    if USE_AMP:\n                        scaler.unscale_(optimizer)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), config['training'].get('max_grad_norm', 1.0))\n                    \n                    if USE_AMP:\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        optimizer.step()\n                    \n                    scheduler.step()\n                    optimizer.zero_grad()\n                    global_step += 1\n                    \n                    # GPU 메모리 정리\n                    if global_step % 50 == 0:  # 50 step마다\n                        clear_gpu_memory()\n                        \n            except RuntimeError as e:\n                if \"out of memory\" in str(e):\n                    logger.write(f\"\\n⚠️ OOM Error at step {step}! Clearing cache and skipping batch...\")\n                    clear_gpu_memory()\n                    optimizer.zero_grad()\n                    continue\n                else:\n                    raise e\n        \n        avg_loss = total_loss / len(train_loader)\n        logger.write(f\"  Epoch {epoch+1}: Train Loss = {avg_loss:.4f}\")\n        \n        # GPU 메모리 상태\n        if torch.cuda.is_available():\n            allocated = torch.cuda.memory_allocated(0) / 1024**3\n            reserved = torch.cuda.memory_reserved(0) / 1024**3\n            logger.write(f\"  GPU Memory: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB\")\n        \n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            output_dir = get_path(config['paths']['output_dir'])\n            output_dir.mkdir(parents=True, exist_ok=True)\n            model_path = output_dir / 'best_model_pipeline.pt'\n            \n            model_to_save = model.module if hasattr(model, 'module') else model\n            torch.save(model_to_save.state_dict(), model_path)\n            logger.write(f\"  ✅ Best model saved (loss: {best_loss:.4f})\")\n        \n        clear_gpu_memory()\n    \n    logger.write(f\"\\n{'='*70}\")\n    logger.write(f\"✅ Training completed successfully!\")\n    logger.write(f\"Best loss: {best_loss:.4f}\")\n    logger.write(f\"Total training steps: {global_step}\")\n    logger.write(f\"{'='*70}\\n\")\n    \n    update_status('model_training', 'completed')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T02:53:05.978027Z",
     "iopub.status.busy": "2025-10-10T02:53:05.977925Z",
     "iopub.status.idle": "2025-10-10T02:53:06.016808Z",
     "shell.execute_reply": "2025-10-10T02:53:06.016366Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stage 9: 최종 예측 및 제출\n",
    "if 'final_prediction' in config['pipeline']['stages']:\n",
    "    update_status('final_prediction', 'running')\n",
    "    logger.write(\"\\n=== Final Prediction ===\")\n",
    "    \n",
    "    # 필요한 함수 정의\n",
    "    def get_path(path_str):\n",
    "        \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "        path = Path(path_str)\n",
    "        if not path.is_absolute():\n",
    "            path = notebook_dir / path\n",
    "        return path\n",
    "    \n",
    "    # 테스트 데이터셋 생성\n",
    "    test_dataset = DialogueSummaryDataset(\n",
    "        test_df, tokenizer,\n",
    "        max_input_len=config['models']['primary_models'][0].get('max_input_length', 512),\n",
    "        max_target_len=config['models']['primary_models'][0].get('max_target_length', 128),\n",
    "        is_test=True\n",
    "    )\n",
    "    \n",
    "    # 배치 사이즈 설정 - inference_optimization에서 가져오기\n",
    "    inference_batch_size = 8  # 기본값\n",
    "    if 'inference_optimization' in config:\n",
    "        if 'batch_inference' in config['inference_optimization']:\n",
    "            if config['inference_optimization']['batch_inference'].get('optimal_batch_size') == 'auto':\n",
    "                inference_batch_size = 8\n",
    "            else:\n",
    "                inference_batch_size = config['inference_optimization']['batch_inference'].get('optimal_batch_size', 8)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=inference_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    # 예측 생성 파라미터 설정\n",
    "    # post_processing 섹션에서 가져오기\n",
    "    max_length = 150  # 기본값\n",
    "    if 'post_processing' in config:\n",
    "        if 'length_adjustment' in config['post_processing']:\n",
    "            max_length = config['post_processing']['length_adjustment'].get('max_length', 150)\n",
    "    \n",
    "    # hyperparameter_optimization search_space에서 기본값 가져오기\n",
    "    num_beams = 4  # 기본값\n",
    "    if 'hyperparameter_optimization' in config:\n",
    "        if 'search_space' in config['hyperparameter_optimization']:\n",
    "            num_beams_config = config['hyperparameter_optimization']['search_space'].get('num_beams', {})\n",
    "            if isinstance(num_beams_config, dict):\n",
    "                num_beams = num_beams_config.get('low', 4)  # low 값을 기본으로 사용\n",
    "    \n",
    "    # 예측 생성\n",
    "    logger.write(\"Generating predictions for test set...\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Predicting'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=max_length,\n",
    "                num_beams=num_beams,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3  # 기본값\n",
    "            )\n",
    "            \n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            predictions.extend(preds)\n",
    "    \n",
    "    logger.write(f\"Generated {len(predictions)} predictions\")\n",
    "    \n",
    "    # 제출 파일 생성\n",
    "    # test_df의 fname 컬럼 사용 (id가 아님)\n",
    "    submission_df = pd.DataFrame({\n",
    "        'fname': test_df['fname'],\n",
    "        'summary': predictions\n",
    "    })\n",
    "    \n",
    "    # 제출 파일 저장\n",
    "    submission_dir = get_path(config['paths']['submission_dir'])\n",
    "    submission_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    submission_path = submission_dir / f'full_pipeline_submission_{timestamp}.csv'\n",
    "    submission_df.to_csv(submission_path, index=True, encoding='utf-8')  # index=True로 변경\n",
    "    \n",
    "    logger.write(f\"Submission file saved: {submission_path}\")\n",
    "    logger.write(f\"Shape: {submission_df.shape}\")\n",
    "    \n",
    "    update_status('final_prediction', 'completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}