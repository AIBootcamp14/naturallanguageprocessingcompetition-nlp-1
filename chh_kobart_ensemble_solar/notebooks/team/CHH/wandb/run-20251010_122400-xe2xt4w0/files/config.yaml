_wandb:
    value:
        cli_version: 0.22.2
        e:
            i2yujlki16q3cx3x0p8bqd1vqx45f9fp:
                args:
                    - -f
                    - /tmp/tmp_ccsbiqh.json
                    - '--HistoryManager.hist_file=:memory:'
                cpu_count: 8
                cpu_count_logical: 16
                cudaVersion: "12.6"
                disk:
                    /:
                        total: "1081101176832"
                        used: "144118181888"
                email: ieyeppo.job@gmail.com
                executable: /home/ieyeppo/.pyenv/versions/nlp_py3_11_9/bin/python
                git:
                    commit: 71899e97a01fb85e59416b6d0ff28542e78d4725
                    remote: git@github.com:iejob/natural-language-processing-competition.git
                gpu: NVIDIA GeForce RTX 4090
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-b2b9e31d-4ca9-4907-d713-96771c28a1dd
                host: PotG
                memory:
                    total: "42058579968"
                os: Linux-6.6.87.1-microsoft-standard-WSL2-x86_64-with-glibc2.39
                program: <python with no main file>
                python: CPython 3.11.9
                root: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH
                startedAt: "2025-10-10T03:24:00.803291Z"
                writerId: i2yujlki16q3cx3x0p8bqd1vqx45f9fp
        m: []
        python_version: 3.11.9
        t:
            "1":
                - 1
                - 35
            "2":
                - 1
                - 35
            "3":
                - 13
                - 15
                - 16
            "4": 3.11.9
            "5": 0.22.2
            "8":
                - 13
            "12": 0.22.2
            "13": linux-x86_64
augmentation:
    value:
        enabled: true
        target_ratio: 1.5
        techniques:
            back_translation:
                enabled: true
                languages:
                    - en
                    - ja
                translation_model: Helsinki-NLP/opus-mt
            dialogue_reordering:
                enabled: false
            paraphrase:
                enabled: true
                model: lcw99/t5-base-korean-paraphrase
                num_variants: 2
                quality_threshold: 0.7
            token_replacement:
                enabled: true
                preserve_entities: true
                replacement_ratio: 0.15
cross_validation:
    value:
        enabled: true
        ensemble_folds: true
        n_splits: 5
        random_state: 42
        save_all_folds: true
        shuffle: true
        train_all_folds: true
data_quality:
    value:
        checks:
            semantic:
                check_information_loss: true
                max_compression_ratio: 0.5
                min_compression_ratio: 0.1
            statistical:
                outlier_detection: true
                outlier_method: isolation_forest
                outlier_threshold: 0.05
            structural:
                check_duplicates: true
                check_encoding: true
                check_nulls: true
        enabled: true
        handle_issues:
            fix_encoding: true
            remove_duplicates: true
            remove_outliers: true
deployment:
    value:
        monitoring:
            enabled: true
            health_check_interval: 60
            metrics_port: 9090
        serving:
            framework: fastapi
            port: 8000
            workers: 4
        versioning:
            enabled: true
            registry: local
ensemble:
    value:
        advanced:
            blending:
                enabled: false
                validation_size: 0.2
            stacking:
                cv_folds: 3
                enabled: true
                meta_learner: lgbm
        base_method: weighted_average
        test_time_augmentation:
            aggregation: mean
            enabled: true
            num_augmentations: 5
experiment:
    value:
        checkpointing:
            keep_last_n: 3
            save_best_only: false
            save_every_n_epochs: 1
        description: 모든 최적화 기법이 적용된 최종 파이프라인
        name: full_pipeline_v1
        results_format:
            - json
            - csv
            - pickle
        save_all_results: true
        timestamp: true
        version: 1.0.0
gpu:
    value:
        auto_optimization:
            enabled: true
            find_optimal_batch_size: true
            gradient_accumulation_auto: true
        cuda_device: 0
        device: cuda
        gpu_check_path: ../../../src/utils/gpu_optimization/team_gpu_check.py
        memory_fraction: 0.95
        mixed_precision: true
        use_gpu_optimization: true
hyperparameter_optimization:
    value:
        direction: maximize
        enabled: true
        metric: rouge_l
        n_trials: 100
        pruner: MedianPruner
        sampler: TPESampler
        search_space:
            batch_size:
                choices:
                    - 4
                    - 8
                    - 16
                type: categorical
            learning_rate:
                high: "1e-4"
                log: true
                low: "1e-6"
                type: float
            lora_alpha:
                high: 128
                low: 8
                step: 8
                type: int
            lora_r:
                high: 64
                low: 4
                step: 4
                type: int
            num_beams:
                high: 8
                low: 2
                type: int
            temperature:
                high: 1
                low: 0.1
                type: float
inference_optimization:
    value:
        batch_inference:
            dynamic_batching: true
            enabled: true
            optimal_batch_size: auto
        onnx_conversion:
            enabled: true
            optimize: true
            quantization: dynamic
        tensorrt:
            enabled: false
            precision: fp16
logging:
    value:
        format: '%(asctime)s - [%(pipeline_stage)s] - %(name)s - %(levelname)s - %(message)s'
        level: INFO
        loggers:
            - pipeline
            - training
            - evaluation
            - inference
        notebook_logger_path: ../../../src/logging/notebook_logger.py
        save_to_file: true
        use_notebook_logger: true
models:
    value:
        auxiliary_models:
            - model_type: seq2seq
              name: digit82/kobart-summarization
              weight: 0.1
            - model_type: seq2seq
              name: gogamza/kobart-summarization
              weight: 0.05
        primary_models:
            - lora_alpha: 32
              lora_r: 16
              name: upstage/SOLAR-10.7B-Instruct-v1.0
              use_lora: true
              weight: 0.35
            - lora_alpha: 16
              lora_r: 8
              name: EleutherAI/polyglot-ko-12.8b
              use_lora: true
              weight: 0.3
            - lora_alpha: 16
              lora_r: 8
              name: nlpai-lab/kullm-v2
              use_lora: true
              weight: 0.2
paths:
    value:
        augmented_data_dir: ./data/augmented
        cache_dir: ./cache/full_pipeline
        data_dir: ../../../data/raw
        dev_file: ../../../data/raw/dev.csv
        log_dir: ./logs/full_pipeline
        output_dir: ./models/full_pipeline
        preprocessed_data_dir: ./data/preprocessed
        submission_dir: ./submissions/full_pipeline
        test_file: ../../../data/raw/test.csv
        train_file: ../../../data/raw/train.csv
        visualization_dir: ./logs/full_pipeline/visualizations
performance_targets:
    value:
        overall: 0.85
        rouge_1: 0.45
        rouge_2: 0.3
        rouge_l: 0.4
pipeline:
    value:
        parallel_stages:
            - - model_training
              - prompt_optimization
            - - cross_validation
              - tta_preparation
        stages:
            - data_quality_check
            - data_preprocessing
            - data_augmentation
            - model_training
            - cross_validation
            - ensemble
            - hyperparameter_optimization
            - inference_optimization
            - final_prediction
post_processing:
    value:
        grammar_correction:
            enabled: true
            tool: py-hanspell
        length_adjustment:
            max_length: 150
            min_length: 30
            target_length: 80
        quality_check:
            check_coherence: true
            check_completeness: true
            min_rouge_score: 0.3
preprocessing:
    value:
        data_split:
            seed: 42
            stratify: false
            validation_ratio: 0.1
        noise_removal:
            fix_escaped_chars: true
            normalize_whitespace: true
            remove_html_tags: true
            remove_special_tokens: false
        token_normalization:
            masking_tokens:
                preserve: true
                tokens:
                    - '#PhoneNumber#'
                    - '#Address#'
                    - '#SSN#'
                    - '#Email#'
            person_tokens:
                format: '#Person{id}#'
                standardize: true
prompt_engineering:
    value:
        ab_testing:
            enabled: true
            num_variants: 5
            selection_metric: rouge_l
        enabled: true
        templates:
            chain_of_thought:
                enabled: true
                template: |
                    다음 대화를 단계적으로 분석하여 요약하세요.

                    1단계: 주요 주제 파악
                    2단계: 핵심 정보 추출
                    3단계: 간결한 요약 작성

                    대화: {dialogue}

                    분석 및 요약:
            few_shot:
                enabled: true
                example_selection: random
                num_examples: 3
            zero_shot:
                enabled: true
                template: |
                    다음 대화를 3-5문장으로 요약하세요:
                    {dialogue}

                    요약:
reproducibility:
    value:
        benchmark: false
        deterministic: true
        seed: 42
        worker_init_fn: true
solar_api:
    value:
        api_key: up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT
        enabled: true
        hybrid_approach:
            confidence_threshold: 0.7
            use_for_difficult_samples: true
            use_for_validation: true
        optimization:
            batch_size: 10
            cache_responses: true
            token_budget: 100000
training:
    value:
        batch_size: 4
        early_stopping:
            metric: eval_rouge_l
            patience: 3
            threshold: 0.001
        fp16: true
        gradient_accumulation_steps: 8
        gradient_checkpointing: true
        learning_rate: "2e-5"
        max_grad_norm: 0.3
        num_epochs: 5
        scheduler: cosine
        seed: 42
        warmup_ratio: 0.1
        weight_decay: 0.01
visualization:
    value:
        enabled: true
        plots:
            - training_curves
            - model_comparison
            - confusion_matrix
            - rouge_distribution
            - sample_difficulty_heatmap
            - ensemble_weights
            - hyperparameter_importance
        save_path: ../logs/full_pipeline/visualizations
        training_viz_path: ../../../src/utils/visualizations/training_viz.py
        use_training_viz: true
wandb:
    value:
        entity: ieyeppo
        log_artifacts: true
        log_datasets: true
        log_models: true
        mode: online
        name: full-pipeline-integrated
        notes: 모든 기법이 통합된 최종 파이프라인
        project: nlp-competition
        tags:
            - full_pipeline
            - production
            - all_techniques
