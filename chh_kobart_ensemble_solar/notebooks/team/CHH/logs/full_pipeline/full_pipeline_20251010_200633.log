[2025-10-10 20:06:33] ==================================================
[2025-10-10 20:06:33] FULL PIPELINE EXECUTION STARTED
[2025-10-10 20:06:33] Timestamp: 20251010_200633
[2025-10-10 20:06:33] Config: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/configs/config_full_pipeline.yaml
[2025-10-10 20:06:33] ==================================================
[2025-10-10 20:06:33] GPU Tier: LOW
[2025-10-10 20:06:33] Auto-optimization enabled
[2025-10-10 20:06:33] Finding optimal batch size...
[2025-10-10 20:06:33] [data_quality_check] Status: running
[2025-10-10 20:06:33] 
=== Data Quality Check ===
[2025-10-10 20:06:33] Loading data from config paths:
[2025-10-10 20:06:33]   - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv
[2025-10-10 20:06:33]   - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv
[2025-10-10 20:06:33]   - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv
[2025-10-10 20:06:33] ‚úÖ Loaded 12457 training samples
[2025-10-10 20:06:33] ‚úÖ Loaded 499 dev samples
[2025-10-10 20:06:33] ‚úÖ Loaded 499 test samples
[2025-10-10 20:06:33] Null values - Train: 0, Dev: 0, Test: 0
[2025-10-10 20:06:33] Duplicate rows in training data: 0
[2025-10-10 20:06:33] ‚úÖ Data loading completed successfully!
[2025-10-10 20:06:33] [data_quality_check] Status: completed
[2025-10-10 20:06:33] 
=== Comprehensive Data Quality Validation ===
[2025-10-10 20:06:33] 
üìä Data Quality Report:
[2025-10-10 20:06:33] 
Structural Validation:
[2025-10-10 20:06:33]   - Train shape: (12457, 4)
[2025-10-10 20:06:33]   - Dev shape: (499, 4)
[2025-10-10 20:06:33]   - Test shape: (499, 2)
[2025-10-10 20:06:33]   - Column match: True
[2025-10-10 20:06:33] 
Text Quality:
[2025-10-10 20:06:33]   - Avg dialogue length: 406.1
[2025-10-10 20:06:33]   - Compression ratio: 23.23%
[2025-10-10 20:06:33]   - Encoding issues: 0
[2025-10-10 20:06:33]   - Special chars: 12455
[2025-10-10 20:06:33] 
Label Distribution:
[2025-10-10 20:06:33]   - Unique topics: 9235
[2025-10-10 20:06:33]   - Imbalance ratio: 130.00
[2025-10-10 20:06:33] 
Outlier Detection:
[2025-10-10 20:06:33]   - Outlier count: 355
[2025-10-10 20:06:33]   - Outlier ratio: 2.85%
[2025-10-10 20:06:33] 
üìã Recommendations:
[2025-10-10 20:06:33]   ‚úì Clean special characters from text
[2025-10-10 20:06:33]   ‚úì Consider data augmentation for underrepresented topics
[2025-10-10 20:06:33] ‚ö†Ô∏è Error during data validation: You must call wandb.init() before wandb.log()
[2025-10-10 20:06:33]    Skipping detailed validation. Please check data loading in cell 7.
[2025-10-10 20:06:33] Visualizations will be saved to: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/logs/full_pipeline/visualizations
[2025-10-10 20:06:36] WandB initialized for full pipeline tracking
[2025-10-10 20:06:36] [data_preprocessing] Status: running
[2025-10-10 20:06:36] 
=== Data Preprocessing ===
[2025-10-10 20:06:36] Preprocessed 12457 training samples
[2025-10-10 20:06:36] Preprocessed 499 dev samples
[2025-10-10 20:06:36] Preprocessed 499 test samples
[2025-10-10 20:06:36] 
Text Length Statistics:
[2025-10-10 20:06:36]   Dialogue - Mean: 347.3, Max: 1952
[2025-10-10 20:06:36]   Summary - Mean: 85.8, Max: 376
[2025-10-10 20:06:36] [data_preprocessing] Status: completed
[2025-10-10 20:06:36] [hyperparameter_optimization] Status: running
[2025-10-10 20:06:36] 
======================================================================
[2025-10-10 20:06:36] üéØ HYPERPARAMETER OPTIMIZATION STAGE
[2025-10-10 20:06:36] ======================================================================
[2025-10-10 20:06:36] ‚úÖ Optimization ENABLED with 100 trials
[2025-10-10 20:06:36] 
============================================================
[2025-10-10 20:06:36] üéØ OPTUNA HYPERPARAMETER OPTIMIZATION STARTING
[2025-10-10 20:06:36] ============================================================
[2025-10-10 20:06:36] Number of trials: 100
[2025-10-10 20:06:36] Optimization metric: rouge_l
[2025-10-10 20:06:36] 
üöÄ Starting optimization...
[2025-10-10 20:06:36] 
Trial 0: {'learning_rate': 5.6115164153345e-05, 'batch_size': 4, 'lora_r': 12, 'lora_alpha': 24, 'num_beams': 2, 'temperature': 0.8795585311974417, 'warmup_ratio': 0.12022300234864176, 'weight_decay': 0.07080725777960455, 'top_p': 0.8041168988591605}
[2025-10-10 20:06:36] 
Trial 1: {'learning_rate': 0.0008706020878304854, 'batch_size': 4, 'lora_r': 12, 'lora_alpha': 40, 'num_beams': 5, 'temperature': 0.48875051677790415, 'warmup_ratio': 0.058245828039608386, 'weight_decay': 0.06118528947223795, 'top_p': 0.8278987721304084}
[2025-10-10 20:06:36] 
Trial 2: {'learning_rate': 3.8396292998041685e-05, 'batch_size': 16, 'lora_r': 16, 'lora_alpha': 72, 'num_beams': 6, 'temperature': 0.14180537144799796, 'warmup_ratio': 0.12150897038028768, 'weight_decay': 0.017052412368729154, 'top_p': 0.813010318597056}
[2025-10-10 20:06:36] 
Trial 3: {'learning_rate': 0.000790261954970823, 'batch_size': 4, 'lora_r': 8, 'lora_alpha': 88, 'num_beams': 5, 'temperature': 0.20983441136030095, 'warmup_ratio': 0.09903538202225404, 'weight_decay': 0.0034388521115218396, 'top_p': 0.9818640804157565}
[2025-10-10 20:06:36] 
Trial 4: {'learning_rate': 3.292759134423613e-05, 'batch_size': 4, 'lora_r': 36, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.7976195410250031, 'warmup_ratio': 0.18789978831283782, 'weight_decay': 0.08948273504276488, 'top_p': 0.919579995762217}
[2025-10-10 20:06:36] 
Trial 5: {'learning_rate': 0.0006978281265126031, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 56, 'num_beams': 3, 'temperature': 0.8458637582367364, 'warmup_ratio': 0.07135066533871785, 'weight_decay': 0.02809345096873808, 'top_p': 0.9085392166316497}
[2025-10-10 20:06:37] 
Trial 6: {'learning_rate': 1.913588048769229e-05, 'batch_size': 16, 'lora_r': 52, 'lora_alpha': 32, 'num_beams': 2, 'temperature': 0.8339152856093507, 'warmup_ratio': 0.14137146876952342, 'weight_decay': 0.07290071680409874, 'top_p': 0.9542540693371891}
[2025-10-10 20:06:37] 
Trial 7: {'learning_rate': 1.4063366777718176e-05, 'batch_size': 16, 'lora_r': 40, 'lora_alpha': 48, 'num_beams': 2, 'temperature': 0.379884089544096, 'warmup_ratio': 0.06503666440534941, 'weight_decay': 0.0729606178338064, 'top_p': 0.9275114942710426}
[2025-10-10 20:06:37] 
Trial 8: {'learning_rate': 0.000594874681321977, 'batch_size': 16, 'lora_r': 52, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.5444160367279517, 'warmup_ratio': 0.10454656587639882, 'weight_decay': 0.042754101835854964, 'top_p': 0.8050838253488191}
[2025-10-10 20:06:37] 
Trial 9: {'learning_rate': 1.6435497475111308e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 120, 'num_beams': 3, 'temperature': 0.4693446307320668, 'warmup_ratio': 0.15111022770860974, 'weight_decay': 0.022879816549162248, 'top_p': 0.8153959819657587}
[2025-10-10 20:06:37] 
Trial 10: {'learning_rate': 0.0002509538254778771, 'batch_size': 8, 'lora_r': 64, 'lora_alpha': 128, 'num_beams': 4, 'temperature': 0.37050834074441147, 'warmup_ratio': 0.0031189599316912286, 'weight_decay': 0.03924528921026325, 'top_p': 0.8669590352446472}
[2025-10-10 20:06:37] 
Trial 11: {'learning_rate': 1.0322960416065201e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 128, 'num_beams': 3, 'temperature': 0.3360442409320184, 'warmup_ratio': 0.18218996750099392, 'weight_decay': 0.09435438058122501, 'top_p': 0.8647628938861509}
[2025-10-10 20:06:37] 
Trial 12: {'learning_rate': 1.0370579352014641e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 128, 'num_beams': 4, 'temperature': 0.6804495294564787, 'warmup_ratio': 0.19775497252335106, 'weight_decay': 0.09904235739514478, 'top_p': 0.8590398672080966}
[2025-10-10 20:06:37] 
Trial 13: {'learning_rate': 0.00012774135799436964, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 104, 'num_beams': 3, 'temperature': 0.3022059308213879, 'warmup_ratio': 0.16191281769380567, 'weight_decay': 0.01896901131981868, 'top_p': 0.8593943414843724}
[2025-10-10 20:06:37] 
Trial 14: {'learning_rate': 2.1533663334390727e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 104, 'num_beams': 4, 'temperature': 0.6503220664418476, 'warmup_ratio': 0.16274515950801005, 'weight_decay': 0.05166548565180652, 'top_p': 0.8830054677342667}
[2025-10-10 20:06:37] 
Trial 15: {'learning_rate': 2.4165483913864722e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 104, 'num_beams': 4, 'temperature': 0.6636798035918531, 'warmup_ratio': 0.157051761228143, 'weight_decay': 0.0006794582733295057, 'top_p': 0.8360378813543303}
[2025-10-10 20:06:37] 
Trial 16: {'learning_rate': 6.956746038661218e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 104, 'num_beams': 6, 'temperature': 0.6784268911829191, 'warmup_ratio': 0.16304971347740554, 'weight_decay': 0.055188970463428993, 'top_p': 0.8940003385967338}
[2025-10-10 20:06:37] 
Trial 17: {'learning_rate': 0.00013738198354053957, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 88, 'num_beams': 4, 'temperature': 0.995123861989222, 'warmup_ratio': 0.14050981032764043, 'weight_decay': 0.033282416286616795, 'top_p': 0.8866571662960941}
[2025-10-10 20:06:37] 
Trial 18: {'learning_rate': 2.565570347466517e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 8, 'num_beams': 3, 'temperature': 0.45267481671743476, 'warmup_ratio': 0.1729760059402413, 'weight_decay': 0.04828486464613923, 'top_p': 0.8379315845736517}
[2025-10-10 20:06:37] 
Trial 19: {'learning_rate': 5.657396087817041e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 112, 'num_beams': 5, 'temperature': 0.6005475021920503, 'warmup_ratio': 0.14473687452448478, 'weight_decay': 0.02169838469202746, 'top_p': 0.9430718175625277}
[2025-10-10 20:06:37] 
Trial 20: {'learning_rate': 1.8438882376111873e-05, 'batch_size': 8, 'lora_r': 64, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.7497199490525606, 'warmup_ratio': 0.027753987886119755, 'weight_decay': 0.05718553129235758, 'top_p': 0.9987685570099417}
[2025-10-10 20:06:37] 
Trial 21: {'learning_rate': 1.683848556284197e-05, 'batch_size': 8, 'lora_r': 60, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.7468655799630235, 'warmup_ratio': 0.0014942070483525624, 'weight_decay': 0.061836192221023066, 'top_p': 0.9757254013166067}
[2025-10-10 20:06:37] 
Trial 22: {'learning_rate': 3.127131627807907e-05, 'batch_size': 8, 'lora_r': 4, 'lora_alpha': 112, 'num_beams': 7, 'temperature': 0.5957128359321127, 'warmup_ratio': 0.03063050371447289, 'weight_decay': 0.08208672433681731, 'top_p': 0.994075960980361}
[2025-10-10 20:06:37] 
Trial 23: {'learning_rate': 3.90539962849963e-05, 'batch_size': 8, 'lora_r': 4, 'lora_alpha': 120, 'num_beams': 8, 'temperature': 0.5873167389465909, 'warmup_ratio': 0.030803275149133752, 'weight_decay': 0.08148272405058854, 'top_p': 0.8805783124166526}
[2025-10-10 20:06:37] 
Trial 24: {'learning_rate': 8.403991127384985e-05, 'batch_size': 8, 'lora_r': 4, 'lora_alpha': 112, 'num_beams': 7, 'temperature': 0.4710274858116029, 'warmup_ratio': 0.1033660521394493, 'weight_decay': 0.012169455502476813, 'top_p': 0.9424558555729028}
[2025-10-10 20:06:37] 
Trial 25: {'learning_rate': 2.452510912989695e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 112, 'num_beams': 7, 'temperature': 0.5302243724466196, 'warmup_ratio': 0.0804800128901909, 'weight_decay': 0.08487682398674518, 'top_p': 0.9100897473891826}
[2025-10-10 20:06:37] 
Trial 26: {'learning_rate': 1.2739385933835197e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 96, 'num_beams': 5, 'temperature': 0.6350284049381522, 'warmup_ratio': 0.12181876304438032, 'weight_decay': 0.029880663607875134, 'top_p': 0.9640723701100812}
[2025-10-10 20:06:37] 
Trial 27: {'learning_rate': 3.5610140632963465e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 120, 'num_beams': 4, 'temperature': 0.42776666328018165, 'warmup_ratio': 0.04048265469146311, 'weight_decay': 0.046029485305756374, 'top_p': 0.8254055086438484}
[2025-10-10 20:06:37] 
Trial 28: {'learning_rate': 0.0002090316068728911, 'batch_size': 4, 'lora_r': 40, 'lora_alpha': 64, 'num_beams': 3, 'temperature': 0.25976266522502295, 'warmup_ratio': 0.08862058456303999, 'weight_decay': 0.03602600827614375, 'top_p': 0.8502931757834995}
[2025-10-10 20:06:37] 
Trial 29: {'learning_rate': 5.342037044887353e-05, 'batch_size': 16, 'lora_r': 16, 'lora_alpha': 80, 'num_beams': 2, 'temperature': 0.9306004540295836, 'warmup_ratio': 0.13067292225107183, 'weight_decay': 0.0809760169872833, 'top_p': 0.9995237949195853}
[2025-10-10 20:06:37] 
Trial 30: {'learning_rate': 5.572499750139758e-05, 'batch_size': 4, 'lora_r': 8, 'lora_alpha': 120, 'num_beams': 8, 'temperature': 0.7275267954460478, 'warmup_ratio': 0.14961198398797018, 'weight_decay': 0.008934880367805834, 'top_p': 0.9274995338850026}
[2025-10-10 20:06:37] 
Trial 31: {'learning_rate': 3.094824177427026e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 120, 'num_beams': 4, 'temperature': 0.41434230737368083, 'warmup_ratio': 0.04511356346602678, 'weight_decay': 0.04731037182895204, 'top_p': 0.8211646027005765}
[2025-10-10 20:06:37] 
Trial 32: {'learning_rate': 4.127644122189065e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 96, 'num_beams': 5, 'temperature': 0.5382740247050618, 'warmup_ratio': 0.04862924515974718, 'weight_decay': 0.06353192693130189, 'top_p': 0.8001964558156949}
[2025-10-10 20:06:37] 
Trial 33: {'learning_rate': 1.921628288305131e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 120, 'num_beams': 4, 'temperature': 0.49703807688182705, 'warmup_ratio': 0.031105511208068377, 'weight_decay': 0.06726500545244228, 'top_p': 0.8431558325184365}
[2025-10-10 20:06:37] 
Trial 34: {'learning_rate': 3.092169966321551e-05, 'batch_size': 8, 'lora_r': 12, 'lora_alpha': 112, 'num_beams': 3, 'temperature': 0.43283343513352945, 'warmup_ratio': 0.020633958420788447, 'weight_decay': 0.025344039838279056, 'top_p': 0.8220539492156288}
[2025-10-10 20:06:37] 
Trial 35: {'learning_rate': 1.317706001964015e-05, 'batch_size': 4, 'lora_r': 36, 'lora_alpha': 96, 'num_beams': 4, 'temperature': 0.6018640608902907, 'warmup_ratio': 0.051374024631548235, 'weight_decay': 0.05325989793124686, 'top_p': 0.8140386624198233}
[2025-10-10 20:06:37] 
Trial 36: {'learning_rate': 4.706669513733055e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 128, 'num_beams': 5, 'temperature': 0.15149894820208998, 'warmup_ratio': 0.17540680707153258, 'weight_decay': 0.03994122947087525, 'top_p': 0.8776955612686084}
[2025-10-10 20:06:37] 
Trial 37: {'learning_rate': 4.7657558622432465e-05, 'batch_size': 16, 'lora_r': 16, 'lora_alpha': 128, 'num_beams': 5, 'temperature': 0.18316925433715736, 'warmup_ratio': 0.18612453092975198, 'weight_decay': 0.04000326691864714, 'top_p': 0.8752511701111695}
[2025-10-10 20:06:37] 
Trial 38: {'learning_rate': 2.4205817609308327e-05, 'batch_size': 4, 'lora_r': 24, 'lora_alpha': 104, 'num_beams': 6, 'temperature': 0.1587345254754327, 'warmup_ratio': 0.17574815541512825, 'weight_decay': 0.013110143608165236, 'top_p': 0.8974295447028237}
[2025-10-10 20:06:37] 
Trial 39: {'learning_rate': 2.531494835284367e-05, 'batch_size': 4, 'lora_r': 20, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.23161393776092942, 'warmup_ratio': 0.11376353997362912, 'weight_decay': 0.012787574144916825, 'top_p': 0.9019753053266991}
[2025-10-10 20:06:37] 
Trial 40: {'learning_rate': 1.6873896735711707e-05, 'batch_size': 4, 'lora_r': 12, 'lora_alpha': 104, 'num_beams': 7, 'temperature': 0.12101077392936, 'warmup_ratio': 0.1946448262091431, 'weight_decay': 0.021797660594574973, 'top_p': 0.921367729376461}
[2025-10-10 20:06:37] 
Trial 41: {'learning_rate': 2.016990986416263e-05, 'batch_size': 4, 'lora_r': 24, 'lora_alpha': 112, 'num_beams': 6, 'temperature': 0.16781736823297833, 'warmup_ratio': 0.1719144766376781, 'weight_decay': 0.006838893299693837, 'top_p': 0.8899899147100928}
[2025-10-10 20:06:37] 
Trial 42: {'learning_rate': 7.315317123213242e-05, 'batch_size': 4, 'lora_r': 24, 'lora_alpha': 128, 'num_beams': 6, 'temperature': 0.10898373397063726, 'warmup_ratio': 0.17666476815831086, 'weight_decay': 0.015121316840524262, 'top_p': 0.9082635108940528}
[2025-10-10 20:06:37] 
Trial 43: {'learning_rate': 2.987550564700592e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 96, 'num_beams': 5, 'temperature': 0.27229653218647604, 'warmup_ratio': 0.1312614772306692, 'weight_decay': 0.03149393197467222, 'top_p': 0.8717366962457426}
[2025-10-10 20:06:37] 
Trial 44: {'learning_rate': 1.4183533306486784e-05, 'batch_size': 16, 'lora_r': 36, 'lora_alpha': 104, 'num_beams': 6, 'temperature': 0.3330280784857712, 'warmup_ratio': 0.16834508714623803, 'weight_decay': 0.07362506042898428, 'top_p': 0.9359224673765495}
[2025-10-10 20:06:37] 
Trial 45: {'learning_rate': 2.2125857907120275e-05, 'batch_size': 8, 'lora_r': 16, 'lora_alpha': 120, 'num_beams': 5, 'temperature': 0.19234876816197186, 'warmup_ratio': 0.1564552423218515, 'weight_decay': 0.025485267457427647, 'top_p': 0.8968008735475811}
[2025-10-10 20:06:37] 
Trial 46: {'learning_rate': 4.410553554527763e-05, 'batch_size': 8, 'lora_r': 12, 'lora_alpha': 48, 'num_beams': 2, 'temperature': 0.7963122850242701, 'warmup_ratio': 0.18189387147264963, 'weight_decay': 0.03622538665091601, 'top_p': 0.8545578630975141}
[2025-10-10 20:06:37] 
Trial 47: {'learning_rate': 2.8793297545562394e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 128, 'num_beams': 7, 'temperature': 0.14441639986086824, 'warmup_ratio': 0.19304852996515295, 'weight_decay': 0.0024125324630044215, 'top_p': 0.8845632607966017}
[2025-10-10 20:06:37] 
Trial 48: {'learning_rate': 0.0001106314283459816, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 112, 'num_beams': 6, 'temperature': 0.227509281192289, 'warmup_ratio': 0.152254905249286, 'weight_decay': 0.04371339282623083, 'top_p': 0.91427665181948}
[2025-10-10 20:06:37] 
Trial 49: {'learning_rate': 1.0218175796834212e-05, 'batch_size': 16, 'lora_r': 44, 'lora_alpha': 80, 'num_beams': 5, 'temperature': 0.5017014353557825, 'warmup_ratio': 0.16418201035248006, 'weight_decay': 0.018055373676510417, 'top_p': 0.9032601502373351}
[2025-10-10 20:06:37] 
Trial 50: {'learning_rate': 1.4733364262930062e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 104, 'num_beams': 3, 'temperature': 0.7156901210138211, 'warmup_ratio': 0.14017765897144893, 'weight_decay': 0.09966547351713763, 'top_p': 0.9552864405280675}
[2025-10-10 20:06:37] 
Trial 51: {'learning_rate': 3.4749287491699306e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 120, 'num_beams': 4, 'temperature': 0.5804493544071787, 'warmup_ratio': 0.06462677823093144, 'weight_decay': 0.04525628475662426, 'top_p': 0.8295050470927703}
[2025-10-10 20:06:37] 
Trial 52: {'learning_rate': 3.709539583911614e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 120, 'num_beams': 4, 'temperature': 0.37166339692151296, 'warmup_ratio': 0.011684432550358836, 'weight_decay': 0.05264710807566457, 'top_p': 0.8107728263361236}
[2025-10-10 20:06:37] 
Trial 53: {'learning_rate': 2.2116471515291207e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 128, 'num_beams': 4, 'temperature': 0.6427941433608708, 'warmup_ratio': 0.037550236523587396, 'weight_decay': 0.05681344701573311, 'top_p': 0.8469543460207246}
[2025-10-10 20:06:37] 
Trial 54: {'learning_rate': 2.0602507190704607e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 128, 'num_beams': 5, 'temperature': 0.6590026610203907, 'warmup_ratio': 0.1783392489343954, 'weight_decay': 0.07002797498285046, 'top_p': 0.8642848146742853}
[2025-10-10 20:06:37] 
Trial 55: {'learning_rate': 1.6153222842386155e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 112, 'num_beams': 3, 'temperature': 0.6294595126891122, 'warmup_ratio': 0.19905541465294616, 'weight_decay': 0.09340740175674117, 'top_p': 0.876193610295522}
[2025-10-10 20:06:37] 
Trial 56: {'learning_rate': 1.240977432071961e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 128, 'num_beams': 3, 'temperature': 0.7843024391422477, 'warmup_ratio': 0.012859854671353824, 'weight_decay': 0.07712187730513362, 'top_p': 0.8481411504106939}
[2025-10-10 20:06:37] 
Trial 57: {'learning_rate': 2.701752798859616e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.7004057497694031, 'warmup_ratio': 0.07889302920314219, 'weight_decay': 0.050980467678198305, 'top_p': 0.8649055419818599}
[2025-10-10 20:06:37] 
Trial 58: {'learning_rate': 0.00046780959898243686, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 40, 'num_beams': 8, 'temperature': 0.6941039570881306, 'warmup_ratio': 0.09462173181517183, 'weight_decay': 0.04973904900065393, 'top_p': 0.8921902459743193}
[2025-10-10 20:06:37] 
Trial 59: {'learning_rate': 2.7552780289527886e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 32, 'num_beams': 8, 'temperature': 0.5551481428755193, 'warmup_ratio': 0.07806911127120207, 'weight_decay': 0.03985403218649806, 'top_p': 0.882326120791791}
[2025-10-10 20:06:37] 
Trial 60: {'learning_rate': 2.522156294909442e-05, 'batch_size': 8, 'lora_r': 8, 'lora_alpha': 16, 'num_beams': 8, 'temperature': 0.574282276871496, 'warmup_ratio': 0.07785966373611808, 'weight_decay': 0.05998144965629997, 'top_p': 0.8689683785783211}
[2025-10-10 20:06:37] 
Trial 61: {'learning_rate': 2.7556704908524016e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.8503731063778148, 'warmup_ratio': 0.06780992918089138, 'weight_decay': 0.04151060115765849, 'top_p': 0.8804624729548008}
[2025-10-10 20:06:37] 
Trial 62: {'learning_rate': 6.507558563298224e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 8, 'num_beams': 7, 'temperature': 0.6219690558816099, 'warmup_ratio': 0.05844252858732275, 'weight_decay': 0.03663431449996464, 'top_p': 0.8626240918018101}
[2025-10-10 20:06:37] 
Trial 63: {'learning_rate': 4.5725233374529764e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 16, 'num_beams': 8, 'temperature': 0.5580159350790999, 'warmup_ratio': 0.11082473016769612, 'weight_decay': 0.026785425261978142, 'top_p': 0.8846400400556139}
[2025-10-10 20:06:37] 
Trial 64: {'learning_rate': 0.0009841670344314273, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 16, 'num_beams': 8, 'temperature': 0.5139044376055386, 'warmup_ratio': 0.08118173588223437, 'weight_decay': 0.026851414418151847, 'top_p': 0.9882704605407188}
[2025-10-10 20:06:37] 
Trial 65: {'learning_rate': 1.677379500013992e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.4720398360237838, 'warmup_ratio': 0.11154008727367384, 'weight_decay': 0.022201193441123306, 'top_p': 0.8864128918251735}
[2025-10-10 20:06:37] 
Trial 66: {'learning_rate': 1.1805094925833307e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 16, 'num_beams': 8, 'temperature': 0.45784145810741744, 'warmup_ratio': 0.11609704954088851, 'weight_decay': 0.021540806414871373, 'top_p': 0.8885106166288887}
[2025-10-10 20:06:37] 
Trial 67: {'learning_rate': 1.7219427754068686e-05, 'batch_size': 16, 'lora_r': 36, 'lora_alpha': 24, 'num_beams': 7, 'temperature': 0.7583678305641154, 'warmup_ratio': 0.13378523527591568, 'weight_decay': 0.009268606046102927, 'top_p': 0.8994189389655497}
[2025-10-10 20:06:37] 
Trial 68: {'learning_rate': 2.227458918150894e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.4032573606932476, 'warmup_ratio': 0.10944598496589243, 'weight_decay': 0.0054989837204231715, 'top_p': 0.9166081492895803}
[2025-10-10 20:06:37] 
Trial 69: {'learning_rate': 1.500126697452724e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.4034661117946926, 'warmup_ratio': 0.10510925206548839, 'weight_decay': 0.004912847433152478, 'top_p': 0.9248114000175955}
[2025-10-10 20:06:37] 
Trial 70: {'learning_rate': 1.5400439475960335e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.3901632296243603, 'warmup_ratio': 0.10580681222644418, 'weight_decay': 0.005397124106637472, 'top_p': 0.9304083613930098}
[2025-10-10 20:06:37] 
Trial 71: {'learning_rate': 1.828294303807379e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.3474546763851418, 'warmup_ratio': 0.0934595482583817, 'weight_decay': 0.014607022987833684, 'top_p': 0.9200236760389789}
[2025-10-10 20:06:37] 
Trial 72: {'learning_rate': 1.1435810914716776e-05, 'batch_size': 4, 'lora_r': 32, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.33201876993592494, 'warmup_ratio': 0.09525746034919104, 'weight_decay': 0.0013933224834431959, 'top_p': 0.920183215162878}
[2025-10-10 20:06:37] 
Trial 73: {'learning_rate': 1.9771826397832063e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 16, 'num_beams': 8, 'temperature': 0.40981012847367354, 'warmup_ratio': 0.10739268597925176, 'weight_decay': 0.0095385904705074, 'top_p': 0.9152595587510741}
[2025-10-10 20:06:37] 
Trial 74: {'learning_rate': 1.8143008517456992e-05, 'batch_size': 4, 'lora_r': 36, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.47684162984530515, 'warmup_ratio': 0.12560327793078482, 'weight_decay': 0.019995904459648595, 'top_p': 0.9074294266770475}
[2025-10-10 20:06:37] 
Trial 75: {'learning_rate': 1.4906103445745445e-05, 'batch_size': 4, 'lora_r': 32, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.43618972460521527, 'warmup_ratio': 0.08814925950702149, 'weight_decay': 7.35595467084892e-05, 'top_p': 0.9256834318901477}
[2025-10-10 20:06:37] 
Trial 76: {'learning_rate': 2.208400972446465e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 16, 'num_beams': 8, 'temperature': 0.40035389978847513, 'warmup_ratio': 0.11097497189069713, 'weight_decay': 0.014031318241253232, 'top_p': 0.9415565846684786}
[2025-10-10 20:06:37] 
Trial 77: {'learning_rate': 1.357786283008655e-05, 'batch_size': 4, 'lora_r': 36, 'lora_alpha': 32, 'num_beams': 8, 'temperature': 0.3135427858079572, 'warmup_ratio': 0.09885958858542945, 'weight_decay': 0.004281444433456277, 'top_p': 0.9327038596265456}
[2025-10-10 20:06:37] 
Trial 78: {'learning_rate': 1.72532490277807e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 8, 'num_beams': 7, 'temperature': 0.344813366665613, 'warmup_ratio': 0.08848887549706172, 'weight_decay': 0.015359912124473924, 'top_p': 0.9144777489726054}
[2025-10-10 20:06:37] 
Trial 79: {'learning_rate': 1.1448309995393061e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 16, 'num_beams': 2, 'temperature': 0.36458205062918725, 'warmup_ratio': 0.1236372528993306, 'weight_decay': 0.010758431052341637, 'top_p': 0.9512302741997053}
[2025-10-10 20:06:37] 
Trial 80: {'learning_rate': 3.325476800946089e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.2917912976383152, 'warmup_ratio': 0.0980888035232409, 'weight_decay': 0.023223697349299802, 'top_p': 0.8561699149765433}
[2025-10-10 20:06:37] 
Trial 81: {'learning_rate': 2.196268696397313e-05, 'batch_size': 4, 'lora_r': 20, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.5186151702694785, 'warmup_ratio': 0.11715169483201453, 'weight_decay': 0.006783072767123227, 'top_p': 0.8917978085828453}
[2025-10-10 20:06:37] 
Trial 82: {'learning_rate': 1.943225669383202e-05, 'batch_size': 4, 'lora_r': 24, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.45867044719272854, 'warmup_ratio': 0.11075785636187255, 'weight_decay': 0.016299867404336393, 'top_p': 0.9044817406853216}
[2025-10-10 20:06:37] 
Trial 83: {'learning_rate': 0.00017292288933910116, 'batch_size': 4, 'lora_r': 24, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.44380575356914137, 'warmup_ratio': 0.11000987122405093, 'weight_decay': 0.01676357634891254, 'top_p': 0.9062796860141209}
[2025-10-10 20:06:37] 
Trial 84: {'learning_rate': 1.864931316758299e-05, 'batch_size': 4, 'lora_r': 16, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.3597751627595744, 'warmup_ratio': 0.10378071760180821, 'weight_decay': 0.02953697610556498, 'top_p': 0.9239144866671962}
[2025-10-10 20:06:37] 
Trial 85: {'learning_rate': 2.390876676852373e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 56, 'num_beams': 8, 'temperature': 0.5535495696488193, 'warmup_ratio': 0.0836483438398633, 'weight_decay': 0.018318651155860927, 'top_p': 0.9140355173144243}
[2025-10-10 20:06:37] 
Trial 86: {'learning_rate': 1.5744080207489305e-05, 'batch_size': 16, 'lora_r': 32, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.41577082566232243, 'warmup_ratio': 0.07221727006541367, 'weight_decay': 0.03358134330290126, 'top_p': 0.8868213295511301}
[2025-10-10 20:06:37] 
Trial 87: {'learning_rate': 1.3135674084080652e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.4779026446671986, 'warmup_ratio': 0.09365419210458016, 'weight_decay': 0.052074570891942555, 'top_p': 0.8952959825768304}
[2025-10-10 20:06:37] 
Trial 88: {'learning_rate': 2.049176115499461e-05, 'batch_size': 4, 'lora_r': 28, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.48857300984945373, 'warmup_ratio': 0.11987882467355263, 'weight_decay': 0.0070240442391849124, 'top_p': 0.9010897430763072}
[2025-10-10 20:06:37] 
Trial 89: {'learning_rate': 4.036631667620837e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.46076346103133853, 'warmup_ratio': 0.13465728539302008, 'weight_decay': 0.024397342418100917, 'top_p': 0.8749639464130595}
[2025-10-10 20:06:37] 
Trial 90: {'learning_rate': 2.7461362320348037e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.49223607590318796, 'warmup_ratio': 0.11930274786669925, 'weight_decay': 0.007485256825922772, 'top_p': 0.9025822708881998}
[2025-10-10 20:06:37] 
Trial 91: {'learning_rate': 2.7059892654940416e-05, 'batch_size': 8, 'lora_r': 16, 'lora_alpha': 32, 'num_beams': 8, 'temperature': 0.48867524640240195, 'warmup_ratio': 0.12112095867161037, 'weight_decay': 0.011316286544565082, 'top_p': 0.901635581522616}
[2025-10-10 20:06:37] 
Trial 92: {'learning_rate': 2.0311290052771927e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.5062987931152043, 'warmup_ratio': 0.1470818273377289, 'weight_decay': 0.008942661888523412, 'top_p': 0.9112037994996472}
[2025-10-10 20:06:37] 
Trial 93: {'learning_rate': 3.3520309541633297e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 8, 'num_beams': 8, 'temperature': 0.5381471664206512, 'warmup_ratio': 0.12615216734637805, 'weight_decay': 0.01960017494143058, 'top_p': 0.9022732667748795}
[2025-10-10 20:06:37] 
Trial 94: {'learning_rate': 2.4468050922989584e-05, 'batch_size': 8, 'lora_r': 20, 'lora_alpha': 72, 'num_beams': 8, 'temperature': 0.6939696538470411, 'warmup_ratio': 0.11272487254158559, 'weight_decay': 0.01643758158606402, 'top_p': 0.8368405681097312}
[2025-10-10 20:06:37] 
Trial 95: {'learning_rate': 2.9940053916304718e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.433215886684908, 'warmup_ratio': 0.11843534839885794, 'weight_decay': 0.006490197409568283, 'top_p': 0.8954977756983721}
[2025-10-10 20:06:37] 
Trial 96: {'learning_rate': 3.7871144059822215e-05, 'batch_size': 8, 'lora_r': 32, 'lora_alpha': 40, 'num_beams': 7, 'temperature': 0.5674438568729533, 'warmup_ratio': 0.11813474610329967, 'weight_decay': 0.007608700209314483, 'top_p': 0.8693628968756135}
[2025-10-10 20:06:37] 
Trial 97: {'learning_rate': 2.99194408693566e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.434168517959546, 'warmup_ratio': 0.13010399980738133, 'weight_decay': 0.0037311690938391356, 'top_p': 0.8944295933312929}
[2025-10-10 20:06:37] 
Trial 98: {'learning_rate': 2.2671102794102827e-05, 'batch_size': 4, 'lora_r': 20, 'lora_alpha': 32, 'num_beams': 8, 'temperature': 0.46035451790032855, 'warmup_ratio': 0.10033950263417583, 'weight_decay': 0.0027564594012335457, 'top_p': 0.8828512118276668}
[2025-10-10 20:06:37] 
Trial 99: {'learning_rate': 4.450524452644817e-05, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 24, 'num_beams': 7, 'temperature': 0.6121885418481761, 'warmup_ratio': 0.11553342592413801, 'weight_decay': 0.012027852131779086, 'top_p': 0.9178003776721214}
[2025-10-10 20:06:37] 
============================================================
[2025-10-10 20:06:37] ‚úÖ OPTIMIZATION COMPLETED!
[2025-10-10 20:06:37] ============================================================
[2025-10-10 20:06:37] Best score: 0.8963
[2025-10-10 20:06:37] Best parameters:
[2025-10-10 20:06:37]   - learning_rate: 2.049176115499461e-05
[2025-10-10 20:06:37]   - batch_size: 4
[2025-10-10 20:06:37]   - lora_r: 28
[2025-10-10 20:06:37]   - lora_alpha: 8
[2025-10-10 20:06:37]   - num_beams: 8
[2025-10-10 20:06:37]   - temperature: 0.48857300984945373
[2025-10-10 20:06:37]   - warmup_ratio: 0.11987882467355263
[2025-10-10 20:06:37]   - weight_decay: 0.0070240442391849124
[2025-10-10 20:06:37]   - top_p: 0.9010897430763072
[2025-10-10 20:06:37] 
üìä Top 5 trials:
[2025-10-10 20:06:37] 1. Score: 0.8963
[2025-10-10 20:06:37] 
‚úÖ Config updated with optimal hyperparameters!
[2025-10-10 20:06:37] 
üìÅ Optimization results saved:
[2025-10-10 20:06:37]   - Study: logs/full_pipeline/optuna/optuna_study_20251010_200633.pkl
[2025-10-10 20:06:37]   - CSV: logs/full_pipeline/optuna/optuna_results_20251010_200633.csv
[2025-10-10 20:06:37]   - Best params: logs/full_pipeline/optuna/best_params_20251010_200633.json
[2025-10-10 20:06:37] 
‚úÖ Config has been updated with optimal hyperparameters!
[2025-10-10 20:06:37] [hyperparameter_optimization] Status: completed
[2025-10-10 20:06:37] ‚úÖ Solar API initialized for cross-validation
[2025-10-10 20:06:37] [model_training] Status: running
[2025-10-10 20:06:37] 
=== Model Training (GPU Optimized) ===
[2025-10-10 20:06:39] ‚úÖ Mixed Precision (FP16) Training ENABLED - 40% memory reduction
[2025-10-10 20:06:39] 
üßπ GPU Î©îÎ™®Î¶¨ ÏôÑÏ†Ñ Ï†ïÎ¶¨ Ï§ë...
[2025-10-10 20:06:39] Training primary model: gogamza/kobart-base-v2
[2025-10-10 20:06:40] ‚úÖ Tokenizer loaded
[2025-10-10 20:06:41] ‚úÖ Model loaded to CPU
[2025-10-10 20:06:42] Model moved to cuda
[2025-10-10 20:06:42] GPU Memory - Total: 23.99GB, Reserved: 0.52GB, Allocated: 0.46GB
[2025-10-10 20:06:42] ‚úÖ Gradient Accumulation: 1 steps
[2025-10-10 20:06:42]    Physical batch size: 4
[2025-10-10 20:06:42]    Effective batch size: 4
[2025-10-10 20:06:42] 
‚öôÔ∏è Optimizer Ï¥àÍ∏∞Ìôî Ï§ë...
[2025-10-10 20:06:42] ‚úÖ Optimizer initialized successfully
[2025-10-10 20:06:42] 
======================================================================
[2025-10-10 20:06:42] üöÄ TRAINING START - GPU Optimized
[2025-10-10 20:06:42] ======================================================================
[2025-10-10 20:06:42] Epochs: 30
[2025-10-10 20:06:42] Gradient Accumulation: 1
[2025-10-10 20:06:42] Mixed Precision (FP16): True
[2025-10-10 20:06:42] Gradient Checkpointing: False
[2025-10-10 20:06:42] ======================================================================

[2025-10-10 20:09:34]   Epoch 1: Train Loss = 2.5708
[2025-10-10 20:09:34]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:09:34]   ‚úÖ Best model saved (loss: 2.5708)
[2025-10-10 20:12:33]   Epoch 2: Train Loss = 1.4324
[2025-10-10 20:12:33]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:12:33]   ‚úÖ Best model saved (loss: 1.4324)
[2025-10-10 20:15:28]   Epoch 3: Train Loss = 1.2617
[2025-10-10 20:15:28]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:15:28]   ‚úÖ Best model saved (loss: 1.2617)
[2025-10-10 20:18:27]   Epoch 4: Train Loss = 1.1004
[2025-10-10 20:18:27]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:18:28]   ‚úÖ Best model saved (loss: 1.1004)
[2025-10-10 20:21:23]   Epoch 5: Train Loss = 0.9112
[2025-10-10 20:21:23]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:21:23]   ‚úÖ Best model saved (loss: 0.9112)
[2025-10-10 20:24:22]   Epoch 6: Train Loss = 0.7450
[2025-10-10 20:24:22]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:24:22]   ‚úÖ Best model saved (loss: 0.7450)
[2025-10-10 20:27:19]   Epoch 7: Train Loss = 0.6070
[2025-10-10 20:27:19]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:27:19]   ‚úÖ Best model saved (loss: 0.6070)
[2025-10-10 20:30:17]   Epoch 8: Train Loss = 0.4948
[2025-10-10 20:30:17]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:30:17]   ‚úÖ Best model saved (loss: 0.4948)
[2025-10-10 20:33:11]   Epoch 9: Train Loss = 0.4017
[2025-10-10 20:33:11]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:33:12]   ‚úÖ Best model saved (loss: 0.4017)
[2025-10-10 20:36:09]   Epoch 10: Train Loss = 0.3273
[2025-10-10 20:36:09]   GPU Memory: Allocated=1.44GB, Reserved=1.64GB
[2025-10-10 20:36:09]   ‚úÖ Best model saved (loss: 0.3273)
[2025-10-10 20:39:05]   Epoch 11: Train Loss = 0.2656
[2025-10-10 20:39:05]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:39:05]   ‚úÖ Best model saved (loss: 0.2656)
[2025-10-10 20:42:01]   Epoch 12: Train Loss = 0.2163
[2025-10-10 20:42:01]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:42:01]   ‚úÖ Best model saved (loss: 0.2163)
[2025-10-10 20:44:55]   Epoch 13: Train Loss = 0.1767
[2025-10-10 20:44:55]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:44:55]   ‚úÖ Best model saved (loss: 0.1767)
[2025-10-10 20:47:52]   Epoch 14: Train Loss = 0.1446
[2025-10-10 20:47:52]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:47:52]   ‚úÖ Best model saved (loss: 0.1446)
[2025-10-10 20:50:45]   Epoch 15: Train Loss = 0.1202
[2025-10-10 20:50:45]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:50:47]   ‚úÖ Best model saved (loss: 0.1202)
[2025-10-10 20:53:44]   Epoch 16: Train Loss = 0.0979
[2025-10-10 20:53:44]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:53:44]   ‚úÖ Best model saved (loss: 0.0979)
[2025-10-10 20:56:37]   Epoch 17: Train Loss = 0.0822
[2025-10-10 20:56:37]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:56:38]   ‚úÖ Best model saved (loss: 0.0822)
[2025-10-10 20:59:37]   Epoch 18: Train Loss = 0.0687
[2025-10-10 20:59:37]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 20:59:37]   ‚úÖ Best model saved (loss: 0.0687)
[2025-10-10 21:02:29]   Epoch 19: Train Loss = 0.0588
[2025-10-10 21:02:29]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:02:29]   ‚úÖ Best model saved (loss: 0.0588)
[2025-10-10 21:05:27]   Epoch 20: Train Loss = 0.0493
[2025-10-10 21:05:27]   GPU Memory: Allocated=1.44GB, Reserved=1.64GB
[2025-10-10 21:05:28]   ‚úÖ Best model saved (loss: 0.0493)
[2025-10-10 21:08:24]   Epoch 21: Train Loss = 0.0423
[2025-10-10 21:08:24]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:08:24]   ‚úÖ Best model saved (loss: 0.0423)
[2025-10-10 21:11:23]   Epoch 22: Train Loss = 0.0360
[2025-10-10 21:11:23]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:11:24]   ‚úÖ Best model saved (loss: 0.0360)
[2025-10-10 21:14:19]   Epoch 23: Train Loss = 0.0315
[2025-10-10 21:14:19]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:14:19]   ‚úÖ Best model saved (loss: 0.0315)
[2025-10-10 21:17:17]   Epoch 24: Train Loss = 0.0270
[2025-10-10 21:17:17]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:17:18]   ‚úÖ Best model saved (loss: 0.0270)
[2025-10-10 21:20:12]   Epoch 25: Train Loss = 0.0235
[2025-10-10 21:20:12]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:20:12]   ‚úÖ Best model saved (loss: 0.0235)
[2025-10-10 21:23:10]   Epoch 26: Train Loss = 0.0208
[2025-10-10 21:23:10]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:23:10]   ‚úÖ Best model saved (loss: 0.0208)
[2025-10-10 21:26:07]   Epoch 27: Train Loss = 0.0181
[2025-10-10 21:26:07]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:26:07]   ‚úÖ Best model saved (loss: 0.0181)
[2025-10-10 21:29:04]   Epoch 28: Train Loss = 0.0164
[2025-10-10 21:29:04]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:29:05]   ‚úÖ Best model saved (loss: 0.0164)
[2025-10-10 21:32:00]   Epoch 29: Train Loss = 0.0159
[2025-10-10 21:32:00]   GPU Memory: Allocated=1.44GB, Reserved=3.42GB
[2025-10-10 21:32:00]   ‚úÖ Best model saved (loss: 0.0159)
[2025-10-10 21:34:59]   Epoch 30: Train Loss = 0.0139
[2025-10-10 21:34:59]   GPU Memory: Allocated=1.44GB, Reserved=1.64GB
[2025-10-10 21:35:00]   ‚úÖ Best model saved (loss: 0.0139)
[2025-10-10 21:35:00] 
======================================================================
[2025-10-10 21:35:00] ‚úÖ Training completed successfully!
[2025-10-10 21:35:00] Best loss: 0.0139
[2025-10-10 21:35:00] Total training steps: 93450
[2025-10-10 21:35:00] ======================================================================

[2025-10-10 21:35:00] [model_training] Status: completed
[2025-10-10 21:35:00] [final_prediction] Status: running
[2025-10-10 21:35:00] 
=== Final Prediction ===
[2025-10-10 21:35:00] Generating predictions for test set...
[2025-10-10 21:36:31] Generated 499 predictions
[2025-10-10 21:36:31] 
=== Solar API Cross-Validation ===
[2025-10-10 21:36:31] 
=== Solar API Cross-Validation ===
[2025-10-10 21:36:46] Comparisons completed: 10 samples
[2025-10-10 21:36:46] Avg model length: 234.3
[2025-10-10 21:36:46] Avg API length: 183.8
[2025-10-10 21:36:46] API calls made: 10
[2025-10-10 21:36:46] Estimated tokens used: 1377
[2025-10-10 21:36:46] ‚úÖ Solar API cross-validation completed
[2025-10-10 21:36:46]    Model avg length: 234.3
[2025-10-10 21:36:46]    API avg length: 183.8
[2025-10-10 21:36:46]    API calls made: 10
[2025-10-10 21:36:46] Submission file saved: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/submissions/full_pipeline/full_pipeline_submission_20251010_200633.csv
[2025-10-10 21:36:46] Shape: (499, 2)
[2025-10-10 21:36:46] [final_prediction] Status: completed
