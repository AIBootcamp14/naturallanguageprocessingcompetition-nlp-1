2025-10-15 01:37:49 | wandb: Detected [openai] in use.
2025-10-15 01:37:49 | wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
2025-10-15 01:37:49 | wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-10-15 01:37:49 | 📋 실험명: 1015-0137-kfold
2025-10-15 01:37:49 | 🔗 WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/lpnmwho8
2025-10-15 01:37:49 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:256: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-15 01:37:49 | 학습 진행 중...
2025-10-15 01:38:11 | {'loss': 2.0439, 'grad_norm': 3.8435347080230713, 'learning_rate': 1.80972e-05, 'epoch': 0.16}
2025-10-15 01:38:32 | {'loss': 1.6079, 'grad_norm': 3.825542688369751, 'learning_rate': 3.63772e-05, 'epoch': 0.32}
2025-10-15 01:38:52 | {'loss': 1.5516, 'grad_norm': 3.601555109024048, 'learning_rate': 5.4657199999999996e-05, 'epoch': 0.48}
2025-10-15 01:39:13 | {'loss': 1.531, 'grad_norm': 3.2691919803619385, 'learning_rate': 7.29372e-05, 'epoch': 0.64}
2025-10-15 01:39:34 | {'loss': 1.5104, 'grad_norm': 3.7309181690216064, 'learning_rate': 9.12172e-05, 'epoch': 0.8}
2025-10-15 01:39:54 | {'loss': 1.4654, 'grad_norm': 3.524055004119873, 'learning_rate': 8.982083769633509e-05, 'epoch': 0.96}
2025-10-15 01:45:14 | {'eval_loss': 1.4193016290664673, 'eval_rouge1': 0.3904751452546782, 'eval_rouge2': 0.24210926104784167, 'eval_rougeL': 0.38288769060067424, 'eval_rouge_sum': 1.015472096903194, 'eval_runtime': 315.5053, 'eval_samples_per_second': 7.898, 'eval_steps_per_second': 0.494, 'epoch': 1.0}
2025-10-15 01:45:34 | {'loss': 1.282, 'grad_norm': 3.3895342350006104, 'learning_rate': 8.82257242582897e-05, 'epoch': 1.12}
2025-10-15 01:45:55 | {'loss': 1.2288, 'grad_norm': 3.0341920852661133, 'learning_rate': 8.663061082024434e-05, 'epoch': 1.28}
2025-10-15 01:46:17 | {'loss': 1.2169, 'grad_norm': 2.882014513015747, 'learning_rate': 8.503549738219895e-05, 'epoch': 1.44}
2025-10-15 01:46:41 | {'loss': 1.2469, 'grad_norm': 3.897798538208008, 'learning_rate': 8.344038394415358e-05, 'epoch': 1.61}
2025-10-15 01:47:05 | {'loss': 1.2076, 'grad_norm': 3.171177625656128, 'learning_rate': 8.18452705061082e-05, 'epoch': 1.77}
2025-10-15 01:47:28 | {'loss': 1.2235, 'grad_norm': 3.8137927055358887, 'learning_rate': 8.025015706806283e-05, 'epoch': 1.93}
2025-10-15 01:53:36 | {'eval_loss': 1.3633685111999512, 'eval_rouge1': 0.41159217242413026, 'eval_rouge2': 0.25836360674272013, 'eval_rougeL': 0.4051230017851383, 'eval_rouge_sum': 1.0750787809519888, 'eval_runtime': 357.6155, 'eval_samples_per_second': 6.968, 'eval_steps_per_second': 0.436, 'epoch': 2.0}
2025-10-15 01:54:01 | {'loss': 1.016, 'grad_norm': 2.626234292984009, 'learning_rate': 7.865504363001744e-05, 'epoch': 2.09}
2025-10-15 01:54:41 | {'loss': 0.8556, 'grad_norm': 2.7687644958496094, 'learning_rate': 7.705993019197208e-05, 'epoch': 2.25}
2025-10-15 01:55:23 | {'loss': 0.8728, 'grad_norm': 3.1205925941467285, 'learning_rate': 7.546481675392669e-05, 'epoch': 2.41}
2025-10-15 01:55:50 | {'loss': 0.8835, 'grad_norm': 3.2679688930511475, 'learning_rate': 7.386970331588133e-05, 'epoch': 2.57}
2025-10-15 01:56:14 | {'loss': 0.8932, 'grad_norm': 3.312293767929077, 'learning_rate': 7.227458987783596e-05, 'epoch': 2.73}
2025-10-15 01:56:37 | {'loss': 0.897, 'grad_norm': 2.923285722732544, 'learning_rate': 7.067947643979058e-05, 'epoch': 2.89}
2025-10-15 02:02:49 | {'eval_loss': 1.3991811275482178, 'eval_rouge1': 0.4258183301059979, 'eval_rouge2': 0.26959563526083313, 'eval_rougeL': 0.4181247394195853, 'eval_rouge_sum': 1.1135387047864163, 'eval_runtime': 355.1773, 'eval_samples_per_second': 7.016, 'eval_steps_per_second': 0.439, 'epoch': 3.0}
2025-10-15 02:03:00 | {'loss': 0.8276, 'grad_norm': 2.9799489974975586, 'learning_rate': 6.90843630017452e-05, 'epoch': 3.05}
2025-10-15 02:03:23 | {'loss': 0.6097, 'grad_norm': 3.2190732955932617, 'learning_rate': 6.748924956369983e-05, 'epoch': 3.21}
2025-10-15 02:03:47 | {'loss': 0.6165, 'grad_norm': 3.6121230125427246, 'learning_rate': 6.589413612565445e-05, 'epoch': 3.37}
2025-10-15 02:04:11 | {'loss': 0.6268, 'grad_norm': 2.7466907501220703, 'learning_rate': 6.429902268760908e-05, 'epoch': 3.53}
2025-10-15 02:04:36 | {'loss': 0.6392, 'grad_norm': 3.183790445327759, 'learning_rate': 6.27039092495637e-05, 'epoch': 3.69}
2025-10-15 02:05:00 | {'loss': 0.6426, 'grad_norm': 3.0941646099090576, 'learning_rate': 6.110879581151833e-05, 'epoch': 3.85}
2025-10-15 02:11:22 | {'eval_loss': 1.5070770978927612, 'eval_rouge1': 0.45847481899666953, 'eval_rouge2': 0.29005141326036615, 'eval_rougeL': 0.4455885658563098, 'eval_rouge_sum': 1.1941147981133455, 'eval_runtime': 360.4501, 'eval_samples_per_second': 6.914, 'eval_steps_per_second': 0.433, 'epoch': 4.0}
2025-10-15 02:11:27 | {'loss': 0.6229, 'grad_norm': 2.579951763153076, 'learning_rate': 5.9513682373472944e-05, 'epoch': 4.01}
2025-10-15 02:11:51 | {'loss': 0.4143, 'grad_norm': 3.0185115337371826, 'learning_rate': 5.7918568935427575e-05, 'epoch': 4.17}
2025-10-15 02:12:15 | {'loss': 0.4364, 'grad_norm': 3.153991937637329, 'learning_rate': 5.63234554973822e-05, 'epoch': 4.33}
2025-10-15 02:12:38 | {'loss': 0.431, 'grad_norm': 3.0333666801452637, 'learning_rate': 5.4728342059336824e-05, 'epoch': 4.49}
2025-10-15 02:13:02 | {'loss': 0.4495, 'grad_norm': 3.0814995765686035, 'learning_rate': 5.313322862129145e-05, 'epoch': 4.65}
2025-10-15 02:13:26 | {'loss': 0.4545, 'grad_norm': 2.522648811340332, 'learning_rate': 5.153811518324607e-05, 'epoch': 4.82}
2025-10-15 02:13:50 | {'loss': 0.4667, 'grad_norm': 2.8764383792877197, 'learning_rate': 4.99430017452007e-05, 'epoch': 4.98}
2025-10-15 02:21:14 | {'eval_loss': 1.5847960710525513, 'eval_rouge1': 0.4465035191170444, 'eval_rouge2': 0.28472834816696757, 'eval_rougeL': 0.43643202253937285, 'eval_rouge_sum': 1.1676638898233849, 'eval_runtime': 440.5982, 'eval_samples_per_second': 5.656, 'eval_steps_per_second': 0.354, 'epoch': 5.0}
2025-10-15 02:21:46 | {'loss': 0.3177, 'grad_norm': 2.3683791160583496, 'learning_rate': 4.834788830715533e-05, 'epoch': 5.14}
2025-10-15 02:22:25 | {'loss': 0.2996, 'grad_norm': 2.308716297149658, 'learning_rate': 4.6752774869109946e-05, 'epoch': 5.3}
2025-10-15 02:23:02 | {'loss': 0.3107, 'grad_norm': 3.029107093811035, 'learning_rate': 4.515766143106457e-05, 'epoch': 5.46}
2025-10-15 02:23:41 | {'loss': 0.307, 'grad_norm': 3.018998146057129, 'learning_rate': 4.3562547993019195e-05, 'epoch': 5.62}
2025-10-15 02:24:19 | {'loss': 0.3143, 'grad_norm': 2.9203295707702637, 'learning_rate': 4.196743455497382e-05, 'epoch': 5.78}
2025-10-15 02:24:57 | {'loss': 0.3204, 'grad_norm': 2.596210479736328, 'learning_rate': 4.0372321116928443e-05, 'epoch': 5.94}
2025-10-15 02:33:32 | {'eval_loss': 1.6546066999435425, 'eval_rouge1': 0.44050015686234745, 'eval_rouge2': 0.2818316980446988, 'eval_rougeL': 0.4310840043730296, 'eval_rouge_sum': 1.1534158592800758, 'eval_runtime': 501.5382, 'eval_samples_per_second': 4.969, 'eval_steps_per_second': 0.311, 'epoch': 6.0}
2025-10-15 02:34:01 | {'loss': 0.2488, 'grad_norm': 2.1364448070526123, 'learning_rate': 3.877720767888307e-05, 'epoch': 6.1}
2025-10-15 02:34:41 | {'loss': 0.2085, 'grad_norm': 2.4540274143218994, 'learning_rate': 3.718209424083769e-05, 'epoch': 6.26}
2025-10-15 02:35:21 | {'loss': 0.2197, 'grad_norm': 2.1722257137298584, 'learning_rate': 3.558698080279232e-05, 'epoch': 6.42}
2025-10-15 02:36:03 | {'loss': 0.216, 'grad_norm': 2.167043685913086, 'learning_rate': 3.399186736474694e-05, 'epoch': 6.58}
2025-10-15 02:36:40 | {'loss': 0.2192, 'grad_norm': 2.156496047973633, 'learning_rate': 3.2396753926701566e-05, 'epoch': 6.74}
2025-10-15 02:37:21 | {'loss': 0.2147, 'grad_norm': 2.2034196853637695, 'learning_rate': 3.080164048865619e-05, 'epoch': 6.9}
2025-10-15 02:45:02 | {'eval_loss': 1.7391232252120972, 'eval_rouge1': 0.4641277623592565, 'eval_rouge2': 0.29199976588662435, 'eval_rougeL': 0.4520153022274265, 'eval_rouge_sum': 1.2081428304733073, 'eval_runtime': 438.5784, 'eval_samples_per_second': 5.682, 'eval_steps_per_second': 0.356, 'epoch': 7.0}
2025-10-15 02:45:17 | {'loss': 0.1901, 'grad_norm': 1.8942406177520752, 'learning_rate': 2.9206527050610818e-05, 'epoch': 7.06}
2025-10-15 02:45:52 | {'loss': 0.1459, 'grad_norm': 1.6815235614776611, 'learning_rate': 2.7611413612565442e-05, 'epoch': 7.22}
2025-10-15 02:46:28 | {'loss': 0.1527, 'grad_norm': 2.150669574737549, 'learning_rate': 2.6016300174520067e-05, 'epoch': 7.38}
2025-10-15 02:47:05 | {'loss': 0.151, 'grad_norm': 2.1596081256866455, 'learning_rate': 2.442118673647469e-05, 'epoch': 7.54}
2025-10-15 02:47:43 | {'loss': 0.1532, 'grad_norm': 1.9382624626159668, 'learning_rate': 2.282607329842932e-05, 'epoch': 7.7}
2025-10-15 02:48:18 | {'loss': 0.1524, 'grad_norm': 1.8583292961120605, 'learning_rate': 2.1230959860383943e-05, 'epoch': 7.87}
2025-10-15 02:54:28 | {'eval_loss': 1.797174334526062, 'eval_rouge1': 0.4562116804784507, 'eval_rouge2': 0.2912289144011507, 'eval_rougeL': 0.4462478438673826, 'eval_rouge_sum': 1.193688438746984, 'eval_runtime': 340.0409, 'eval_samples_per_second': 7.329, 'eval_steps_per_second': 0.459, 'epoch': 8.0}
2025-10-15 02:54:35 | {'loss': 0.1448, 'grad_norm': 2.099320650100708, 'learning_rate': 1.963584642233857e-05, 'epoch': 8.03}
2025-10-15 02:54:58 | {'loss': 0.1026, 'grad_norm': 1.641937255859375, 'learning_rate': 1.8040732984293196e-05, 'epoch': 8.19}
2025-10-15 02:55:21 | {'loss': 0.1089, 'grad_norm': 1.6978543996810913, 'learning_rate': 1.644561954624782e-05, 'epoch': 8.35}
2025-10-15 02:55:43 | {'loss': 0.1091, 'grad_norm': 2.010374069213867, 'learning_rate': 1.4850506108202444e-05, 'epoch': 8.51}
2025-10-15 02:56:05 | {'loss': 0.1064, 'grad_norm': 1.347853183746338, 'learning_rate': 1.3255392670157069e-05, 'epoch': 8.67}
2025-10-15 02:56:26 | {'loss': 0.1069, 'grad_norm': 1.826810359954834, 'learning_rate': 1.1660279232111693e-05, 'epoch': 8.83}
2025-10-15 02:56:47 | {'loss': 0.1068, 'grad_norm': 1.478243350982666, 'learning_rate': 1.0065165794066318e-05, 'epoch': 8.99}
2025-10-15 03:04:24 | {'eval_loss': 1.83775794506073, 'eval_rouge1': 0.4640450860927266, 'eval_rouge2': 0.29497326944917646, 'eval_rougeL': 0.45327907709513654, 'eval_rouge_sum': 1.2122974326370395, 'eval_runtime': 455.3706, 'eval_samples_per_second': 5.472, 'eval_steps_per_second': 0.343, 'epoch': 9.0}
2025-10-15 03:05:00 | {'loss': 0.081, 'grad_norm': 1.237660527229309, 'learning_rate': 8.470052356020942e-06, 'epoch': 9.15}
2025-10-15 03:05:35 | {'loss': 0.0818, 'grad_norm': 1.4337315559387207, 'learning_rate': 6.8749389179755664e-06, 'epoch': 9.31}
2025-10-15 03:06:10 | {'loss': 0.0793, 'grad_norm': 1.6111451387405396, 'learning_rate': 5.279825479930192e-06, 'epoch': 9.47}
2025-10-15 03:06:46 | {'loss': 0.08, 'grad_norm': 1.29619562625885, 'learning_rate': 3.684712041884817e-06, 'epoch': 9.63}
2025-10-15 03:07:25 | {'loss': 0.0788, 'grad_norm': 1.6407006978988647, 'learning_rate': 2.0895986038394414e-06, 'epoch': 9.79}
2025-10-15 03:08:00 | {'loss': 0.0795, 'grad_norm': 1.1951714754104614, 'learning_rate': 4.944851657940663e-07, 'epoch': 9.95}
2025-10-15 03:15:13 | {'eval_loss': 1.8662344217300415, 'eval_rouge1': 0.4606701858640066, 'eval_rouge2': 0.29561506305139945, 'eval_rougeL': 0.45053645953069216, 'eval_rouge_sum': 1.2068217084460982, 'eval_runtime': 422.3312, 'eval_samples_per_second': 5.901, 'eval_steps_per_second': 0.369, 'epoch': 10.0}
2025-10-15 03:15:16 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-15 03:15:16 | {'train_runtime': 5847.0504, 'train_samples_per_second': 17.043, 'train_steps_per_second': 1.065, 'train_loss': 0.5650465482310728, 'epoch': 10.0}
2025-10-15 03:15:16 | 최종 모델 저장 중...
2025-10-15 03:15:17 | → 모델 저장 위치: experiments/20251015/20251015_013734_kobart_balanced_kfold/fold_1/kfold/final_model
2025-10-15 03:15:17 | 최종 평가 중...
2025-10-15 03:21:57 | 최종 평가 결과:
2025-10-15 03:21:57 | eval_rouge1: 0.4640
2025-10-15 03:21:57 | eval_rouge2: 0.2950
2025-10-15 03:21:57 | eval_rougeL: 0.4533
2025-10-15 03:21:57 | eval_rouge_sum: 1.2123
