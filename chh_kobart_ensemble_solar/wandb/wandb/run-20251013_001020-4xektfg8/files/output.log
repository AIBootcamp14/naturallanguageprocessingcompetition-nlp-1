2025-10-13 00:10:21 | wandb: Detected [openai] in use.
2025-10-13 00:10:21 | wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
2025-10-13 00:10:21 | wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-10-13 00:10:21 | ðŸ“‹ ì‹¤í—˜ëª…: 1013-0010-llama_3.2_3b_qlora
2025-10-13 00:10:21 | ðŸ”— WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/4xektfg8
2025-10-13 00:10:21 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-13 00:10:21 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-13 00:10:21 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-13 00:10:21 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-13 00:10:21 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [01:10<00:00,  1.77it/s]
2025-10-13 00:10:21 | 0%|          | 0/125 [00:00<?, ?it/s]
2025-10-13 00:10:24 | 1%|          | 1/125 [00:03<06:34,  3.18s/it]
2025-10-13 00:10:27 | 2%|â–         | 2/125 [00:05<05:40,  2.76s/it]
2025-10-13 00:10:32 | 3%|â–Ž         | 4/125 [00:10<05:11,  2.58s/it]
2025-10-13 00:10:34 | 4%|â–         | 5/125 [00:13<05:02,  2.52s/it]
2025-10-13 00:10:37 | 5%|â–         | 6/125 [00:15<05:10,  2.61s/it]
2025-10-13 00:10:40 | 6%|â–Œ         | 7/125 [00:19<05:33,  2.83s/it]
2025-10-13 00:10:44 | >> ë¡œê·¸ ë¦¬ë””ë ‰ì…˜ ì¤‘ë£Œ.
Traceback (most recent call last):
  File "/home/ieyeppo/AI_Lab/natural-language-processing-competition/scripts/train.py", line 713, in <module>
    main()
  File "/home/ieyeppo/AI_Lab/natural-language-processing-competition/scripts/train.py", line 583, in main
    results = trainer.train()
              ^^^^^^^^^^^^^^^
  File "/home/ieyeppo/AI_Lab/natural-language-processing-competition/src/trainers/full_pipeline_trainer.py", line 59, in train
    model_results, model_paths = self._train_multiple_models(train_df, eval_df)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/AI_Lab/natural-language-processing-competition/src/trainers/full_pipeline_trainer.py", line 225, in _train_multiple_models
    train_result = trainer.train()
                   ^^^^^^^^^^^^^^^
  File "/home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py", line 262, in train
    train_result = self.trainer.train()             # í•™ìŠµ ì‹¤í–‰
                   ^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/trainer.py", line 4110, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/peft/peft_model.py", line 1850, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/peft/tuners/tuners_utils.py", line 222, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 459, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/utils/generic.py", line 1064, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 395, in forward
    hidden_states = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 488, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/autograd/function.py", line 576, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 262, in forward
    outputs = run_function(*args)
              ^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 294, in forward
    hidden_states, _ = self.self_attn(
                       ^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 238, in forward
    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/peft/tuners/lora/layer.py", line 771, in forward
    result = result + lora_B(lora_A(dropout(x))) * scaling
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
