#!/usr/bin/env python3
"""
ì¶”ë¡  ëª¨ë“ˆ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'scripts'))

import torch
import pandas as pd
from typing import Dict
from torch.utils.data import DataLoader
from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast
from data_loader import Preprocess
from dataset import prepare_test_dataset
from inference_utils import generate_summaries, postprocess_summaries


class Inferencer:
    """
    ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í´ë˜ìŠ¤
    """

    def __init__(self, config: Dict, experiment_name: str, checkpoint_name: str):
        """
        Inferencer ì´ˆê¸°í™”

        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            experiment_name: ì‹¤í—˜ ì´ë¦„
            checkpoint_name: ì²´í¬í¬ì¸íŠ¸ ì´ë¦„ (ì˜ˆ: 'checkpoint-2068')
        """
        self.config = config
        self.experiment_name = experiment_name
        self.checkpoint_name = checkpoint_name
        self.device = self._get_device()

        # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ìë™ ìƒì„±
        self.checkpoint_path = os.path.join(
            self.config['general']['output_dir'],
            checkpoint_name
        )

    def _get_device(self) -> torch.device:
        """
        ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤

        Returns:
            torch.device
        """
        from utils import get_device
        return get_device()

    def run(self, model: BartForConditionalGeneration, tokenizer: PreTrainedTokenizerFast,
           output_path: str):
        """
        ì „ì²´ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤

        Args:
            model: ì¶”ë¡ í•  ëª¨ë¸
            tokenizer: í† í¬ë‚˜ì´ì €
            output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (CSV)
        """
        print("\n" + "=" * 80)
        print(f"ğŸš€ {self.experiment_name} ì¶”ë¡  ì‹œì‘")
        print("=" * 80)
        print(f"ì²´í¬í¬ì¸íŠ¸: {self.checkpoint_name}")
        print(f"ì¶œë ¥ ê²½ë¡œ: {output_path}")
        print("=" * 80)

        # 1. Test ë°ì´í„°ì…‹ ì¤€ë¹„
        print("\n" + "=" * 80)
        print("1ë‹¨ê³„: Test ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")
        print("=" * 80)

        preprocessor = Preprocess(
            bos_token=self.config['tokenizer']['bos_token'],
            eos_token=self.config['tokenizer']['eos_token']
        )

        test_data_df, test_dataset = prepare_test_dataset(
            self.config, preprocessor, tokenizer
        )

        # DataLoader ìƒì„±
        test_dataloader = DataLoader(
            test_dataset,
            batch_size=self.config['inference']['batch_size'],
            shuffle=False
        )

        print(f"âœ… Test ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: {len(test_dataset)} samples")

        # 2. ìš”ì•½ ìƒì„±
        print("\n" + "=" * 80)
        print("2ë‹¨ê³„: ìš”ì•½ ìƒì„± ì¤‘...")
        print("=" * 80)

        # tokenizerë¥¼ configì— ì„ì‹œ ì €ì¥ (generate_summariesì—ì„œ ì‚¬ìš©)
        self.config['tokenizer'] = tokenizer

        fnames, raw_summaries = generate_summaries(
            model, test_dataloader, self.config, self.device
        )

        print(f"âœ… {len(fnames)}ê°œì˜ ìš”ì•½ë¬¸ ìƒì„± ì™„ë£Œ")
        print(f"   - ì²« ë²ˆì§¸ íŒŒì¼: {fnames[0]}")
        print(f"   - ì›ë³¸ ìš”ì•½ ì˜ˆì‹œ: {raw_summaries[0][:100]}...")

        # 3. í›„ì²˜ë¦¬ (íŠ¹ìˆ˜ í† í° ì œê±°)
        print("\n" + "=" * 80)
        print("3ë‹¨ê³„: í›„ì²˜ë¦¬ ì¤‘ (íŠ¹ìˆ˜ í† í° ì œê±°)...")
        print("=" * 80)

        remove_tokens = self.config['inference']['remove_tokens']
        print(f"ì œê±°í•  í† í°: {remove_tokens}")

        cleaned_summaries = postprocess_summaries(raw_summaries, remove_tokens)

        print(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ")
        print(f"   - í›„ì²˜ë¦¬ ìš”ì•½ ì˜ˆì‹œ: {cleaned_summaries[0][:100]}...")

        # 4. ê²°ê³¼ ì €ì¥ (Competition í˜•ì‹: index í¬í•¨)
        print("\n" + "=" * 80)
        print("4ë‹¨ê³„: ê²°ê³¼ ì €ì¥ ì¤‘...")
        print("=" * 80)

        result_df = pd.DataFrame({
            'fname': fnames,
            'summary': cleaned_summaries
        })

        # index=Trueë¡œ ì €ì¥ (competition ì œì¶œ í˜•ì‹)
        result_df.to_csv(output_path, index=True)

        print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   í˜•ì‹: CSV with index column (competition format)")

        # 5. ê²°ê³¼ í™•ì¸
        print("\n" + "=" * 80)
        print("ğŸ” ê²°ê³¼ í™•ì¸")
        print("=" * 80)
        print(f"ì´ {len(result_df)}ê°œ ìš”ì•½ ìƒì„±")
        print(f"\nìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
        print(result_df.head(3))

        print("\n" + "=" * 80)
        print(f"âœ… {self.experiment_name} ì¶”ë¡  ì™„ë£Œ!")
        print("=" * 80)
        print(f"ì œì¶œ íŒŒì¼: {output_path}")

        return result_df
