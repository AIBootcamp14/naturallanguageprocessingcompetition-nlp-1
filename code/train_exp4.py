#!/usr/bin/env python3
"""
Experiment #4: ê¸¸ì´ ì •ê·œí™” + Max Length 768

ë³€ê²½ì‚¬í•­:
1. encoder_max_len: 512 â†’ 768 (ê¸´ ëŒ€í™” ì²˜ë¦¬)
2. length_penalty: 0.6 ì¶”ê°€ (GNMT ê¸¸ì´ ì •ê·œí™”)

ì˜ˆìƒ íš¨ê³¼: +1~2ì  (Baseline 46.95 â†’ 48~49ì )
ì†Œìš” ì‹œê°„: ~30ë¶„
"""

import sys
sys.path.append('../scripts')

import torch

from utils import load_config, get_device, set_seed
from data_loader import Preprocess
from tokenizer_utils import load_tokenizer
from model_utils import load_model_for_train
from dataset import prepare_train_dataset
from trainer_utils import get_trainer

print("="*80)
print("ğŸš€ Experiment #4: ê¸¸ì´ ì •ê·œí™” + Max Length 768")
print("="*80)
print()
print("ë³€ê²½ì‚¬í•­:")
print("  1. encoder_max_len: 512 â†’ 768")
print("  2. length_penalty: 0.6 (GNMT)")
print()
print("ì˜ˆìƒ íš¨ê³¼: +1~2ì  (46.95 â†’ 48~49ì )")
print("="*80)

# Config - config_exp4.yaml ì‚¬ìš©
config = load_config('./config_exp4.yaml')
device = get_device()
set_seed(config['training']['seed'])

print(f"\nâœ… Config ë¡œë“œ ì™„ë£Œ")
print(f"   Device: {device}")
print(f"   Encoder Max Length: {config['tokenizer']['encoder_max_len']}")
print(f"   Length Penalty: {config['inference'].get('length_penalty', 1.0)}")
print(f"   Learning Rate: {config['training']['learning_rate']}")
print(f"   Epochs: {config['training']['num_train_epochs']}")

# Wandb ë¹„í™œì„±í™” í™•ì¸
print(f"   Wandb: {config['training'].get('report_to', 'none')}")

# Tokenizer
tokenizer = load_tokenizer(
    config['general']['model_name'],
    config['tokenizer']['special_tokens']
)
print(f"\nâœ… Tokenizer ë¡œë“œ ì™„ë£Œ (vocab size: {len(tokenizer)})")

# Dataset
preprocessor = Preprocess(
    bos_token=config['tokenizer']['bos_token'],
    eos_token=config['tokenizer']['eos_token']
)

data_path = config['general']['data_path']
train_dataset, val_dataset = prepare_train_dataset(
    config, preprocessor, data_path, tokenizer
)

print(f"\nâœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ")
print(f"   Train: {len(train_dataset)} samples")
print(f"   Val: {len(val_dataset)} samples")

# Model
model = load_model_for_train(config, tokenizer, device)
print(f"\nâœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# Trainer
trainer = get_trainer(
    config=config,
    model=model,
    tokenizer=tokenizer,
    train_dataset=train_dataset,
    val_dataset=val_dataset
)

print(f"\nâœ… Trainer ì„¤ì • ì™„ë£Œ")

# Train
print("\n" + "="*80)
print("ğŸš€ í•™ìŠµ ì‹œì‘... (ì•½ 30ë¶„ ì†Œìš”)")
print("="*80 + "\n")

trainer.train()

print("\n" + "="*80)
print("âœ… í•™ìŠµ ì™„ë£Œ!")
print("="*80)

# Save final model info
print(f"\nğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {config['general']['output_dir']}")
print(f"ğŸ“Š Best checkpointë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ì§„í–‰í•˜ì„¸ìš”")
print(f"\në‹¤ìŒ ë‹¨ê³„:")
print(f"1. python infer_test_exp4.py ì‹¤í–‰")
print(f"2. prediction/exp4_output.csv ì œì¶œ")
print(f"3. ì ìˆ˜ ë¹„êµ (Baseline 46.95 vs Exp #4)")
print("="*80)
