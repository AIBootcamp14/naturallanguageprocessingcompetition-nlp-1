{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Experiment #2: í›„ì²˜ë¦¬ ê°œì„  (Post-processing v2)\n\n**ë‚ ì§œ**: 2025-10-13  \n**ë² ì´ìŠ¤**: Baseline Modular (46.9526)  \n**ë³€ê²½ì‚¬í•­**: `postprocess_summaries_v2` ì‚¬ìš© (ê³µë°± ì •ê·œí™” + ì¤‘ë³µ ë¬¸ì¥ ì œê±°)\n\n**ëª©í‘œ**: +0.5~1.2ì   \n**ì˜ˆìƒ ì ìˆ˜**: 47.5~48.2\n\n**ì£¼ìš” ë³€ê²½**:\n- `scripts/inference_utils.py`ì— `postprocess_summaries_v2()` ì¶”ê°€\n- í•™ìŠµ ìƒëµ (ê¸°ì¡´ checkpoint-1750 ì‚¬ìš©)\n- ì¶”ë¡ ë§Œ ì‹¤í–‰\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# scripts ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ëª¨ë“ˆ import\n",
    "from utils import load_config, get_device, set_seed\n",
    "from data_loader import Preprocess, load_data\n",
    "from tokenizer_utils import load_tokenizer\n",
    "from model_utils import load_model_for_train, get_model_info\n",
    "from dataset import prepare_train_dataset, prepare_test_dataset\n",
    "from trainer_utils import get_trainer\n",
    "from inference_utils import run_inference\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ëª¨ë“ˆ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config ë¡œë“œ ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config ë¡œë“œ\n",
    "config = load_config('./config.yaml')\n",
    "\n",
    "# Device ì„¤ì •\n",
    "device = get_device()\n",
    "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# ì‹œë“œ ì„¤ì • (ì¬í˜„ì„±)\n",
    "set_seed(config['training']['seed'])\n",
    "print(f\"ì‹œë“œ ì„¤ì • ì™„ë£Œ: {config['training']['seed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wandb ì„¤ì • (ì„ íƒì )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ\n",
    "# import wandb\n",
    "# from dotenv import load_dotenv\n",
    "# \n",
    "# load_dotenv()\n",
    "# wandb.login()\n",
    "# wandb.init(\n",
    "#     project=config['wandb']['project'],\n",
    "#     entity=config['wandb']['entity'],\n",
    "#     name=config['wandb']['name'] + \"-modular\"\n",
    "# )\n",
    "\n",
    "# Wandb ë¹„í™œì„±í™” (ê¸°ë³¸ê°’)\n",
    "config['training']['report_to'] = 'none'\n",
    "print(\"Wandb ë¹„í™œì„±í™” (report_to='none')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenizer ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer ë¡œë“œ (special tokens ì¶”ê°€)\n",
    "model_name = config['general']['model_name']\n",
    "special_tokens = config['tokenizer']['special_tokens']\n",
    "\n",
    "tokenizer = load_tokenizer(model_name, special_tokens)\n",
    "\n",
    "print(f\"âœ… Tokenizer ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"ëª¨ë¸: {model_name}\")\n",
    "print(f\"Vocab size: {len(tokenizer)}\")\n",
    "print(f\"Special tokens: {special_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë°ì´í„°ì…‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor ìƒì„±\n",
    "preprocessor = Preprocess(\n",
    "    bos_token=config['tokenizer']['bos_token'],\n",
    "    eos_token=config['tokenizer']['eos_token']\n",
    ")\n",
    "\n",
    "# Train/Val ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "data_path = config['general']['data_path']\n",
    "train_dataset, val_dataset = prepare_train_dataset(\n",
    "    config, preprocessor, data_path, tokenizer\n",
    ")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Val: {len(val_dataset)} samples\")\n",
    "\n",
    "# ìƒ˜í”Œ í™•ì¸\n",
    "print(\"\\nìƒ˜í”Œ ë°ì´í„°:\")\n",
    "sample = train_dataset[0]\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: shape={value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ëª¨ë¸ ë¡œë“œ (checkpointì—ì„œ ì§ì ‘)\nfrom model_utils import load_model_for_inference\n\ncheckpoint_path = '../submission/checkpoint-1750'\nprint(f\"Checkpoint ë¡œë“œ ì¤‘: {checkpoint_path}\")\n\nmodel = load_model_for_inference(checkpoint_path, tokenizer, device)\n\nprint(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (checkpoint-1750)\")\n\n# ëª¨ë¸ ì •ë³´ ì¶œë ¥\nmodel_info = get_model_info(model)\nprint(\"\\nëª¨ë¸ ì •ë³´:\")\nfor key, value in model_info.items():\n    if 'parameters' in key:\n        print(f\"  {key}: {value:,}\")\n    else:\n        print(f\"  {key}: {value}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer ìƒì„±\n",
    "trainer = get_trainer(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"í•™ìŠµ ì—í­: {config['training']['num_train_epochs']}\")\n",
    "print(f\"í•™ìŠµë¥ : {config['training']['learning_rate']}\")\n",
    "print(f\"ë°°ì¹˜ í¬ê¸°: {config['training']['per_device_train_batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test ë°ì´í„° ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ë¡  ì‹¤í–‰\n",
    "print(\"\\nğŸ”® ì¶”ë¡  ì‹œì‘...\\n\")\n",
    "\n",
    "result_df = run_inference(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    test_dataloader=test_dataloader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    save_path='./prediction/output_modular.csv'\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ì¶”ë¡  ì™„ë£Œ!\")\n",
    "print(f\"ê²°ê³¼ íŒŒì¼: ./prediction/output_modular.csv\")\n",
    "print(f\"ìƒ˜í”Œ ìˆ˜: {len(result_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²˜ìŒ 5ê°œ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nìƒ˜í”Œ ê²°ê³¼ (ì²˜ìŒ 5ê°œ):\")\n",
    "print(\"=\" * 80)\n",
    "for i in range(min(5, len(result_df))):\n",
    "    print(f\"\\n[{i}] {result_df.iloc[i]['fname']}\")\n",
    "    print(f\"ìš”ì•½: {result_df.iloc[i]['summary'][:100]}...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ì¶”ë¡  ì‹¤í–‰ (postprocess_summaries_v2 ì‚¬ìš©)\nprint(\"\\nğŸ”® ì¶”ë¡  ì‹œì‘...\\n\")\n\n# 1. ìš”ì•½ ìƒì„±\nfrom inference_utils import generate_summaries, postprocess_summaries_v2, save_predictions\n\nconfig['tokenizer'] = tokenizer\nfnames, raw_summaries = generate_summaries(model, test_dataloader, config, device)\n\nprint(f\"âœ… {len(fnames)}ê°œì˜ ìš”ì•½ë¬¸ ìƒì„± ì™„ë£Œ\")\nprint(f\"   - ì›ë³¸ ìš”ì•½ ì˜ˆì‹œ: {raw_summaries[0][:100]}...\")\n\n# 2. í›„ì²˜ë¦¬ v2 (Exp #2ì˜ í•µì‹¬!)\nprint(\"\\nğŸ”¥ í›„ì²˜ë¦¬ v2 ì ìš© ì¤‘...\")\nprint(\"   - íŠ¹ìˆ˜ í† í° ì œê±°\")\nprint(\"   - ê³µë°± ì •ê·œí™”\")\nprint(\"   - ì¤‘ë³µ ë¬¸ì¥ ì œê±°\")\n\nremove_tokens = config['inference']['remove_tokens']\ncleaned_summaries = postprocess_summaries_v2(raw_summaries, remove_tokens)\n\nprint(f\"âœ… í›„ì²˜ë¦¬ v2 ì™„ë£Œ\")\nprint(f\"   - í›„ì²˜ë¦¬ ìš”ì•½ ì˜ˆì‹œ: {cleaned_summaries[0][:100]}...\")\n\n# 3. CSV ì €ì¥\noutput_path = save_predictions(\n    fnames, cleaned_summaries,\n    output_dir='./prediction',\n    filename='output_modular_v2.csv'\n)\n\nprint(f\"\\nâœ… ì¶”ë¡  ì™„ë£Œ!\")\nprint(f\"ê²°ê³¼ íŒŒì¼: {output_path}\")\nprint(f\"ìƒ˜í”Œ ìˆ˜: {len(fnames)}\")\n\n# DataFrame ìƒì„± (í™•ì¸ìš©)\nimport pandas as pd\nresult_df = pd.DataFrame({\n    'fname': fnames,\n    'summary': cleaned_summaries\n})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì›ë³¸ Baselineê³¼ ë¹„êµ (ì„ íƒì )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë³¸ baseline.ipynbì˜ ê²°ê³¼ì™€ ë¹„êµ\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    baseline_output = pd.read_csv('./prediction/output.csv')\n",
    "    modular_output = pd.read_csv('./prediction/output_modular.csv')\n",
    "    \n",
    "    # ë™ì¼í•œ ìƒ˜í”Œ ìˆ˜ì¸ì§€ í™•ì¸\n",
    "    print(f\"\\nBaseline ìƒ˜í”Œ ìˆ˜: {len(baseline_output)}\")\n",
    "    print(f\"Modular ìƒ˜í”Œ ìˆ˜: {len(modular_output)}\")\n",
    "    \n",
    "    # fname ìˆœì„œê°€ ë™ì¼í•œì§€ í™•ì¸\n",
    "    if baseline_output['fname'].equals(modular_output['fname']):\n",
    "        print(\"âœ… fname ìˆœì„œ ì¼ì¹˜\")\n",
    "    else:\n",
    "        print(\"âš ï¸ fname ìˆœì„œ ë¶ˆì¼ì¹˜\")\n",
    "    \n",
    "    # ì¼ì¹˜í•˜ëŠ” ìƒ˜í”Œ ìˆ˜ ê³„ì‚°\n",
    "    identical_count = (baseline_output['summary'] == modular_output['summary']).sum()\n",
    "    print(f\"\\në™ì¼í•œ ìš”ì•½ë¬¸ ìˆ˜: {identical_count} / {len(baseline_output)}\")\n",
    "    print(f\"ì¼ì¹˜ìœ¨: {identical_count / len(baseline_output) * 100:.2f}%\")\n",
    "    \nexcept FileNotFoundError:\n",
    "    print(\"âš ï¸ ì›ë³¸ baseline ê²°ê³¼ íŒŒì¼(output.csv)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"baseline.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CSV ê²€ì¦\nfrom utils import validate_csv\n\nvalidation_result = validate_csv('./prediction/output_modular_v2.csv')\n\nprint(\"\\nCSV ê²€ì¦ ê²°ê³¼:\")\nprint(f\"ìœ íš¨ì„±: {'âœ… í†µê³¼' if validation_result['valid'] else 'âŒ ì‹¤íŒ¨'}\")\nprint(f\"ìƒ˜í”Œ ìˆ˜: {validation_result['num_samples']}\")\nprint(f\"ì»¬ëŸ¼: {validation_result['columns']}\")\n\nif validation_result['errors']:\n    print(\"\\nâš ï¸ ì˜¤ë¥˜:\")\n    for error in validation_result['errors']:\n        print(f\"  - {error}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Baseline Modularê³¼ ë¹„êµ",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}