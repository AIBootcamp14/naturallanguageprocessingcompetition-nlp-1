"""
ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ

PRD 04: ì„±ëŠ¥ ê°œì„  ì „ëµ êµ¬í˜„
- Back-translation (í•œâ†’ì˜â†’í•œ)
- Paraphrase ìƒì„±
- ë¬¸ì¥ ìˆœì„œ ì„ê¸°
- ë™ì˜ì–´ ì¹˜í™˜
- Dialogue Sampling
"""

import random
from typing import List, Tuple, Optional
from pathlib import Path
from transformers import MarianMTModel, MarianTokenizer, pipeline
import re
import pandas as pd

from src.checkpoints.augmentation_checkpoint import AugmentationCheckpointManager


class DataAugmenter:
    """ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ"""

    def __init__(self, logger=None, checkpoint_dir: Optional[str] = None):
        """
        Args:
            logger: Logger ì¸ìŠ¤í„´ìŠ¤
            checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ì„ íƒ)
        """
        self.logger = logger
        self._log("DataAugmenter ì´ˆê¸°í™”")

        # Back-translation ëª¨ë¸ (ì§€ì—° ë¡œë”©)
        self.ko_en_model = None
        self.ko_en_tokenizer = None
        self.en_ko_model = None
        self.en_ko_tokenizer = None

        # ì¦ê°• ë°©ë²• ë“±ë¡
        self.augmenters = {
            'back_translate': BackTranslationAugmenter(),
            'paraphrase': ParaphraseAugmenter(),
            'shuffle': ShuffleAugmenter(),
            'synonym': SynonymReplacementAugmenter(),
            'sample': DialogueSamplingAugmenter()
        }

        # âœ… ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì
        self.checkpoint_manager = None
        if checkpoint_dir:
            self.checkpoint_manager = AugmentationCheckpointManager(checkpoint_dir)

    def _log(self, msg: str):
        """ë¡œê¹… í—¬í¼"""
        if self.logger:
            self.logger.write(msg)
        else:
            print(msg)

    def augment(
        self,
        dialogues: List[str],
        summaries: List[str],
        methods: List[str] = ["shuffle"],
        samples_per_method: int = 1,
        resume: bool = True,
        save_interval: int = 100
    ) -> Tuple[List[str], List[str]]:
        """
        ë°ì´í„° ì¦ê°• ì‹¤í–‰ (ì²´í¬í¬ì¸íŠ¸ ì§€ì›)

        Args:
            dialogues: ëŒ€í™” ë¦¬ìŠ¤íŠ¸
            summaries: ìš”ì•½ ë¦¬ìŠ¤íŠ¸
            methods: ì¦ê°• ë°©ë²• ë¦¬ìŠ¤íŠ¸
                     ["back_translate", "paraphrase", "shuffle", "synonym", "sample"]
            samples_per_method: ë°©ë²•ë‹¹ ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
            resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ ì‹¤í–‰ ì—¬ë¶€
            save_interval: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸° (ê¸°ë³¸: 100ê°œë§ˆë‹¤)

        Returns:
            (ì¦ê°•ëœ dialogues, ì¦ê°•ëœ summaries)
        """
        original_size = len(dialogues)
        target_augmented_count = original_size * len(methods) * samples_per_method
        total_target_size = original_size + target_augmented_count

        # âœ… ì²´í¬í¬ì¸íŠ¸ í™•ì¸ ë° ë¡œë“œ
        if resume and self.checkpoint_manager:
            checkpoint = self.checkpoint_manager.load_checkpoint()
            if checkpoint and self.checkpoint_manager.is_complete(total_target_size):
                self._log("âœ… ì¦ê°• ë°ì´í„° ì²´í¬í¬ì¸íŠ¸ ë°œê²¬. ë¡œë“œ ì¤‘...")
                aug_data = checkpoint['augmented_data']
                return aug_data['dialogue'].tolist(), aug_data['summary'].tolist()

        self._log(f"\në°ì´í„° ì¦ê°• ì‹œì‘")
        self._log(f"  - ì›ë³¸ ë°ì´í„°: {len(dialogues)}ê°œ")
        self._log(f"  - ì¦ê°• ë°©ë²•: {methods}")
        self._log(f"  - ë°©ë²•ë‹¹ ìƒ˜í”Œ ìˆ˜: {samples_per_method}")
        self._log(f"  - ëª©í‘œ ë°ì´í„° í¬ê¸°: {total_target_size}ê°œ")

        augmented_dialogues = []
        augmented_summaries = []

        for idx, (dialogue, summary) in enumerate(zip(dialogues, summaries)):
            # ì›ë³¸ ì¶”ê°€
            augmented_dialogues.append(dialogue)
            augmented_summaries.append(summary)

            # ì¦ê°• ë°ì´í„° ìƒì„±
            for method in methods:
                for _ in range(samples_per_method):
                    try:
                        if method == "back_translate":
                            aug_dialogue = self.back_translate(dialogue)
                        elif method == "paraphrase":
                            aug_dialogue = self.paraphrase(dialogue)
                        elif method == "shuffle":
                            aug_dialogue = self.shuffle_turns(dialogue)
                        elif method == "synonym":
                            aug_dialogue = self.synonym_replacement(dialogue)
                        elif method == "sample":
                            aug_dialogue = self.sample_dialogue(dialogue)
                        else:
                            self._log(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¦ê°• ë°©ë²•: {method}")
                            continue

                        if aug_dialogue and aug_dialogue != dialogue:
                            augmented_dialogues.append(aug_dialogue)
                            augmented_summaries.append(summary)

                    except Exception as e:
                        self._log(f"ì¦ê°• ì‹¤íŒ¨ ({method}): {str(e)}")
                        continue

            # âœ… ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if self.checkpoint_manager and (idx + 1) % save_interval == 0:
                current_df = pd.DataFrame({
                    'dialogue': augmented_dialogues,
                    'summary': augmented_summaries
                })
                progress = {
                    'completed': len(augmented_dialogues),
                    'total': total_target_size,
                    'ratio': len(augmented_dialogues) / total_target_size,
                    'original_size': original_size
                }
                self.checkpoint_manager.save_checkpoint(
                    augmented_data=current_df,
                    progress=progress,
                    methods=methods
                )
                self._log(f"ğŸ’¾ ì¦ê°• ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {idx+1}/{original_size} ì›ë³¸ ì²˜ë¦¬ ì™„ë£Œ (ì´ {len(augmented_dialogues)}ê°œ)")

        # âœ… ìµœì¢… ì €ì¥
        if self.checkpoint_manager:
            final_df = pd.DataFrame({
                'dialogue': augmented_dialogues,
                'summary': augmented_summaries
            })
            progress = {
                'completed': len(augmented_dialogues),
                'total': total_target_size,
                'ratio': 1.0,
                'original_size': original_size
            }
            self.checkpoint_manager.save_checkpoint(
                augmented_data=final_df,
                progress=progress,
                methods=methods
            )
            self._log(f"ğŸ’¾ ì¦ê°• ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ")

        self._log(f"ë°ì´í„° ì¦ê°• ì™„ë£Œ: {len(augmented_dialogues)}ê°œ")
        return augmented_dialogues, augmented_summaries

    def back_translate(self, text: str) -> str:
        """
        Back-translation (í•œâ†’ì˜â†’í•œ)

        Args:
            text: í•œêµ­ì–´ í…ìŠ¤íŠ¸

        Returns:
            ì—­ë²ˆì—­ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸
        """
        # ëª¨ë¸ ë¡œë”© (ì§€ì—° ë¡œë”©)
        if self.ko_en_model is None:
            self._log("Back-translation ëª¨ë¸ ë¡œë”© ì¤‘... (Helsinki-NLP/opus-mt-ko-en)")
            self.ko_en_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ko-en")
            self.ko_en_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-ko-en")

        if self.en_ko_model is None:
            self._log("Back-translation ëª¨ë¸ ë¡œë”© ì¤‘... (Helsinki-NLP/opus-mt-en-ko)")
            self.en_ko_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ko")
            self.en_ko_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ko")

        try:
            # í•œâ†’ì˜
            inputs = self.ko_en_tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
            translated_en = self.ko_en_model.generate(**inputs, max_length=512)
            en_text = self.ko_en_tokenizer.decode(translated_en[0], skip_special_tokens=True)

            # ì˜â†’í•œ
            inputs = self.en_ko_tokenizer(en_text, return_tensors="pt", truncation=True, max_length=512)
            translated_ko = self.en_ko_model.generate(**inputs, max_length=512)
            ko_text = self.en_ko_tokenizer.decode(translated_ko[0], skip_special_tokens=True)

            return ko_text

        except Exception as e:
            self._log(f"Back-translation ì‹¤íŒ¨: {str(e)}")
            return text

    def paraphrase(self, text: str) -> str:
        """
        Paraphrase ìƒì„± (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)

        Note: ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” T5/KoGPT ëª¨ë¸ ì‚¬ìš© ê¶Œì¥

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸

        Returns:
            íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆëœ í…ìŠ¤íŠ¸
        """
        # ê°„ë‹¨í•œ ë™ì˜ì–´ ì¹˜í™˜ ê·œì¹™
        replacements = {
            "ì•ˆë…•í•˜ì„¸ìš”": ["ì•ˆë…•", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "í™˜ì˜í•©ë‹ˆë‹¤"],
            "ê°ì‚¬í•©ë‹ˆë‹¤": ["ê³ ë§™ìŠµë‹ˆë‹¤", "ê°ì‚¬í•´ìš”", "ê³ ë§ˆì›Œìš”"],
            "ì£„ì†¡í•©ë‹ˆë‹¤": ["ë¯¸ì•ˆí•©ë‹ˆë‹¤", "ì£„ì†¡í•´ìš”", "ë¯¸ì•ˆí•´ìš”"],
            "ë„¤": ["ì˜ˆ", "ì•Œê² ìŠµë‹ˆë‹¤", "ê·¸ë ‡ìŠµë‹ˆë‹¤"],
            "ì•„ë‹ˆìš”": ["ì•„ë‹™ë‹ˆë‹¤", "ì•„ë‹ˆì—ìš”", "ê·¸ë ‡ì§€ ì•ŠìŠµë‹ˆë‹¤"],
        }

        paraphrased = text
        for original, synonyms in replacements.items():
            if original in paraphrased:
                paraphrased = paraphrased.replace(original, random.choice(synonyms))

        return paraphrased

    def shuffle_turns(self, dialogue: str, preserve_ratio: float = 0.3) -> str:
        """
        ëŒ€í™” í„´ ìˆœì„œ ì„ê¸° (ì¼ë¶€ë§Œ)

        Args:
            dialogue: ëŒ€í™” í…ìŠ¤íŠ¸
            preserve_ratio: ìœ ì§€í•  í„´ ë¹„ìœ¨ (ì²˜ìŒ/ë ë³´ì¡´)

        Returns:
            í„´ì´ ì„ì¸ ëŒ€í™”
        """
        # Person íƒœê·¸ë¡œ í„´ ë¶„ë¦¬
        turns = re.split(r'(#Person\d+#:)', dialogue)
        turns = [t.strip() for t in turns if t.strip()]

        if len(turns) < 6:  # ë„ˆë¬´ ì§§ìœ¼ë©´ ì„ì§€ ì•ŠìŒ
            return dialogue

        # Person íƒœê·¸ì™€ ë‚´ìš©ì„ ìŒìœ¼ë¡œ ë¬¶ê¸°
        paired_turns = []
        for i in range(0, len(turns) - 1, 2):
            if i + 1 < len(turns):
                paired_turns.append(turns[i] + " " + turns[i + 1])

        if len(paired_turns) < 3:
            return dialogue

        # ì²˜ìŒ/ë ë³´ì¡´, ì¤‘ê°„ë§Œ ì„ê¸°
        preserve_count = max(1, int(len(paired_turns) * preserve_ratio))
        start_turns = paired_turns[:preserve_count]
        end_turns = paired_turns[-preserve_count:]
        middle_turns = paired_turns[preserve_count:-preserve_count]

        # ì¤‘ê°„ í„´ ì„ê¸°
        random.shuffle(middle_turns)

        # ì¬ì¡°í•©
        shuffled_turns = start_turns + middle_turns + end_turns
        return " ".join(shuffled_turns)

    def synonym_replacement(self, text: str, n: int = 3) -> str:
        """
        ë™ì˜ì–´ ì¹˜í™˜ (ê°„ë‹¨í•œ ë²„ì „)

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            n: ì¹˜í™˜í•  ë‹¨ì–´ ìˆ˜

        Returns:
            ë™ì˜ì–´ê°€ ì¹˜í™˜ëœ í…ìŠ¤íŠ¸
        """
        # í•œêµ­ì–´ ë™ì˜ì–´ ì‚¬ì „ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        synonyms = {
            "ì¢‹ë‹¤": ["í›Œë¥­í•˜ë‹¤", "ë©‹ì§€ë‹¤", "ê´œì°®ë‹¤"],
            "ë‚˜ì˜ë‹¤": ["ì•ˆì¢‹ë‹¤", "ë³„ë¡œë‹¤", "í˜•í¸ì—†ë‹¤"],
            "í¬ë‹¤": ["ê±°ëŒ€í•˜ë‹¤", "ë„“ë‹¤", "ê´‘ëŒ€í•˜ë‹¤"],
            "ì‘ë‹¤": ["ì ë‹¤", "ë¯¸ë¯¸í•˜ë‹¤", "ì†Œì†Œí•˜ë‹¤"],
            "ë¹ ë¥´ë‹¤": ["ì‹ ì†í•˜ë‹¤", "ì¬ë¹ ë¥´ë‹¤", "ë‚ ìŒ”ë‹¤"],
            "ëŠë¦¬ë‹¤": ["ë”ë””ë‹¤", "êµ¼ëœ¨ë‹¤", "ëŠ¦ë‹¤"],
        }

        result = text
        replaced_count = 0

        for original, synonym_list in synonyms.items():
            if original in result and replaced_count < n:
                result = result.replace(original, random.choice(synonym_list), 1)
                replaced_count += 1

        return result

    def sample_dialogue(self, dialogue: str, ratio: float = 0.8) -> str:
        """
        ëŒ€í™” ìƒ˜í”Œë§ (ì¼ë¶€ í„´ ì„ íƒ)

        Args:
            dialogue: ëŒ€í™” í…ìŠ¤íŠ¸
            ratio: ìœ ì§€í•  í„´ ë¹„ìœ¨

        Returns:
            ìƒ˜í”Œë§ëœ ëŒ€í™”
        """
        # Person íƒœê·¸ë¡œ í„´ ë¶„ë¦¬
        turns = re.split(r'(#Person\d+#:)', dialogue)
        turns = [t.strip() for t in turns if t.strip()]

        if len(turns) < 4:  # ë„ˆë¬´ ì§§ìœ¼ë©´ ìƒ˜í”Œë§ ì•ˆ í•¨
            return dialogue

        # Person íƒœê·¸ì™€ ë‚´ìš©ì„ ìŒìœ¼ë¡œ ë¬¶ê¸°
        paired_turns = []
        for i in range(0, len(turns) - 1, 2):
            if i + 1 < len(turns):
                paired_turns.append(turns[i] + " " + turns[i + 1])

        # ìœ ì§€í•  í„´ ìˆ˜ ê³„ì‚°
        keep_count = max(2, int(len(paired_turns) * ratio))

        # ì¤‘ìš”í•œ í„´ ìš°ì„  ì„ íƒ (ì²˜ìŒ, ë, ëœë¤)
        if len(paired_turns) <= keep_count:
            return dialogue

        # ì²˜ìŒê³¼ ëì€ í•­ìƒ ìœ ì§€
        sampled_turns = [paired_turns[0]]

        # ì¤‘ê°„ì—ì„œ ëœë¤ ì„ íƒ
        middle_turns = paired_turns[1:-1]
        if middle_turns:
            sample_size = keep_count - 2  # ì²˜ìŒ/ë ì œì™¸
            sampled_middle = random.sample(middle_turns, min(sample_size, len(middle_turns)))
            sampled_turns.extend(sampled_middle)

        # ë§ˆì§€ë§‰ í„´ ì¶”ê°€
        sampled_turns.append(paired_turns[-1])

        return " ".join(sampled_turns)


def augment_data(
    dialogues: List[str],
    summaries: List[str],
    methods: List[str] = ["shuffle"],
    samples_per_method: int = 1,
    logger=None,
    checkpoint_dir: Optional[str] = None,
    resume: bool = True,
    save_interval: int = 100
) -> Tuple[List[str], List[str]]:
    """
    í¸ì˜ í•¨ìˆ˜: ë°ì´í„° ì¦ê°•

    Args:
        dialogues: ëŒ€í™” ë¦¬ìŠ¤íŠ¸
        summaries: ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        methods: ì¦ê°• ë°©ë²• ë¦¬ìŠ¤íŠ¸
        samples_per_method: ë°©ë²•ë‹¹ ìƒ˜í”Œ ìˆ˜
        logger: Logger ì¸ìŠ¤í„´ìŠ¤
        checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ (ì„ íƒ)
        resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ ì‹¤í–‰ ì—¬ë¶€
        save_interval: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸°

    Returns:
        (ì¦ê°•ëœ dialogues, ì¦ê°•ëœ summaries)
    """
    augmenter = DataAugmenter(logger=logger, checkpoint_dir=checkpoint_dir)
    return augmenter.augment(dialogues, summaries, methods, samples_per_method, resume, save_interval)


# ê°œë³„ ì¦ê°•ê¸° í´ë˜ìŠ¤ë“¤
class BackTranslationAugmenter:
    """ì—­ë²ˆì—­ ì¦ê°•ê¸°"""

    def __init__(self):
        self.ko_en_model = None
        self.ko_en_tokenizer = None
        self.en_ko_model = None
        self.en_ko_tokenizer = None

    def augment(self, dialogue: str, summary: str) -> Tuple[str, str]:
        """ì—­ë²ˆì—­ ìˆ˜í–‰"""
        # ëª¨ë¸ ë¡œë”© (ì§€ì—° ë¡œë”©)
        if self.ko_en_model is None:
            self.ko_en_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ko-en")
            self.ko_en_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-ko-en")
            self.en_ko_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ko")
            self.en_ko_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ko")

        # ëŒ€í™” ì—­ë²ˆì—­
        inputs = self.ko_en_tokenizer(dialogue, return_tensors="pt", truncation=True, max_length=512)
        translated_en = self.ko_en_model.generate(**inputs, max_length=512)
        en_text = self.ko_en_tokenizer.decode(translated_en[0], skip_special_tokens=True)

        inputs = self.en_ko_tokenizer(en_text, return_tensors="pt", truncation=True, max_length=512)
        translated_ko = self.en_ko_model.generate(**inputs, max_length=512)
        aug_dialogue = self.en_ko_tokenizer.decode(translated_ko[0], skip_special_tokens=True)

        # ìš”ì•½ ì—­ë²ˆì—­
        inputs = self.ko_en_tokenizer(summary, return_tensors="pt", truncation=True, max_length=512)
        translated_en = self.ko_en_model.generate(**inputs, max_length=512)
        en_text = self.ko_en_tokenizer.decode(translated_en[0], skip_special_tokens=True)

        inputs = self.en_ko_tokenizer(en_text, return_tensors="pt", truncation=True, max_length=512)
        translated_ko = self.en_ko_model.generate(**inputs, max_length=512)
        aug_summary = self.en_ko_tokenizer.decode(translated_ko[0], skip_special_tokens=True)

        return aug_dialogue, aug_summary


class ParaphraseAugmenter:
    """ì˜ì—­ ì¦ê°•ê¸°"""

    def __init__(self):
        self.replacements = {
            "ì•ˆë…•í•˜ì„¸ìš”": ["ì•ˆë…•", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "í™˜ì˜í•©ë‹ˆë‹¤"],
            "ê°ì‚¬í•©ë‹ˆë‹¤": ["ê³ ë§™ìŠµë‹ˆë‹¤", "ê°ì‚¬í•´ìš”", "ê³ ë§ˆì›Œìš”"],
            "ì£„ì†¡í•©ë‹ˆë‹¤": ["ë¯¸ì•ˆí•©ë‹ˆë‹¤", "ì£„ì†¡í•´ìš”", "ë¯¸ì•ˆí•´ìš”"],
            "ë„¤": ["ì˜ˆ", "ì•Œê² ìŠµë‹ˆë‹¤", "ê·¸ë ‡ìŠµë‹ˆë‹¤"],
            "ì•„ë‹ˆìš”": ["ì•„ë‹™ë‹ˆë‹¤", "ì•„ë‹ˆì—ìš”", "ê·¸ë ‡ì§€ ì•ŠìŠµë‹ˆë‹¤"],
        }

    def augment(self, dialogue: str, summary: str) -> Tuple[str, str]:
        """ì˜ì—­ ìˆ˜í–‰"""
        aug_dialogue = dialogue
        for original, synonyms in self.replacements.items():
            if original in aug_dialogue:
                aug_dialogue = aug_dialogue.replace(original, random.choice(synonyms))

        aug_summary = summary
        for original, synonyms in self.replacements.items():
            if original in aug_summary:
                aug_summary = aug_summary.replace(original, random.choice(synonyms))

        return aug_dialogue, aug_summary


class ShuffleAugmenter:
    """í„´ ì„ê¸° ì¦ê°•ê¸°"""

    def __init__(self, preserve_ratio: float = 0.3):
        self.preserve_ratio = preserve_ratio

    def augment(self, dialogue: str, summary: str) -> Tuple[str, str]:
        """í„´ ì„ê¸° ìˆ˜í–‰"""
        # ì¤„ë°”ê¿ˆìœ¼ë¡œ í„´ ë¶„ë¦¬ (ì¼ë°˜ì ì¸ ëŒ€í™” í˜•ì‹)
        turns = [t.strip() for t in dialogue.split('\n') if t.strip()]

        if len(turns) < 3:
            return dialogue, summary

        # ì²˜ìŒ/ë ë³´ì¡´, ì¤‘ê°„ë§Œ ì„ê¸°
        preserve_count = max(1, int(len(turns) * self.preserve_ratio))
        start_turns = turns[:preserve_count]
        end_turns = turns[-preserve_count:] if preserve_count > 0 else []
        middle_turns = turns[preserve_count:-preserve_count] if preserve_count > 0 else turns

        if middle_turns:
            random.shuffle(middle_turns)

        shuffled_turns = start_turns + middle_turns + end_turns
        return '\n'.join(shuffled_turns), summary


class SynonymReplacementAugmenter:
    """ë™ì˜ì–´ ì¹˜í™˜ ì¦ê°•ê¸°"""

    def __init__(self, replace_ratio: float = 0.3):
        self.replace_ratio = replace_ratio
        self.synonyms = {
            "ì¢‹ë‹¤": ["í›Œë¥­í•˜ë‹¤", "ë©‹ì§€ë‹¤", "ê´œì°®ë‹¤"],
            "ë‚˜ì˜ë‹¤": ["ì•ˆì¢‹ë‹¤", "ë³„ë¡œë‹¤", "í˜•í¸ì—†ë‹¤"],
            "í¬ë‹¤": ["ê±°ëŒ€í•˜ë‹¤", "ë„“ë‹¤", "ê´‘ëŒ€í•˜ë‹¤"],
            "ì‘ë‹¤": ["ì ë‹¤", "ë¯¸ë¯¸í•˜ë‹¤", "ì†Œì†Œí•˜ë‹¤"],
            "ë¹ ë¥´ë‹¤": ["ì‹ ì†í•˜ë‹¤", "ì¬ë¹ ë¥´ë‹¤", "ë‚ ìŒ”ë‹¤"],
            "ëŠë¦¬ë‹¤": ["ë”ë””ë‹¤", "êµ¼ëœ¨ë‹¤", "ëŠ¦ë‹¤"],
            "ë°¥": ["ì‹ì‚¬", "ìŒì‹", "ë¼ë‹ˆ"],
            "ë¨¹ë‹¤": ["ì„­ì·¨í•˜ë‹¤", "ë“œì‹œë‹¤", "ì‹ì‚¬í•˜ë‹¤"],
        }

    def augment(self, dialogue: str, summary: str) -> Tuple[str, str]:
        """ë™ì˜ì–´ ì¹˜í™˜ ìˆ˜í–‰"""
        aug_dialogue = dialogue
        for original, synonym_list in self.synonyms.items():
            if original in aug_dialogue:
                aug_dialogue = aug_dialogue.replace(original, random.choice(synonym_list))

        return aug_dialogue, summary


class DialogueSamplingAugmenter:
    """ëŒ€í™” ìƒ˜í”Œë§ ì¦ê°•ê¸°"""

    def __init__(self, sample_ratio: float = 0.7):
        self.sample_ratio = sample_ratio

    def augment(self, dialogue: str, summary: str) -> Tuple[str, str]:
        """ëŒ€í™” ìƒ˜í”Œë§ ìˆ˜í–‰"""
        turns = [t.strip() for t in dialogue.split('\n') if t.strip()]

        if len(turns) < 3:
            return dialogue, summary

        # ìœ ì§€í•  í„´ ìˆ˜ ê³„ì‚°
        keep_count = max(2, int(len(turns) * self.sample_ratio))

        if len(turns) <= keep_count:
            return dialogue, summary

        # ì²˜ìŒê³¼ ëì€ í•­ìƒ ìœ ì§€
        sampled_turns = [turns[0]]

        # ì¤‘ê°„ì—ì„œ ëœë¤ ì„ íƒ
        middle_turns = turns[1:-1]
        if middle_turns and keep_count > 2:
            sample_size = keep_count - 2
            sampled_middle = random.sample(middle_turns, min(sample_size, len(middle_turns)))
            sampled_turns.extend(sampled_middle)

        # ë§ˆì§€ë§‰ í„´ ì¶”ê°€
        if len(turns) > 1:
            sampled_turns.append(turns[-1])

        return '\n'.join(sampled_turns), summary


def augment_dataset(
    dialogues: List[str],
    summaries: List[str],
    methods: List[str] = ["shuffle"],
    n_aug: int = 1
) -> Tuple[List[str], List[str]]:
    """
    í¸ì˜ í•¨ìˆ˜: ë°ì´í„°ì…‹ ì¦ê°•

    Args:
        dialogues: ëŒ€í™” ë¦¬ìŠ¤íŠ¸
        summaries: ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        methods: ì¦ê°• ë°©ë²• ë¦¬ìŠ¤íŠ¸
        n_aug: ë°©ë²•ë‹¹ ìƒì„±í•  ì¦ê°• ë°ì´í„° ìˆ˜

    Returns:
        (ì¦ê°•ëœ dialogues, ì¦ê°•ëœ summaries)
    """
    augmenters_map = {
        'back_translate': BackTranslationAugmenter(),
        'paraphrase': ParaphraseAugmenter(),
        'shuffle': ShuffleAugmenter(),
        'synonym': SynonymReplacementAugmenter(),
        'sample': DialogueSamplingAugmenter()
    }

    augmented_dialogues = []
    augmented_summaries = []

    for dialogue, summary in zip(dialogues, summaries):
        for method in methods:
            for _ in range(n_aug):
                if method in augmenters_map:
                    try:
                        aug_dialogue, aug_summary = augmenters_map[method].augment(dialogue, summary)
                        augmented_dialogues.append(aug_dialogue)
                        augmented_summaries.append(aug_summary)
                    except Exception as e:
                        print(f"ì¦ê°• ì‹¤íŒ¨ ({method}): {str(e)}")
                        continue

    return augmented_dialogues, augmented_summaries
