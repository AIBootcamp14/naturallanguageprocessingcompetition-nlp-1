"""
í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŒ… í”„ë ˆì„ì›Œí¬

PRD 15: í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŒ… ì „ëµ
- ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ë³€í˜• ë¹„êµ
- í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
- ìµœì  í”„ë¡¬í”„íŠ¸ ìë™ ì„ íƒ
"""

from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
import numpy as np
from collections import defaultdict
import time
from pathlib import Path
import json

# ë‚´ë¶€ ëª¨ë“ˆ
from ..evaluation.metrics import RougeCalculator
from ..api.solar_api import SolarAPI


@dataclass
class PromptVariant:
    """
    í”„ë¡¬í”„íŠ¸ ë³€í˜• ë°ì´í„° í´ë˜ìŠ¤

    Attributes:
        name: ë³€í˜• ì´ë¦„
        template: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        description: ë³€í˜• ì„¤ëª…
        results: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        rouge_scores: ROUGE ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
        avg_latency: í‰ê·  ì‘ë‹µ ì‹œê°„ (ì´ˆ)
        token_usage: í‰ê·  í† í° ì‚¬ìš©ëŸ‰
    """
    name: str
    template: str
    description: str = ""
    results: List[str] = field(default_factory=list)
    rouge_scores: Dict[str, float] = field(default_factory=dict)
    avg_latency: float = 0.0
    token_usage: int = 0


@dataclass
class ABTestResult:
    """
    A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤

    Attributes:
        best_variant: ìµœê³  ì„±ëŠ¥ ë³€í˜•ëª…
        all_scores: ëª¨ë“  ë³€í˜•ì˜ ì ìˆ˜
        statistical_significance: í†µê³„ì  ìœ ì˜ì„± ì—¬ë¶€
        p_value: p-value (ë‚®ì„ìˆ˜ë¡ ìœ ì˜ë¯¸)
        winner_margin: 1ë“±ê³¼ 2ë“±ì˜ ì°¨ì´
    """
    best_variant: str
    all_scores: Dict[str, Dict[str, float]]
    statistical_significance: bool
    p_value: float
    winner_margin: float


class PromptABTester:
    """
    í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŒ… í´ë˜ìŠ¤

    ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ë³€í˜•ì„ ë¹„êµí•˜ì—¬ ìµœì ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ìŒ
    """

    def __init__(
        self,
        api_client: Optional[SolarAPI] = None,
        rouge_calculator: Optional[RougeCalculator] = None,
        logger=None
    ):
        """
        Args:
            api_client: Solar API í´ë¼ì´ì–¸íŠ¸ (ìš”ì•½ ìƒì„±ìš©)
            rouge_calculator: ROUGE ê³„ì‚°ê¸°
            logger: Logger ì¸ìŠ¤í„´ìŠ¤
        """
        self.variants: Dict[str, PromptVariant] = {}
        self.api_client = api_client
        self.rouge_calculator = rouge_calculator or RougeCalculator()
        self.logger = logger

        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        self.test_results: Optional[ABTestResult] = None

    def _log(self, msg: str):
        """ë¡œê¹… í—¬í¼"""
        if self.logger:
            self.logger.write(msg)
        else:
            print(msg)

    def add_variant(
        self,
        name: str,
        template: str,
        description: str = ""
    ):
        """
        í…ŒìŠ¤íŠ¸ ë³€í˜• ì¶”ê°€

        Args:
            name: ë³€í˜• ì´ë¦„ (ê³ ìœ í•´ì•¼ í•¨)
            template: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ({dialogue} í”Œë ˆì´ìŠ¤í™€ë” í¬í•¨)
            description: ë³€í˜• ì„¤ëª…

        Raises:
            ValueError: ë³€í˜•ëª…ì´ ì¤‘ë³µë˜ê±°ë‚˜ í…œí”Œë¦¿ì´ ì˜ëª»ëœ ê²½ìš°
        """
        # ì¤‘ë³µ ì²´í¬
        if name in self.variants:
            raise ValueError(f"ë³€í˜•ëª… '{name}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")

        # í…œí”Œë¦¿ ê²€ì¦
        if '{dialogue}' not in template:
            raise ValueError("í…œí”Œë¦¿ì— {dialogue} í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìŠµë‹ˆë‹¤")

        # ë³€í˜• ì¶”ê°€
        self.variants[name] = PromptVariant(
            name=name,
            template=template,
            description=description
        )

        self._log(f"âœ“ ë³€í˜• ì¶”ê°€ë¨: {name}")

    def _generate_summary(
        self,
        dialogue: str,
        template: str
    ) -> Tuple[str, float]:
        """
        ë‹¨ì¼ ëŒ€í™” ìš”ì•½ ìƒì„± (ë‚´ë¶€ í•¨ìˆ˜)

        Args:
            dialogue: ì…ë ¥ ëŒ€í™”
            template: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

        Returns:
            (ìš”ì•½ ê²°ê³¼, ì‘ë‹µ ì‹œê°„)
        """
        if not self.api_client:
            raise RuntimeError("API í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = template.format(dialogue=dialogue)

        # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
        start_time = time.time()

        # API í˜¸ì¶œ (Solar API ì‚¬ìš©)
        summary = self.api_client.summarize(prompt)

        latency = time.time() - start_time

        return summary, latency

    def run_ab_test(
        self,
        dialogues: List[str],
        references: List[str],
        sample_size: Optional[int] = None
    ) -> ABTestResult:
        """
        A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰

        Args:
            dialogues: í…ŒìŠ¤íŠ¸ ëŒ€í™” ë¦¬ìŠ¤íŠ¸
            references: ì •ë‹µ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
            sample_size: ìƒ˜í”Œ í¬ê¸° (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)

        Returns:
            ABTestResult: í…ŒìŠ¤íŠ¸ ê²°ê³¼

        Raises:
            ValueError: ë³€í˜•ì´ ì—†ê±°ë‚˜ ë°ì´í„° í¬ê¸°ê°€ ë§ì§€ ì•ŠëŠ” ê²½ìš°
        """
        # ì…ë ¥ ê²€ì¦
        if not self.variants:
            raise ValueError("í…ŒìŠ¤íŠ¸í•  ë³€í˜•ì´ ì—†ìŠµë‹ˆë‹¤")

        if len(dialogues) != len(references):
            raise ValueError(
                f"ëŒ€í™”ì™€ ì •ë‹µ ê°œìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤: {len(dialogues)} vs {len(references)}"
            )

        # ìƒ˜í”Œë§
        if sample_size and sample_size < len(dialogues):
            indices = np.random.choice(len(dialogues), sample_size, replace=False)
            dialogues = [dialogues[i] for i in indices]
            references = [references[i] for i in indices]

        self._log(f"\n{'='*60}")
        self._log(f"A/B í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self._log(f"  - ë³€í˜• ìˆ˜: {len(self.variants)}")
        self._log(f"  - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(dialogues)}ê°œ")
        self._log(f"{'='*60}\n")

        # ê° ë³€í˜• í…ŒìŠ¤íŠ¸
        all_scores = {}

        for variant_name, variant in self.variants.items():
            self._log(f"\n[{variant_name}] í…ŒìŠ¤íŠ¸ ì¤‘...")
            self._log(f"  ì„¤ëª…: {variant.description}")

            predictions = []
            latencies = []

            # ê° ëŒ€í™”ì— ëŒ€í•´ ìš”ì•½ ìƒì„±
            for i, dialogue in enumerate(dialogues, 1):
                try:
                    summary, latency = self._generate_summary(
                        dialogue,
                        variant.template
                    )
                    predictions.append(summary)
                    latencies.append(latency)

                    if i % 10 == 0:
                        self._log(f"  ì§„í–‰: {i}/{len(dialogues)}")

                except Exception as e:
                    self._log(f"  âš ï¸ ì˜¤ë¥˜ ë°œìƒ (ìƒ˜í”Œ {i}): {str(e)}")
                    predictions.append("")
                    latencies.append(0.0)

            # ROUGE ì ìˆ˜ ê³„ì‚°
            scores = self.rouge_calculator.calculate_batch(
                predictions,
                references
            )

            # ê²°ê³¼ ì €ì¥
            variant.results = predictions
            variant.rouge_scores = {
                'rouge1': scores['rouge1']['fmeasure'],
                'rouge2': scores['rouge2']['fmeasure'],
                'rougeL': scores['rougeL']['fmeasure'],
                'rouge_sum': sum([
                    scores['rouge1']['fmeasure'],
                    scores['rouge2']['fmeasure'],
                    scores['rougeL']['fmeasure']
                ])
            }
            variant.avg_latency = np.mean(latencies)

            all_scores[variant_name] = variant.rouge_scores

            # ê²°ê³¼ ì¶œë ¥
            self._log(f"\n  ê²°ê³¼:")
            self._log(f"    ROUGE-1: {variant.rouge_scores['rouge1']:.4f}")
            self._log(f"    ROUGE-2: {variant.rouge_scores['rouge2']:.4f}")
            self._log(f"    ROUGE-L: {variant.rouge_scores['rougeL']:.4f}")
            self._log(f"    ROUGE-Sum: {variant.rouge_scores['rouge_sum']:.4f}")
            self._log(f"    í‰ê·  ì‘ë‹µì‹œê°„: {variant.avg_latency:.3f}ì´ˆ")

        # ìµœê³  ì„±ëŠ¥ ë³€í˜• ì°¾ê¸°
        best_variant = max(
            self.variants.keys(),
            key=lambda name: self.variants[name].rouge_scores['rouge_sum']
        )

        # í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
        rouge_sums = [
            variant.rouge_scores['rouge_sum']
            for variant in self.variants.values()
        ]

        # 1ë“±ê³¼ 2ë“± ì ìˆ˜
        sorted_scores = sorted(rouge_sums, reverse=True)
        winner_margin = sorted_scores[0] - sorted_scores[1] if len(sorted_scores) > 1 else 0.0

        # ê°„ë‹¨í•œ t-test (í‘œì¤€í¸ì°¨ ê¸°ë°˜)
        std = np.std(rouge_sums)
        p_value = std / (sorted_scores[0] + 1e-10)  # ì •ê·œí™”ëœ í‘œì¤€í¸ì°¨
        statistical_significance = p_value < 0.05 and winner_margin > 0.01

        # ê²°ê³¼ ìƒì„±
        self.test_results = ABTestResult(
            best_variant=best_variant,
            all_scores=all_scores,
            statistical_significance=statistical_significance,
            p_value=p_value,
            winner_margin=winner_margin
        )

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        self._log(f"\n{'='*60}")
        self._log(f"A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        self._log(f"{'='*60}")
        self._log(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_variant}")
        self._log(f"   ì ìˆ˜: {self.variants[best_variant].rouge_scores['rouge_sum']:.4f}")
        self._log(f"   ìŠ¹ì°¨: {winner_margin:.4f}")
        self._log(f"   í†µê³„ì  ìœ ì˜ì„±: {'âœ“ ìœ ì˜ë¯¸' if statistical_significance else 'âœ— ë¶ˆì¶©ë¶„'}")
        self._log(f"   p-value: {p_value:.4f}")
        self._log(f"{'='*60}\n")

        return self.test_results

    def get_best_variant(self) -> Optional[PromptVariant]:
        """
        ìµœì  ë³€í˜• ë°˜í™˜

        Returns:
            PromptVariant: ìµœê³  ì„±ëŠ¥ ë³€í˜• (í…ŒìŠ¤íŠ¸ ë¯¸ì‹¤í–‰ ì‹œ None)
        """
        if not self.test_results:
            self._log("âš ï¸ A/B í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
            return None

        return self.variants[self.test_results.best_variant]

    def generate_report(
        self,
        output_path: Optional[str] = None
    ) -> str:
        """
        í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±

        Args:
            output_path: ë³´ê³ ì„œ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì¶œë ¥ë§Œ)

        Returns:
            str: ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        """
        if not self.test_results:
            return "A/B í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”"

        # ë³´ê³ ì„œ ìƒì„±
        lines = []
        lines.append("=" * 80)
        lines.append("í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ")
        lines.append("=" * 80)
        lines.append("")

        # í…ŒìŠ¤íŠ¸ ê°œìš”
        lines.append("## í…ŒìŠ¤íŠ¸ ê°œìš”")
        lines.append(f"  - í…ŒìŠ¤íŠ¸ ë³€í˜• ìˆ˜: {len(self.variants)}")
        lines.append(f"  - ìµœê³  ì„±ëŠ¥ ë³€í˜•: {self.test_results.best_variant}")
        lines.append(f"  - í†µê³„ì  ìœ ì˜ì„±: {'ìœ ì˜ë¯¸' if self.test_results.statistical_significance else 'ë¶ˆì¶©ë¶„'}")
        lines.append("")

        # ë³€í˜•ë³„ ìƒì„¸ ê²°ê³¼
        lines.append("## ë³€í˜•ë³„ ê²°ê³¼")
        lines.append("")

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_variants = sorted(
            self.variants.items(),
            key=lambda x: x[1].rouge_scores['rouge_sum'],
            reverse=True
        )

        for rank, (name, variant) in enumerate(sorted_variants, 1):
            lines.append(f"### {rank}. {name}")
            lines.append(f"   ì„¤ëª…: {variant.description}")
            lines.append(f"   ROUGE-1: {variant.rouge_scores['rouge1']:.4f}")
            lines.append(f"   ROUGE-2: {variant.rouge_scores['rouge2']:.4f}")
            lines.append(f"   ROUGE-L: {variant.rouge_scores['rougeL']:.4f}")
            lines.append(f"   ROUGE-Sum: {variant.rouge_scores['rouge_sum']:.4f}")
            lines.append(f"   í‰ê·  ì‘ë‹µì‹œê°„: {variant.avg_latency:.3f}ì´ˆ")
            lines.append("")

        # í†µê³„ ë¶„ì„
        lines.append("## í†µê³„ ë¶„ì„")
        lines.append(f"   ìŠ¹ì°¨ (1ë“±-2ë“±): {self.test_results.winner_margin:.4f}")
        lines.append(f"   p-value: {self.test_results.p_value:.4f}")
        lines.append("")

        # ê¶Œì¥ì‚¬í•­
        lines.append("## ê¶Œì¥ì‚¬í•­")
        if self.test_results.statistical_significance:
            lines.append(f"âœ“ '{self.test_results.best_variant}' ë³€í˜•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        else:
            lines.append(f"âš ï¸ ë³€í˜• ê°„ ì„±ëŠ¥ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            lines.append(f"   ë” ë§ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸í•˜ê±°ë‚˜ ë³€í˜•ì„ ìˆ˜ì •í•´ë³´ì„¸ìš”.")
        lines.append("")

        lines.append("=" * 80)

        report = "\n".join(lines)

        # íŒŒì¼ ì €ì¥
        if output_path:
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
            self._log(f"ë³´ê³ ì„œ ì €ì¥ë¨: {output_path}")

        return report

    def export_results(
        self,
        output_path: str
    ):
        """
        í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°

        Args:
            output_path: JSON íŒŒì¼ ì €ì¥ ê²½ë¡œ
        """
        if not self.test_results:
            self._log("âš ï¸ A/B í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
            return

        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        export_data = {
            'best_variant': self.test_results.best_variant,
            'statistical_significance': self.test_results.statistical_significance,
            'p_value': self.test_results.p_value,
            'winner_margin': self.test_results.winner_margin,
            'variants': {}
        }

        for name, variant in self.variants.items():
            export_data['variants'][name] = {
                'name': variant.name,
                'template': variant.template,
                'description': variant.description,
                'rouge_scores': variant.rouge_scores,
                'avg_latency': variant.avg_latency
            }

        # JSON ì €ì¥
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)

        self._log(f"ê²°ê³¼ ì €ì¥ë¨: {output_path}")


def create_ab_tester(
    api_client: Optional[SolarAPI] = None,
    rouge_calculator: Optional[RougeCalculator] = None,
    logger=None
) -> PromptABTester:
    """
    PromptABTester íŒ©í† ë¦¬ í•¨ìˆ˜

    Args:
        api_client: Solar API í´ë¼ì´ì–¸íŠ¸
        rouge_calculator: ROUGE ê³„ì‚°ê¸°
        logger: Logger ì¸ìŠ¤í„´ìŠ¤

    Returns:
        PromptABTester ì¸ìŠ¤í„´ìŠ¤
    """
    return PromptABTester(
        api_client=api_client,
        rouge_calculator=rouge_calculator,
        logger=logger
    )


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # A/B í…ŒìŠ¤í„° ìƒì„±
    tester = create_ab_tester()

    # ë³€í˜• ì¶”ê°€
    tester.add_variant(
        name="zero_shot",
        template="ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{dialogue}\n\nìš”ì•½:",
        description="ê¸°ë³¸ Zero-shot í”„ë¡¬í”„íŠ¸"
    )

    tester.add_variant(
        name="detailed",
        template="""ì•„ë˜ ëŒ€í™”ë¥¼ ì½ê³  í•µì‹¬ ë‚´ìš©ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ëŒ€í™”:
{dialogue}

ìš”ì•½:""",
        description="ìƒì„¸í•œ ì§€ì‹œì‚¬í•­ í¬í•¨"
    )

    tester.add_variant(
        name="structured",
        template="""[íƒœìŠ¤í¬] ëŒ€í™” ìš”ì•½
[í˜•ì‹] í•œ ë¬¸ë‹¨, 3-5ë¬¸ì¥
[ìŠ¤íƒ€ì¼] ê°ê´€ì , ê°„ê²°í•¨

ëŒ€í™” ë‚´ìš©:
{dialogue}

ìš”ì•½ ê²°ê³¼:""",
        description="êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸"
    )

    # A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì˜ˆì‹œ ë°ì´í„° í•„ìš”)
    # result = tester.run_ab_test(dialogues, references)

    # ìµœê³  ë³€í˜• í™•ì¸
    # best = tester.get_best_variant()
    # print(f"Best variant: {best.name}")

    # ë³´ê³ ì„œ ìƒì„±
    # report = tester.generate_report("reports/ab_test_report.txt")
    # print(report)
