# ==================== OptunaTrainer ==================== #
"""
Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ Trainer

PRD 13: Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ëª¨ë“ˆ
ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ê²ƒì´ ëª©í‘œ
"""

# ---------------------- ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---------------------- #
import json
from pathlib import Path
from typing import Dict, Any

# ---------------------- ë‚´ë¶€ ëª¨ë“ˆ ---------------------- #
from src.trainers.base_trainer import BaseTrainer
from src.config import load_model_config
from src.models import load_model_and_tokenizer
from src.data import DialogueSummarizationDataset
from src.training import create_trainer
from src.optimization import OptunaOptimizer


# ==================== OptunaTrainer ==================== #
class OptunaTrainer(BaseTrainer):
    """Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ Trainer"""

    def train(self):
        """
        Optuna íŠœë‹ ì‹¤í–‰

        Returns:
            dict: íŠœë‹ ê²°ê³¼
                - mode: 'optuna'
                - model: ìµœì í™”ëœ ëª¨ë¸
                - best_params: ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°
                - best_value: ìµœê³  ROUGE ì ìˆ˜
                - n_trials: ìˆ˜í–‰ëœ ì‹œë„ íšŸìˆ˜
        """
        self.log("=" * 60)
        self.log("ğŸ“Š OPTUNA íŠœë‹ ëª¨ë“œ ì‹œì‘")
        self.log(f"ğŸ”§ ëª¨ë¸: {self.args.models[0]}")
        self.log(f"ğŸ”¢ ì‹œë„ íšŸìˆ˜: {self.args.optuna_trials}")
        self.log(f"â± ìµœëŒ€ ì‹œê°„: {self.args.optuna_timeout}")
        self.log("=" * 60)

        # 1. ë°ì´í„° ë¡œë“œ
        self.log("\n[1/3] ë°ì´í„° ë¡œë“œ...")
        train_df, eval_df = self.load_data()

        # 2. Config ë¡œë“œ
        self.log("\n[2/3] Config ë¡œë“œ...")
        model_name = self.args.models[0]
        config = load_model_config(model_name)

        # ëª…ë ¹í–‰ ì¸ìë¡œ Config ì˜¤ë²„ë¼ì´ë“œ
        self._override_config(config)

        self.log(f"   Config ë¡œë“œ ì™„ë£Œ: {model_name}")

        # 3. Optuna Optimizer ì´ˆê¸°í™”
        self.log(f"\n[3/3] Optuna íŠœë‹ ì‹œì‘...")

        # âœ… --resume_from ì˜µì…˜ ì²˜ë¦¬
        optimizer_output_dir = self.args.output_dir
        if hasattr(self.args, 'resume_from') and self.args.resume_from:
            # --resume_fromì´ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²½ìš° ìƒìœ„ í´ë” ì‚¬ìš©
            resume_path = Path(self.args.resume_from)
            if resume_path.name == 'checkpoints':
                optimizer_output_dir = str(resume_path.parent)
            else:
                optimizer_output_dir = self.args.resume_from
            self.log(f"ğŸ”„ Resume from: {optimizer_output_dir}")

        # Optuna Optimizer ì´ˆê¸°í™” (ë°ì´í„°í”„ë ˆì„ ì „ë‹¬)
        optimizer = OptunaOptimizer(
            config=config,
            train_df=train_df,
            eval_df=eval_df,
            n_trials=self.args.optuna_trials,
            timeout=self.args.optuna_timeout,
            study_name=f"optuna_{model_name}_{self.args.experiment_name}",
            storage=None,
            direction="maximize",
            logger=self.logger,
            output_dir=optimizer_output_dir  # resume_from ì ìš©ëœ ê²½ë¡œ ì „ë‹¬
        )

        # íŠœë‹ ì‹¤í–‰
        study = optimizer.optimize()

        # ê²°ê³¼ ë°˜í™˜
        best_params = optimizer.get_best_params()
        best_value = optimizer.get_best_value()

        results = {
            'mode': 'optuna',
            'model': model_name,
            'best_params': best_params,
            'best_value': best_value,
            'n_trials': len(study.trials),
            'study_name': optimizer.study_name
        }

        # ê²°ê³¼ ì €ì¥
        self.log("\nê²°ê³¼ ì €ì¥ ì¤‘...")
        optimizer.save_results(str(self.output_dir))

        # ì‹œê°í™” (ì„ íƒ)
        if self.args.save_visualizations:
            self.log("\nì‹œê°í™” ìƒì„± ì¤‘...")
            try:
                optimizer.plot_optimization_history(str(self.output_dir))
            except Exception as e:
                self.log(f"    âš ï¸  ì‹œê°í™” ì˜¤ë¥˜: {e}")

        self.log("\n" + "=" * 60)
        self.log("âœ… OPTUNA íŠœë‹ ì™„ë£Œ!")
        self.log(f"\nğŸ“ˆ ìµœê³  ROUGE-L F1: {best_value:.4f}")
        self.log(f"\nğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
        for key, value in best_params.items():
            self.log(f"  {key}: {value}")
        self.log("=" * 60)

        return results

    def save_results(self, results):
        """
        ê²°ê³¼ ì €ì¥

        Args:
            results: íŠœë‹ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        result_path = self.output_dir / "optuna_results.json"

        # ì €ì¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        saveable_results = {
            'mode': results['mode'],
            'model': results['model'],
            'best_params': results['best_params'],
            'best_value': results['best_value'],
            'n_trials': results['n_trials'],
            'study_name': results['study_name']
        }

        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(saveable_results, f, indent=2, ensure_ascii=False)

        self.log(f"\nğŸ“‚ ê²°ê³¼ ì €ì¥: {result_path}")

        # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ Config ìƒì„± (ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥)
        best_config_path = self.output_dir / "best_config.yaml"
        self.log(f"ğŸ“‚ ìµœì  Config ì €ì¥: {best_config_path}")


# ==================== í¸ì˜ í•¨ìˆ˜ ==================== #
def create_optuna_trainer(args, logger, wandb_logger=None):
    """
    OptunaTrainer ìƒì„± í¸ì˜ í•¨ìˆ˜

    Args:
        args: ëª…ë ¹í–‰ ì¸ì
        logger: Logger ì¸ìŠ¤í„´ìŠ¤
        wandb_logger: WandB Logger (ì„ íƒ)

    Returns:
        OptunaTrainer ì¸ìŠ¤í„´ìŠ¤
    """
    return OptunaTrainer(args, logger, wandb_logger)
