{
  "os": "Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39",
  "python": "CPython 3.11.9",
  "startedAt": "2025-10-12T13:22:52.512337Z",
  "args": [
    "--mode",
    "full",
    "--models",
    "all",
    "--epochs",
    "1",
    "--batch_size",
    "16",
    "--learning_rate",
    "5e-6",
    "--gradient_accumulation_steps",
    "2",
    "--warmup_ratio",
    "0.1",
    "--weight_decay",
    "0.01",
    "--max_grad_norm",
    "1.0",
    "--label_smoothing",
    "0.1",
    "--use_augmentation",
    "--augmentation_methods",
    "back_translation",
    "paraphrase",
    "synonym",
    "turn_shuffle",
    "--augmentation_ratio",
    "0.05",
    "--k_folds",
    "2",
    "--fold_seed",
    "42",
    "--ensemble_strategy",
    "stacking",
    "--use_tta",
    "--tta_strategies",
    "paraphrase",
    "reorder",
    "synonym",
    "mask",
    "--tta_num_aug",
    "1",
    "--use_solar_api",
    "--solar_model",
    "solar-1-mini-chat",
    "--prompt_strategy",
    "few_shot_standard",
    "--validate_data_quality",
    "--quality_threshold",
    "0.7",
    "--optimize_inference",
    "--optimization_method",
    "quantization",
    "--use_batch_optimization",
    "--num_beams",
    "4",
    "--temperature",
    "0.7",
    "--top_p",
    "0.9",
    "--top_k",
    "50",
    "--repetition_penalty",
    "1.2",
    "--length_penalty",
    "1.0",
    "--no_repeat_ngram_size",
    "3",
    "--save_visualizations",
    "--experiment_name",
    "test_full_pipeline_optimized",
    "--seed",
    "42"
  ],
  "program": "/home/ieyeppo/AI_Lab/natural-language-processing-competition/scripts/train.py",
  "codePath": "scripts/train.py",
  "codePathLocal": "scripts/train.py",
  "git": {
    "remote": "git@github.com:iejob/natural-language-processing-competition.git",
    "commit": "3e35c2f1a2a18a15d09c924672ed1bf015e16807"
  },
  "email": "ieyeppo.job@gmail.com",
  "root": "/home/ieyeppo/AI_Lab/natural-language-processing-competition/wandb",
  "host": "PotG",
  "executable": "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/bin/python",
  "cpu_count": 6,
  "cpu_count_logical": 12,
  "gpu": "NVIDIA GeForce RTX 4090",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "1081101176832",
      "used": "290828664832"
    }
  },
  "memory": {
    "total": "33656340480"
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 4090",
      "memoryTotal": "25757220864",
      "architecture": "Ada",
      "uuid": "GPU-b2b9e31d-4ca9-4907-d713-96771c28a1dd"
    }
  ],
  "cudaVersion": "12.6",
  "writerId": "t8dplkb8ymaf5jp786rpl9qz8tvqe3ij"
}