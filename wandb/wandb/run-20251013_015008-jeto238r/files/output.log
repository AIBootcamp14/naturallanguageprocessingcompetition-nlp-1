2025-10-13 01:50:11 | ðŸ“‹ ì‹¤í—˜ëª…: 1013-0150-solar_10.7b_qlora
2025-10-13 01:50:11 | ðŸ”— WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/jeto238r
2025-10-13 01:50:11 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-13 01:50:11 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-13 01:50:11 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-13 01:50:11 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [1:06:37<00:00, 31.98s/it]
2025-10-13 01:50:11 | 0%|          | 0/125 [00:00<?, ?it/s]
2025-10-13 01:50:34 | âŒ solar-10.7b í•™ìŠµ ì‹¤íŒ¨: RuntimeError: Function MmBackward0 returned an invalid gradient at index 1 - expected device meta but got cuda:0
2025-10-13 01:50:34 | ì˜¤ë¥˜ ë¡œê·¸ ì €ìž¥: experiments/20251013/20251013_001540_test_full_pipeline_quick/errors/solar-10.7b_error.log
2025-10-13 01:50:34 | ==================================================
2025-10-13 01:50:34 | ëª¨ë¸ 5/6: polyglot-ko-12.8b
2025-10-13 01:50:34 | ==================================================
2025-10-13 01:50:34 | ëª¨ë¸ íƒ€ìž…: causal_lm
2025-10-13 01:50:34 | Loading Causal LM: EleutherAI/polyglot-ko-12.8b
2025-10-13 01:50:34 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-13 01:50:35 | Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]
2025-10-13 01:50:36 | Loading checkpoint shards:   4%|â–Ž         | 1/28 [00:01<00:30,  1.13s/it]
2025-10-13 01:50:36 | Loading checkpoint shards:   7%|â–‹         | 2/28 [00:01<00:18,  1.42it/s]
2025-10-13 01:50:37 | Loading checkpoint shards:  11%|â–ˆ         | 3/28 [00:02<00:15,  1.59it/s]
2025-10-13 01:50:37 | Loading checkpoint shards:  14%|â–ˆâ–        | 4/28 [00:02<00:13,  1.73it/s]
2025-10-13 01:50:38 | Loading checkpoint shards:  18%|â–ˆâ–Š        | 5/28 [00:03<00:12,  1.90it/s]
2025-10-13 01:50:38 | Loading checkpoint shards:  21%|â–ˆâ–ˆâ–       | 6/28 [00:03<00:11,  1.95it/s]
2025-10-13 01:50:39 | Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 7/28 [00:03<00:10,  1.99it/s]
2025-10-13 01:50:39 | Loading checkpoint shards:  29%|â–ˆâ–ˆâ–Š       | 8/28 [00:04<00:10,  1.99it/s]
2025-10-13 01:50:39 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:04<00:00,  6.14it/s]
2025-10-13 01:50:40 | WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.
2025-10-13 01:50:40 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-13 01:50:40 | LoRA ì„¤ì • ì ìš© ì¤‘...
2025-10-13 01:50:40 | ðŸ” ìžë™ íƒì§€ëœ target_modules: ['query_key_value', 'dense', 'dense_h_to_4h', 'dense_4h_to_h']
2025-10-13 01:50:40 | âœ… LoRA ì ìš© ì™„ë£Œ
2025-10-13 01:50:40 | í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 52,428,800 (0.40%)
2025-10-13 01:50:40 | ì „ì²´ íŒŒë¼ë¯¸í„°: 12,946,032,640
2025-10-13 01:50:40 | Input require grads í™œì„±í™” (LoRA + Gradient Checkpointing)
2025-10-13 01:50:40 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-13 01:50:40 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-13 01:50:40 | ============================================================
2025-10-13 01:50:40 | ëª¨ë¸ í•™ìŠµ ì‹œìž‘
2025-10-13 01:50:40 | ============================================================
2025-10-13 01:50:41 | WandB ë¡œê·¸ì¸ ìƒíƒœ: ieyeppo-job
2025-10-13 01:50:41 | wandb: Finishing previous runs because reinit is set to True.
