# ==================== í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ==================== #
"""
ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/train.py --experiment baseline_kobart
    python scripts/train.py --experiment baseline_kobart --debug
"""

# ---------------------- í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---------------------- #
import sys
import argparse
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ---------------------- ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ---------------------- #
import pandas as pd

# ---------------------- í”„ë¡œì íŠ¸ ëª¨ë“ˆ ---------------------- #
from src.config import load_config
from src.models import load_model_and_tokenizer
from src.data import DialogueSummarizationDataset
from src.training import create_trainer
from src.utils.config.seed import set_seed
from src.logging.logger import Logger
from src.utils.core.common import create_log_path
from src.utils.gpu_optimization.team_gpu_check import (
    get_gpu_info,
    check_gpu_tier,
    get_optimal_batch_size
)


# ==================== ë©”ì¸ í•¨ìˆ˜ ==================== #
def main():
    # -------------- ì¸ì íŒŒì‹± -------------- #
    parser = argparse.ArgumentParser(description="ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--experiment",
        type=str,
        required=True,
        help="ì‹¤í—˜ ì´ë¦„ (ì˜ˆ: baseline_kobart)"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="ë””ë²„ê·¸ ëª¨ë“œ (ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)"
    )
    args = parser.parse_args()

    # -------------- Logger ì´ˆê¸°í™” -------------- #
    log_path = create_log_path("outputs/logs", f"train_{args.experiment}")
    logger = Logger(log_path, print_also=True)
    logger.start_redirect()

    try:
        logger.write("=" * 60)
        logger.write(f"í•™ìŠµ ì‹œì‘: {args.experiment}")
        logger.write("=" * 60)

        # -------------- GPU ì •ë³´ ì¶œë ¥ -------------- #
        logger.write("\n[GPU ì •ë³´]")
        gpu_info = get_gpu_info()
        for key, value in gpu_info.items():
            logger.write(f"  {key}: {value}")

        gpu_tier = check_gpu_tier()
        logger.write(f"  GPU Tier: {gpu_tier}")

        # -------------- 1. Config ë¡œë“œ -------------- #
        logger.write("\n[1/6] Config ë¡œë”©...")
        config = load_config(args.experiment)

        # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        if args.debug:
            logger.write("  âš ï¸ ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”")
            config.training.epochs = 2
            config.training.batch_size = 4
            config.wandb.enabled = False
        else:
            # GPU tierì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ìµœì í™” ì œì•ˆ
            optimal_batch_size = get_optimal_batch_size("kobart", gpu_tier)
            if config.training.batch_size != optimal_batch_size:
                logger.write(f"  ğŸ’¡ ì¶”ì²œ ë°°ì¹˜ í¬ê¸°: {optimal_batch_size} (í˜„ì¬: {config.training.batch_size})")

        # ì‹œë“œ ì„¤ì •
        set_seed(config.experiment.seed)
        logger.write(f"  âœ… Config ë¡œë“œ ì™„ë£Œ (seed: {config.experiment.seed})")

        # -------------- 2. ë°ì´í„° ë¡œë“œ -------------- #
        logger.write("\n[2/6] ë°ì´í„° ë¡œë”©...")
        train_df = pd.read_csv(config.paths.train_data)
        eval_df = pd.read_csv(config.paths.dev_data)

        # ë””ë²„ê·¸ ëª¨ë“œ: ë°ì´í„° ì¶•ì†Œ
        if args.debug:
            train_df = train_df.head(100)
            eval_df = eval_df.head(20)
            logger.write(f"  âš ï¸ ë””ë²„ê·¸: í•™ìŠµ {len(train_df)}ê°œ, ê²€ì¦ {len(eval_df)}ê°œ")
        else:
            logger.write(f"  âœ… í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ")
            logger.write(f"  âœ… ê²€ì¦ ë°ì´í„°: {len(eval_df)}ê°œ")

        # -------------- 3. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ -------------- #
        logger.write("\n[3/6] ëª¨ë¸ ë¡œë”©...")
        model, tokenizer = load_model_and_tokenizer(config, logger=logger)
        logger.write("  âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        # -------------- 4. Dataset ìƒì„± -------------- #
        logger.write("\n[4/6] Dataset ìƒì„±...")
        train_dataset = DialogueSummarizationDataset(
            dialogues=train_df['dialogue'].tolist(),
            summaries=train_df['summary'].tolist(),
            tokenizer=tokenizer,
            encoder_max_len=config.tokenizer.encoder_max_len,
            decoder_max_len=config.tokenizer.decoder_max_len,
            preprocess=True
        )

        eval_dataset = DialogueSummarizationDataset(
            dialogues=eval_df['dialogue'].tolist(),
            summaries=eval_df['summary'].tolist(),
            tokenizer=tokenizer,
            encoder_max_len=config.tokenizer.encoder_max_len,
            decoder_max_len=config.tokenizer.decoder_max_len,
            preprocess=True
        )

        logger.write(f"  âœ… í•™ìŠµ Dataset: {len(train_dataset)}ê°œ")
        logger.write(f"  âœ… ê²€ì¦ Dataset: {len(eval_dataset)}ê°œ")

        # -------------- 5. Trainer ìƒì„± ë° í•™ìŠµ -------------- #
        logger.write("\n[5/6] í•™ìŠµ ì‹œì‘...")
        trainer = create_trainer(
            config=config,
            model=model,
            tokenizer=tokenizer,
            train_dataset=train_dataset,
            eval_dataset=eval_dataset,
            use_wandb=config.wandb.enabled and not args.debug,
            logger=logger
        )

        # í•™ìŠµ ì‹¤í–‰
        results = trainer.train()

        # -------------- 6. ê²°ê³¼ ì¶œë ¥ -------------- #
        logger.write("\n[6/6] í•™ìŠµ ì™„ë£Œ!")
        logger.write(f"  ìµœì¢… ëª¨ë¸ ì €ì¥: {results['final_model_path']}")
        if 'best_model_checkpoint' in results:
            logger.write(f"  ìµœìƒ ì²´í¬í¬ì¸íŠ¸: {results['best_model_checkpoint']}")

        if 'eval_metrics' in results and results['eval_metrics']:
            logger.write("\n  ìµœì¢… í‰ê°€ ê²°ê³¼:")
            for key, value in results['eval_metrics'].items():
                if 'rouge' in key:
                    logger.write(f"    {key}: {value:.4f}")

        logger.write("\n" + "=" * 60)
        logger.write("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        logger.write("=" * 60)

    finally:
        # Logger ì •ë¦¬
        logger.stop_redirect()
        logger.close()


# ==================== ì‹¤í–‰ë¶€ ==================== #
if __name__ == "__main__":
    main()
