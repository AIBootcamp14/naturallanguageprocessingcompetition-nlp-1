{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Modular Version\n",
    "\n",
    "**목적**: 모듈화된 코드를 사용하여 baseline을 재현합니다.\n",
    "\n",
    "**기대 결과**: baseline.ipynb와 동일한 성능 (46-47점)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# scripts 디렉토리를 Python path에 추가\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 모듈 import\n",
    "from utils import load_config, get_device, set_seed\n",
    "from data_loader import Preprocess, load_data\n",
    "from tokenizer_utils import load_tokenizer\n",
    "from model_utils import load_model_for_train, get_model_info\n",
    "from dataset import prepare_train_dataset, prepare_test_dataset\n",
    "from trainer_utils import get_trainer\n",
    "from inference_utils import run_inference\n",
    "\n",
    "print(\"✅ 모든 모듈 import 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config 로드 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 로드\n",
    "config = load_config('./config.yaml')\n",
    "\n",
    "# Device 설정\n",
    "device = get_device()\n",
    "print(f\"디바이스: {device}\")\n",
    "\n",
    "# 시드 설정 (재현성)\n",
    "set_seed(config['training']['seed'])\n",
    "print(f\"시드 설정 완료: {config['training']['seed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wandb 설정 (선택적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb 사용 시 주석 해제\n",
    "# import wandb\n",
    "# from dotenv import load_dotenv\n",
    "# \n",
    "# load_dotenv()\n",
    "# wandb.login()\n",
    "# wandb.init(\n",
    "#     project=config['wandb']['project'],\n",
    "#     entity=config['wandb']['entity'],\n",
    "#     name=config['wandb']['name'] + \"-modular\"\n",
    "# )\n",
    "\n",
    "# Wandb 비활성화 (기본값)\n",
    "config['training']['report_to'] = 'none'\n",
    "print(\"Wandb 비활성화 (report_to='none')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenizer 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 로드 (special tokens 추가)\n",
    "model_name = config['general']['model_name']\n",
    "special_tokens = config['tokenizer']['special_tokens']\n",
    "\n",
    "tokenizer = load_tokenizer(model_name, special_tokens)\n",
    "\n",
    "print(f\"✅ Tokenizer 로드 완료\")\n",
    "print(f\"모델: {model_name}\")\n",
    "print(f\"Vocab size: {len(tokenizer)}\")\n",
    "print(f\"Special tokens: {special_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor 생성\n",
    "preprocessor = Preprocess(\n",
    "    bos_token=config['tokenizer']['bos_token'],\n",
    "    eos_token=config['tokenizer']['eos_token']\n",
    ")\n",
    "\n",
    "# Train/Val 데이터셋 준비\n",
    "data_path = config['general']['data_path']\n",
    "train_dataset, val_dataset = prepare_train_dataset(\n",
    "    config, preprocessor, data_path, tokenizer\n",
    ")\n",
    "\n",
    "print(f\"✅ 데이터셋 준비 완료\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Val: {len(val_dataset)} samples\")\n",
    "\n",
    "# 샘플 확인\n",
    "print(\"\\n샘플 데이터:\")\n",
    "sample = train_dataset[0]\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: shape={value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = load_model_for_train(config, tokenizer, device)\n",
    "\n",
    "print(f\"✅ 모델 로드 완료\")\n",
    "\n",
    "# 모델 정보 출력\n",
    "model_info = get_model_info(model)\n",
    "print(\"\\n모델 정보:\")\n",
    "for key, value in model_info.items():\n",
    "    if 'parameters' in key:\n",
    "        print(f\"  {key}: {value:,}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trainer 설정 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 생성\n",
    "trainer = get_trainer(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset\n",
    ")\n",
    "\n",
    "print(\"✅ Trainer 설정 완료\")\n",
    "print(f\"학습 에폭: {config['training']['num_train_epochs']}\")\n",
    "print(f\"학습률: {config['training']['learning_rate']}\")\n",
    "print(f\"배치 크기: {config['training']['per_device_train_batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시작\n",
    "print(\"\\n🚀 학습 시작...\\n\")\n",
    "trainer.train()\n",
    "print(\"\\n✅ 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터셋 준비\n",
    "test_data, test_dataset = prepare_test_dataset(config, preprocessor, tokenizer)\n",
    "\n",
    "print(f\"✅ Test 데이터셋 준비 완료\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# DataLoader 생성\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['inference']['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 실행\n",
    "print(\"\\n🔮 추론 시작...\\n\")\n",
    "\n",
    "result_df = run_inference(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    test_dataloader=test_dataloader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    save_path='./prediction/output_modular.csv'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ 추론 완료!\")\n",
    "print(f\"결과 파일: ./prediction/output_modular.csv\")\n",
    "print(f\"샘플 수: {len(result_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 5개 샘플 출력\n",
    "print(\"\\n샘플 결과 (처음 5개):\")\n",
    "print(\"=\" * 80)\n",
    "for i in range(min(5, len(result_df))):\n",
    "    print(f\"\\n[{i}] {result_df.iloc[i]['fname']}\")\n",
    "    print(f\"요약: {result_df.iloc[i]['summary'][:100]}...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 검증\n",
    "from utils import validate_csv\n",
    "\n",
    "validation_result = validate_csv('./prediction/output_modular.csv')\n",
    "\n",
    "print(\"\\nCSV 검증 결과:\")\n",
    "print(f\"유효성: {'✅ 통과' if validation_result['valid'] else '❌ 실패'}\")\n",
    "print(f\"샘플 수: {validation_result['num_samples']}\")\n",
    "print(f\"컬럼: {validation_result['columns']}\")\n",
    "\n",
    "if validation_result['errors']:\n",
    "    print(\"\\n⚠️ 오류:\")\n",
    "    for error in validation_result['errors']:\n",
    "        print(f\"  - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 원본 Baseline과 비교 (선택적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 baseline.ipynb의 결과와 비교\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    baseline_output = pd.read_csv('./prediction/output.csv')\n",
    "    modular_output = pd.read_csv('./prediction/output_modular.csv')\n",
    "    \n",
    "    # 동일한 샘플 수인지 확인\n",
    "    print(f\"\\nBaseline 샘플 수: {len(baseline_output)}\")\n",
    "    print(f\"Modular 샘플 수: {len(modular_output)}\")\n",
    "    \n",
    "    # fname 순서가 동일한지 확인\n",
    "    if baseline_output['fname'].equals(modular_output['fname']):\n",
    "        print(\"✅ fname 순서 일치\")\n",
    "    else:\n",
    "        print(\"⚠️ fname 순서 불일치\")\n",
    "    \n",
    "    # 일치하는 샘플 수 계산\n",
    "    identical_count = (baseline_output['summary'] == modular_output['summary']).sum()\n",
    "    print(f\"\\n동일한 요약문 수: {identical_count} / {len(baseline_output)}\")\n",
    "    print(f\"일치율: {identical_count / len(baseline_output) * 100:.2f}%\")\n",
    "    \nexcept FileNotFoundError:\n",
    "    print(\"⚠️ 원본 baseline 결과 파일(output.csv)을 찾을 수 없습니다.\")\n",
    "    print(\"baseline.ipynb를 먼저 실행해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ 완료\n",
    "\n",
    "**다음 단계**:\n",
    "1. `./prediction/output_modular.csv`를 대회 플랫폼에 제출\n",
    "2. 점수 확인 (46-47점 기대)\n",
    "3. 모듈화된 코드를 활용하여 실험 진행 (Learning rate 튜닝, 데이터 증강 등)\n",
    "\n",
    "**모듈 사용 방법**:\n",
    "- 새로운 실험을 위해 이 notebook을 복사하고 config를 수정\n",
    "- 각 모듈은 독립적으로 수정 가능\n",
    "- 모든 실험은 notebook으로 추적 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
