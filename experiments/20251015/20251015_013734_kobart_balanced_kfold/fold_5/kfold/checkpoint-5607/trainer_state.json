{
  "best_global_step": 5607,
  "best_metric": 1.209737592510694,
  "best_model_checkpoint": "experiments/20251015/20251015_013734_kobart_balanced_kfold/fold_5/kfold/checkpoint-5607",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 5607,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.585365295410156,
      "learning_rate": 1.80972e-05,
      "loss": 2.0263,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 3.945899724960327,
      "learning_rate": 3.63772e-05,
      "loss": 1.5969,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.566885471343994,
      "learning_rate": 5.4657199999999996e-05,
      "loss": 1.5625,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.5406200885772705,
      "learning_rate": 7.29372e-05,
      "loss": 1.5191,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 5.17777156829834,
      "learning_rate": 9.12172e-05,
      "loss": 1.4951,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.418663501739502,
      "learning_rate": 8.982083769633509e-05,
      "loss": 1.4711,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.461945652961731,
      "eval_rouge1": 0.3802352974167428,
      "eval_rouge2": 0.23150527722084896,
      "eval_rougeL": 0.3665082725373369,
      "eval_rouge_sum": 0.9782488471749287,
      "eval_runtime": 401.4722,
      "eval_samples_per_second": 6.205,
      "eval_steps_per_second": 0.389,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.114906072616577,
      "learning_rate": 8.82257242582897e-05,
      "loss": 1.2767,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 9.599915504455566,
      "learning_rate": 8.663061082024434e-05,
      "loss": 1.2027,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.5160365104675293,
      "learning_rate": 8.503549738219895e-05,
      "loss": 1.2227,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.0145466327667236,
      "learning_rate": 8.344038394415358e-05,
      "loss": 1.233,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 2.954576015472412,
      "learning_rate": 8.18452705061082e-05,
      "loss": 1.2113,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.00075626373291,
      "learning_rate": 8.025015706806283e-05,
      "loss": 1.2178,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3617980480194092,
      "eval_rouge1": 0.41366312933762833,
      "eval_rouge2": 0.2595388922820762,
      "eval_rougeL": 0.40564432351311197,
      "eval_rouge_sum": 1.0788463451328165,
      "eval_runtime": 406.9416,
      "eval_samples_per_second": 6.121,
      "eval_steps_per_second": 0.383,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 2.852675199508667,
      "learning_rate": 7.865504363001744e-05,
      "loss": 1.014,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 2.8584976196289062,
      "learning_rate": 7.705993019197208e-05,
      "loss": 0.8649,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.4780771732330322,
      "learning_rate": 7.546481675392669e-05,
      "loss": 0.8653,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 4.451434135437012,
      "learning_rate": 7.386970331588133e-05,
      "loss": 0.8813,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 4.225039482116699,
      "learning_rate": 7.227458987783596e-05,
      "loss": 0.8924,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.2117528915405273,
      "learning_rate": 7.067947643979058e-05,
      "loss": 0.8926,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.400778889656067,
      "eval_rouge1": 0.444172764291807,
      "eval_rouge2": 0.28327201304474336,
      "eval_rougeL": 0.4351974766858461,
      "eval_rouge_sum": 1.1626422540223964,
      "eval_runtime": 409.7698,
      "eval_samples_per_second": 6.079,
      "eval_steps_per_second": 0.381,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 2.997591257095337,
      "learning_rate": 6.90843630017452e-05,
      "loss": 0.822,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 2.8086087703704834,
      "learning_rate": 6.748924956369983e-05,
      "loss": 0.5986,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 2.742763042449951,
      "learning_rate": 6.589413612565445e-05,
      "loss": 0.613,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 2.8307390213012695,
      "learning_rate": 6.429902268760908e-05,
      "loss": 0.6333,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 2.9665637016296387,
      "learning_rate": 6.27039092495637e-05,
      "loss": 0.6351,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.029090404510498,
      "learning_rate": 6.110879581151833e-05,
      "loss": 0.6378,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.4894907474517822,
      "eval_rouge1": 0.43638973720701324,
      "eval_rouge2": 0.2747001547572166,
      "eval_rougeL": 0.426314184947476,
      "eval_rouge_sum": 1.137404076911706,
      "eval_runtime": 413.815,
      "eval_samples_per_second": 6.02,
      "eval_steps_per_second": 0.377,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 3.076024293899536,
      "learning_rate": 5.9513682373472944e-05,
      "loss": 0.6361,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 2.944962739944458,
      "learning_rate": 5.7918568935427575e-05,
      "loss": 0.4228,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 2.8129031658172607,
      "learning_rate": 5.63234554973822e-05,
      "loss": 0.4255,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 2.460153102874756,
      "learning_rate": 5.4728342059336824e-05,
      "loss": 0.4437,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 2.9103126525878906,
      "learning_rate": 5.313322862129145e-05,
      "loss": 0.4427,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.138399600982666,
      "learning_rate": 5.153811518324607e-05,
      "loss": 0.4488,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 3.1528427600860596,
      "learning_rate": 4.99430017452007e-05,
      "loss": 0.4589,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6024926900863647,
      "eval_rouge1": 0.44834003601720895,
      "eval_rouge2": 0.28535035362973676,
      "eval_rougeL": 0.43748306837903067,
      "eval_rouge_sum": 1.1711734580259765,
      "eval_runtime": 400.8262,
      "eval_samples_per_second": 6.215,
      "eval_steps_per_second": 0.389,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.7062528133392334,
      "learning_rate": 4.834788830715533e-05,
      "loss": 0.3149,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 2.493779182434082,
      "learning_rate": 4.6752774869109946e-05,
      "loss": 0.3003,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 2.2161717414855957,
      "learning_rate": 4.515766143106457e-05,
      "loss": 0.2992,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 2.093888521194458,
      "learning_rate": 4.3562547993019195e-05,
      "loss": 0.3096,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 2.8410837650299072,
      "learning_rate": 4.196743455497382e-05,
      "loss": 0.3166,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 2.665344715118408,
      "learning_rate": 4.0372321116928443e-05,
      "loss": 0.315,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.660935401916504,
      "eval_rouge1": 0.44128966623783117,
      "eval_rouge2": 0.2799396234003353,
      "eval_rougeL": 0.4301104477876049,
      "eval_rouge_sum": 1.1513397374257712,
      "eval_runtime": 411.2356,
      "eval_samples_per_second": 6.057,
      "eval_steps_per_second": 0.379,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 2.1023616790771484,
      "learning_rate": 3.877720767888307e-05,
      "loss": 0.2494,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 2.4705212116241455,
      "learning_rate": 3.718209424083769e-05,
      "loss": 0.2072,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 2.225376605987549,
      "learning_rate": 3.558698080279232e-05,
      "loss": 0.2125,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 2.724674701690674,
      "learning_rate": 3.399186736474694e-05,
      "loss": 0.2142,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 3.3995749950408936,
      "learning_rate": 3.2396753926701566e-05,
      "loss": 0.2162,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 2.1786365509033203,
      "learning_rate": 3.080164048865619e-05,
      "loss": 0.2172,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.7340869903564453,
      "eval_rouge1": 0.447717806167723,
      "eval_rouge2": 0.2826964494950548,
      "eval_rougeL": 0.43628483993552913,
      "eval_rouge_sum": 1.166699095598307,
      "eval_runtime": 405.2914,
      "eval_samples_per_second": 6.146,
      "eval_steps_per_second": 0.385,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 1.9973840713500977,
      "learning_rate": 2.9206527050610818e-05,
      "loss": 0.1898,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 2.1207711696624756,
      "learning_rate": 2.7611413612565442e-05,
      "loss": 0.1441,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.006422758102417,
      "learning_rate": 2.6016300174520067e-05,
      "loss": 0.1482,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 2.0903074741363525,
      "learning_rate": 2.442118673647469e-05,
      "loss": 0.1475,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 1.9477741718292236,
      "learning_rate": 2.282607329842932e-05,
      "loss": 0.1506,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 2.1785311698913574,
      "learning_rate": 2.1230959860383943e-05,
      "loss": 0.1501,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.8073689937591553,
      "eval_rouge1": 0.45383190623399816,
      "eval_rouge2": 0.28704865280262043,
      "eval_rougeL": 0.4416267408768111,
      "eval_rouge_sum": 1.1825072999134296,
      "eval_runtime": 407.5316,
      "eval_samples_per_second": 6.112,
      "eval_steps_per_second": 0.383,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 1.6800915002822876,
      "learning_rate": 1.963584642233857e-05,
      "loss": 0.1407,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 1.4382919073104858,
      "learning_rate": 1.8040732984293196e-05,
      "loss": 0.106,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 1.586861491203308,
      "learning_rate": 1.644561954624782e-05,
      "loss": 0.106,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 1.9099141359329224,
      "learning_rate": 1.4850506108202444e-05,
      "loss": 0.1074,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 1.8284330368041992,
      "learning_rate": 1.3255392670157069e-05,
      "loss": 0.105,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 1.6146959066390991,
      "learning_rate": 1.1660279232111693e-05,
      "loss": 0.1043,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 1.8312900066375732,
      "learning_rate": 1.0065165794066318e-05,
      "loss": 0.1048,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.8449456691741943,
      "eval_rouge1": 0.4632358847820775,
      "eval_rouge2": 0.2954698985130164,
      "eval_rougeL": 0.45103180921559993,
      "eval_rouge_sum": 1.209737592510694,
      "eval_runtime": 407.9498,
      "eval_samples_per_second": 6.106,
      "eval_steps_per_second": 0.382,
      "step": 5607
    }
  ],
  "logging_steps": 100,
  "max_steps": 6230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.734485094268928e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
