{
  "best_global_step": 2492,
  "best_metric": 1.1931160887887846,
  "best_model_checkpoint": "experiments/20251015/20251015_013734_kobart_balanced_kfold/fold_2/kfold/checkpoint-2492",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 4361,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 5.31545877456665,
      "learning_rate": 1.80972e-05,
      "loss": 2.0466,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 4.796176910400391,
      "learning_rate": 3.63772e-05,
      "loss": 1.6201,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.3712990283966064,
      "learning_rate": 5.4657199999999996e-05,
      "loss": 1.5231,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 4.223225116729736,
      "learning_rate": 7.29372e-05,
      "loss": 1.5169,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.088057041168213,
      "learning_rate": 9.12172e-05,
      "loss": 1.4987,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.8663907051086426,
      "learning_rate": 8.982083769633509e-05,
      "loss": 1.4882,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.414243221282959,
      "eval_rouge1": 0.4035975889141587,
      "eval_rouge2": 0.25635688285532315,
      "eval_rougeL": 0.3968957825054073,
      "eval_rouge_sum": 1.0568502542748892,
      "eval_runtime": 398.1827,
      "eval_samples_per_second": 6.258,
      "eval_steps_per_second": 0.392,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 4.79495096206665,
      "learning_rate": 8.82257242582897e-05,
      "loss": 1.2667,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 3.294379949569702,
      "learning_rate": 8.663061082024434e-05,
      "loss": 1.2082,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.390331268310547,
      "learning_rate": 8.503549738219895e-05,
      "loss": 1.2259,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.0226871967315674,
      "learning_rate": 8.344038394415358e-05,
      "loss": 1.2288,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 2.9840567111968994,
      "learning_rate": 8.18452705061082e-05,
      "loss": 1.241,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.215672731399536,
      "learning_rate": 8.025015706806283e-05,
      "loss": 1.2181,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.374950647354126,
      "eval_rouge1": 0.41410113618067834,
      "eval_rouge2": 0.26378673157176946,
      "eval_rougeL": 0.4063035608960998,
      "eval_rouge_sum": 1.0841914286485477,
      "eval_runtime": 390.6489,
      "eval_samples_per_second": 6.379,
      "eval_steps_per_second": 0.399,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 3.16611909866333,
      "learning_rate": 7.865504363001744e-05,
      "loss": 1.0208,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 3.241356134414673,
      "learning_rate": 7.705993019197208e-05,
      "loss": 0.8462,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 2.915555238723755,
      "learning_rate": 7.546481675392669e-05,
      "loss": 0.8717,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 3.152559995651245,
      "learning_rate": 7.386970331588133e-05,
      "loss": 0.8731,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 4.4121294021606445,
      "learning_rate": 7.227458987783596e-05,
      "loss": 0.9046,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.074669361114502,
      "learning_rate": 7.067947643979058e-05,
      "loss": 0.8951,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.41354501247406,
      "eval_rouge1": 0.43460288694402033,
      "eval_rouge2": 0.2755649074344803,
      "eval_rougeL": 0.42694814214412713,
      "eval_rouge_sum": 1.1371159365226278,
      "eval_runtime": 391.3526,
      "eval_samples_per_second": 6.368,
      "eval_steps_per_second": 0.399,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 2.8222362995147705,
      "learning_rate": 6.90843630017452e-05,
      "loss": 0.8147,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.047128438949585,
      "learning_rate": 6.748924956369983e-05,
      "loss": 0.6074,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 2.7995059490203857,
      "learning_rate": 6.589413612565445e-05,
      "loss": 0.617,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 3.1235461235046387,
      "learning_rate": 6.429902268760908e-05,
      "loss": 0.6249,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 2.9358716011047363,
      "learning_rate": 6.27039092495637e-05,
      "loss": 0.6434,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.1127986907958984,
      "learning_rate": 6.110879581151833e-05,
      "loss": 0.638,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.509141206741333,
      "eval_rouge1": 0.4559684228539767,
      "eval_rouge2": 0.29107788740064466,
      "eval_rougeL": 0.4460697785341631,
      "eval_rouge_sum": 1.1931160887887846,
      "eval_runtime": 397.7038,
      "eval_samples_per_second": 6.266,
      "eval_steps_per_second": 0.392,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.240285873413086,
      "learning_rate": 5.9513682373472944e-05,
      "loss": 0.6337,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 2.632636785507202,
      "learning_rate": 5.7918568935427575e-05,
      "loss": 0.4177,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 2.7097814083099365,
      "learning_rate": 5.63234554973822e-05,
      "loss": 0.4276,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 2.961890459060669,
      "learning_rate": 5.4728342059336824e-05,
      "loss": 0.4458,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 2.9611117839813232,
      "learning_rate": 5.313322862129145e-05,
      "loss": 0.447,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.1712048053741455,
      "learning_rate": 5.153811518324607e-05,
      "loss": 0.4543,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 2.9233756065368652,
      "learning_rate": 4.99430017452007e-05,
      "loss": 0.4529,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.5982587337493896,
      "eval_rouge1": 0.4506821840645327,
      "eval_rouge2": 0.2890129878519212,
      "eval_rougeL": 0.44101254005723173,
      "eval_rouge_sum": 1.1807077119736857,
      "eval_runtime": 389.055,
      "eval_samples_per_second": 6.405,
      "eval_steps_per_second": 0.401,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.496323347091675,
      "learning_rate": 4.834788830715533e-05,
      "loss": 0.3116,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 2.6572048664093018,
      "learning_rate": 4.6752774869109946e-05,
      "loss": 0.298,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 2.3496317863464355,
      "learning_rate": 4.515766143106457e-05,
      "loss": 0.302,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 2.724595785140991,
      "learning_rate": 4.3562547993019195e-05,
      "loss": 0.3102,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 3.05000901222229,
      "learning_rate": 4.196743455497382e-05,
      "loss": 0.3115,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 2.74334454536438,
      "learning_rate": 4.0372321116928443e-05,
      "loss": 0.3213,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.6620252132415771,
      "eval_rouge1": 0.4495510145374154,
      "eval_rouge2": 0.2862316052989714,
      "eval_rougeL": 0.4387299896973906,
      "eval_rouge_sum": 1.1745126095337775,
      "eval_runtime": 402.1991,
      "eval_samples_per_second": 6.196,
      "eval_steps_per_second": 0.388,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 2.4465787410736084,
      "learning_rate": 3.877720767888307e-05,
      "loss": 0.246,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 1.9984999895095825,
      "learning_rate": 3.718209424083769e-05,
      "loss": 0.206,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 2.149364471435547,
      "learning_rate": 3.558698080279232e-05,
      "loss": 0.2101,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 2.24288010597229,
      "learning_rate": 3.399186736474694e-05,
      "loss": 0.2135,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 2.4222373962402344,
      "learning_rate": 3.2396753926701566e-05,
      "loss": 0.2175,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 1.8474878072738647,
      "learning_rate": 3.080164048865619e-05,
      "loss": 0.2178,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.7306936979293823,
      "eval_rouge1": 0.45425785117289746,
      "eval_rouge2": 0.29141369650124305,
      "eval_rougeL": 0.443803283536838,
      "eval_rouge_sum": 1.1894748312109784,
      "eval_runtime": 397.6352,
      "eval_samples_per_second": 6.267,
      "eval_steps_per_second": 0.392,
      "step": 4361
    }
  ],
  "logging_steps": 100,
  "max_steps": 6230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.12660833222656e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
