{
  "best_global_step": 5607,
  "best_metric": 1.2122974326370395,
  "best_model_checkpoint": "experiments/20251015/20251015_013734_kobart_balanced_kfold/fold_1/kfold/checkpoint-5607",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6230,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 3.8435347080230713,
      "learning_rate": 1.80972e-05,
      "loss": 2.0439,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 3.825542688369751,
      "learning_rate": 3.63772e-05,
      "loss": 1.6079,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.601555109024048,
      "learning_rate": 5.4657199999999996e-05,
      "loss": 1.5516,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.2691919803619385,
      "learning_rate": 7.29372e-05,
      "loss": 1.531,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.7309181690216064,
      "learning_rate": 9.12172e-05,
      "loss": 1.5104,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.524055004119873,
      "learning_rate": 8.982083769633509e-05,
      "loss": 1.4654,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4193016290664673,
      "eval_rouge1": 0.3904751452546782,
      "eval_rouge2": 0.24210926104784167,
      "eval_rougeL": 0.38288769060067424,
      "eval_rouge_sum": 1.015472096903194,
      "eval_runtime": 315.5053,
      "eval_samples_per_second": 7.898,
      "eval_steps_per_second": 0.494,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.3895342350006104,
      "learning_rate": 8.82257242582897e-05,
      "loss": 1.282,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 3.0341920852661133,
      "learning_rate": 8.663061082024434e-05,
      "loss": 1.2288,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 2.882014513015747,
      "learning_rate": 8.503549738219895e-05,
      "loss": 1.2169,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.897798538208008,
      "learning_rate": 8.344038394415358e-05,
      "loss": 1.2469,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 3.171177625656128,
      "learning_rate": 8.18452705061082e-05,
      "loss": 1.2076,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.8137927055358887,
      "learning_rate": 8.025015706806283e-05,
      "loss": 1.2235,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3633685111999512,
      "eval_rouge1": 0.41159217242413026,
      "eval_rouge2": 0.25836360674272013,
      "eval_rougeL": 0.4051230017851383,
      "eval_rouge_sum": 1.0750787809519888,
      "eval_runtime": 357.6155,
      "eval_samples_per_second": 6.968,
      "eval_steps_per_second": 0.436,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 2.626234292984009,
      "learning_rate": 7.865504363001744e-05,
      "loss": 1.016,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 2.7687644958496094,
      "learning_rate": 7.705993019197208e-05,
      "loss": 0.8556,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.1205925941467285,
      "learning_rate": 7.546481675392669e-05,
      "loss": 0.8728,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 3.2679688930511475,
      "learning_rate": 7.386970331588133e-05,
      "loss": 0.8835,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.312293767929077,
      "learning_rate": 7.227458987783596e-05,
      "loss": 0.8932,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 2.923285722732544,
      "learning_rate": 7.067947643979058e-05,
      "loss": 0.897,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3991811275482178,
      "eval_rouge1": 0.4258183301059979,
      "eval_rouge2": 0.26959563526083313,
      "eval_rougeL": 0.4181247394195853,
      "eval_rouge_sum": 1.1135387047864163,
      "eval_runtime": 355.1773,
      "eval_samples_per_second": 7.016,
      "eval_steps_per_second": 0.439,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 2.9799489974975586,
      "learning_rate": 6.90843630017452e-05,
      "loss": 0.8276,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.2190732955932617,
      "learning_rate": 6.748924956369983e-05,
      "loss": 0.6097,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 3.6121230125427246,
      "learning_rate": 6.589413612565445e-05,
      "loss": 0.6165,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 2.7466907501220703,
      "learning_rate": 6.429902268760908e-05,
      "loss": 0.6268,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 3.183790445327759,
      "learning_rate": 6.27039092495637e-05,
      "loss": 0.6392,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.0941646099090576,
      "learning_rate": 6.110879581151833e-05,
      "loss": 0.6426,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5070770978927612,
      "eval_rouge1": 0.45847481899666953,
      "eval_rouge2": 0.29005141326036615,
      "eval_rougeL": 0.4455885658563098,
      "eval_rouge_sum": 1.1941147981133455,
      "eval_runtime": 360.4501,
      "eval_samples_per_second": 6.914,
      "eval_steps_per_second": 0.433,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.579951763153076,
      "learning_rate": 5.9513682373472944e-05,
      "loss": 0.6229,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 3.0185115337371826,
      "learning_rate": 5.7918568935427575e-05,
      "loss": 0.4143,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 3.153991937637329,
      "learning_rate": 5.63234554973822e-05,
      "loss": 0.4364,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 3.0333666801452637,
      "learning_rate": 5.4728342059336824e-05,
      "loss": 0.431,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 3.0814995765686035,
      "learning_rate": 5.313322862129145e-05,
      "loss": 0.4495,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 2.522648811340332,
      "learning_rate": 5.153811518324607e-05,
      "loss": 0.4545,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 2.8764383792877197,
      "learning_rate": 4.99430017452007e-05,
      "loss": 0.4667,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.5847960710525513,
      "eval_rouge1": 0.4465035191170444,
      "eval_rouge2": 0.28472834816696757,
      "eval_rougeL": 0.43643202253937285,
      "eval_rouge_sum": 1.1676638898233849,
      "eval_runtime": 440.5982,
      "eval_samples_per_second": 5.656,
      "eval_steps_per_second": 0.354,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.3683791160583496,
      "learning_rate": 4.834788830715533e-05,
      "loss": 0.3177,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 2.308716297149658,
      "learning_rate": 4.6752774869109946e-05,
      "loss": 0.2996,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 3.029107093811035,
      "learning_rate": 4.515766143106457e-05,
      "loss": 0.3107,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 3.018998146057129,
      "learning_rate": 4.3562547993019195e-05,
      "loss": 0.307,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 2.9203295707702637,
      "learning_rate": 4.196743455497382e-05,
      "loss": 0.3143,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 2.596210479736328,
      "learning_rate": 4.0372321116928443e-05,
      "loss": 0.3204,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.6546066999435425,
      "eval_rouge1": 0.44050015686234745,
      "eval_rouge2": 0.2818316980446988,
      "eval_rougeL": 0.4310840043730296,
      "eval_rouge_sum": 1.1534158592800758,
      "eval_runtime": 501.5382,
      "eval_samples_per_second": 4.969,
      "eval_steps_per_second": 0.311,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 2.1364448070526123,
      "learning_rate": 3.877720767888307e-05,
      "loss": 0.2488,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 2.4540274143218994,
      "learning_rate": 3.718209424083769e-05,
      "loss": 0.2085,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 2.1722257137298584,
      "learning_rate": 3.558698080279232e-05,
      "loss": 0.2197,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 2.167043685913086,
      "learning_rate": 3.399186736474694e-05,
      "loss": 0.216,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 2.156496047973633,
      "learning_rate": 3.2396753926701566e-05,
      "loss": 0.2192,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 2.2034196853637695,
      "learning_rate": 3.080164048865619e-05,
      "loss": 0.2147,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.7391232252120972,
      "eval_rouge1": 0.4641277623592565,
      "eval_rouge2": 0.29199976588662435,
      "eval_rougeL": 0.4520153022274265,
      "eval_rouge_sum": 1.2081428304733073,
      "eval_runtime": 438.5784,
      "eval_samples_per_second": 5.682,
      "eval_steps_per_second": 0.356,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 1.8942406177520752,
      "learning_rate": 2.9206527050610818e-05,
      "loss": 0.1901,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 1.6815235614776611,
      "learning_rate": 2.7611413612565442e-05,
      "loss": 0.1459,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.150669574737549,
      "learning_rate": 2.6016300174520067e-05,
      "loss": 0.1527,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 2.1596081256866455,
      "learning_rate": 2.442118673647469e-05,
      "loss": 0.151,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 1.9382624626159668,
      "learning_rate": 2.282607329842932e-05,
      "loss": 0.1532,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 1.8583292961120605,
      "learning_rate": 2.1230959860383943e-05,
      "loss": 0.1524,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.797174334526062,
      "eval_rouge1": 0.4562116804784507,
      "eval_rouge2": 0.2912289144011507,
      "eval_rougeL": 0.4462478438673826,
      "eval_rouge_sum": 1.193688438746984,
      "eval_runtime": 340.0409,
      "eval_samples_per_second": 7.329,
      "eval_steps_per_second": 0.459,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 2.099320650100708,
      "learning_rate": 1.963584642233857e-05,
      "loss": 0.1448,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 1.641937255859375,
      "learning_rate": 1.8040732984293196e-05,
      "loss": 0.1026,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 1.6978543996810913,
      "learning_rate": 1.644561954624782e-05,
      "loss": 0.1089,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 2.010374069213867,
      "learning_rate": 1.4850506108202444e-05,
      "loss": 0.1091,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 1.347853183746338,
      "learning_rate": 1.3255392670157069e-05,
      "loss": 0.1064,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 1.826810359954834,
      "learning_rate": 1.1660279232111693e-05,
      "loss": 0.1069,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 1.478243350982666,
      "learning_rate": 1.0065165794066318e-05,
      "loss": 0.1068,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.83775794506073,
      "eval_rouge1": 0.4640450860927266,
      "eval_rouge2": 0.29497326944917646,
      "eval_rougeL": 0.45327907709513654,
      "eval_rouge_sum": 1.2122974326370395,
      "eval_runtime": 455.3706,
      "eval_samples_per_second": 5.472,
      "eval_steps_per_second": 0.343,
      "step": 5607
    },
    {
      "epoch": 9.149277688603531,
      "grad_norm": 1.237660527229309,
      "learning_rate": 8.470052356020942e-06,
      "loss": 0.081,
      "step": 5700
    },
    {
      "epoch": 9.309791332263242,
      "grad_norm": 1.4337315559387207,
      "learning_rate": 6.8749389179755664e-06,
      "loss": 0.0818,
      "step": 5800
    },
    {
      "epoch": 9.470304975922954,
      "grad_norm": 1.6111451387405396,
      "learning_rate": 5.279825479930192e-06,
      "loss": 0.0793,
      "step": 5900
    },
    {
      "epoch": 9.630818619582664,
      "grad_norm": 1.29619562625885,
      "learning_rate": 3.684712041884817e-06,
      "loss": 0.08,
      "step": 6000
    },
    {
      "epoch": 9.791332263242376,
      "grad_norm": 1.6407006978988647,
      "learning_rate": 2.0895986038394414e-06,
      "loss": 0.0788,
      "step": 6100
    },
    {
      "epoch": 9.951845906902086,
      "grad_norm": 1.1951714754104614,
      "learning_rate": 4.944851657940663e-07,
      "loss": 0.0795,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.8662344217300415,
      "eval_rouge1": 0.4606701858640066,
      "eval_rouge2": 0.29561506305139945,
      "eval_rougeL": 0.45053645953069216,
      "eval_rouge_sum": 1.2068217084460982,
      "eval_runtime": 422.3312,
      "eval_samples_per_second": 5.901,
      "eval_steps_per_second": 0.369,
      "step": 6230
    }
  ],
  "logging_steps": 100,
  "max_steps": 6230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.0380119031808e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
