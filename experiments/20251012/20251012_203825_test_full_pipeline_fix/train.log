2025-10-12 20:38:25 | >> í‘œì¤€ ì¶œë ¥ ë° ì˜¤ë¥˜ë¥¼ ë¡œê·¸ íŒŒì¼ë¡œ ë¦¬ë””ë ‰ì…˜ ì‹œì‘
2025-10-12 20:38:27 | ğŸ“Š FULL ëª¨ë“œ ì‹¤í–‰ ì¤‘...
2025-10-12 20:38:27 | ============================================================
2025-10-12 20:38:27 | = FULL PIPELINE ì‹¤í–‰ ì‹œì‘
2025-10-12 20:38:27 | =ëŒ€ìƒ ëª¨ë¸: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-12 20:38:27 | =ì•™ìƒë¸” ì•™ìƒë¸” ì „ëµ: stacking
2025-10-12 20:38:27 | = TTA ì‚¬ìš©: False
2025-10-12 20:38:27 | ============================================================
2025-10-12 20:38:27 | [1/6] ë°ì´í„° ë¡œë”©...
2025-10-12 20:38:27 | âœ… í•™ìŠµ ë°ì´í„°: 12457ê°œ
2025-10-12 20:38:27 | âœ… ê²€ì¦ ë°ì´í„°: 499ê°œ
2025-10-12 20:38:27 | [2/6] ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ (6 ëª¨ë¸)...
2025-10-12 20:38:27 | ==================================================
2025-10-12 20:38:27 | ëª¨ë¸ 1/6: kobart
2025-10-12 20:38:27 | ==================================================
2025-10-12 20:38:27 | ëª¨ë¸ íƒ€ì…: encoder_decoder
2025-10-12 20:38:27 | ============================================================
2025-10-12 20:38:27 | ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì‹œì‘
2025-10-12 20:38:27 | ============================================================
2025-10-12 20:38:27 | í† í¬ë‚˜ì´ì € ë¡œë”©: digit82/kobart-summarization
2025-10-12 20:38:28 | ëª¨ë¸ ë¡œë”©: digit82/kobart-summarization
2025-10-12 20:38:28 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 20:38:29 | â†’ ë””ë°”ì´ìŠ¤: cuda
2025-10-12 20:38:29 | â†’ ì „ì²´ íŒŒë¼ë¯¸í„°: 123,859,968
2025-10-12 20:38:29 | â†’ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: 123,859,968
2025-10-12 20:38:29 | ============================================================
2025-10-12 20:38:29 | âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ
2025-10-12 20:38:29 | ============================================================
2025-10-12 20:38:30 | ============================================================
2025-10-12 20:38:30 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:38:30 | ============================================================
2025-10-12 20:38:30 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:38:30 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:38:30 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 20:38:31 | 1%|          | 9/1558 [00:00<01:56, 13.29it/s]
2025-10-12 20:38:31 | 2%|â–         | 24/1558 [00:01<01:12, 21.28it/s]
2025-10-12 20:38:32 | 3%|â–         | 39/1558 [00:02<01:06, 22.68it/s]
2025-10-12 20:38:33 | 4%|â–         | 57/1558 [00:03<01:04, 23.20it/s]
2025-10-12 20:38:33 | 5%|â–         | 72/1558 [00:03<01:04, 22.97it/s]
2025-10-12 20:38:34 | 6%|â–Œ         | 87/1558 [00:04<01:01, 23.88it/s]
2025-10-12 20:38:35 | {'loss': 2.747, 'grad_norm': 8.180588722229004, 'learning_rate': 9.9e-07, 'epoch': 0.06}
2025-10-12 20:38:35 | 6%|â–‹         | 100/1558 [00:04<01:04, 22.60it/s]
2025-10-12 20:38:35 | 7%|â–‹         | 102/1558 [00:04<01:05, 22.33it/s]
2025-10-12 20:38:35 | 8%|â–Š         | 117/1558 [00:05<01:03, 22.59it/s]
2025-10-12 20:38:36 | 9%|â–Š         | 135/1558 [00:06<01:05, 21.67it/s]
2025-10-12 20:38:37 | 10%|â–‰         | 150/1558 [00:07<01:05, 21.47it/s]
2025-10-12 20:38:37 | 11%|â–ˆ         | 165/1558 [00:07<00:57, 24.17it/s]
2025-10-12 20:38:38 | 12%|â–ˆâ–        | 180/1558 [00:08<00:56, 24.28it/s]
2025-10-12 20:38:39 | 13%|â–ˆâ–        | 195/1558 [00:08<00:55, 24.43it/s]
2025-10-12 20:38:39 | {'loss': 2.0335, 'grad_norm': 10.03442096710205, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.13}
2025-10-12 20:38:39 | 13%|â–ˆâ–        | 200/1558 [00:09<00:58, 23.23it/s]
2025-10-12 20:38:39 | 14%|â–ˆâ–        | 213/1558 [00:09<00:56, 24.01it/s]
2025-10-12 20:38:40 | 15%|â–ˆâ–        | 228/1558 [00:10<00:57, 23.09it/s]
2025-10-12 20:38:41 | 16%|â–ˆâ–Œ        | 243/1558 [00:11<00:59, 22.02it/s]
2025-10-12 20:38:42 | 17%|â–ˆâ–‹        | 258/1558 [00:11<01:00, 21.34it/s]
2025-10-12 20:38:42 | 18%|â–ˆâ–Š        | 273/1558 [00:12<00:56, 22.92it/s]
2025-10-12 20:38:43 | 19%|â–ˆâ–Š        | 291/1558 [00:13<00:52, 24.05it/s]
2025-10-12 20:38:43 | {'loss': 1.854, 'grad_norm': 6.359502792358398, 'learning_rate': 2.99e-06, 'epoch': 0.19}
2025-10-12 20:38:43 | 19%|â–ˆâ–‰        | 300/1558 [00:13<00:51, 24.23it/s]
2025-10-12 20:38:44 | 20%|â–ˆâ–‰        | 306/1558 [00:14<01:38, 12.68it/s]
2025-10-12 20:38:45 | 21%|â–ˆâ–ˆ        | 321/1558 [00:15<00:58, 21.17it/s]
2025-10-12 20:38:45 | 22%|â–ˆâ–ˆâ–       | 336/1558 [00:15<00:54, 22.22it/s]
2025-10-12 20:38:46 | 23%|â–ˆâ–ˆâ–       | 351/1558 [00:16<00:51, 23.38it/s]
2025-10-12 20:38:47 | 24%|â–ˆâ–ˆâ–       | 369/1558 [00:17<00:51, 23.27it/s]
2025-10-12 20:38:47 | 25%|â–ˆâ–ˆâ–       | 384/1558 [00:17<00:52, 22.28it/s]
2025-10-12 20:38:48 | 26%|â–ˆâ–ˆâ–Œ       | 399/1558 [00:18<00:50, 22.73it/s]
2025-10-12 20:38:48 | {'loss': 1.7595, 'grad_norm': 6.687829971313477, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.26}
2025-10-12 20:38:48 | 26%|â–ˆâ–ˆâ–Œ       | 400/1558 [00:18<00:50, 22.73it/s]
2025-10-12 20:38:49 | 27%|â–ˆâ–ˆâ–‹       | 414/1558 [00:18<00:47, 24.28it/s]
2025-10-12 20:38:49 | 28%|â–ˆâ–ˆâ–Š       | 429/1558 [00:19<00:47, 23.98it/s]
2025-10-12 20:38:50 | 29%|â–ˆâ–ˆâ–Š       | 447/1558 [00:20<00:50, 22.05it/s]
2025-10-12 20:38:51 | 30%|â–ˆâ–ˆâ–‰       | 462/1558 [00:21<00:45, 23.92it/s]
2025-10-12 20:38:51 | 31%|â–ˆâ–ˆâ–ˆ       | 477/1558 [00:21<00:46, 23.31it/s]
2025-10-12 20:38:52 | 32%|â–ˆâ–ˆâ–ˆâ–      | 492/1558 [00:22<00:44, 24.23it/s]
2025-10-12 20:38:52 | {'loss': 1.6645, 'grad_norm': 5.662252426147461, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.32}
2025-10-12 20:38:52 | 32%|â–ˆâ–ˆâ–ˆâ–      | 500/1558 [00:22<00:43, 24.06it/s]
2025-10-12 20:38:53 | 33%|â–ˆâ–ˆâ–ˆâ–      | 507/1558 [00:22<00:45, 23.29it/s]
2025-10-12 20:38:53 | 34%|â–ˆâ–ˆâ–ˆâ–      | 522/1558 [00:23<00:43, 23.96it/s]
2025-10-12 20:38:54 | 35%|â–ˆâ–ˆâ–ˆâ–      | 540/1558 [00:24<00:43, 23.51it/s]
2025-10-12 20:38:55 | 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 555/1558 [00:24<00:42, 23.44it/s]
2025-10-12 20:38:55 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 570/1558 [00:25<00:40, 24.43it/s]
2025-10-12 20:38:56 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 585/1558 [00:26<00:39, 24.90it/s]
2025-10-12 20:38:56 | 39%|â–ˆâ–ˆâ–ˆâ–Š      | 600/1558 [00:26<00:38, 24.99it/s]
2025-10-12 20:38:56 | {'loss': 1.6316, 'grad_norm': 6.63812780380249, 'learning_rate': 4.532136105860114e-06, 'epoch': 0.39}
2025-10-12 20:38:56 | 39%|â–ˆâ–ˆâ–ˆâ–Š      | 600/1558 [00:26<00:38, 24.99it/s]
2025-10-12 20:38:57 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 618/1558 [00:27<00:39, 24.04it/s]
2025-10-12 20:38:58 | 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 633/1558 [00:28<00:40, 22.93it/s]
2025-10-12 20:38:59 | 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 648/1558 [00:28<00:40, 22.39it/s]
2025-10-12 20:38:59 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 663/1558 [00:29<00:43, 20.66it/s]
2025-10-12 20:39:00 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 678/1558 [00:30<00:39, 22.53it/s]
2025-10-12 20:39:01 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 696/1558 [00:30<00:37, 23.03it/s]
2025-10-12 20:39:01 | {'loss': 1.6049, 'grad_norm': 7.677985191345215, 'learning_rate': 4.059546313799622e-06, 'epoch': 0.45}
2025-10-12 20:39:01 | 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 700/1558 [00:31<00:36, 23.53it/s]
2025-10-12 20:39:01 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 711/1558 [00:31<00:36, 23.18it/s]
2025-10-12 20:39:02 | 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 726/1558 [00:32<00:36, 22.88it/s]
2025-10-12 20:39:03 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 741/1558 [00:32<00:35, 23.02it/s]
2025-10-12 20:39:03 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 756/1558 [00:33<00:35, 22.43it/s]
2025-10-12 20:39:04 | 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 774/1558 [00:34<00:34, 22.74it/s]
2025-10-12 20:39:05 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 789/1558 [00:35<00:34, 22.39it/s]
2025-10-12 20:39:05 | {'loss': 1.5706, 'grad_norm': 5.508379936218262, 'learning_rate': 3.5869565217391305e-06, 'epoch': 0.51}
2025-10-12 20:39:05 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 800/1558 [00:35<00:34, 22.01it/s]
2025-10-12 20:39:05 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 804/1558 [00:35<00:34, 22.12it/s]
2025-10-12 20:39:06 | 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 819/1558 [00:36<00:32, 23.02it/s]
2025-10-12 20:39:07 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 834/1558 [00:37<00:30, 23.43it/s]
2025-10-12 20:39:08 | 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 852/1558 [00:37<00:30, 22.82it/s]
2025-10-12 20:39:08 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 867/1558 [00:38<00:29, 23.71it/s]
2025-10-12 20:39:09 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 882/1558 [00:39<00:29, 22.63it/s]
2025-10-12 20:39:09 | 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 897/1558 [00:39<00:29, 22.77it/s]
2025-10-12 20:39:10 | {'loss': 1.5792, 'grad_norm': 6.10036039352417, 'learning_rate': 3.114366729678639e-06, 'epoch': 0.58}
2025-10-12 20:39:10 | 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 900/1558 [00:39<00:28, 22.89it/s]
2025-10-12 20:39:10 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 912/1558 [00:40<00:28, 22.73it/s]
2025-10-12 20:39:11 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 930/1558 [00:41<00:28, 21.96it/s]
2025-10-12 20:39:12 | 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 945/1558 [00:41<00:28, 21.64it/s]
2025-10-12 20:39:12 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 960/1558 [00:42<00:26, 22.62it/s]
2025-10-12 20:39:13 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 975/1558 [00:43<00:24, 23.34it/s]
2025-10-12 20:39:14 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 990/1558 [00:43<00:24, 23.11it/s]
2025-10-12 20:39:14 | {'loss': 1.5576, 'grad_norm': 5.245622158050537, 'learning_rate': 2.641776937618148e-06, 'epoch': 0.64}
2025-10-12 20:39:14 | 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1000/1558 [00:44<00:25, 22.18it/s]
2025-10-12 20:39:14 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1005/1558 [00:44<00:25, 21.92it/s]
2025-10-12 20:39:15 | 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1023/1558 [00:45<00:23, 22.97it/s]
2025-10-12 20:39:16 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1038/1558 [00:46<00:23, 22.20it/s]
2025-10-12 20:39:17 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1053/1558 [00:47<00:36, 13.87it/s]
2025-10-12 20:39:18 | 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1068/1558 [00:47<00:24, 20.24it/s]
2025-10-12 20:39:18 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1083/1558 [00:48<00:20, 22.66it/s]
2025-10-12 20:39:19 | {'loss': 1.5503, 'grad_norm': 5.734011650085449, 'learning_rate': 2.169187145557656e-06, 'epoch': 0.71}
2025-10-12 20:39:19 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1100/1558 [00:49<00:21, 21.57it/s]
2025-10-12 20:39:20 | 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1116/1558 [00:50<00:19, 22.20it/s]
2025-10-12 20:39:21 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1131/1558 [00:50<00:19, 21.87it/s]
2025-10-12 20:39:21 | 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1146/1558 [00:51<00:18, 22.61it/s]
2025-10-12 20:39:22 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1161/1558 [00:52<00:17, 22.82it/s]
2025-10-12 20:39:23 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1179/1558 [00:52<00:16, 23.15it/s]
2025-10-12 20:39:23 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1194/1558 [00:53<00:15, 23.15it/s]
2025-10-12 20:39:24 | {'loss': 1.5246, 'grad_norm': 4.481096267700195, 'learning_rate': 1.6965973534971647e-06, 'epoch': 0.77}
2025-10-12 20:39:24 | 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1200/1558 [00:53<00:15, 22.72it/s]
2025-10-12 20:39:24 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1209/1558 [00:54<00:15, 22.44it/s]
2025-10-12 20:39:25 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1224/1558 [00:54<00:14, 22.89it/s]
2025-10-12 20:39:25 | 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1239/1558 [00:55<00:14, 22.26it/s]
2025-10-12 20:39:26 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1257/1558 [00:56<00:13, 22.32it/s]
2025-10-12 20:39:27 | 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1272/1558 [00:57<00:12, 22.63it/s]
2025-10-12 20:39:27 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1287/1558 [00:57<00:11, 22.81it/s]
2025-10-12 20:39:28 | {'loss': 1.5155, 'grad_norm': 5.404287815093994, 'learning_rate': 1.224007561436673e-06, 'epoch': 0.83}
2025-10-12 20:39:28 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1300/1558 [00:58<00:11, 22.75it/s]
2025-10-12 20:39:28 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1302/1558 [00:58<00:11, 22.80it/s]
2025-10-12 20:39:29 | 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1317/1558 [00:59<00:10, 22.10it/s]
2025-10-12 20:39:30 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1335/1558 [00:59<00:10, 22.16it/s]
2025-10-12 20:39:30 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1350/1558 [01:00<00:08, 23.57it/s]
2025-10-12 20:39:31 | 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1365/1558 [01:01<00:08, 22.89it/s]
2025-10-12 20:39:32 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1380/1558 [01:01<00:07, 22.91it/s]
2025-10-12 20:39:32 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1395/1558 [01:02<00:07, 23.26it/s]
2025-10-12 20:39:32 | {'loss': 1.5504, 'grad_norm': 5.75089168548584, 'learning_rate': 7.514177693761815e-07, 'epoch': 0.9}
2025-10-12 20:39:32 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1400/1558 [01:02<00:07, 21.96it/s]
2025-10-12 20:39:33 | 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1410/1558 [01:03<00:06, 22.23it/s]
2025-10-12 20:39:34 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1428/1558 [01:03<00:05, 22.22it/s]
2025-10-12 20:39:34 | 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1443/1558 [01:04<00:05, 22.91it/s]
2025-10-12 20:39:35 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1458/1558 [01:05<00:04, 21.53it/s]
2025-10-12 20:39:36 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1473/1558 [01:05<00:03, 22.58it/s]
2025-10-12 20:39:36 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1488/1558 [01:06<00:02, 23.50it/s]
2025-10-12 20:39:37 | {'loss': 1.5458, 'grad_norm': 4.620901107788086, 'learning_rate': 2.7882797731569e-07, 'epoch': 0.96}
2025-10-12 20:39:37 | 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1500/1558 [01:07<00:02, 21.26it/s]
2025-10-12 20:39:37 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1506/1558 [01:07<00:02, 21.54it/s]
2025-10-12 20:39:38 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1521/1558 [01:08<00:01, 21.57it/s]
2025-10-12 20:39:39 | 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1536/1558 [01:08<00:00, 22.28it/s]
2025-10-12 20:39:39 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1552/1558 [01:09<00:00, 19.44it/s]
2025-10-12 20:39:41 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 20:39:41 | [A
2025-10-12 20:39:42 | 3%|â–         | 2/63 [00:00<00:29,  2.09it/s]
2025-10-12 20:39:42 | [A
2025-10-12 20:39:43 | 5%|â–         | 3/63 [00:01<00:40,  1.49it/s]
2025-10-12 20:39:43 | [A
2025-10-12 20:39:44 | 6%|â–‹         | 4/63 [00:02<00:44,  1.32it/s]
2025-10-12 20:39:44 | [A
2025-10-12 20:39:45 | 8%|â–Š         | 5/63 [00:03<00:45,  1.27it/s]
2025-10-12 20:39:45 | [A
2025-10-12 20:39:45 | 10%|â–‰         | 6/63 [00:04<00:45,  1.24it/s]
2025-10-12 20:39:45 | [A
2025-10-12 20:39:46 | 11%|â–ˆ         | 7/63 [00:05<00:44,  1.25it/s]
2025-10-12 20:39:46 | [A
2025-10-12 20:39:47 | 13%|â–ˆâ–        | 8/63 [00:06<00:45,  1.21it/s]
2025-10-12 20:39:47 | [A
2025-10-12 20:39:48 | 14%|â–ˆâ–        | 9/63 [00:06<00:43,  1.24it/s]
2025-10-12 20:39:48 | [A
2025-10-12 20:39:49 | 16%|â–ˆâ–Œ        | 10/63 [00:07<00:43,  1.22it/s]
2025-10-12 20:39:49 | [A
2025-10-12 20:39:50 | 17%|â–ˆâ–‹        | 11/63 [00:09<00:52,  1.01s/it]
2025-10-12 20:39:50 | [A
2025-10-12 20:39:51 | 19%|â–ˆâ–‰        | 12/63 [00:10<00:49,  1.03it/s]
2025-10-12 20:39:51 | [A
2025-10-12 20:39:51 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1558/1558 [01:21<00:00, 17.11it/s]
2025-10-12 20:39:52 | 21%|â–ˆâ–ˆ        | 13/63 [00:10<00:46,  1.08it/s]
2025-10-12 20:39:52 | [A
2025-10-12 20:39:53 | 22%|â–ˆâ–ˆâ–       | 14/63 [00:11<00:45,  1.08it/s]
2025-10-12 20:39:53 | [A
2025-10-12 20:39:54 | 24%|â–ˆâ–ˆâ–       | 15/63 [00:12<00:43,  1.11it/s]
2025-10-12 20:39:54 | [A
2025-10-12 20:39:54 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:13<00:42,  1.09it/s]
2025-10-12 20:39:54 | [A
2025-10-12 20:39:55 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:14<00:41,  1.12it/s]
2025-10-12 20:39:55 | [A
2025-10-12 20:39:56 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:15<00:39,  1.15it/s]
2025-10-12 20:39:56 | [A
2025-10-12 20:39:57 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:16<00:37,  1.17it/s]
2025-10-12 20:39:57 | [A
2025-10-12 20:39:58 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:16<00:36,  1.17it/s]
2025-10-12 20:39:58 | [A
2025-10-12 20:39:59 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:17<00:35,  1.18it/s]
2025-10-12 20:39:59 | [A
2025-10-12 20:40:00 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:18<00:35,  1.17it/s]
2025-10-12 20:40:00 | [A
2025-10-12 20:40:00 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:19<00:33,  1.18it/s]
2025-10-12 20:40:00 | [A
2025-10-12 20:40:01 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:20<00:32,  1.19it/s]
2025-10-12 20:40:01 | [A
2025-10-12 20:40:02 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:21<00:31,  1.21it/s]
2025-10-12 20:40:02 | [A
2025-10-12 20:40:03 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:21<00:30,  1.22it/s]
2025-10-12 20:40:03 | [A
2025-10-12 20:40:04 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:22<00:31,  1.15it/s]
2025-10-12 20:40:04 | [A
2025-10-12 20:40:05 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:24<00:34,  1.01it/s]
2025-10-12 20:40:05 | [A
2025-10-12 20:40:06 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:25<00:36,  1.07s/it]
2025-10-12 20:40:06 | [A
2025-10-12 20:40:07 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:26<00:34,  1.04s/it]
2025-10-12 20:40:07 | [A
2025-10-12 20:40:08 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:27<00:32,  1.01s/it]
2025-10-12 20:40:08 | [A
2025-10-12 20:40:09 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:28<00:30,  1.02it/s]
2025-10-12 20:40:09 | [A
2025-10-12 20:40:10 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:29<00:28,  1.05it/s]
2025-10-12 20:40:10 | [A
2025-10-12 20:40:11 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:30<00:26,  1.08it/s]
2025-10-12 20:40:11 | [A
2025-10-12 20:40:12 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:30<00:25,  1.09it/s]
2025-10-12 20:40:12 | [A
2025-10-12 20:40:13 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:31<00:24,  1.09it/s]
2025-10-12 20:40:13 | [A
2025-10-12 20:40:14 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:32<00:23,  1.12it/s]
2025-10-12 20:40:14 | [A
2025-10-12 20:40:14 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:33<00:21,  1.16it/s]
2025-10-12 20:40:14 | [A
2025-10-12 20:40:16 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:34<00:24,  1.02s/it]
2025-10-12 20:40:16 | [A
2025-10-12 20:40:17 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [00:36<00:25,  1.09s/it]
2025-10-12 20:40:17 | [A
2025-10-12 20:40:18 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [00:37<00:24,  1.10s/it]
2025-10-12 20:40:18 | [A
2025-10-12 20:40:19 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:38<00:23,  1.12s/it]
2025-10-12 20:40:19 | [A
2025-10-12 20:40:20 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [00:39<00:21,  1.06s/it]
2025-10-12 20:40:20 | [A
2025-10-12 20:40:21 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [00:40<00:18,  1.02it/s]
2025-10-12 20:40:21 | [A
2025-10-12 20:40:22 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [00:40<00:16,  1.09it/s]
2025-10-12 20:40:22 | [A
2025-10-12 20:40:23 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [00:42<00:18,  1.07s/it]
2025-10-12 20:40:23 | [A
2025-10-12 20:40:24 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [00:43<00:16,  1.04s/it]
2025-10-12 20:40:24 | [A
2025-10-12 20:40:25 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [00:44<00:15,  1.02s/it]
2025-10-12 20:40:25 | [A
2025-10-12 20:40:26 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [00:45<00:14,  1.03s/it]
2025-10-12 20:40:26 | [A
2025-10-12 20:40:27 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [00:46<00:13,  1.00s/it]
2025-10-12 20:40:27 | [A
2025-10-12 20:40:28 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [00:47<00:12,  1.00s/it]
2025-10-12 20:40:28 | [A
2025-10-12 20:40:29 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [00:48<00:10,  1.01it/s]
2025-10-12 20:40:29 | [A
2025-10-12 20:40:30 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [00:49<00:09,  1.01it/s]
2025-10-12 20:40:30 | [A
2025-10-12 20:40:31 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [00:50<00:09,  1.03s/it]
2025-10-12 20:40:31 | [A
2025-10-12 20:40:33 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [00:51<00:09,  1.14s/it]
2025-10-12 20:40:33 | [A
2025-10-12 20:40:34 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [00:53<00:08,  1.23s/it]
2025-10-12 20:40:34 | [A
2025-10-12 20:40:35 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [00:54<00:07,  1.23s/it]
2025-10-12 20:40:35 | [A
2025-10-12 20:40:36 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [00:55<00:06,  1.21s/it]
2025-10-12 20:40:36 | [A
2025-10-12 20:40:37 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [00:56<00:04,  1.16s/it]
2025-10-12 20:40:37 | [A
2025-10-12 20:40:38 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [00:57<00:03,  1.08s/it]
2025-10-12 20:40:38 | [A
2025-10-12 20:40:39 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [00:58<00:01,  1.01it/s]
2025-10-12 20:40:39 | [A
2025-10-12 20:40:40 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [00:59<00:00,  1.05it/s]
2025-10-12 20:40:40 | [A
2025-10-12 20:40:41 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:59<00:00,  1.09it/s]
2025-10-12 20:40:41 | [A
2025-10-12 20:40:41 | [A
2025-10-12 20:40:41 | {'eval_loss': 1.4561704397201538, 'eval_rouge1': 0.412728720177079, 'eval_rouge2': 0.2552644070704623, 'eval_rougeL': 0.40563583966739586, 'eval_rouge_sum': 1.073628966914937, 'eval_runtime': 61.121, 'eval_samples_per_second': 8.164, 'eval_steps_per_second': 1.031, 'epoch': 1.0}
2025-10-12 20:40:41 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1558/1558 [02:11<00:00, 17.11it/s]
2025-10-12 20:40:41 | [A
2025-10-12 20:40:41 | [A
2025-10-12 20:40:42 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-12 20:40:42 | {'train_runtime': 132.5508, 'train_samples_per_second': 93.979, 'train_steps_per_second': 11.754, 'train_loss': 1.707322464674826, 'epoch': 1.0}
2025-10-12 20:40:42 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1558/1558 [02:12<00:00, 17.11it/s]
2025-10-12 20:40:42 | ìµœì¢… ëª¨ë¸ ì €ì¥ ì¤‘...
2025-10-12 20:40:43 | â†’ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: experiments/20251012/20251012_203825_test_full_pipeline_fix/model_0_kobart/default/final_model
2025-10-12 20:40:43 | ìµœì¢… í‰ê°€ ì¤‘...
2025-10-12 20:40:44 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 20:40:45 | 3%|â–         | 2/63 [00:00<00:24,  2.44it/s]
2025-10-12 20:40:45 | 5%|â–         | 3/63 [00:01<00:35,  1.68it/s]
2025-10-12 20:40:46 | 6%|â–‹         | 4/63 [00:02<00:38,  1.54it/s]
2025-10-12 20:40:47 | 8%|â–Š         | 5/63 [00:03<00:39,  1.47it/s]
2025-10-12 20:40:48 | 10%|â–‰         | 6/63 [00:03<00:40,  1.41it/s]
2025-10-12 20:40:48 | 11%|â–ˆ         | 7/63 [00:04<00:39,  1.41it/s]
2025-10-12 20:40:49 | 13%|â–ˆâ–        | 8/63 [00:05<00:40,  1.36it/s]
2025-10-12 20:40:50 | 14%|â–ˆâ–        | 9/63 [00:06<00:41,  1.30it/s]
2025-10-12 20:40:51 | 16%|â–ˆâ–Œ        | 10/63 [00:07<00:41,  1.29it/s]
2025-10-12 20:40:52 | 17%|â–ˆâ–‹        | 11/63 [00:07<00:41,  1.27it/s]
2025-10-12 20:40:52 | 19%|â–ˆâ–‰        | 12/63 [00:08<00:40,  1.25it/s]
2025-10-12 20:40:53 | 21%|â–ˆâ–ˆ        | 13/63 [00:09<00:40,  1.23it/s]
2025-10-12 20:40:54 | 22%|â–ˆâ–ˆâ–       | 14/63 [00:10<00:39,  1.23it/s]
2025-10-12 20:40:56 | 24%|â–ˆâ–ˆâ–       | 15/63 [00:11<00:49,  1.03s/it]
2025-10-12 20:40:57 | 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:13<00:52,  1.11s/it]
2025-10-12 20:40:58 | 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:14<00:48,  1.06s/it]
2025-10-12 20:40:59 | 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:15<00:46,  1.02s/it]
2025-10-12 20:41:00 | 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:16<00:43,  1.00it/s]
2025-10-12 20:41:01 | 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:16<00:42,  1.01it/s]
2025-10-12 20:41:02 | 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:17<00:41,  1.00it/s]
2025-10-12 20:41:03 | 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:19<00:41,  1.01s/it]
2025-10-12 20:41:04 | 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:20<00:40,  1.01s/it]
2025-10-12 20:41:05 | 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:21<00:39,  1.00s/it]
2025-10-12 20:41:06 | 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:22<00:38,  1.00s/it]
2025-10-12 20:41:07 | 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:23<00:37,  1.01s/it]
2025-10-12 20:41:08 | 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:24<00:36,  1.02s/it]
2025-10-12 20:41:09 | 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:25<00:35,  1.02s/it]
2025-10-12 20:41:10 | 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:26<00:34,  1.03s/it]
2025-10-12 20:41:11 | 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:27<00:33,  1.02s/it]
2025-10-12 20:41:12 | 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:28<00:33,  1.04s/it]
2025-10-12 20:41:13 | 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:29<00:32,  1.06s/it]
2025-10-12 20:41:14 | 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:30<00:31,  1.06s/it]
2025-10-12 20:41:15 | 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:31<00:30,  1.07s/it]
2025-10-12 20:41:17 | 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:32<00:30,  1.11s/it]
2025-10-12 20:41:18 | 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:33<00:30,  1.12s/it]
2025-10-12 20:41:19 | 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:35<00:29,  1.13s/it]
2025-10-12 20:41:20 | 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:36<00:28,  1.13s/it]
2025-10-12 20:41:21 | 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:37<00:27,  1.14s/it]
2025-10-12 20:41:22 | 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [00:38<00:26,  1.16s/it]
2025-10-12 20:41:24 | 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [00:39<00:26,  1.19s/it]
2025-10-12 20:41:25 | 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [00:41<00:25,  1.21s/it]
2025-10-12 20:41:26 | 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [00:42<00:24,  1.24s/it]
2025-10-12 20:41:28 | 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [00:44<00:26,  1.40s/it]
2025-10-12 20:41:29 | 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [00:45<00:24,  1.34s/it]
2025-10-12 20:41:30 | 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [00:46<00:22,  1.30s/it]
2025-10-12 20:41:32 | 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [00:47<00:20,  1.28s/it]
2025-10-12 20:41:33 | 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [00:48<00:18,  1.26s/it]
2025-10-12 20:41:34 | 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [00:50<00:17,  1.27s/it]
2025-10-12 20:41:35 | 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [00:51<00:16,  1.31s/it]
2025-10-12 20:41:37 | 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [00:53<00:15,  1.32s/it]
2025-10-12 20:41:38 | 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [00:54<00:15,  1.41s/it]
2025-10-12 20:41:40 | 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [00:55<00:13,  1.38s/it]
2025-10-12 20:41:41 | 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [00:57<00:11,  1.33s/it]
2025-10-12 20:41:42 | 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [00:58<00:10,  1.31s/it]
2025-10-12 20:41:44 | 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [00:59<00:09,  1.31s/it]
2025-10-12 20:41:45 | 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:00<00:07,  1.29s/it]
2025-10-12 20:41:46 | 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:02<00:06,  1.31s/it]
2025-10-12 20:41:47 | 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:03<00:05,  1.29s/it]
2025-10-12 20:41:49 | 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:04<00:03,  1.26s/it]
2025-10-12 20:41:50 | 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:05<00:02,  1.25s/it]
2025-10-12 20:41:51 | 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:07<00:01,  1.22s/it]
2025-10-12 20:41:52 | 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:08<00:00,  1.23s/it]
2025-10-12 20:41:52 | ìµœì¢… í‰ê°€ ê²°ê³¼:
2025-10-12 20:41:52 | eval_rouge1: 0.4127
2025-10-12 20:41:52 | eval_rouge2: 0.2553
2025-10-12 20:41:52 | eval_rougeL: 0.4056
2025-10-12 20:41:52 | eval_rouge_sum: 1.0736
2025-10-12 20:41:52 | ============================================================
2025-10-12 20:41:52 | âœ… í•™ìŠµ ì™„ë£Œ!
2025-10-12 20:41:52 | ============================================================
2025-10-12 20:41:52 | âœ… kobart í•™ìŠµ ì™„ë£Œ
2025-10-12 20:41:52 | ==================================================
2025-10-12 20:41:52 | ëª¨ë¸ 2/6: llama-3.2-korean-3b
2025-10-12 20:41:52 | ==================================================
2025-10-12 20:41:52 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-12 20:41:52 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-12 20:41:52 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-12 20:41:53 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-12 20:41:53 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-12 20:41:53 | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.22it/s]
2025-10-12 20:41:54 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  2.03it/s]
2025-10-12 20:41:54 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-12 20:41:55 | íŒ¨ë”© í† í° ì„¤ì •: <|eot_id|>
2025-10-12 20:41:55 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-12 20:41:55 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-12 20:41:55 | ============================================================
2025-10-12 20:41:55 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:41:55 | ============================================================
2025-10-12 20:41:55 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:41:55 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 20:41:55 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:41:55 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-12 20:41:55 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 20:42:21 | âŒ llama-3.2-korean-3b í•™ìŠµ ì‹¤íŒ¨: ValueError: Attempting to unscale FP16 gradients.
2025-10-12 20:42:21 | ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: experiments/20251012/20251012_203825_test_full_pipeline_fix/errors/llama-3.2-korean-3b_error.log
2025-10-12 20:42:21 | ==================================================
2025-10-12 20:42:21 | ëª¨ë¸ 3/6: qwen3-4b
2025-10-12 20:42:21 | ==================================================
2025-10-12 20:42:21 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-12 20:42:21 | Loading Causal LM: Qwen/Qwen3-4B-Instruct-2507
2025-10-12 20:42:21 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-12 20:42:22 | Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2025-10-12 20:42:22 | [A
2025-10-12 20:42:24 | Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:02<00:05,  2.91s/it]
2025-10-12 20:42:24 | [A
2025-10-12 20:42:28 | Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.14s/it]
2025-10-12 20:42:28 | [A
2025-10-12 20:42:28 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
2025-10-12 20:42:28 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-12 20:42:29 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-12 20:42:29 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-12 20:42:29 | ============================================================
2025-10-12 20:42:29 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:42:29 | ============================================================
2025-10-12 20:42:29 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:42:29 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 20:42:29 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:42:29 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
2025-10-12 20:42:29 | 0%|          | 0/1558 [00:34<?, ?it/s]
2025-10-12 20:42:47 | âŒ qwen3-4b í•™ìŠµ ì‹¤íŒ¨: ValueError: Attempting to unscale FP16 gradients.
2025-10-12 20:42:47 | ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: experiments/20251012/20251012_203825_test_full_pipeline_fix/errors/qwen3-4b_error.log
2025-10-12 20:42:47 | ==================================================
2025-10-12 20:42:47 | ëª¨ë¸ 4/6: solar-10.7b
2025-10-12 20:42:47 | ==================================================
2025-10-12 20:42:47 | ëª¨ë¸ íƒ€ì…: causal_lm
2025-10-12 20:42:47 | Loading Causal LM: upstage/solar-10.7b-instruct-v1.0
2025-10-12 20:42:47 | ëª¨ë¸ ë¡œë”© ì¤‘...
2025-10-12 20:42:48 | Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
2025-10-12 20:42:48 | [A
2025-10-12 20:42:53 | Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:20,  5.08s/it]
2025-10-12 20:42:53 | [A
2025-10-12 20:42:58 | Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:15,  5.08s/it]
2025-10-12 20:42:58 | [A
2025-10-12 20:43:16 | Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:27<00:21, 10.72s/it]
2025-10-12 20:43:16 | [A
2025-10-12 20:43:19 | Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:31<00:08,  8.03s/it]
2025-10-12 20:43:19 | [A
2025-10-12 20:43:19 | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  6.31s/it]
2025-10-12 20:43:20 | WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.
2025-10-12 20:43:20 | í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...
2025-10-12 20:43:21 | âœ… Gradient Checkpointing í™œì„±í™”
2025-10-12 20:43:21 | âœ… Causal LM ë¡œë“œ ì™„ë£Œ
2025-10-12 20:43:22 | ============================================================
2025-10-12 20:43:22 | ëª¨ë¸ í•™ìŠµ ì‹œì‘
2025-10-12 20:43:22 | ============================================================
2025-10-12 20:43:22 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 20:43:22 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 20:43:22 | í•™ìŠµ ì§„í–‰ ì¤‘...
2025-10-12 20:43:22 | 0%|          | 0/1558 [00:52<?, ?it/s]
