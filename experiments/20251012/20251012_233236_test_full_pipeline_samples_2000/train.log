2025-10-12 23:32:36 | >> 표준 출력 및 오류를 로그 파일로 리디렉션 시작
2025-10-12 23:32:38 | 📊 FULL 모드 실행 중...
2025-10-12 23:32:38 | ============================================================
2025-10-12 23:32:38 | = FULL PIPELINE 실행 시작
2025-10-12 23:32:38 | =대상 모델: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-12 23:32:38 | =앙상블 앙상블 전략: stacking
2025-10-12 23:32:38 | = TTA 사용: True
2025-10-12 23:32:38 | ============================================================
2025-10-12 23:32:38 | [1/6] 데이터 로딩...
2025-10-12 23:32:38 | ✅ 학습 데이터: 12457개
2025-10-12 23:32:38 | ✅ 검증 데이터: 499개
2025-10-12 23:32:38 | ⚙️ max_train_samples 적용: 학습 데이터 2000개로 제한
2025-10-12 23:32:38 | [2/6] 다중 모델 학습 (6 모델)...
2025-10-12 23:32:38 | ==================================================
2025-10-12 23:32:38 | 모델 1/6: kobart
2025-10-12 23:32:38 | ==================================================
2025-10-12 23:32:38 | 모델 타입: encoder_decoder
2025-10-12 23:32:38 | ============================================================
2025-10-12 23:32:38 | 모델 및 토크나이저 로딩 시작
2025-10-12 23:32:38 | ============================================================
2025-10-12 23:32:38 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-12 23:32:39 | 모델 로딩: digit82/kobart-summarization
2025-10-12 23:32:39 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 23:32:40 | → 디바이스: cuda
2025-10-12 23:32:40 | → 전체 파라미터: 123,859,968
2025-10-12 23:32:40 | → 학습 가능 파라미터: 123,859,968
2025-10-12 23:32:40 | ============================================================
2025-10-12 23:32:40 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-12 23:32:40 | ============================================================
2025-10-12 23:32:40 | ============================================================
2025-10-12 23:32:40 | 모델 학습 시작
2025-10-12 23:32:40 | ============================================================
2025-10-12 23:32:40 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 23:32:40 | 학습 진행 중...
2025-10-12 23:32:40 | 0%|          | 0/250 [00:00<?, ?it/s]
2025-10-12 23:32:41 | 1%|          | 3/250 [00:00<00:37,  6.53it/s]
2025-10-12 23:32:41 | 2%|▏         | 6/250 [00:00<00:20, 11.73it/s]
2025-10-12 23:32:41 | 4%|▎         | 9/250 [00:00<00:15, 15.10it/s]
2025-10-12 23:32:41 | 5%|▍         | 12/250 [00:00<00:13, 17.18it/s]
2025-10-12 23:32:41 | 6%|▌         | 15/250 [00:01<00:12, 18.79it/s]
2025-10-12 23:32:42 | 7%|▋         | 18/250 [00:01<00:11, 20.02it/s]
2025-10-12 23:32:42 | 8%|▊         | 21/250 [00:01<00:11, 20.51it/s]
2025-10-12 23:32:42 | 10%|▉         | 24/250 [00:01<00:10, 21.22it/s]
2025-10-12 23:32:42 | 11%|█         | 27/250 [00:01<00:10, 21.25it/s]
2025-10-12 23:32:42 | 12%|█▏        | 30/250 [00:01<00:10, 21.76it/s]
2025-10-12 23:32:42 | 13%|█▎        | 33/250 [00:01<00:09, 22.08it/s]
2025-10-12 23:32:42 | 14%|█▍        | 36/250 [00:02<00:09, 21.85it/s]
2025-10-12 23:32:42 | 16%|█▌        | 39/250 [00:02<00:09, 22.00it/s]
2025-10-12 23:32:43 | 17%|█▋        | 42/250 [00:02<00:09, 22.52it/s]
2025-10-12 23:32:43 | 18%|█▊        | 45/250 [00:02<00:08, 23.36it/s]
2025-10-12 23:32:43 | 19%|█▉        | 48/250 [00:02<00:08, 23.63it/s]
2025-10-12 23:32:43 | 20%|██        | 51/250 [00:02<00:08, 23.42it/s]
2025-10-12 23:32:43 | 22%|██▏       | 54/250 [00:02<00:08, 22.94it/s]
2025-10-12 23:32:43 | 23%|██▎       | 57/250 [00:02<00:08, 22.96it/s]
2025-10-12 23:32:43 | 24%|██▍       | 60/250 [00:03<00:08, 22.67it/s]
2025-10-12 23:32:45 | 25%|██▌       | 63/250 [00:04<00:29,  6.44it/s]
2025-10-12 23:32:45 | 26%|██▋       | 66/250 [00:04<00:22,  8.17it/s]
2025-10-12 23:32:45 | 28%|██▊       | 69/250 [00:04<00:17, 10.17it/s]
2025-10-12 23:32:45 | 29%|██▉       | 72/250 [00:04<00:14, 12.39it/s]
2025-10-12 23:32:45 | 30%|███       | 75/250 [00:04<00:12, 14.49it/s]
2025-10-12 23:32:45 | 31%|███       | 78/250 [00:04<00:10, 16.36it/s]
2025-10-12 23:32:45 | 32%|███▏      | 81/250 [00:05<00:09, 18.31it/s]
2025-10-12 23:32:46 | 34%|███▎      | 84/250 [00:05<00:08, 19.40it/s]
2025-10-12 23:32:46 | 35%|███▍      | 87/250 [00:05<00:08, 20.27it/s]
2025-10-12 23:32:46 | 36%|███▌      | 90/250 [00:05<00:07, 21.52it/s]
2025-10-12 23:32:46 | 37%|███▋      | 93/250 [00:05<00:07, 21.81it/s]
2025-10-12 23:32:46 | 38%|███▊      | 96/250 [00:05<00:06, 22.36it/s]
2025-10-12 23:32:46 | 40%|███▉      | 99/250 [00:05<00:06, 22.97it/s]
2025-10-12 23:32:46 | {'loss': 2.7236, 'grad_norm': 8.553088188171387, 'learning_rate': 9.9e-07, 'epoch': 0.4}
2025-10-12 23:32:46 | 40%|████      | 100/250 [00:05<00:06, 22.97it/s]
2025-10-12 23:32:46 | 41%|████      | 102/250 [00:05<00:06, 23.32it/s]
2025-10-12 23:32:46 | 42%|████▏     | 105/250 [00:06<00:06, 23.62it/s]
2025-10-12 23:32:47 | 43%|████▎     | 108/250 [00:06<00:05, 23.91it/s]
2025-10-12 23:32:47 | 44%|████▍     | 111/250 [00:06<00:05, 23.61it/s]
2025-10-12 23:32:47 | 46%|████▌     | 114/250 [00:06<00:05, 23.68it/s]
2025-10-12 23:32:47 | 47%|████▋     | 117/250 [00:06<00:05, 23.37it/s]
2025-10-12 23:32:47 | 48%|████▊     | 120/250 [00:06<00:05, 23.88it/s]
2025-10-12 23:32:47 | 49%|████▉     | 123/250 [00:06<00:05, 23.61it/s]
2025-10-12 23:32:47 | 50%|█████     | 126/250 [00:06<00:05, 24.01it/s]
2025-10-12 23:32:47 | 52%|█████▏    | 129/250 [00:07<00:05, 23.53it/s]
2025-10-12 23:32:48 | 53%|█████▎    | 132/250 [00:07<00:05, 23.49it/s]
2025-10-12 23:32:48 | 54%|█████▍    | 135/250 [00:07<00:04, 23.07it/s]
2025-10-12 23:32:48 | 55%|█████▌    | 138/250 [00:07<00:04, 22.46it/s]
2025-10-12 23:32:48 | 56%|█████▋    | 141/250 [00:07<00:04, 22.93it/s]
2025-10-12 23:32:48 | 58%|█████▊    | 144/250 [00:07<00:04, 22.94it/s]
2025-10-12 23:32:48 | 59%|█████▉    | 147/250 [00:07<00:04, 22.75it/s]
2025-10-12 23:32:48 | 60%|██████    | 150/250 [00:08<00:04, 22.80it/s]
2025-10-12 23:32:48 | 61%|██████    | 153/250 [00:08<00:04, 22.91it/s]
2025-10-12 23:32:49 | 62%|██████▏   | 156/250 [00:08<00:04, 22.73it/s]
2025-10-12 23:32:49 | 64%|██████▎   | 159/250 [00:08<00:03, 23.18it/s]
2025-10-12 23:32:49 | 65%|██████▍   | 162/250 [00:08<00:03, 23.67it/s]
2025-10-12 23:32:49 | 66%|██████▌   | 165/250 [00:08<00:03, 23.42it/s]
2025-10-12 23:32:49 | 67%|██████▋   | 168/250 [00:08<00:03, 23.36it/s]
2025-10-12 23:32:49 | 68%|██████▊   | 171/250 [00:08<00:03, 23.28it/s]
2025-10-12 23:32:49 | 70%|██████▉   | 174/250 [00:09<00:03, 22.83it/s]
2025-10-12 23:32:49 | 71%|███████   | 177/250 [00:09<00:03, 23.57it/s]
2025-10-12 23:32:50 | 72%|███████▏  | 180/250 [00:09<00:02, 24.12it/s]
2025-10-12 23:32:50 | 73%|███████▎  | 183/250 [00:09<00:02, 23.73it/s]
2025-10-12 23:32:50 | 74%|███████▍  | 186/250 [00:09<00:02, 23.72it/s]
2025-10-12 23:32:50 | 76%|███████▌  | 189/250 [00:09<00:02, 23.70it/s]
2025-10-12 23:32:50 | 77%|███████▋  | 192/250 [00:09<00:02, 24.06it/s]
2025-10-12 23:32:50 | 78%|███████▊  | 195/250 [00:09<00:02, 24.22it/s]
2025-10-12 23:32:50 | 79%|███████▉  | 198/250 [00:10<00:02, 24.12it/s]
2025-10-12 23:32:50 | {'loss': 2.0443, 'grad_norm': 7.496359348297119, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.8}
2025-10-12 23:32:50 | 80%|████████  | 200/250 [00:10<00:02, 24.12it/s]
2025-10-12 23:32:51 | 82%|████████▏ | 204/250 [00:10<00:01, 24.29it/s]
2025-10-12 23:32:51 | 83%|████████▎ | 207/250 [00:10<00:01, 24.66it/s]
2025-10-12 23:32:51 | 84%|████████▍ | 210/250 [00:10<00:01, 24.29it/s]
2025-10-12 23:32:51 | 85%|████████▌ | 213/250 [00:10<00:01, 24.09it/s]
2025-10-12 23:32:51 | 86%|████████▋ | 216/250 [00:10<00:01, 24.32it/s]
2025-10-12 23:32:51 | 88%|████████▊ | 219/250 [00:10<00:01, 24.11it/s]
2025-10-12 23:32:51 | 89%|████████▉ | 222/250 [00:11<00:01, 24.08it/s]
2025-10-12 23:32:51 | 90%|█████████ | 225/250 [00:11<00:01, 23.61it/s]
2025-10-12 23:32:52 | 91%|█████████ | 228/250 [00:11<00:00, 23.11it/s]
2025-10-12 23:32:52 | 92%|█████████▏| 231/250 [00:11<00:00, 22.96it/s]
2025-10-12 23:32:52 | 94%|█████████▎| 234/250 [00:11<00:00, 23.52it/s]
2025-10-12 23:32:52 | 95%|█████████▍| 237/250 [00:11<00:00, 23.71it/s]
2025-10-12 23:32:52 | 96%|█████████▌| 240/250 [00:11<00:00, 24.19it/s]
2025-10-12 23:32:52 | 97%|█████████▋| 243/250 [00:11<00:00, 24.45it/s]
2025-10-12 23:32:52 | 98%|█████████▊| 246/250 [00:12<00:00, 24.91it/s]
2025-10-12 23:32:52 | 100%|█████████▉| 249/250 [00:12<00:00, 24.98it/s]
2025-10-12 23:32:53 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 23:32:53 | [A
2025-10-12 23:32:54 | 3%|▎         | 2/63 [00:00<00:23,  2.62it/s]
2025-10-12 23:32:54 | [A
2025-10-12 23:32:55 | 5%|▍         | 3/63 [00:01<00:31,  1.93it/s]
2025-10-12 23:32:55 | [A
2025-10-12 23:32:56 | 6%|▋         | 4/63 [00:02<00:37,  1.56it/s]
2025-10-12 23:32:56 | [A
2025-10-12 23:32:57 | 8%|▊         | 5/63 [00:03<00:40,  1.42it/s]
2025-10-12 23:32:57 | [A
2025-10-12 23:32:57 | 10%|▉         | 6/63 [00:03<00:40,  1.42it/s]
2025-10-12 23:32:57 | [A
2025-10-12 23:32:58 | 11%|█         | 7/63 [00:04<00:40,  1.39it/s]
2025-10-12 23:32:58 | [A
2025-10-12 23:32:59 | 13%|█▎        | 8/63 [00:05<00:39,  1.40it/s]
2025-10-12 23:32:59 | [A
2025-10-12 23:33:00 | 14%|█▍        | 9/63 [00:06<00:40,  1.34it/s]
2025-10-12 23:33:00 | [A
2025-10-12 23:33:00 | 16%|█▌        | 10/63 [00:06<00:39,  1.34it/s]
2025-10-12 23:33:00 | [A
2025-10-12 23:33:01 | 17%|█▋        | 11/63 [00:07<00:38,  1.34it/s]
2025-10-12 23:33:01 | [A
2025-10-12 23:33:02 | 19%|█▉        | 12/63 [00:08<00:38,  1.31it/s]
2025-10-12 23:33:02 | [A
2025-10-12 23:33:03 | 21%|██        | 13/63 [00:09<00:37,  1.35it/s]
2025-10-12 23:33:03 | [A
2025-10-12 23:33:03 | 22%|██▏       | 14/63 [00:09<00:38,  1.28it/s]
2025-10-12 23:33:03 | [A
2025-10-12 23:33:04 | 24%|██▍       | 15/63 [00:10<00:37,  1.28it/s]
2025-10-12 23:33:04 | [A
2025-10-12 23:33:05 | 25%|██▌       | 16/63 [00:11<00:37,  1.25it/s]
2025-10-12 23:33:05 | [A
2025-10-12 23:33:06 | 27%|██▋       | 17/63 [00:12<00:37,  1.24it/s]
2025-10-12 23:33:06 | [A
2025-10-12 23:33:07 | 29%|██▊       | 18/63 [00:13<00:37,  1.21it/s]
2025-10-12 23:33:07 | [A
2025-10-12 23:33:08 | 30%|███       | 19/63 [00:14<00:35,  1.23it/s]
2025-10-12 23:33:08 | [A
2025-10-12 23:33:08 | 32%|███▏      | 20/63 [00:14<00:33,  1.28it/s]
2025-10-12 23:33:08 | [A
2025-10-12 23:33:09 | 33%|███▎      | 21/63 [00:15<00:32,  1.29it/s]
2025-10-12 23:33:09 | [A
2025-10-12 23:33:10 | 35%|███▍      | 22/63 [00:16<00:32,  1.28it/s]
2025-10-12 23:33:10 | [A
2025-10-12 23:33:11 | 37%|███▋      | 23/63 [00:17<00:31,  1.29it/s]
2025-10-12 23:33:11 | [A
2025-10-12 23:33:11 | 100%|██████████| 250/250 [00:31<00:00, 24.98it/s]
2025-10-12 23:33:11 | 38%|███▊      | 24/63 [00:17<00:31,  1.25it/s]
2025-10-12 23:33:11 | [A
2025-10-12 23:33:12 | 40%|███▉      | 25/63 [00:18<00:29,  1.28it/s]
2025-10-12 23:33:12 | [A
2025-10-12 23:33:13 | 41%|████▏     | 26/63 [00:19<00:29,  1.27it/s]
2025-10-12 23:33:13 | [A
2025-10-12 23:33:14 | 43%|████▎     | 27/63 [00:20<00:29,  1.24it/s]
2025-10-12 23:33:14 | [A
2025-10-12 23:33:15 | 44%|████▍     | 28/63 [00:21<00:27,  1.27it/s]
2025-10-12 23:33:15 | [A
2025-10-12 23:33:15 | 46%|████▌     | 29/63 [00:21<00:26,  1.28it/s]
2025-10-12 23:33:15 | [A
2025-10-12 23:33:16 | 48%|████▊     | 30/63 [00:22<00:25,  1.30it/s]
2025-10-12 23:33:16 | [A
2025-10-12 23:33:18 | 49%|████▉     | 31/63 [00:24<00:34,  1.09s/it]
2025-10-12 23:33:18 | [A
2025-10-12 23:33:19 | 51%|█████     | 32/63 [00:25<00:30,  1.02it/s]
2025-10-12 23:33:19 | [A
2025-10-12 23:33:19 | 52%|█████▏    | 33/63 [00:25<00:27,  1.10it/s]
2025-10-12 23:33:19 | [A
2025-10-12 23:33:20 | 54%|█████▍    | 34/63 [00:26<00:25,  1.15it/s]
2025-10-12 23:33:20 | [A
2025-10-12 23:33:21 | 56%|█████▌    | 35/63 [00:27<00:23,  1.20it/s]
2025-10-12 23:33:21 | [A
2025-10-12 23:33:22 | 57%|█████▋    | 36/63 [00:28<00:21,  1.25it/s]
2025-10-12 23:33:22 | [A
2025-10-12 23:33:22 | 59%|█████▊    | 37/63 [00:28<00:20,  1.28it/s]
2025-10-12 23:33:22 | [A
2025-10-12 23:33:23 | 60%|██████    | 38/63 [00:29<00:18,  1.35it/s]
2025-10-12 23:33:23 | [A
2025-10-12 23:33:24 | 62%|██████▏   | 39/63 [00:30<00:17,  1.36it/s]
2025-10-12 23:33:24 | [A
2025-10-12 23:33:25 | 63%|██████▎   | 40/63 [00:31<00:17,  1.32it/s]
2025-10-12 23:33:25 | [A
2025-10-12 23:33:25 | 65%|██████▌   | 41/63 [00:31<00:16,  1.32it/s]
2025-10-12 23:33:25 | [A
2025-10-12 23:33:26 | 67%|██████▋   | 42/63 [00:32<00:15,  1.33it/s]
2025-10-12 23:33:26 | [A
2025-10-12 23:33:27 | 68%|██████▊   | 43/63 [00:33<00:14,  1.34it/s]
2025-10-12 23:33:27 | [A
2025-10-12 23:33:27 | 70%|██████▉   | 44/63 [00:34<00:14,  1.35it/s]
2025-10-12 23:33:27 | [A
2025-10-12 23:33:28 | 71%|███████▏  | 45/63 [00:34<00:13,  1.30it/s]
2025-10-12 23:33:28 | [A
2025-10-12 23:33:29 | 73%|███████▎  | 46/63 [00:35<00:13,  1.23it/s]
2025-10-12 23:33:29 | [A
2025-10-12 23:33:30 | 75%|███████▍  | 47/63 [00:36<00:12,  1.26it/s]
2025-10-12 23:33:30 | [A
2025-10-12 23:33:31 | 76%|███████▌  | 48/63 [00:37<00:11,  1.27it/s]
2025-10-12 23:33:31 | [A
2025-10-12 23:33:31 | 78%|███████▊  | 49/63 [00:37<00:10,  1.30it/s]
2025-10-12 23:33:31 | [A
2025-10-12 23:33:32 | 79%|███████▉  | 50/63 [00:38<00:09,  1.35it/s]
2025-10-12 23:33:32 | [A
2025-10-12 23:33:33 | 81%|████████  | 51/63 [00:39<00:08,  1.34it/s]
2025-10-12 23:33:33 | [A
2025-10-12 23:33:34 | 83%|████████▎ | 52/63 [00:40<00:08,  1.37it/s]
2025-10-12 23:33:34 | [A
2025-10-12 23:33:34 | 84%|████████▍ | 53/63 [00:40<00:07,  1.33it/s]
2025-10-12 23:33:34 | [A
2025-10-12 23:33:35 | 86%|████████▌ | 54/63 [00:41<00:06,  1.33it/s]
2025-10-12 23:33:35 | [A
2025-10-12 23:33:36 | 87%|████████▋ | 55/63 [00:42<00:06,  1.33it/s]
2025-10-12 23:33:36 | [A
2025-10-12 23:33:37 | 89%|████████▉ | 56/63 [00:43<00:05,  1.32it/s]
2025-10-12 23:33:37 | [A
2025-10-12 23:33:37 | 90%|█████████ | 57/63 [00:43<00:04,  1.33it/s]
2025-10-12 23:33:37 | [A
2025-10-12 23:33:38 | 92%|█████████▏| 58/63 [00:44<00:03,  1.31it/s]
2025-10-12 23:33:38 | [A
2025-10-12 23:33:39 | 94%|█████████▎| 59/63 [00:45<00:03,  1.31it/s]
2025-10-12 23:33:39 | [A
2025-10-12 23:33:40 | 95%|█████████▌| 60/63 [00:46<00:02,  1.28it/s]
2025-10-12 23:33:40 | [A
2025-10-12 23:33:41 | 97%|█████████▋| 61/63 [00:47<00:01,  1.29it/s]
2025-10-12 23:33:41 | [A
2025-10-12 23:33:41 | 98%|█████████▊| 62/63 [00:47<00:00,  1.31it/s]
2025-10-12 23:33:41 | [A
2025-10-12 23:33:42 | 100%|██████████| 63/63 [00:48<00:00,  1.31it/s]
2025-10-12 23:33:42 | [A
2025-10-12 23:33:42 | [A
2025-10-12 23:33:42 | {'eval_loss': 1.7264643907546997, 'eval_rouge1': 0.4105526458836093, 'eval_rouge2': 0.24094433442398724, 'eval_rougeL': 0.4027112633280926, 'eval_rouge_sum': 1.054208243635689, 'eval_runtime': 49.5688, 'eval_samples_per_second': 10.067, 'eval_steps_per_second': 1.271, 'epoch': 1.0}
2025-10-12 23:33:42 | 100%|██████████| 250/250 [01:01<00:00, 24.98it/s]
2025-10-12 23:33:42 | [A
2025-10-12 23:33:42 | [A
2025-10-12 23:33:43 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-12 23:33:43 | {'train_runtime': 63.0863, 'train_samples_per_second': 31.703, 'train_steps_per_second': 3.963, 'train_loss': 2.272196502685547, 'epoch': 1.0}
2025-10-12 23:33:43 | 100%|██████████| 250/250 [01:03<00:00, 24.98it/s]
2025-10-12 23:33:43 | 최종 모델 저장 중...
2025-10-12 23:33:44 | → 모델 저장 위치: experiments/20251012/20251012_233236_test_full_pipeline_samples_2000/model_0_kobart/default/final_model
2025-10-12 23:33:44 | 최종 평가 중...
2025-10-12 23:33:45 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 23:33:46 | 3%|▎         | 2/63 [00:00<00:23,  2.57it/s]
2025-10-12 23:33:46 | 5%|▍         | 3/63 [00:01<00:34,  1.76it/s]
2025-10-12 23:33:47 | 6%|▋         | 4/63 [00:02<00:40,  1.47it/s]
2025-10-12 23:33:48 | 8%|▊         | 5/63 [00:03<00:43,  1.34it/s]
2025-10-12 23:33:49 | 10%|▉         | 6/63 [00:04<00:42,  1.35it/s]
2025-10-12 23:33:50 | 11%|█         | 7/63 [00:04<00:41,  1.36it/s]
2025-10-12 23:33:52 | 13%|█▎        | 8/63 [00:06<01:01,  1.11s/it]
2025-10-12 23:33:52 | 14%|█▍        | 9/63 [00:07<00:53,  1.00it/s]
2025-10-12 23:33:53 | 16%|█▌        | 10/63 [00:08<00:49,  1.06it/s]
2025-10-12 23:33:54 | 17%|█▋        | 11/63 [00:09<00:46,  1.12it/s]
2025-10-12 23:33:55 | 19%|█▉        | 12/63 [00:09<00:42,  1.21it/s]
2025-10-12 23:33:55 | 21%|██        | 13/63 [00:10<00:40,  1.25it/s]
2025-10-12 23:33:56 | 22%|██▏       | 14/63 [00:11<00:37,  1.30it/s]
2025-10-12 23:33:57 | 24%|██▍       | 15/63 [00:11<00:36,  1.32it/s]
2025-10-12 23:33:57 | 25%|██▌       | 16/63 [00:12<00:34,  1.36it/s]
2025-10-12 23:33:58 | 27%|██▋       | 17/63 [00:13<00:34,  1.35it/s]
2025-10-12 23:33:59 | 29%|██▊       | 18/63 [00:14<00:33,  1.35it/s]
2025-10-12 23:34:00 | 30%|███       | 19/63 [00:14<00:32,  1.35it/s]
2025-10-12 23:34:00 | 32%|███▏      | 20/63 [00:15<00:32,  1.33it/s]
2025-10-12 23:34:01 | 33%|███▎      | 21/63 [00:16<00:31,  1.32it/s]
2025-10-12 23:34:02 | 35%|███▍      | 22/63 [00:17<00:32,  1.27it/s]
2025-10-12 23:34:03 | 37%|███▋      | 23/63 [00:18<00:32,  1.22it/s]
2025-10-12 23:34:04 | 38%|███▊      | 24/63 [00:18<00:31,  1.23it/s]
2025-10-12 23:34:05 | 40%|███▉      | 25/63 [00:19<00:31,  1.22it/s]
2025-10-12 23:34:05 | 41%|████▏     | 26/63 [00:20<00:29,  1.25it/s]
2025-10-12 23:34:06 | 43%|████▎     | 27/63 [00:21<00:28,  1.24it/s]
2025-10-12 23:34:07 | 44%|████▍     | 28/63 [00:22<00:27,  1.30it/s]
2025-10-12 23:34:08 | 46%|████▌     | 29/63 [00:22<00:25,  1.31it/s]
2025-10-12 23:34:08 | 48%|████▊     | 30/63 [00:23<00:26,  1.26it/s]
2025-10-12 23:34:09 | 49%|████▉     | 31/63 [00:24<00:25,  1.27it/s]
2025-10-12 23:34:10 | 51%|█████     | 32/63 [00:25<00:24,  1.26it/s]
2025-10-12 23:34:11 | 52%|█████▏    | 33/63 [00:25<00:23,  1.29it/s]
2025-10-12 23:34:12 | 54%|█████▍    | 34/63 [00:26<00:22,  1.30it/s]
2025-10-12 23:34:12 | 56%|█████▌    | 35/63 [00:27<00:21,  1.30it/s]
2025-10-12 23:34:13 | 57%|█████▋    | 36/63 [00:28<00:20,  1.33it/s]
2025-10-12 23:34:14 | 59%|█████▊    | 37/63 [00:28<00:19,  1.32it/s]
2025-10-12 23:34:15 | 60%|██████    | 38/63 [00:29<00:19,  1.30it/s]
2025-10-12 23:34:15 | 62%|██████▏   | 39/63 [00:30<00:18,  1.31it/s]
2025-10-12 23:34:16 | 63%|██████▎   | 40/63 [00:31<00:17,  1.35it/s]
2025-10-12 23:34:17 | 65%|██████▌   | 41/63 [00:31<00:16,  1.34it/s]
2025-10-12 23:34:18 | 67%|██████▋   | 42/63 [00:32<00:15,  1.33it/s]
2025-10-12 23:34:18 | 68%|██████▊   | 43/63 [00:33<00:15,  1.31it/s]
2025-10-12 23:34:19 | 70%|██████▉   | 44/63 [00:34<00:14,  1.28it/s]
2025-10-12 23:34:20 | 71%|███████▏  | 45/63 [00:35<00:14,  1.27it/s]
2025-10-12 23:34:21 | 73%|███████▎  | 46/63 [00:35<00:13,  1.26it/s]
2025-10-12 23:34:22 | 75%|███████▍  | 47/63 [00:36<00:12,  1.28it/s]
2025-10-12 23:34:22 | 76%|███████▌  | 48/63 [00:37<00:11,  1.31it/s]
2025-10-12 23:34:23 | 78%|███████▊  | 49/63 [00:38<00:10,  1.30it/s]
2025-10-12 23:34:25 | 79%|███████▉  | 50/63 [00:40<00:14,  1.10s/it]
2025-10-12 23:34:26 | 81%|████████  | 51/63 [00:40<00:11,  1.01it/s]
2025-10-12 23:34:26 | 83%|████████▎ | 52/63 [00:41<00:10,  1.08it/s]
2025-10-12 23:34:27 | 84%|████████▍ | 53/63 [00:42<00:08,  1.12it/s]
2025-10-12 23:34:28 | 86%|████████▌ | 54/63 [00:43<00:07,  1.17it/s]
2025-10-12 23:34:29 | 87%|████████▋ | 55/63 [00:43<00:06,  1.21it/s]
2025-10-12 23:34:30 | 89%|████████▉ | 56/63 [00:44<00:05,  1.23it/s]
2025-10-12 23:34:30 | 90%|█████████ | 57/63 [00:45<00:04,  1.25it/s]
2025-10-12 23:34:31 | 92%|█████████▏| 58/63 [00:46<00:03,  1.29it/s]
2025-10-12 23:34:32 | 94%|█████████▎| 59/63 [00:46<00:03,  1.32it/s]
2025-10-12 23:34:32 | 95%|█████████▌| 60/63 [00:47<00:02,  1.33it/s]
2025-10-12 23:34:33 | 97%|█████████▋| 61/63 [00:48<00:01,  1.37it/s]
2025-10-12 23:34:34 | 98%|█████████▊| 62/63 [00:49<00:00,  1.34it/s]
2025-10-12 23:34:35 | 100%|██████████| 63/63 [00:49<00:00,  1.31it/s]
2025-10-12 23:34:35 | 최종 평가 결과:
2025-10-12 23:34:35 | eval_rouge1: 0.4106
2025-10-12 23:34:35 | eval_rouge2: 0.2409
2025-10-12 23:34:35 | eval_rougeL: 0.4027
2025-10-12 23:34:35 | eval_rouge_sum: 1.0542
2025-10-12 23:34:35 | ============================================================
2025-10-12 23:34:35 | ✅ 학습 완료!
2025-10-12 23:34:35 | ============================================================
2025-10-12 23:34:35 | ✅ kobart 학습 완료
2025-10-12 23:34:35 | ==================================================
2025-10-12 23:34:35 | 모델 2/6: llama-3.2-korean-3b
2025-10-12 23:34:35 | ==================================================
2025-10-12 23:34:35 | 모델 타입: causal_lm
2025-10-12 23:34:35 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-12 23:34:35 | 모델 로딩 중...
2025-10-12 23:34:35 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-12 23:34:35 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-12 23:34:36 | Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.57it/s]
2025-10-12 23:34:36 | Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.76it/s]
2025-10-12 23:34:36 | 토크나이저 로딩 중...
2025-10-12 23:34:37 | 패딩 토큰 설정: <|eot_id|>
2025-10-12 23:34:37 | LoRA 설정 적용 중...
2025-10-12 23:34:37 | 🔍 자동 탐지된 target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']
2025-10-12 23:34:37 | ✅ LoRA 적용 완료
2025-10-12 23:34:37 | 학습 가능 파라미터: 24,313,856 (0.75%)
2025-10-12 23:34:37 | 전체 파라미터: 3,237,063,680
2025-10-12 23:34:37 | Input require grads 활성화 (LoRA + Gradient Checkpointing)
2025-10-12 23:34:37 | ✅ Gradient Checkpointing 활성화
2025-10-12 23:34:37 | ✅ Causal LM 로드 완료
2025-10-12 23:34:37 | ============================================================
2025-10-12 23:34:37 | 모델 학습 시작
2025-10-12 23:34:37 | ============================================================
2025-10-12 23:34:38 | WandB 로그인 상태: ieyeppo-job
2025-10-12 23:34:38 | wandb: Currently logged in as: ieyeppo-job (kimsunmin0227-hufs) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
2025-10-12 23:34:38 | wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
2025-10-12 23:34:39 | wandb: setting up run jj8hwkzh
2025-10-12 23:34:39 | wandb: Tracking run with wandb version 0.22.2
2025-10-12 23:34:39 | wandb: Run data is saved locally in /home/ieyeppo/AI_Lab/natural-language-processing-competition/wandb/wandb/run-20251012_233438-jj8hwkzh
wandb: Run `wandb offline` to turn off syncing.
2025-10-12 23:34:39 | wandb: Syncing run 1012-2334-llama_3.2_3b_qlora
2025-10-12 23:34:39 | wandb: ⭐️ View project at https://wandb.ai/ieyeppo/nlp-competition
2025-10-12 23:34:39 | wandb: 🚀 View run at https://wandb.ai/ieyeppo/nlp-competition/runs/jj8hwkzh
2025-10-12 23:34:39 | wandb: Detected [openai] in use.
2025-10-12 23:34:39 | wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
2025-10-12 23:34:39 | wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-10-12 23:34:39 | 📋 실험명: 1012-2334-llama_3.2_3b_qlora
2025-10-12 23:34:39 | 🔗 WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/jj8hwkzh
2025-10-12 23:34:39 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 23:34:39 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 23:34:39 | 학습 진행 중...
2025-10-12 23:34:39 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-12 23:34:39 | 0%|          | 0/250 [00:00<?, ?it/s]
2025-10-12 23:34:46 | 1%|          | 2/250 [00:06<13:55,  3.37s/it]
2025-10-12 23:34:52 | 2%|▏         | 4/250 [00:12<12:56,  3.16s/it]
2025-10-12 23:35:03 | 3%|▎         | 7/250 [00:23<13:46,  3.40s/it]
2025-10-12 23:35:09 | 4%|▎         | 9/250 [00:30<13:40,  3.41s/it]
2025-10-12 23:35:13 | {'loss': 1.6234, 'grad_norm': 2.0193655490875244, 'learning_rate': 9e-08, 'epoch': 0.04}
2025-10-12 23:35:13 | 4%|▍         | 10/250 [00:33<13:26,  3.36s/it]
2025-10-12 23:35:19 | 5%|▍         | 12/250 [00:39<12:54,  3.25s/it]
2025-10-12 23:35:25 | 6%|▌         | 14/250 [00:46<12:39,  3.22s/it]
2025-10-12 23:35:36 | 7%|▋         | 17/250 [00:56<13:17,  3.42s/it]
2025-10-12 23:35:42 | 8%|▊         | 19/250 [01:03<12:39,  3.29s/it]
2025-10-12 23:35:46 | {'loss': 1.5487, 'grad_norm': 2.1541213989257812, 'learning_rate': 1.9e-07, 'epoch': 0.08}
2025-10-12 23:35:46 | 8%|▊         | 20/250 [01:06<12:34,  3.28s/it]
2025-10-12 23:35:52 | 9%|▉         | 22/250 [01:12<12:16,  3.23s/it]
2025-10-12 23:35:58 | 10%|▉         | 24/250 [01:19<12:02,  3.20s/it]
2025-10-12 23:36:09 | 11%|█         | 27/250 [01:29<12:48,  3.45s/it]
2025-10-12 23:36:15 | 12%|█▏        | 29/250 [01:36<12:03,  3.27s/it]
2025-10-12 23:36:18 | {'loss': 1.5919, 'grad_norm': 2.1342108249664307, 'learning_rate': 2.9000000000000003e-07, 'epoch': 0.12}
2025-10-12 23:36:18 | 12%|█▏        | 30/250 [01:39<11:48,  3.22s/it]
2025-10-12 23:36:24 | 13%|█▎        | 32/250 [01:45<11:12,  3.08s/it]
2025-10-12 23:36:30 | 14%|█▎        | 34/250 [01:50<10:46,  2.99s/it]
2025-10-12 23:36:40 | 15%|█▍        | 37/250 [02:00<11:31,  3.25s/it]
2025-10-12 23:36:46 | 16%|█▌        | 39/250 [02:06<10:53,  3.10s/it]
2025-10-12 23:36:49 | {'loss': 1.6301, 'grad_norm': 2.168320655822754, 'learning_rate': 3.9e-07, 'epoch': 0.16}
2025-10-12 23:36:49 | 16%|█▌        | 40/250 [02:09<10:34,  3.02s/it]
2025-10-12 23:36:55 | 17%|█▋        | 42/250 [02:15<10:15,  2.96s/it]
2025-10-12 23:37:00 | 18%|█▊        | 44/250 [02:21<10:01,  2.92s/it]
2025-10-12 23:37:09 | 19%|█▉        | 47/250 [02:29<09:52,  2.92s/it]
2025-10-12 23:37:16 | 20%|█▉        | 49/250 [02:37<10:48,  3.23s/it]
2025-10-12 23:37:20 | {'loss': 1.624, 'grad_norm': 2.1325876712799072, 'learning_rate': 4.900000000000001e-07, 'epoch': 0.2}
2025-10-12 23:37:20 | 20%|██        | 50/250 [02:40<11:04,  3.32s/it]
2025-10-12 23:37:26 | 21%|██        | 52/250 [02:47<10:56,  3.32s/it]
2025-10-12 23:37:33 | 22%|██▏       | 54/250 [02:53<10:29,  3.21s/it]
2025-10-12 23:37:42 | 23%|██▎       | 57/250 [03:03<10:26,  3.25s/it]
2025-10-12 23:37:50 | 24%|██▎       | 59/250 [03:10<11:19,  3.56s/it]
2025-10-12 23:37:53 | {'loss': 1.5523, 'grad_norm': 1.8329565525054932, 'learning_rate': 5.900000000000001e-07, 'epoch': 0.24}
2025-10-12 23:37:53 | 24%|██▍       | 60/250 [03:13<10:45,  3.40s/it]
2025-10-12 23:37:59 | 25%|██▍       | 62/250 [03:19<10:01,  3.20s/it]
2025-10-12 23:38:05 | 26%|██▌       | 64/250 [03:26<09:38,  3.11s/it]
2025-10-12 23:38:14 | 27%|██▋       | 67/250 [03:34<09:10,  3.01s/it]
2025-10-12 23:38:22 | 28%|██▊       | 69/250 [03:42<10:03,  3.33s/it]
2025-10-12 23:38:25 | {'loss': 1.6085, 'grad_norm': 2.066457509994507, 'learning_rate': 6.900000000000001e-07, 'epoch': 0.28}
2025-10-12 23:38:25 | 28%|██▊       | 70/250 [03:45<10:01,  3.34s/it]
2025-10-12 23:38:31 | 29%|██▉       | 72/250 [03:51<09:25,  3.18s/it]
2025-10-12 23:38:37 | 30%|██▉       | 74/250 [03:57<08:53,  3.03s/it]
2025-10-12 23:38:46 | 31%|███       | 77/250 [04:06<08:37,  2.99s/it]
2025-10-12 23:38:53 | 32%|███▏      | 79/250 [04:13<09:29,  3.33s/it]
2025-10-12 23:38:56 | {'loss': 1.5791, 'grad_norm': 2.310434341430664, 'learning_rate': 7.900000000000001e-07, 'epoch': 0.32}
2025-10-12 23:38:56 | 32%|███▏      | 80/250 [04:17<09:30,  3.36s/it]
2025-10-12 23:39:03 | 33%|███▎      | 82/250 [04:23<09:12,  3.29s/it]
2025-10-12 23:39:08 | 34%|███▎      | 84/250 [04:29<08:24,  3.04s/it]
2025-10-12 23:39:17 | 35%|███▍      | 87/250 [04:37<07:50,  2.89s/it]
2025-10-12 23:39:23 | 36%|███▌      | 89/250 [04:43<07:53,  2.94s/it]
2025-10-12 23:39:27 | {'loss': 1.5767, 'grad_norm': 1.8840872049331665, 'learning_rate': 8.900000000000001e-07, 'epoch': 0.36}
2025-10-12 23:39:27 | 36%|███▌      | 90/250 [04:47<08:49,  3.31s/it]
