2025-10-12 23:13:04 | >> 표준 출력 및 오류를 로그 파일로 리디렉션 시작
2025-10-12 23:13:06 | 📊 FULL 모드 실행 중...
2025-10-12 23:13:06 | ============================================================
2025-10-12 23:13:06 | = FULL PIPELINE 실행 시작
2025-10-12 23:13:06 | =대상 모델: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-12 23:13:06 | =앙상블 앙상블 전략: stacking
2025-10-12 23:13:06 | = TTA 사용: True
2025-10-12 23:13:06 | ============================================================
2025-10-12 23:13:06 | [1/6] 데이터 로딩...
2025-10-12 23:13:06 | ✅ 학습 데이터: 12457개
2025-10-12 23:13:06 | ✅ 검증 데이터: 499개
2025-10-12 23:13:06 | ⚙️ max_train_samples 적용: 학습 데이터 6000개로 제한
2025-10-12 23:13:06 | [2/6] 다중 모델 학습 (6 모델)...
2025-10-12 23:13:06 | ==================================================
2025-10-12 23:13:06 | 모델 1/6: kobart
2025-10-12 23:13:06 | ==================================================
2025-10-12 23:13:06 | 모델 타입: encoder_decoder
2025-10-12 23:13:06 | ============================================================
2025-10-12 23:13:06 | 모델 및 토크나이저 로딩 시작
2025-10-12 23:13:06 | ============================================================
2025-10-12 23:13:06 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-12 23:13:07 | 모델 로딩: digit82/kobart-summarization
2025-10-12 23:13:07 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 23:13:08 | → 디바이스: cuda
2025-10-12 23:13:08 | → 전체 파라미터: 123,859,968
2025-10-12 23:13:08 | → 학습 가능 파라미터: 123,859,968
2025-10-12 23:13:08 | ============================================================
2025-10-12 23:13:08 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-12 23:13:08 | ============================================================
2025-10-12 23:13:08 | ============================================================
2025-10-12 23:13:08 | 모델 학습 시작
2025-10-12 23:13:08 | ============================================================
2025-10-12 23:13:08 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 23:13:08 | 학습 진행 중...
2025-10-12 23:13:08 | 0%|          | 0/750 [00:00<?, ?it/s]
2025-10-12 23:13:09 | 1%|          | 6/750 [00:00<01:06, 11.19it/s]
2025-10-12 23:13:10 | 2%|▏         | 14/750 [00:01<00:40, 17.96it/s]
2025-10-12 23:13:10 | 3%|▎         | 20/750 [00:01<00:36, 20.10it/s]
2025-10-12 23:13:10 | 4%|▍         | 29/750 [00:01<00:32, 22.01it/s]
2025-10-12 23:13:10 | 5%|▍         | 35/750 [00:02<00:32, 22.09it/s]
2025-10-12 23:13:11 | 6%|▌         | 44/750 [00:02<00:30, 23.41it/s]
2025-10-12 23:13:11 | 7%|▋         | 50/750 [00:02<00:29, 23.80it/s]
2025-10-12 23:13:11 | 8%|▊         | 59/750 [00:03<00:30, 22.87it/s]
2025-10-12 23:13:12 | 9%|▊         | 65/750 [00:03<00:30, 22.55it/s]
2025-10-12 23:13:12 | 10%|▉         | 74/750 [00:03<00:30, 22.46it/s]
2025-10-12 23:13:12 | 11%|█         | 80/750 [00:03<00:30, 22.02it/s]
2025-10-12 23:13:13 | 12%|█▏        | 89/750 [00:04<00:31, 21.28it/s]
2025-10-12 23:13:13 | 13%|█▎        | 95/750 [00:04<00:29, 21.88it/s]
2025-10-12 23:13:13 | {'loss': 2.7155, 'grad_norm': 9.164268493652344, 'learning_rate': 9.9e-07, 'epoch': 0.13}
2025-10-12 23:13:13 | 13%|█▎        | 100/750 [00:04<00:28, 22.53it/s]
2025-10-12 23:13:13 | 14%|█▍        | 104/750 [00:05<00:27, 23.24it/s]
2025-10-12 23:13:14 | 15%|█▍        | 110/750 [00:05<00:27, 23.50it/s]
2025-10-12 23:13:14 | 16%|█▌        | 119/750 [00:05<00:27, 23.25it/s]
2025-10-12 23:13:14 | 17%|█▋        | 125/750 [00:05<00:28, 22.28it/s]
2025-10-12 23:13:15 | 18%|█▊        | 134/750 [00:06<00:26, 23.41it/s]
2025-10-12 23:13:15 | 19%|█▊        | 140/750 [00:06<00:26, 23.40it/s]
2025-10-12 23:13:15 | 20%|█▉        | 149/750 [00:07<00:26, 22.91it/s]
2025-10-12 23:13:16 | 21%|██        | 155/750 [00:07<00:26, 22.61it/s]
2025-10-12 23:13:16 | 22%|██▏       | 164/750 [00:07<00:27, 21.46it/s]
2025-10-12 23:13:17 | 23%|██▎       | 170/750 [00:09<01:09,  8.31it/s]
2025-10-12 23:13:18 | 24%|██▍       | 179/750 [00:09<00:41, 13.69it/s]
2025-10-12 23:13:18 | 25%|██▍       | 185/750 [00:09<00:33, 16.97it/s]
2025-10-12 23:13:19 | 26%|██▌       | 194/750 [00:10<00:27, 19.94it/s]
2025-10-12 23:13:19 | 27%|██▋       | 200/750 [00:10<00:25, 21.53it/s]
2025-10-12 23:13:19 | {'loss': 2.0765, 'grad_norm': 6.093132495880127, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.27}
2025-10-12 23:13:19 | 27%|██▋       | 200/750 [00:10<00:25, 21.53it/s]
2025-10-12 23:13:19 | 28%|██▊       | 209/750 [00:10<00:24, 22.23it/s]
2025-10-12 23:13:20 | 29%|██▊       | 215/750 [00:11<00:24, 22.20it/s]
2025-10-12 23:13:20 | 30%|██▉       | 224/750 [00:11<00:23, 22.71it/s]
2025-10-12 23:13:20 | 31%|███       | 230/750 [00:11<00:23, 22.01it/s]
2025-10-12 23:13:21 | 32%|███▏      | 239/750 [00:12<00:23, 21.65it/s]
2025-10-12 23:13:21 | 33%|███▎      | 245/750 [00:12<00:23, 21.85it/s]
2025-10-12 23:13:21 | 34%|███▍      | 254/750 [00:12<00:22, 22.00it/s]
2025-10-12 23:13:22 | 35%|███▍      | 260/750 [00:13<00:22, 21.59it/s]
2025-10-12 23:13:22 | 36%|███▌      | 269/750 [00:13<00:20, 23.92it/s]
2025-10-12 23:13:22 | 37%|███▋      | 275/750 [00:13<00:19, 24.83it/s]
2025-10-12 23:13:22 | 38%|███▊      | 284/750 [00:14<00:18, 25.21it/s]
2025-10-12 23:13:23 | 39%|███▊      | 290/750 [00:14<00:18, 25.43it/s]
2025-10-12 23:13:23 | 40%|███▉      | 299/750 [00:14<00:17, 25.89it/s]
2025-10-12 23:13:23 | {'loss': 1.8262, 'grad_norm': 6.358558177947998, 'learning_rate': 2.99e-06, 'epoch': 0.4}
2025-10-12 23:13:23 | 40%|████      | 300/750 [00:14<00:17, 25.89it/s]
2025-10-12 23:13:23 | 41%|████      | 305/750 [00:14<00:17, 25.77it/s]
2025-10-12 23:13:24 | 42%|████▏     | 314/750 [00:15<00:17, 25.04it/s]
2025-10-12 23:13:24 | 43%|████▎     | 320/750 [00:15<00:17, 24.50it/s]
2025-10-12 23:13:24 | 44%|████▍     | 329/750 [00:15<00:16, 24.85it/s]
2025-10-12 23:13:25 | 45%|████▍     | 335/750 [00:16<00:16, 25.40it/s]
2025-10-12 23:13:25 | 46%|████▌     | 344/750 [00:16<00:16, 25.01it/s]
2025-10-12 23:13:25 | 47%|████▋     | 350/750 [00:16<00:15, 25.32it/s]
2025-10-12 23:13:25 | 48%|████▊     | 359/750 [00:17<00:15, 25.57it/s]
2025-10-12 23:13:26 | 49%|████▊     | 365/750 [00:17<00:14, 25.71it/s]
2025-10-12 23:13:26 | 50%|████▉     | 374/750 [00:17<00:14, 25.22it/s]
2025-10-12 23:13:26 | 51%|█████     | 380/750 [00:17<00:14, 25.12it/s]
2025-10-12 23:13:27 | 52%|█████▏    | 389/750 [00:18<00:14, 25.25it/s]
2025-10-12 23:13:27 | 53%|█████▎    | 395/750 [00:18<00:13, 25.75it/s]
2025-10-12 23:13:27 | {'loss': 1.7446, 'grad_norm': 6.9460859298706055, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.53}
2025-10-12 23:13:27 | 53%|█████▎    | 400/750 [00:18<00:13, 25.33it/s]
2025-10-12 23:13:27 | 54%|█████▍    | 404/750 [00:18<00:13, 25.57it/s]
2025-10-12 23:13:27 | 55%|█████▍    | 410/750 [00:19<00:13, 25.83it/s]
2025-10-12 23:13:28 | 56%|█████▌    | 419/750 [00:19<00:12, 25.60it/s]
2025-10-12 23:13:28 | 57%|█████▋    | 425/750 [00:19<00:12, 25.58it/s]
2025-10-12 23:13:28 | 58%|█████▊    | 434/750 [00:19<00:12, 25.55it/s]
2025-10-12 23:13:29 | 59%|█████▊    | 440/750 [00:20<00:12, 25.81it/s]
2025-10-12 23:13:29 | 60%|█████▉    | 449/750 [00:20<00:11, 26.21it/s]
2025-10-12 23:13:29 | 61%|██████    | 455/750 [00:20<00:11, 25.78it/s]
2025-10-12 23:13:30 | 62%|██████▏   | 464/750 [00:21<00:11, 25.13it/s]
2025-10-12 23:13:30 | 63%|██████▎   | 470/750 [00:21<00:11, 25.04it/s]
2025-10-12 23:13:30 | 64%|██████▍   | 479/750 [00:21<00:10, 25.37it/s]
2025-10-12 23:13:30 | 65%|██████▍   | 485/750 [00:21<00:10, 25.57it/s]
2025-10-12 23:13:31 | 66%|██████▌   | 494/750 [00:22<00:10, 25.19it/s]
2025-10-12 23:13:31 | 67%|██████▋   | 500/750 [00:22<00:09, 25.59it/s]
2025-10-12 23:13:31 | {'loss': 1.7093, 'grad_norm': 6.4172844886779785, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.67}
2025-10-12 23:13:31 | 67%|██████▋   | 500/750 [00:22<00:09, 25.59it/s]
2025-10-12 23:13:31 | 68%|██████▊   | 509/750 [00:22<00:09, 25.87it/s]
2025-10-12 23:13:32 | 69%|██████▊   | 515/750 [00:23<00:09, 26.01it/s]
2025-10-12 23:13:32 | 70%|██████▉   | 524/750 [00:23<00:08, 25.61it/s]
2025-10-12 23:13:32 | 71%|███████   | 530/750 [00:23<00:08, 25.30it/s]
2025-10-12 23:13:33 | 72%|███████▏  | 539/750 [00:24<00:08, 25.05it/s]
2025-10-12 23:13:33 | 73%|███████▎  | 545/750 [00:24<00:08, 25.44it/s]
2025-10-12 23:13:33 | 74%|███████▍  | 554/750 [00:24<00:07, 25.55it/s]
2025-10-12 23:13:33 | 75%|███████▍  | 560/750 [00:24<00:07, 25.59it/s]
2025-10-12 23:13:34 | 76%|███████▌  | 569/750 [00:25<00:07, 24.98it/s]
2025-10-12 23:13:34 | 77%|███████▋  | 575/750 [00:25<00:06, 25.12it/s]
2025-10-12 23:13:34 | 78%|███████▊  | 584/750 [00:25<00:06, 25.44it/s]
2025-10-12 23:13:35 | 79%|███████▊  | 590/750 [00:26<00:06, 25.58it/s]
2025-10-12 23:13:35 | 80%|███████▉  | 599/750 [00:26<00:05, 25.84it/s]
2025-10-12 23:13:35 | {'loss': 1.6426, 'grad_norm': 5.977294445037842, 'learning_rate': 3.0200000000000003e-06, 'epoch': 0.8}
2025-10-12 23:13:35 | 80%|████████  | 600/750 [00:26<00:05, 25.84it/s]
2025-10-12 23:13:35 | 81%|████████  | 605/750 [00:26<00:05, 24.68it/s]
2025-10-12 23:13:35 | 82%|████████▏ | 614/750 [00:27<00:05, 25.49it/s]
2025-10-12 23:13:36 | 83%|████████▎ | 620/750 [00:27<00:05, 24.41it/s]
2025-10-12 23:13:36 | 84%|████████▍ | 629/750 [00:27<00:05, 24.02it/s]
2025-10-12 23:13:36 | 85%|████████▍ | 635/750 [00:27<00:04, 23.96it/s]
2025-10-12 23:13:37 | 86%|████████▌ | 644/750 [00:28<00:04, 25.18it/s]
2025-10-12 23:13:37 | 87%|████████▋ | 650/750 [00:28<00:03, 25.38it/s]
2025-10-12 23:13:37 | 88%|████████▊ | 659/750 [00:28<00:03, 25.62it/s]
2025-10-12 23:13:38 | 89%|████████▊ | 665/750 [00:29<00:03, 25.78it/s]
2025-10-12 23:13:38 | 90%|████████▉ | 674/750 [00:29<00:02, 25.96it/s]
2025-10-12 23:13:38 | 91%|█████████ | 680/750 [00:29<00:02, 25.95it/s]
2025-10-12 23:13:38 | 92%|█████████▏| 689/750 [00:30<00:02, 25.52it/s]
2025-10-12 23:13:39 | 93%|█████████▎| 695/750 [00:30<00:02, 25.99it/s]
2025-10-12 23:13:39 | {'loss': 1.5897, 'grad_norm': 6.199431896209717, 'learning_rate': 1.02e-06, 'epoch': 0.93}
2025-10-12 23:13:39 | 93%|█████████▎| 700/750 [00:30<00:01, 25.97it/s]
2025-10-12 23:13:39 | 94%|█████████▍| 704/750 [00:30<00:01, 25.63it/s]
2025-10-12 23:13:39 | 95%|█████████▍| 710/750 [00:30<00:01, 25.41it/s]
2025-10-12 23:13:40 | 96%|█████████▌| 719/750 [00:31<00:01, 25.08it/s]
2025-10-12 23:13:40 | 97%|█████████▋| 725/750 [00:31<00:00, 25.23it/s]
2025-10-12 23:13:40 | 98%|█████████▊| 734/750 [00:31<00:00, 25.27it/s]
2025-10-12 23:13:40 | 99%|█████████▊| 740/750 [00:32<00:00, 25.35it/s]
2025-10-12 23:13:41 | 100%|█████████▉| 749/750 [00:32<00:00, 25.65it/s]
2025-10-12 23:13:42 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 23:13:42 | [A
2025-10-12 23:13:42 | 3%|▎         | 2/63 [00:00<00:21,  2.90it/s]
2025-10-12 23:13:42 | [A
2025-10-12 23:13:43 | 5%|▍         | 3/63 [00:01<00:31,  1.92it/s]
2025-10-12 23:13:43 | [A
2025-10-12 23:13:44 | 6%|▋         | 4/63 [00:02<00:36,  1.63it/s]
2025-10-12 23:13:44 | [A
2025-10-12 23:13:45 | 8%|▊         | 5/63 [00:02<00:36,  1.61it/s]
2025-10-12 23:13:45 | [A
2025-10-12 23:13:45 | 10%|▉         | 6/63 [00:03<00:37,  1.54it/s]
2025-10-12 23:13:45 | [A
2025-10-12 23:13:46 | 11%|█         | 7/63 [00:04<00:39,  1.41it/s]
2025-10-12 23:13:46 | [A
2025-10-12 23:13:47 | 13%|█▎        | 8/63 [00:05<00:41,  1.33it/s]
2025-10-12 23:13:47 | [A
2025-10-12 23:13:48 | 14%|█▍        | 9/63 [00:06<00:41,  1.30it/s]
2025-10-12 23:13:48 | [A
2025-10-12 23:13:49 | 16%|█▌        | 10/63 [00:06<00:40,  1.31it/s]
2025-10-12 23:13:49 | [A
2025-10-12 23:13:49 | 17%|█▋        | 11/63 [00:07<00:40,  1.29it/s]
2025-10-12 23:13:49 | [A
2025-10-12 23:13:51 | 19%|█▉        | 12/63 [00:09<00:55,  1.09s/it]
2025-10-12 23:13:51 | [A
2025-10-12 23:13:52 | 21%|██        | 13/63 [00:10<00:48,  1.02it/s]
2025-10-12 23:13:52 | [A
2025-10-12 23:13:53 | 22%|██▏       | 14/63 [00:10<00:42,  1.14it/s]
2025-10-12 23:13:53 | [A
2025-10-12 23:13:53 | 24%|██▍       | 15/63 [00:11<00:39,  1.20it/s]
2025-10-12 23:13:53 | [A
2025-10-12 23:13:54 | 25%|██▌       | 16/63 [00:12<00:36,  1.28it/s]
2025-10-12 23:13:54 | [A
2025-10-12 23:13:55 | 27%|██▋       | 17/63 [00:12<00:34,  1.32it/s]
2025-10-12 23:13:55 | [A
2025-10-12 23:13:55 | 29%|██▊       | 18/63 [00:13<00:34,  1.32it/s]
2025-10-12 23:13:55 | [A
2025-10-12 23:13:56 | 30%|███       | 19/63 [00:14<00:33,  1.33it/s]
2025-10-12 23:13:56 | [A
2025-10-12 23:13:57 | 32%|███▏      | 20/63 [00:15<00:33,  1.30it/s]
2025-10-12 23:13:57 | [A
2025-10-12 23:13:58 | 33%|███▎      | 21/63 [00:16<00:33,  1.24it/s]
2025-10-12 23:13:58 | [A
2025-10-12 23:13:59 | 35%|███▍      | 22/63 [00:16<00:32,  1.25it/s]
2025-10-12 23:13:59 | [A
2025-10-12 23:13:59 | 37%|███▋      | 23/63 [00:17<00:32,  1.22it/s]
2025-10-12 23:13:59 | [A
2025-10-12 23:14:00 | 38%|███▊      | 24/63 [00:18<00:30,  1.29it/s]
2025-10-12 23:14:00 | [A
2025-10-12 23:14:01 | 100%|██████████| 750/750 [00:52<00:00, 25.65it/s]
2025-10-12 23:14:01 | 40%|███▉      | 25/63 [00:19<00:28,  1.32it/s]
2025-10-12 23:14:01 | [A
2025-10-12 23:14:02 | 41%|████▏     | 26/63 [00:20<00:29,  1.25it/s]
2025-10-12 23:14:02 | [A
2025-10-12 23:14:03 | 43%|████▎     | 27/63 [00:20<00:28,  1.25it/s]
2025-10-12 23:14:03 | [A
2025-10-12 23:14:03 | 44%|████▍     | 28/63 [00:21<00:27,  1.26it/s]
2025-10-12 23:14:03 | [A
2025-10-12 23:14:04 | 46%|████▌     | 29/63 [00:22<00:27,  1.25it/s]
2025-10-12 23:14:04 | [A
2025-10-12 23:14:05 | 48%|████▊     | 30/63 [00:23<00:26,  1.23it/s]
2025-10-12 23:14:05 | [A
2025-10-12 23:14:06 | 49%|████▉     | 31/63 [00:24<00:25,  1.25it/s]
2025-10-12 23:14:06 | [A
2025-10-12 23:14:07 | 51%|█████     | 32/63 [00:24<00:24,  1.26it/s]
2025-10-12 23:14:07 | [A
2025-10-12 23:14:07 | 52%|█████▏    | 33/63 [00:25<00:24,  1.21it/s]
2025-10-12 23:14:07 | [A
2025-10-12 23:14:08 | 54%|█████▍    | 34/63 [00:26<00:23,  1.26it/s]
2025-10-12 23:14:08 | [A
2025-10-12 23:14:09 | 56%|█████▌    | 35/63 [00:27<00:21,  1.31it/s]
2025-10-12 23:14:09 | [A
2025-10-12 23:14:10 | 57%|█████▋    | 36/63 [00:27<00:21,  1.28it/s]
2025-10-12 23:14:10 | [A
2025-10-12 23:14:10 | 59%|█████▊    | 37/63 [00:28<00:19,  1.30it/s]
2025-10-12 23:14:10 | [A
2025-10-12 23:14:11 | 60%|██████    | 38/63 [00:29<00:19,  1.30it/s]
2025-10-12 23:14:11 | [A
2025-10-12 23:14:12 | 62%|██████▏   | 39/63 [00:30<00:18,  1.30it/s]
2025-10-12 23:14:12 | [A
2025-10-12 23:14:13 | 63%|██████▎   | 40/63 [00:30<00:17,  1.33it/s]
2025-10-12 23:14:13 | [A
2025-10-12 23:14:13 | 65%|██████▌   | 41/63 [00:31<00:16,  1.33it/s]
2025-10-12 23:14:13 | [A
2025-10-12 23:14:14 | 67%|██████▋   | 42/63 [00:32<00:15,  1.34it/s]
2025-10-12 23:14:14 | [A
2025-10-12 23:14:15 | 68%|██████▊   | 43/63 [00:33<00:14,  1.35it/s]
2025-10-12 23:14:15 | [A
2025-10-12 23:14:16 | 70%|██████▉   | 44/63 [00:33<00:14,  1.33it/s]
2025-10-12 23:14:16 | [A
2025-10-12 23:14:17 | 71%|███████▏  | 45/63 [00:34<00:14,  1.27it/s]
2025-10-12 23:14:17 | [A
2025-10-12 23:14:17 | 73%|███████▎  | 46/63 [00:35<00:13,  1.27it/s]
2025-10-12 23:14:17 | [A
2025-10-12 23:14:18 | 75%|███████▍  | 47/63 [00:36<00:12,  1.31it/s]
2025-10-12 23:14:18 | [A
2025-10-12 23:14:19 | 76%|███████▌  | 48/63 [00:37<00:11,  1.31it/s]
2025-10-12 23:14:19 | [A
2025-10-12 23:14:20 | 78%|███████▊  | 49/63 [00:37<00:11,  1.26it/s]
2025-10-12 23:14:20 | [A
2025-10-12 23:14:20 | 79%|███████▉  | 50/63 [00:38<00:10,  1.27it/s]
2025-10-12 23:14:20 | [A
2025-10-12 23:14:21 | 81%|████████  | 51/63 [00:39<00:09,  1.27it/s]
2025-10-12 23:14:21 | [A
2025-10-12 23:14:22 | 83%|████████▎ | 52/63 [00:40<00:08,  1.23it/s]
2025-10-12 23:14:22 | [A
2025-10-12 23:14:24 | 84%|████████▍ | 53/63 [00:42<00:11,  1.15s/it]
2025-10-12 23:14:24 | [A
2025-10-12 23:14:25 | 86%|████████▌ | 54/63 [00:43<00:09,  1.04s/it]
2025-10-12 23:14:25 | [A
2025-10-12 23:14:26 | 87%|████████▋ | 55/63 [00:43<00:07,  1.02it/s]
2025-10-12 23:14:26 | [A
2025-10-12 23:14:26 | 89%|████████▉ | 56/63 [00:44<00:06,  1.12it/s]
2025-10-12 23:14:26 | [A
2025-10-12 23:14:27 | 90%|█████████ | 57/63 [00:45<00:05,  1.19it/s]
2025-10-12 23:14:27 | [A
2025-10-12 23:14:28 | 92%|█████████▏| 58/63 [00:46<00:04,  1.20it/s]
2025-10-12 23:14:28 | [A
2025-10-12 23:14:29 | 94%|█████████▎| 59/63 [00:46<00:03,  1.22it/s]
2025-10-12 23:14:29 | [A
2025-10-12 23:14:29 | 95%|█████████▌| 60/63 [00:47<00:02,  1.25it/s]
2025-10-12 23:14:29 | [A
2025-10-12 23:14:30 | 97%|█████████▋| 61/63 [00:48<00:01,  1.24it/s]
2025-10-12 23:14:30 | [A
2025-10-12 23:14:31 | 98%|█████████▊| 62/63 [00:49<00:00,  1.24it/s]
2025-10-12 23:14:31 | [A
2025-10-12 23:14:32 | 100%|██████████| 63/63 [00:50<00:00,  1.27it/s]
2025-10-12 23:14:32 | [A
2025-10-12 23:14:32 | [A
2025-10-12 23:14:32 | {'eval_loss': 1.5233756303787231, 'eval_rouge1': 0.4136381573078092, 'eval_rouge2': 0.26269165474014805, 'eval_rougeL': 0.4049570068806617, 'eval_rouge_sum': 1.081286818928619, 'eval_runtime': 50.9432, 'eval_samples_per_second': 9.795, 'eval_steps_per_second': 1.237, 'epoch': 1.0}
2025-10-12 23:14:32 | 100%|██████████| 750/750 [01:23<00:00, 25.65it/s]
2025-10-12 23:14:32 | [A
2025-10-12 23:14:32 | [A
2025-10-12 23:14:33 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-12 23:14:33 | {'train_runtime': 84.6754, 'train_samples_per_second': 70.859, 'train_steps_per_second': 8.857, 'train_loss': 1.8797120259602864, 'epoch': 1.0}
2025-10-12 23:14:33 | 100%|██████████| 750/750 [01:24<00:00, 25.65it/s]
2025-10-12 23:14:33 | 최종 모델 저장 중...
2025-10-12 23:14:34 | → 모델 저장 위치: experiments/20251012/20251012_231304_test_full_pipeline_optimized_final/model_0_kobart/default/final_model
2025-10-12 23:14:34 | 최종 평가 중...
2025-10-12 23:14:35 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 23:14:35 | 3%|▎         | 2/63 [00:00<00:25,  2.41it/s]
2025-10-12 23:14:36 | 5%|▍         | 3/63 [00:01<00:34,  1.74it/s]
2025-10-12 23:14:37 | 6%|▋         | 4/63 [00:02<00:38,  1.51it/s]
2025-10-12 23:14:38 | 8%|▊         | 5/63 [00:03<00:40,  1.42it/s]
2025-10-12 23:14:39 | 10%|▉         | 6/63 [00:03<00:41,  1.38it/s]
2025-10-12 23:14:39 | 11%|█         | 7/63 [00:04<00:39,  1.41it/s]
2025-10-12 23:14:40 | 13%|█▎        | 8/63 [00:05<00:39,  1.41it/s]
2025-10-12 23:14:41 | 14%|█▍        | 9/63 [00:06<00:36,  1.46it/s]
2025-10-12 23:14:41 | 16%|█▌        | 10/63 [00:06<00:38,  1.36it/s]
2025-10-12 23:14:42 | 17%|█▋        | 11/63 [00:07<00:37,  1.37it/s]
2025-10-12 23:14:43 | 19%|█▉        | 12/63 [00:08<00:38,  1.33it/s]
2025-10-12 23:14:44 | 21%|██        | 13/63 [00:09<00:37,  1.34it/s]
2025-10-12 23:14:45 | 22%|██▏       | 14/63 [00:10<00:39,  1.25it/s]
2025-10-12 23:14:45 | 24%|██▍       | 15/63 [00:10<00:39,  1.22it/s]
2025-10-12 23:14:46 | 25%|██▌       | 16/63 [00:11<00:37,  1.25it/s]
2025-10-12 23:14:47 | 27%|██▋       | 17/63 [00:12<00:34,  1.32it/s]
2025-10-12 23:14:48 | 29%|██▊       | 18/63 [00:13<00:35,  1.28it/s]
2025-10-12 23:14:48 | 30%|███       | 19/63 [00:13<00:33,  1.33it/s]
2025-10-12 23:14:49 | 32%|███▏      | 20/63 [00:14<00:31,  1.34it/s]
2025-10-12 23:14:50 | 33%|███▎      | 21/63 [00:15<00:30,  1.36it/s]
2025-10-12 23:14:51 | 35%|███▍      | 22/63 [00:15<00:29,  1.40it/s]
2025-10-12 23:14:51 | 37%|███▋      | 23/63 [00:16<00:28,  1.39it/s]
2025-10-12 23:14:52 | 38%|███▊      | 24/63 [00:17<00:29,  1.34it/s]
2025-10-12 23:14:53 | 40%|███▉      | 25/63 [00:18<00:28,  1.34it/s]
2025-10-12 23:14:54 | 41%|████▏     | 26/63 [00:18<00:27,  1.34it/s]
2025-10-12 23:14:54 | 43%|████▎     | 27/63 [00:19<00:27,  1.29it/s]
2025-10-12 23:14:55 | 44%|████▍     | 28/63 [00:20<00:26,  1.31it/s]
2025-10-12 23:14:56 | 46%|████▌     | 29/63 [00:21<00:25,  1.34it/s]
2025-10-12 23:14:58 | 48%|████▊     | 30/63 [00:23<00:35,  1.09s/it]
2025-10-12 23:14:59 | 49%|████▉     | 31/63 [00:23<00:32,  1.02s/it]
2025-10-12 23:14:59 | 51%|█████     | 32/63 [00:24<00:28,  1.07it/s]
2025-10-12 23:15:00 | 52%|█████▏    | 33/63 [00:25<00:26,  1.15it/s]
2025-10-12 23:15:01 | 54%|█████▍    | 34/63 [00:26<00:25,  1.12it/s]
2025-10-12 23:15:02 | 56%|█████▌    | 35/63 [00:27<00:24,  1.14it/s]
2025-10-12 23:15:03 | 57%|█████▋    | 36/63 [00:27<00:22,  1.19it/s]
2025-10-12 23:15:03 | 59%|█████▊    | 37/63 [00:28<00:21,  1.20it/s]
2025-10-12 23:15:04 | 60%|██████    | 38/63 [00:29<00:19,  1.27it/s]
2025-10-12 23:15:05 | 62%|██████▏   | 39/63 [00:30<00:18,  1.32it/s]
2025-10-12 23:15:05 | 63%|██████▎   | 40/63 [00:30<00:16,  1.37it/s]
2025-10-12 23:15:06 | 65%|██████▌   | 41/63 [00:31<00:15,  1.39it/s]
2025-10-12 23:15:07 | 67%|██████▋   | 42/63 [00:32<00:15,  1.31it/s]
2025-10-12 23:15:08 | 68%|██████▊   | 43/63 [00:33<00:15,  1.29it/s]
2025-10-12 23:15:09 | 70%|██████▉   | 44/63 [00:34<00:14,  1.27it/s]
2025-10-12 23:15:09 | 71%|███████▏  | 45/63 [00:34<00:14,  1.28it/s]
2025-10-12 23:15:10 | 73%|███████▎  | 46/63 [00:35<00:13,  1.22it/s]
2025-10-12 23:15:11 | 75%|███████▍  | 47/63 [00:36<00:13,  1.21it/s]
2025-10-12 23:15:12 | 76%|███████▌  | 48/63 [00:37<00:12,  1.23it/s]
2025-10-12 23:15:13 | 78%|███████▊  | 49/63 [00:38<00:11,  1.21it/s]
2025-10-12 23:15:13 | 79%|███████▉  | 50/63 [00:38<00:10,  1.27it/s]
2025-10-12 23:15:14 | 81%|████████  | 51/63 [00:39<00:09,  1.32it/s]
2025-10-12 23:15:15 | 83%|████████▎ | 52/63 [00:40<00:08,  1.27it/s]
2025-10-12 23:15:16 | 84%|████████▍ | 53/63 [00:41<00:08,  1.24it/s]
2025-10-12 23:15:17 | 86%|████████▌ | 54/63 [00:42<00:07,  1.23it/s]
2025-10-12 23:15:17 | 87%|████████▋ | 55/63 [00:42<00:06,  1.26it/s]
2025-10-12 23:15:18 | 89%|████████▉ | 56/63 [00:43<00:05,  1.27it/s]
2025-10-12 23:15:19 | 90%|█████████ | 57/63 [00:44<00:04,  1.27it/s]
2025-10-12 23:15:20 | 92%|█████████▏| 58/63 [00:45<00:03,  1.27it/s]
2025-10-12 23:15:20 | 94%|█████████▎| 59/63 [00:45<00:03,  1.30it/s]
2025-10-12 23:15:21 | 95%|█████████▌| 60/63 [00:46<00:02,  1.31it/s]
2025-10-12 23:15:22 | 97%|█████████▋| 61/63 [00:47<00:01,  1.28it/s]
2025-10-12 23:15:23 | 98%|█████████▊| 62/63 [00:48<00:00,  1.30it/s]
2025-10-12 23:15:24 | 100%|██████████| 63/63 [00:49<00:00,  1.29it/s]
2025-10-12 23:15:24 | 최종 평가 결과:
2025-10-12 23:15:24 | eval_rouge1: 0.4136
2025-10-12 23:15:24 | eval_rouge2: 0.2627
2025-10-12 23:15:24 | eval_rougeL: 0.4050
2025-10-12 23:15:24 | eval_rouge_sum: 1.0813
2025-10-12 23:15:24 | ============================================================
2025-10-12 23:15:24 | ✅ 학습 완료!
2025-10-12 23:15:24 | ============================================================
2025-10-12 23:15:24 | ✅ kobart 학습 완료
2025-10-12 23:15:24 | ==================================================
2025-10-12 23:15:24 | 모델 2/6: llama-3.2-korean-3b
2025-10-12 23:15:24 | ==================================================
2025-10-12 23:15:24 | 모델 타입: causal_lm
2025-10-12 23:15:24 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-12 23:15:24 | 모델 로딩 중...
2025-10-12 23:15:24 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-12 23:15:24 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-12 23:15:25 | Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.07it/s]
2025-10-12 23:15:25 | Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.87it/s]
2025-10-12 23:15:26 | 토크나이저 로딩 중...
2025-10-12 23:15:26 | 패딩 토큰 설정: <|eot_id|>
2025-10-12 23:15:26 | LoRA 설정 적용 중...
2025-10-12 23:15:26 | 🔍 자동 탐지된 target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']
2025-10-12 23:15:26 | ✅ LoRA 적용 완료
2025-10-12 23:15:26 | 학습 가능 파라미터: 24,313,856 (0.75%)
2025-10-12 23:15:26 | 전체 파라미터: 3,237,063,680
2025-10-12 23:15:26 | Input require grads 활성화 (LoRA + Gradient Checkpointing)
2025-10-12 23:15:26 | ✅ Gradient Checkpointing 활성화
2025-10-12 23:15:26 | ✅ Causal LM 로드 완료
2025-10-12 23:15:27 | ============================================================
2025-10-12 23:15:27 | 모델 학습 시작
2025-10-12 23:15:27 | ============================================================
2025-10-12 23:15:27 | WandB 로그인 상태: ieyeppo-job
2025-10-12 23:15:27 | wandb: Currently logged in as: ieyeppo-job (kimsunmin0227-hufs) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
2025-10-12 23:15:28 | wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
2025-10-12 23:15:28 | wandb: setting up run fol48gxx
2025-10-12 23:15:28 | wandb: Tracking run with wandb version 0.22.2
2025-10-12 23:15:28 | wandb: Run data is saved locally in /home/ieyeppo/AI_Lab/natural-language-processing-competition/wandb/wandb/run-20251012_231527-fol48gxx
wandb: Run `wandb offline` to turn off syncing.
2025-10-12 23:15:28 | wandb: Syncing run 1012-2315-llama_3.2_3b_qlora
2025-10-12 23:15:28 | wandb: ⭐️ View project at https://wandb.ai/ieyeppo/nlp-competition
2025-10-12 23:15:28 | wandb: 🚀 View run at https://wandb.ai/ieyeppo/nlp-competition/runs/fol48gxx
2025-10-12 23:15:28 | wandb: Detected [openai] in use.
2025-10-12 23:15:28 | wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
2025-10-12 23:15:28 | wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-10-12 23:15:28 | 📋 실험명: 1012-2315-llama_3.2_3b_qlora
2025-10-12 23:15:28 | 🔗 WandB URL: https://wandb.ai/ieyeppo/nlp-competition/runs/fol48gxx
2025-10-12 23:15:28 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 23:15:28 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 23:15:28 | 학습 진행 중...
2025-10-12 23:15:28 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-12 23:15:29 | 0%|          | 0/750 [00:00<?, ?it/s]
2025-10-12 23:15:41 | 1%|          | 4/750 [00:12<37:08,  2.99s/it]
2025-10-12 23:15:57 | {'loss': 1.6069, 'grad_norm': 2.0931859016418457, 'learning_rate': 9e-08, 'epoch': 0.01}
2025-10-12 23:15:57 | 1%|▏         | 10/750 [00:28<33:25,  2.71s/it]
2025-10-12 23:16:04 | 2%|▏         | 12/750 [00:35<39:11,  3.19s/it]
2025-10-12 23:16:23 | 3%|▎         | 19/750 [00:54<32:58,  2.71s/it]
2025-10-12 23:16:26 | {'loss': 1.6726, 'grad_norm': 1.9981169700622559, 'learning_rate': 1.9e-07, 'epoch': 0.03}
2025-10-12 23:16:26 | 3%|▎         | 20/750 [00:57<33:40,  2.77s/it]
2025-10-12 23:16:47 | 4%|▎         | 27/750 [01:18<34:33,  2.87s/it]
2025-10-12 23:16:55 | {'loss': 1.6492, 'grad_norm': 1.8897300958633423, 'learning_rate': 2.9000000000000003e-07, 'epoch': 0.04}
2025-10-12 23:16:55 | 4%|▍         | 30/750 [01:26<33:43,  2.81s/it]
2025-10-12 23:17:06 | 5%|▍         | 34/750 [01:37<33:49,  2.83s/it]
2025-10-12 23:17:24 | {'loss': 1.614, 'grad_norm': 1.8445836305618286, 'learning_rate': 3.9e-07, 'epoch': 0.05}
2025-10-12 23:17:24 | 5%|▌         | 40/750 [01:55<33:51,  2.86s/it]
2025-10-12 23:17:30 | 6%|▌         | 42/750 [02:01<33:10,  2.81s/it]
2025-10-12 23:17:51 | 7%|▋         | 49/750 [02:22<34:45,  2.98s/it]
2025-10-12 23:17:54 | {'loss': 1.6363, 'grad_norm': 1.9223698377609253, 'learning_rate': 4.900000000000001e-07, 'epoch': 0.07}
2025-10-12 23:17:54 | 7%|▋         | 50/750 [02:25<34:50,  2.99s/it]
