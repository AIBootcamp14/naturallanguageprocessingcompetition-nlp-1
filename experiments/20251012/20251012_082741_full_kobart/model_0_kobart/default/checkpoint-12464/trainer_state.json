{
  "best_global_step": 12464,
  "best_metric": 1.183711775087871,
  "best_model_checkpoint": "experiments/20251012/20251012_082741_full_kobart/model_0_kobart/default/checkpoint-12464",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 12464,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06418485237483953,
      "grad_norm": 7.447507858276367,
      "learning_rate": 1.98e-06,
      "loss": 2.5852,
      "step": 100
    },
    {
      "epoch": 0.12836970474967907,
      "grad_norm": 8.83094310760498,
      "learning_rate": 3.980000000000001e-06,
      "loss": 1.8879,
      "step": 200
    },
    {
      "epoch": 0.1925545571245186,
      "grad_norm": 6.686702728271484,
      "learning_rate": 5.98e-06,
      "loss": 1.7644,
      "step": 300
    },
    {
      "epoch": 0.25673940949935814,
      "grad_norm": 6.260129928588867,
      "learning_rate": 7.980000000000002e-06,
      "loss": 1.6904,
      "step": 400
    },
    {
      "epoch": 0.3209242618741977,
      "grad_norm": 5.470142841339111,
      "learning_rate": 9.980000000000001e-06,
      "loss": 1.6008,
      "step": 500
    },
    {
      "epoch": 0.3851091142490372,
      "grad_norm": 6.569478511810303,
      "learning_rate": 9.934350132625996e-06,
      "loss": 1.5742,
      "step": 600
    },
    {
      "epoch": 0.4492939666238768,
      "grad_norm": 7.291100025177002,
      "learning_rate": 9.868037135278515e-06,
      "loss": 1.5504,
      "step": 700
    },
    {
      "epoch": 0.5134788189987163,
      "grad_norm": 5.247951507568359,
      "learning_rate": 9.801724137931035e-06,
      "loss": 1.5136,
      "step": 800
    },
    {
      "epoch": 0.5776636713735558,
      "grad_norm": 5.726874351501465,
      "learning_rate": 9.735411140583554e-06,
      "loss": 1.5233,
      "step": 900
    },
    {
      "epoch": 0.6418485237483954,
      "grad_norm": 5.185211658477783,
      "learning_rate": 9.669098143236075e-06,
      "loss": 1.497,
      "step": 1000
    },
    {
      "epoch": 0.7060333761232349,
      "grad_norm": 5.1771039962768555,
      "learning_rate": 9.602785145888594e-06,
      "loss": 1.487,
      "step": 1100
    },
    {
      "epoch": 0.7702182284980744,
      "grad_norm": 4.297122478485107,
      "learning_rate": 9.536472148541115e-06,
      "loss": 1.4592,
      "step": 1200
    },
    {
      "epoch": 0.834403080872914,
      "grad_norm": 5.1334757804870605,
      "learning_rate": 9.470159151193635e-06,
      "loss": 1.4463,
      "step": 1300
    },
    {
      "epoch": 0.8985879332477535,
      "grad_norm": 5.430708408355713,
      "learning_rate": 9.403846153846154e-06,
      "loss": 1.4776,
      "step": 1400
    },
    {
      "epoch": 0.962772785622593,
      "grad_norm": 4.310719013214111,
      "learning_rate": 9.337533156498675e-06,
      "loss": 1.4614,
      "step": 1500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3736850023269653,
      "eval_rouge1": 0.41216328751088677,
      "eval_rouge2": 0.2597009809608381,
      "eval_rougeL": 0.403069663608233,
      "eval_rouge_sum": 1.0749339320799578,
      "eval_runtime": 87.8409,
      "eval_samples_per_second": 5.681,
      "eval_steps_per_second": 0.717,
      "step": 1558
    },
    {
      "epoch": 1.0269576379974326,
      "grad_norm": 5.807628154754639,
      "learning_rate": 9.271220159151194e-06,
      "loss": 1.4333,
      "step": 1600
    },
    {
      "epoch": 1.0911424903722722,
      "grad_norm": 5.797656059265137,
      "learning_rate": 9.204907161803715e-06,
      "loss": 1.3341,
      "step": 1700
    },
    {
      "epoch": 1.1553273427471118,
      "grad_norm": 5.773209571838379,
      "learning_rate": 9.138594164456234e-06,
      "loss": 1.3508,
      "step": 1800
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 4.825905799865723,
      "learning_rate": 9.072281167108754e-06,
      "loss": 1.3621,
      "step": 1900
    },
    {
      "epoch": 1.2836970474967908,
      "grad_norm": 5.534356594085693,
      "learning_rate": 9.005968169761275e-06,
      "loss": 1.3194,
      "step": 2000
    },
    {
      "epoch": 1.3478818998716302,
      "grad_norm": 5.840755462646484,
      "learning_rate": 8.939655172413794e-06,
      "loss": 1.3358,
      "step": 2100
    },
    {
      "epoch": 1.4120667522464698,
      "grad_norm": 5.051795959472656,
      "learning_rate": 8.873342175066315e-06,
      "loss": 1.3219,
      "step": 2200
    },
    {
      "epoch": 1.4762516046213094,
      "grad_norm": 5.1943135261535645,
      "learning_rate": 8.807029177718834e-06,
      "loss": 1.3272,
      "step": 2300
    },
    {
      "epoch": 1.540436456996149,
      "grad_norm": 5.289418697357178,
      "learning_rate": 8.740716180371354e-06,
      "loss": 1.3103,
      "step": 2400
    },
    {
      "epoch": 1.6046213093709885,
      "grad_norm": 5.727846622467041,
      "learning_rate": 8.674403183023873e-06,
      "loss": 1.3521,
      "step": 2500
    },
    {
      "epoch": 1.6688061617458279,
      "grad_norm": 5.00466251373291,
      "learning_rate": 8.608090185676394e-06,
      "loss": 1.3213,
      "step": 2600
    },
    {
      "epoch": 1.7329910141206675,
      "grad_norm": 5.13674783706665,
      "learning_rate": 8.541777188328913e-06,
      "loss": 1.3314,
      "step": 2700
    },
    {
      "epoch": 1.797175866495507,
      "grad_norm": 4.62805700302124,
      "learning_rate": 8.475464190981432e-06,
      "loss": 1.2976,
      "step": 2800
    },
    {
      "epoch": 1.8613607188703467,
      "grad_norm": 4.8363823890686035,
      "learning_rate": 8.409151193633953e-06,
      "loss": 1.3174,
      "step": 2900
    },
    {
      "epoch": 1.925545571245186,
      "grad_norm": 5.614852428436279,
      "learning_rate": 8.342838196286472e-06,
      "loss": 1.3023,
      "step": 3000
    },
    {
      "epoch": 1.9897304236200257,
      "grad_norm": 5.12407112121582,
      "learning_rate": 8.276525198938992e-06,
      "loss": 1.2797,
      "step": 3100
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3190990686416626,
      "eval_rouge1": 0.42553569976678407,
      "eval_rouge2": 0.2701805119290244,
      "eval_rougeL": 0.4170262016122063,
      "eval_rouge_sum": 1.1127424133080148,
      "eval_runtime": 84.6976,
      "eval_samples_per_second": 5.892,
      "eval_steps_per_second": 0.744,
      "step": 3116
    },
    {
      "epoch": 2.053915275994865,
      "grad_norm": 4.922289848327637,
      "learning_rate": 8.210212201591513e-06,
      "loss": 1.2228,
      "step": 3200
    },
    {
      "epoch": 2.1181001283697047,
      "grad_norm": 4.605948448181152,
      "learning_rate": 8.143899204244032e-06,
      "loss": 1.196,
      "step": 3300
    },
    {
      "epoch": 2.1822849807445444,
      "grad_norm": 5.207523345947266,
      "learning_rate": 8.077586206896553e-06,
      "loss": 1.202,
      "step": 3400
    },
    {
      "epoch": 2.246469833119384,
      "grad_norm": 5.2223381996154785,
      "learning_rate": 8.011273209549072e-06,
      "loss": 1.2268,
      "step": 3500
    },
    {
      "epoch": 2.3106546854942236,
      "grad_norm": 5.3123393058776855,
      "learning_rate": 7.944960212201592e-06,
      "loss": 1.1985,
      "step": 3600
    },
    {
      "epoch": 2.3748395378690628,
      "grad_norm": 5.35224723815918,
      "learning_rate": 7.878647214854111e-06,
      "loss": 1.1936,
      "step": 3700
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 4.472517013549805,
      "learning_rate": 7.812334217506632e-06,
      "loss": 1.2091,
      "step": 3800
    },
    {
      "epoch": 2.503209242618742,
      "grad_norm": 5.861729145050049,
      "learning_rate": 7.746021220159153e-06,
      "loss": 1.205,
      "step": 3900
    },
    {
      "epoch": 2.5673940949935816,
      "grad_norm": 4.661645412445068,
      "learning_rate": 7.679708222811672e-06,
      "loss": 1.2108,
      "step": 4000
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 4.945291996002197,
      "learning_rate": 7.613395225464192e-06,
      "loss": 1.186,
      "step": 4100
    },
    {
      "epoch": 2.6957637997432604,
      "grad_norm": 5.87652063369751,
      "learning_rate": 7.5470822281167114e-06,
      "loss": 1.1907,
      "step": 4200
    },
    {
      "epoch": 2.7599486521181,
      "grad_norm": 6.773406982421875,
      "learning_rate": 7.480769230769231e-06,
      "loss": 1.1829,
      "step": 4300
    },
    {
      "epoch": 2.8241335044929397,
      "grad_norm": 5.137331962585449,
      "learning_rate": 7.414456233421752e-06,
      "loss": 1.1918,
      "step": 4400
    },
    {
      "epoch": 2.8883183568677793,
      "grad_norm": 5.221819877624512,
      "learning_rate": 7.348143236074271e-06,
      "loss": 1.1748,
      "step": 4500
    },
    {
      "epoch": 2.952503209242619,
      "grad_norm": 4.836975574493408,
      "learning_rate": 7.281830238726792e-06,
      "loss": 1.1913,
      "step": 4600
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3018336296081543,
      "eval_rouge1": 0.42731744903611857,
      "eval_rouge2": 0.2711186248628005,
      "eval_rougeL": 0.4188121252396863,
      "eval_rouge_sum": 1.1172481991386054,
      "eval_runtime": 79.8755,
      "eval_samples_per_second": 6.247,
      "eval_steps_per_second": 0.789,
      "step": 4674
    },
    {
      "epoch": 3.016688061617458,
      "grad_norm": 4.438678741455078,
      "learning_rate": 7.215517241379311e-06,
      "loss": 1.1896,
      "step": 4700
    },
    {
      "epoch": 3.0808729139922977,
      "grad_norm": 4.294007778167725,
      "learning_rate": 7.149204244031831e-06,
      "loss": 1.0982,
      "step": 4800
    },
    {
      "epoch": 3.1450577663671373,
      "grad_norm": 5.322514533996582,
      "learning_rate": 7.08289124668435e-06,
      "loss": 1.1053,
      "step": 4900
    },
    {
      "epoch": 3.209242618741977,
      "grad_norm": 5.213200092315674,
      "learning_rate": 7.016578249336871e-06,
      "loss": 1.0886,
      "step": 5000
    },
    {
      "epoch": 3.2734274711168165,
      "grad_norm": 5.572940826416016,
      "learning_rate": 6.950265251989391e-06,
      "loss": 1.1072,
      "step": 5100
    },
    {
      "epoch": 3.337612323491656,
      "grad_norm": 5.449337482452393,
      "learning_rate": 6.88395225464191e-06,
      "loss": 1.111,
      "step": 5200
    },
    {
      "epoch": 3.4017971758664953,
      "grad_norm": 5.757546901702881,
      "learning_rate": 6.8176392572944305e-06,
      "loss": 1.0943,
      "step": 5300
    },
    {
      "epoch": 3.465982028241335,
      "grad_norm": 5.093627452850342,
      "learning_rate": 6.7513262599469495e-06,
      "loss": 1.1039,
      "step": 5400
    },
    {
      "epoch": 3.5301668806161746,
      "grad_norm": 5.056093215942383,
      "learning_rate": 6.68501326259947e-06,
      "loss": 1.1085,
      "step": 5500
    },
    {
      "epoch": 3.594351732991014,
      "grad_norm": 4.99110221862793,
      "learning_rate": 6.618700265251989e-06,
      "loss": 1.1233,
      "step": 5600
    },
    {
      "epoch": 3.658536585365854,
      "grad_norm": 4.949301242828369,
      "learning_rate": 6.55238726790451e-06,
      "loss": 1.0899,
      "step": 5700
    },
    {
      "epoch": 3.7227214377406934,
      "grad_norm": 5.3881025314331055,
      "learning_rate": 6.48607427055703e-06,
      "loss": 1.1409,
      "step": 5800
    },
    {
      "epoch": 3.7869062901155326,
      "grad_norm": 5.229660987854004,
      "learning_rate": 6.4197612732095495e-06,
      "loss": 1.0861,
      "step": 5900
    },
    {
      "epoch": 3.851091142490372,
      "grad_norm": 6.974735736846924,
      "learning_rate": 6.353448275862069e-06,
      "loss": 1.1034,
      "step": 6000
    },
    {
      "epoch": 3.915275994865212,
      "grad_norm": 4.984376907348633,
      "learning_rate": 6.287135278514589e-06,
      "loss": 1.0906,
      "step": 6100
    },
    {
      "epoch": 3.9794608472400514,
      "grad_norm": 6.422083854675293,
      "learning_rate": 6.220822281167109e-06,
      "loss": 1.0884,
      "step": 6200
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.2990140914916992,
      "eval_rouge1": 0.43530832054814333,
      "eval_rouge2": 0.27693188499196797,
      "eval_rougeL": 0.427128337603926,
      "eval_rouge_sum": 1.1393685431440375,
      "eval_runtime": 88.9907,
      "eval_samples_per_second": 5.607,
      "eval_steps_per_second": 0.708,
      "step": 6232
    },
    {
      "epoch": 4.043645699614891,
      "grad_norm": 4.9568867683410645,
      "learning_rate": 6.15450928381963e-06,
      "loss": 1.0325,
      "step": 6300
    },
    {
      "epoch": 4.10783055198973,
      "grad_norm": 6.4863667488098145,
      "learning_rate": 6.088196286472149e-06,
      "loss": 1.03,
      "step": 6400
    },
    {
      "epoch": 4.17201540436457,
      "grad_norm": 5.510989665985107,
      "learning_rate": 6.0218832891246694e-06,
      "loss": 1.0207,
      "step": 6500
    },
    {
      "epoch": 4.2362002567394095,
      "grad_norm": 5.139561176300049,
      "learning_rate": 5.955570291777188e-06,
      "loss": 1.0145,
      "step": 6600
    },
    {
      "epoch": 4.300385109114249,
      "grad_norm": 5.096207618713379,
      "learning_rate": 5.889257294429709e-06,
      "loss": 1.0388,
      "step": 6700
    },
    {
      "epoch": 4.364569961489089,
      "grad_norm": 6.191650867462158,
      "learning_rate": 5.822944297082228e-06,
      "loss": 1.0268,
      "step": 6800
    },
    {
      "epoch": 4.428754813863928,
      "grad_norm": 4.304718017578125,
      "learning_rate": 5.756631299734749e-06,
      "loss": 1.037,
      "step": 6900
    },
    {
      "epoch": 4.492939666238768,
      "grad_norm": 4.341907024383545,
      "learning_rate": 5.690318302387269e-06,
      "loss": 1.0114,
      "step": 7000
    },
    {
      "epoch": 4.557124518613607,
      "grad_norm": 6.70213508605957,
      "learning_rate": 5.624005305039788e-06,
      "loss": 1.0401,
      "step": 7100
    },
    {
      "epoch": 4.621309370988447,
      "grad_norm": 5.165741443634033,
      "learning_rate": 5.557692307692308e-06,
      "loss": 1.024,
      "step": 7200
    },
    {
      "epoch": 4.685494223363286,
      "grad_norm": 6.0549163818359375,
      "learning_rate": 5.491379310344827e-06,
      "loss": 1.0411,
      "step": 7300
    },
    {
      "epoch": 4.7496790757381255,
      "grad_norm": 5.898833751678467,
      "learning_rate": 5.425066312997348e-06,
      "loss": 1.0256,
      "step": 7400
    },
    {
      "epoch": 4.813863928112966,
      "grad_norm": 4.783164978027344,
      "learning_rate": 5.358753315649869e-06,
      "loss": 1.0175,
      "step": 7500
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 5.597585678100586,
      "learning_rate": 5.292440318302388e-06,
      "loss": 1.0306,
      "step": 7600
    },
    {
      "epoch": 4.942233632862644,
      "grad_norm": 5.622791290283203,
      "learning_rate": 5.226127320954908e-06,
      "loss": 1.042,
      "step": 7700
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.2950810194015503,
      "eval_rouge1": 0.4481683813324143,
      "eval_rouge2": 0.2825484856328277,
      "eval_rougeL": 0.43702886914560635,
      "eval_rouge_sum": 1.1677457361108483,
      "eval_runtime": 77.4868,
      "eval_samples_per_second": 6.44,
      "eval_steps_per_second": 0.813,
      "step": 7790
    },
    {
      "epoch": 5.006418485237484,
      "grad_norm": 5.148746490478516,
      "learning_rate": 5.159814323607427e-06,
      "loss": 1.0116,
      "step": 7800
    },
    {
      "epoch": 5.070603337612323,
      "grad_norm": 5.647701263427734,
      "learning_rate": 5.093501326259947e-06,
      "loss": 0.946,
      "step": 7900
    },
    {
      "epoch": 5.134788189987163,
      "grad_norm": 5.871674060821533,
      "learning_rate": 5.027188328912467e-06,
      "loss": 0.951,
      "step": 8000
    },
    {
      "epoch": 5.198973042362002,
      "grad_norm": 4.426774501800537,
      "learning_rate": 4.960875331564987e-06,
      "loss": 0.9566,
      "step": 8100
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 6.2608962059021,
      "learning_rate": 4.894562334217507e-06,
      "loss": 0.954,
      "step": 8200
    },
    {
      "epoch": 5.327342747111682,
      "grad_norm": 5.146047115325928,
      "learning_rate": 4.8282493368700265e-06,
      "loss": 0.951,
      "step": 8300
    },
    {
      "epoch": 5.391527599486521,
      "grad_norm": 5.008913993835449,
      "learning_rate": 4.761936339522547e-06,
      "loss": 0.97,
      "step": 8400
    },
    {
      "epoch": 5.455712451861361,
      "grad_norm": 4.685890197753906,
      "learning_rate": 4.695623342175067e-06,
      "loss": 0.9655,
      "step": 8500
    },
    {
      "epoch": 5.5198973042362,
      "grad_norm": 4.961878776550293,
      "learning_rate": 4.629310344827587e-06,
      "loss": 0.9602,
      "step": 8600
    },
    {
      "epoch": 5.58408215661104,
      "grad_norm": 6.260615825653076,
      "learning_rate": 4.562997347480107e-06,
      "loss": 0.9787,
      "step": 8700
    },
    {
      "epoch": 5.648267008985879,
      "grad_norm": 4.956161022186279,
      "learning_rate": 4.4966843501326266e-06,
      "loss": 0.9716,
      "step": 8800
    },
    {
      "epoch": 5.712451861360719,
      "grad_norm": 6.958173751831055,
      "learning_rate": 4.430371352785146e-06,
      "loss": 0.9713,
      "step": 8900
    },
    {
      "epoch": 5.7766367137355585,
      "grad_norm": 6.0051422119140625,
      "learning_rate": 4.364058355437666e-06,
      "loss": 0.9882,
      "step": 9000
    },
    {
      "epoch": 5.840821566110398,
      "grad_norm": 4.738096237182617,
      "learning_rate": 4.297745358090186e-06,
      "loss": 0.9615,
      "step": 9100
    },
    {
      "epoch": 5.905006418485238,
      "grad_norm": 5.613051414489746,
      "learning_rate": 4.231432360742706e-06,
      "loss": 0.9819,
      "step": 9200
    },
    {
      "epoch": 5.969191270860077,
      "grad_norm": 4.96859073638916,
      "learning_rate": 4.165119363395226e-06,
      "loss": 0.9763,
      "step": 9300
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3045397996902466,
      "eval_rouge1": 0.4281706592375851,
      "eval_rouge2": 0.2745959341525086,
      "eval_rougeL": 0.42220994274000545,
      "eval_rouge_sum": 1.1249765361300992,
      "eval_runtime": 65.5287,
      "eval_samples_per_second": 7.615,
      "eval_steps_per_second": 0.961,
      "step": 9348
    },
    {
      "epoch": 6.033376123234916,
      "grad_norm": 4.815409183502197,
      "learning_rate": 4.098806366047746e-06,
      "loss": 0.9332,
      "step": 9400
    },
    {
      "epoch": 6.097560975609756,
      "grad_norm": 5.242266654968262,
      "learning_rate": 4.0324933687002654e-06,
      "loss": 0.8859,
      "step": 9500
    },
    {
      "epoch": 6.161745827984595,
      "grad_norm": 4.161760330200195,
      "learning_rate": 3.966180371352785e-06,
      "loss": 0.9156,
      "step": 9600
    },
    {
      "epoch": 6.225930680359435,
      "grad_norm": 5.421172618865967,
      "learning_rate": 3.899867374005306e-06,
      "loss": 0.9186,
      "step": 9700
    },
    {
      "epoch": 6.290115532734275,
      "grad_norm": 4.846080780029297,
      "learning_rate": 3.833554376657825e-06,
      "loss": 0.9256,
      "step": 9800
    },
    {
      "epoch": 6.354300385109115,
      "grad_norm": 5.535925388336182,
      "learning_rate": 3.7672413793103452e-06,
      "loss": 0.9216,
      "step": 9900
    },
    {
      "epoch": 6.418485237483954,
      "grad_norm": 5.308370590209961,
      "learning_rate": 3.700928381962865e-06,
      "loss": 0.9184,
      "step": 10000
    },
    {
      "epoch": 6.482670089858793,
      "grad_norm": 4.877481460571289,
      "learning_rate": 3.634615384615385e-06,
      "loss": 0.9179,
      "step": 10100
    },
    {
      "epoch": 6.546854942233633,
      "grad_norm": 5.631250858306885,
      "learning_rate": 3.5683023872679047e-06,
      "loss": 0.9119,
      "step": 10200
    },
    {
      "epoch": 6.611039794608472,
      "grad_norm": 6.0640153884887695,
      "learning_rate": 3.501989389920425e-06,
      "loss": 0.9222,
      "step": 10300
    },
    {
      "epoch": 6.675224646983312,
      "grad_norm": 6.133849143981934,
      "learning_rate": 3.435676392572945e-06,
      "loss": 0.9094,
      "step": 10400
    },
    {
      "epoch": 6.7394094993581515,
      "grad_norm": 5.653570175170898,
      "learning_rate": 3.3693633952254647e-06,
      "loss": 0.9168,
      "step": 10500
    },
    {
      "epoch": 6.803594351732991,
      "grad_norm": 4.982115745544434,
      "learning_rate": 3.3030503978779845e-06,
      "loss": 0.9106,
      "step": 10600
    },
    {
      "epoch": 6.867779204107831,
      "grad_norm": 5.841711044311523,
      "learning_rate": 3.236737400530504e-06,
      "loss": 0.9233,
      "step": 10700
    },
    {
      "epoch": 6.93196405648267,
      "grad_norm": 4.915288925170898,
      "learning_rate": 3.1704244031830238e-06,
      "loss": 0.9076,
      "step": 10800
    },
    {
      "epoch": 6.99614890885751,
      "grad_norm": 4.931646347045898,
      "learning_rate": 3.1041114058355445e-06,
      "loss": 0.9202,
      "step": 10900
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3140476942062378,
      "eval_rouge1": 0.4360142497629546,
      "eval_rouge2": 0.28150099928867456,
      "eval_rougeL": 0.42708095661835965,
      "eval_rouge_sum": 1.144596205669989,
      "eval_runtime": 63.589,
      "eval_samples_per_second": 7.847,
      "eval_steps_per_second": 0.991,
      "step": 10906
    },
    {
      "epoch": 7.060333761232349,
      "grad_norm": 4.4799628257751465,
      "learning_rate": 3.037798408488064e-06,
      "loss": 0.889,
      "step": 11000
    },
    {
      "epoch": 7.124518613607188,
      "grad_norm": 5.487738132476807,
      "learning_rate": 2.9714854111405837e-06,
      "loss": 0.8754,
      "step": 11100
    },
    {
      "epoch": 7.188703465982028,
      "grad_norm": 5.030036926269531,
      "learning_rate": 2.9051724137931036e-06,
      "loss": 0.8655,
      "step": 11200
    },
    {
      "epoch": 7.2528883183568675,
      "grad_norm": 6.039361953735352,
      "learning_rate": 2.8388594164456234e-06,
      "loss": 0.8753,
      "step": 11300
    },
    {
      "epoch": 7.317073170731708,
      "grad_norm": 5.0599493980407715,
      "learning_rate": 2.7725464190981432e-06,
      "loss": 0.8803,
      "step": 11400
    },
    {
      "epoch": 7.381258023106547,
      "grad_norm": 5.428330898284912,
      "learning_rate": 2.7062334217506635e-06,
      "loss": 0.8669,
      "step": 11500
    },
    {
      "epoch": 7.445442875481387,
      "grad_norm": 5.707845211029053,
      "learning_rate": 2.6399204244031833e-06,
      "loss": 0.874,
      "step": 11600
    },
    {
      "epoch": 7.509627727856226,
      "grad_norm": 6.072731971740723,
      "learning_rate": 2.573607427055703e-06,
      "loss": 0.8634,
      "step": 11700
    },
    {
      "epoch": 7.573812580231065,
      "grad_norm": 5.113112449645996,
      "learning_rate": 2.507294429708223e-06,
      "loss": 0.8802,
      "step": 11800
    },
    {
      "epoch": 7.637997432605905,
      "grad_norm": 5.661812782287598,
      "learning_rate": 2.440981432360743e-06,
      "loss": 0.8948,
      "step": 11900
    },
    {
      "epoch": 7.702182284980744,
      "grad_norm": 5.349006652832031,
      "learning_rate": 2.3746684350132627e-06,
      "loss": 0.886,
      "step": 12000
    },
    {
      "epoch": 7.766367137355584,
      "grad_norm": 5.581220626831055,
      "learning_rate": 2.3083554376657825e-06,
      "loss": 0.8932,
      "step": 12100
    },
    {
      "epoch": 7.830551989730424,
      "grad_norm": 5.5005598068237305,
      "learning_rate": 2.2420424403183024e-06,
      "loss": 0.8896,
      "step": 12200
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 4.39846134185791,
      "learning_rate": 2.1757294429708226e-06,
      "loss": 0.8739,
      "step": 12300
    },
    {
      "epoch": 7.958921694480103,
      "grad_norm": 5.660520076751709,
      "learning_rate": 2.1094164456233425e-06,
      "loss": 0.8749,
      "step": 12400
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.32877779006958,
      "eval_rouge1": 0.45286822301346713,
      "eval_rouge2": 0.2883198510487144,
      "eval_rougeL": 0.4425237010256895,
      "eval_rouge_sum": 1.183711775087871,
      "eval_runtime": 62.9283,
      "eval_samples_per_second": 7.93,
      "eval_steps_per_second": 1.001,
      "step": 12464
    }
  ],
  "logging_steps": 100,
  "max_steps": 15580,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.038194824118272e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
