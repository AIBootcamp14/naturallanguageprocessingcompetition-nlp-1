2025-10-12 21:06:52 | >> 표준 출력 및 오류를 로그 파일로 리디렉션 시작
2025-10-12 21:06:54 | 📊 FULL 모드 실행 중...
2025-10-12 21:06:54 | ============================================================
2025-10-12 21:06:54 | = FULL PIPELINE 실행 시작
2025-10-12 21:06:54 | =대상 모델: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-12 21:06:54 | =앙상블 앙상블 전략: stacking
2025-10-12 21:06:54 | = TTA 사용: False
2025-10-12 21:06:54 | ============================================================
2025-10-12 21:06:54 | [1/6] 데이터 로딩...
2025-10-12 21:06:54 | ✅ 학습 데이터: 12457개
2025-10-12 21:06:54 | ✅ 검증 데이터: 499개
2025-10-12 21:06:54 | [2/6] 다중 모델 학습 (6 모델)...
2025-10-12 21:06:54 | ==================================================
2025-10-12 21:06:54 | 모델 1/6: kobart
2025-10-12 21:06:54 | ==================================================
2025-10-12 21:06:54 | 모델 타입: encoder_decoder
2025-10-12 21:06:54 | ============================================================
2025-10-12 21:06:54 | 모델 및 토크나이저 로딩 시작
2025-10-12 21:06:54 | ============================================================
2025-10-12 21:06:54 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-12 21:06:55 | 모델 로딩: digit82/kobart-summarization
2025-10-12 21:06:55 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 21:06:59 | → 디바이스: cuda
2025-10-12 21:06:59 | → 전체 파라미터: 123,859,968
2025-10-12 21:06:59 | → 학습 가능 파라미터: 123,859,968
2025-10-12 21:06:59 | ============================================================
2025-10-12 21:06:59 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-12 21:06:59 | ============================================================
2025-10-12 21:06:59 | ============================================================
2025-10-12 21:06:59 | 모델 학습 시작
2025-10-12 21:06:59 | ============================================================
2025-10-12 21:06:59 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 21:06:59 | 학습 진행 중...
2025-10-12 21:06:59 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 21:07:00 | 1%|          | 9/1558 [00:01<02:39,  9.72it/s]
2025-10-12 21:07:02 | 2%|▏         | 25/1558 [00:02<01:43, 14.88it/s]
2025-10-12 21:07:02 | 3%|▎         | 39/1558 [00:03<01:32, 16.38it/s]
2025-10-12 21:07:03 | 4%|▎         | 55/1558 [00:04<01:29, 16.71it/s]
2025-10-12 21:07:04 | 5%|▍         | 71/1558 [00:05<01:27, 16.97it/s]
2025-10-12 21:07:05 | 6%|▌         | 87/1558 [00:06<01:42, 14.33it/s]
2025-10-12 21:07:06 | {'loss': 2.747, 'grad_norm': 8.180179595947266, 'learning_rate': 9.9e-07, 'epoch': 0.06}
2025-10-12 21:07:06 | 6%|▋         | 100/1558 [00:07<01:58, 12.34it/s]
2025-10-12 21:07:07 | 7%|▋         | 103/1558 [00:07<02:00, 12.06it/s]
2025-10-12 21:07:08 | 8%|▊         | 117/1558 [00:08<02:04, 11.58it/s]
2025-10-12 21:07:09 | 9%|▊         | 133/1558 [00:10<02:07, 11.14it/s]
2025-10-12 21:07:11 | 10%|▉         | 149/1558 [00:12<02:44,  8.58it/s]
2025-10-12 21:07:13 | 11%|█         | 165/1558 [00:13<02:01, 11.45it/s]
2025-10-12 21:07:14 | 12%|█▏        | 181/1558 [00:14<01:59, 11.48it/s]
2025-10-12 21:07:15 | 13%|█▎        | 195/1558 [00:16<01:52, 12.09it/s]
2025-10-12 21:07:16 | {'loss': 2.0334, 'grad_norm': 10.030572891235352, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.13}
2025-10-12 21:07:16 | 13%|█▎        | 200/1558 [00:16<01:53, 11.99it/s]
2025-10-12 21:07:16 | 14%|█▎        | 211/1558 [00:17<01:52, 11.93it/s]
2025-10-12 21:07:18 | 15%|█▍        | 227/1558 [00:18<01:55, 11.53it/s]
2025-10-12 21:07:19 | 16%|█▌        | 243/1558 [00:20<01:54, 11.45it/s]
2025-10-12 21:07:21 | 17%|█▋        | 259/1558 [00:21<01:50, 11.73it/s]
2025-10-12 21:07:22 | 18%|█▊        | 273/1558 [00:22<01:50, 11.65it/s]
2025-10-12 21:07:23 | 19%|█▊        | 289/1558 [00:24<01:47, 11.79it/s]
2025-10-12 21:07:24 | {'loss': 1.854, 'grad_norm': 6.358424186706543, 'learning_rate': 2.99e-06, 'epoch': 0.19}
2025-10-12 21:07:24 | 19%|█▉        | 300/1558 [00:25<01:45, 11.98it/s]
2025-10-12 21:07:25 | 20%|█▉        | 305/1558 [00:25<01:46, 11.81it/s]
2025-10-12 21:07:26 | 21%|██        | 321/1558 [00:26<01:47, 11.51it/s]
2025-10-12 21:07:27 | 22%|██▏       | 335/1558 [00:28<01:45, 11.58it/s]
2025-10-12 21:07:29 | 23%|██▎       | 351/1558 [00:29<01:44, 11.54it/s]
2025-10-12 21:07:30 | 24%|██▎       | 367/1558 [00:30<01:46, 11.21it/s]
2025-10-12 21:07:31 | 25%|██▍       | 383/1558 [00:32<01:42, 11.43it/s]
2025-10-12 21:07:33 | 26%|██▌       | 399/1558 [00:33<01:41, 11.38it/s]
2025-10-12 21:07:33 | {'loss': 1.7595, 'grad_norm': 6.683406352996826, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.26}
2025-10-12 21:07:33 | 26%|██▌       | 400/1558 [00:33<01:41, 11.38it/s]
2025-10-12 21:07:34 | 27%|██▋       | 413/1558 [00:34<01:39, 11.53it/s]
2025-10-12 21:07:35 | 28%|██▊       | 429/1558 [00:36<01:39, 11.39it/s]
2025-10-12 21:07:37 | 29%|██▊       | 445/1558 [00:37<01:31, 12.13it/s]
2025-10-12 21:07:38 | 30%|██▉       | 461/1558 [00:38<01:29, 12.20it/s]
2025-10-12 21:07:39 | 31%|███       | 477/1558 [00:40<01:25, 12.60it/s]
2025-10-12 21:07:40 | 32%|███▏      | 491/1558 [00:41<01:26, 12.31it/s]
2025-10-12 21:07:41 | {'loss': 1.6645, 'grad_norm': 5.662783622741699, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.32}
2025-10-12 21:07:41 | 32%|███▏      | 500/1558 [00:42<01:25, 12.41it/s]
2025-10-12 21:07:42 | 33%|███▎      | 507/1558 [00:42<01:26, 12.20it/s]
2025-10-12 21:07:44 | 34%|███▎      | 523/1558 [00:44<03:02,  5.68it/s]
2025-10-12 21:07:45 | 35%|███▍      | 539/1558 [00:45<01:30, 11.27it/s]
2025-10-12 21:07:46 | 36%|███▌      | 555/1558 [00:47<01:22, 12.09it/s]
2025-10-12 21:07:48 | 37%|███▋      | 569/1558 [00:48<01:21, 12.15it/s]
2025-10-12 21:07:49 | 38%|███▊      | 585/1558 [00:49<01:21, 11.96it/s]
2025-10-12 21:07:50 | {'loss': 1.6316, 'grad_norm': 6.635122776031494, 'learning_rate': 4.532136105860114e-06, 'epoch': 0.39}
2025-10-12 21:07:50 | 39%|███▊      | 600/1558 [00:51<01:22, 11.57it/s]
2025-10-12 21:07:52 | 40%|███▉      | 617/1558 [00:52<01:20, 11.62it/s]
2025-10-12 21:07:53 | 41%|████      | 631/1558 [00:53<01:19, 11.64it/s]
2025-10-12 21:07:54 | 42%|████▏     | 647/1558 [00:55<01:18, 11.68it/s]
2025-10-12 21:07:56 | 43%|████▎     | 663/1558 [00:56<01:16, 11.75it/s]
2025-10-12 21:07:57 | 44%|████▎     | 679/1558 [00:57<01:16, 11.54it/s]
2025-10-12 21:07:58 | 45%|████▍     | 695/1558 [00:59<01:14, 11.53it/s]
2025-10-12 21:07:59 | {'loss': 1.6049, 'grad_norm': 7.677728176116943, 'learning_rate': 4.059546313799622e-06, 'epoch': 0.45}
2025-10-12 21:07:59 | 45%|████▍     | 700/1558 [00:59<01:13, 11.71it/s]
2025-10-12 21:07:59 | 46%|████▌     | 709/1558 [01:00<01:11, 11.94it/s]
2025-10-12 21:08:01 | 47%|████▋     | 725/1558 [01:01<01:10, 11.81it/s]
2025-10-12 21:08:02 | 48%|████▊     | 741/1558 [01:03<01:08, 12.01it/s]
2025-10-12 21:08:04 | 49%|████▊     | 757/1558 [01:04<01:09, 11.44it/s]
2025-10-12 21:08:05 | 50%|████▉     | 773/1558 [01:05<01:04, 12.24it/s]
2025-10-12 21:08:06 | 51%|█████     | 787/1558 [01:07<01:05, 11.73it/s]
2025-10-12 21:08:07 | {'loss': 1.5706, 'grad_norm': 5.509218692779541, 'learning_rate': 3.5869565217391305e-06, 'epoch': 0.51}
2025-10-12 21:08:07 | 51%|█████▏    | 800/1558 [01:08<01:04, 11.75it/s]
2025-10-12 21:08:07 | 52%|█████▏    | 803/1558 [01:08<01:05, 11.58it/s]
2025-10-12 21:08:09 | 53%|█████▎    | 819/1558 [01:09<01:02, 11.76it/s]
2025-10-12 21:08:10 | 54%|█████▎    | 835/1558 [01:11<01:00, 11.91it/s]
2025-10-12 21:08:12 | 55%|█████▍    | 851/1558 [01:12<00:59, 11.85it/s]
2025-10-12 21:08:13 | 56%|█████▌    | 865/1558 [01:13<01:00, 11.53it/s]
2025-10-12 21:08:14 | 57%|█████▋    | 881/1558 [01:15<00:59, 11.47it/s]
2025-10-12 21:08:16 | 58%|█████▊    | 897/1558 [01:16<00:57, 11.51it/s]
2025-10-12 21:08:16 | {'loss': 1.5792, 'grad_norm': 6.09945821762085, 'learning_rate': 3.114366729678639e-06, 'epoch': 0.58}
2025-10-12 21:08:16 | 58%|█████▊    | 900/1558 [01:17<00:56, 11.57it/s]
2025-10-12 21:08:18 | 59%|█████▊    | 913/1558 [01:18<01:03, 10.22it/s]
2025-10-12 21:08:19 | 60%|█████▉    | 929/1558 [01:19<00:56, 11.04it/s]
2025-10-12 21:08:20 | 61%|██████    | 943/1558 [01:21<00:56, 10.97it/s]
2025-10-12 21:08:22 | 62%|██████▏   | 959/1558 [01:22<00:54, 10.96it/s]
2025-10-12 21:08:23 | 63%|██████▎   | 975/1558 [01:24<00:52, 11.19it/s]
2025-10-12 21:08:25 | 64%|██████▎   | 991/1558 [01:25<00:51, 11.04it/s]
2025-10-12 21:08:26 | {'loss': 1.5576, 'grad_norm': 5.244473457336426, 'learning_rate': 2.641776937618148e-06, 'epoch': 0.64}
2025-10-12 21:08:26 | 64%|██████▍   | 1000/1558 [01:26<00:56,  9.93it/s]
2025-10-12 21:08:26 | 65%|██████▍   | 1006/1558 [01:27<00:53, 10.39it/s]
2025-10-12 21:08:28 | 66%|██████▌   | 1022/1558 [01:28<00:51, 10.49it/s]
2025-10-12 21:08:29 | 67%|██████▋   | 1038/1558 [01:30<00:47, 10.95it/s]
2025-10-12 21:08:30 | 68%|██████▊   | 1052/1558 [01:31<00:43, 11.64it/s]
2025-10-12 21:08:32 | 69%|██████▊   | 1068/1558 [01:32<00:41, 11.91it/s]
2025-10-12 21:08:33 | 70%|██████▉   | 1084/1558 [01:34<00:41, 11.35it/s]
2025-10-12 21:08:35 | 71%|███████   | 1100/1558 [01:35<00:38, 11.87it/s]
2025-10-12 21:08:35 | {'loss': 1.5503, 'grad_norm': 5.733467102050781, 'learning_rate': 2.169187145557656e-06, 'epoch': 0.71}
2025-10-12 21:08:35 | 71%|███████   | 1100/1558 [01:35<00:38, 11.87it/s]
2025-10-12 21:08:36 | 72%|███████▏  | 1114/1558 [01:36<00:36, 12.04it/s]
2025-10-12 21:08:37 | 73%|███████▎  | 1130/1558 [01:37<00:34, 12.29it/s]
2025-10-12 21:08:38 | 74%|███████▎  | 1146/1558 [01:39<00:35, 11.45it/s]
2025-10-12 21:08:40 | 75%|███████▍  | 1162/1558 [01:40<00:33, 11.89it/s]
2025-10-12 21:08:41 | 76%|███████▌  | 1178/1558 [01:42<00:32, 11.70it/s]
2025-10-12 21:08:42 | 77%|███████▋  | 1192/1558 [01:43<00:30, 11.95it/s]
2025-10-12 21:08:43 | {'loss': 1.5246, 'grad_norm': 4.481690883636475, 'learning_rate': 1.6965973534971647e-06, 'epoch': 0.77}
2025-10-12 21:08:43 | 77%|███████▋  | 1200/1558 [01:43<00:28, 12.42it/s]
2025-10-12 21:08:43 | 78%|███████▊  | 1208/1558 [01:44<00:27, 12.65it/s]
2025-10-12 21:08:45 | 79%|███████▊  | 1224/1558 [01:45<00:28, 11.84it/s]
2025-10-12 21:08:46 | 80%|███████▉  | 1240/1558 [01:47<00:26, 12.08it/s]
2025-10-12 21:08:47 | 81%|████████  | 1256/1558 [01:48<00:23, 12.63it/s]
2025-10-12 21:08:49 | 82%|████████▏ | 1270/1558 [01:49<00:23, 12.46it/s]
2025-10-12 21:08:50 | 83%|████████▎ | 1286/1558 [01:51<00:23, 11.51it/s]
2025-10-12 21:08:52 | {'loss': 1.5155, 'grad_norm': 5.404027938842773, 'learning_rate': 1.224007561436673e-06, 'epoch': 0.83}
2025-10-12 21:08:52 | 83%|████████▎ | 1300/1558 [01:52<00:22, 11.64it/s]
2025-10-12 21:08:52 | 84%|████████▎ | 1302/1558 [01:52<00:21, 11.67it/s]
2025-10-12 21:08:53 | 85%|████████▍ | 1318/1558 [01:54<00:19, 12.44it/s]
2025-10-12 21:08:54 | 86%|████████▌ | 1334/1558 [01:55<00:17, 12.77it/s]
2025-10-12 21:08:55 | 87%|████████▋ | 1348/1558 [01:56<00:16, 12.65it/s]
2025-10-12 21:08:57 | 88%|████████▊ | 1364/1558 [01:57<00:15, 12.76it/s]
2025-10-12 21:08:58 | 89%|████████▊ | 1380/1558 [01:58<00:13, 12.95it/s]
2025-10-12 21:08:59 | 90%|████████▉ | 1396/1558 [02:00<00:12, 12.95it/s]
2025-10-12 21:08:59 | {'loss': 1.5504, 'grad_norm': 5.750820159912109, 'learning_rate': 7.514177693761815e-07, 'epoch': 0.9}
2025-10-12 21:08:59 | 90%|████████▉ | 1400/1558 [02:00<00:12, 12.95it/s]
2025-10-12 21:09:00 | 91%|█████████ | 1410/1558 [02:01<00:11, 13.15it/s]
2025-10-12 21:09:01 | 92%|█████████▏| 1426/1558 [02:02<00:09, 13.79it/s]
2025-10-12 21:09:02 | 93%|█████████▎| 1442/1558 [02:03<00:07, 16.30it/s]
2025-10-12 21:09:03 | 94%|█████████▎| 1458/1558 [02:04<00:05, 16.71it/s]
2025-10-12 21:09:04 | 95%|█████████▍| 1474/1558 [02:05<00:04, 17.35it/s]
2025-10-12 21:09:05 | 96%|█████████▌| 1488/1558 [02:06<00:04, 16.40it/s]
2025-10-12 21:09:06 | {'loss': 1.5458, 'grad_norm': 4.619958877563477, 'learning_rate': 2.7882797731569e-07, 'epoch': 0.96}
2025-10-12 21:09:06 | 96%|█████████▋| 1500/1558 [02:06<00:03, 17.05it/s]
2025-10-12 21:09:06 | 97%|█████████▋| 1504/1558 [02:06<00:03, 17.12it/s]
2025-10-12 21:09:07 | 98%|█████████▊| 1520/1558 [02:07<00:02, 17.40it/s]
2025-10-12 21:09:08 | 99%|█████████▊| 1536/1558 [02:08<00:01, 16.84it/s]
2025-10-12 21:09:09 | 100%|█████████▉| 1552/1558 [02:09<00:00, 17.50it/s]
2025-10-12 21:09:11 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 21:09:11 | [A
2025-10-12 21:09:11 | 3%|▎         | 2/63 [00:00<00:23,  2.61it/s]
2025-10-12 21:09:11 | [A
2025-10-12 21:09:12 | 5%|▍         | 3/63 [00:01<00:32,  1.83it/s]
2025-10-12 21:09:12 | [A
2025-10-12 21:09:13 | 6%|▋         | 4/63 [00:02<00:37,  1.56it/s]
2025-10-12 21:09:13 | [A
2025-10-12 21:09:14 | 8%|▊         | 5/63 [00:03<00:54,  1.06it/s]
2025-10-12 21:09:14 | [A
2025-10-12 21:09:16 | 10%|▉         | 6/63 [00:05<01:00,  1.07s/it]
2025-10-12 21:09:16 | [A
2025-10-12 21:09:17 | 11%|█         | 7/63 [00:06<01:04,  1.15s/it]
2025-10-12 21:09:17 | [A
2025-10-12 21:09:18 | 13%|█▎        | 8/63 [00:07<01:07,  1.22s/it]
2025-10-12 21:09:18 | [A
2025-10-12 21:09:20 | 14%|█▍        | 9/63 [00:09<01:08,  1.27s/it]
2025-10-12 21:09:20 | [A
2025-10-12 21:09:21 | 16%|█▌        | 10/63 [00:10<01:09,  1.31s/it]
2025-10-12 21:09:21 | [A
2025-10-12 21:09:21 | 100%|██████████| 1558/1558 [02:22<00:00, 15.66it/s]
2025-10-12 21:09:23 | 17%|█▋        | 11/63 [00:12<01:18,  1.51s/it]
2025-10-12 21:09:23 | [A
2025-10-12 21:09:25 | 19%|█▉        | 12/63 [00:14<01:15,  1.47s/it]
2025-10-12 21:09:25 | [A
2025-10-12 21:09:26 | 21%|██        | 13/63 [00:15<01:12,  1.44s/it]
2025-10-12 21:09:26 | [A
2025-10-12 21:09:27 | 22%|██▏       | 14/63 [00:16<01:12,  1.48s/it]
2025-10-12 21:09:27 | [A
2025-10-12 21:09:29 | 24%|██▍       | 15/63 [00:18<01:10,  1.46s/it]
2025-10-12 21:09:29 | [A
2025-10-12 21:09:30 | 25%|██▌       | 16/63 [00:19<01:07,  1.43s/it]
2025-10-12 21:09:30 | [A
2025-10-12 21:09:32 | 27%|██▋       | 17/63 [00:21<01:05,  1.43s/it]
2025-10-12 21:09:32 | [A
2025-10-12 21:09:33 | 29%|██▊       | 18/63 [00:22<01:04,  1.43s/it]
2025-10-12 21:09:33 | [A
2025-10-12 21:09:35 | 30%|███       | 19/63 [00:23<01:02,  1.42s/it]
2025-10-12 21:09:35 | [A
2025-10-12 21:09:36 | 32%|███▏      | 20/63 [00:25<01:01,  1.42s/it]
2025-10-12 21:09:36 | [A
2025-10-12 21:09:37 | 33%|███▎      | 21/63 [00:26<00:59,  1.41s/it]
2025-10-12 21:09:37 | [A
2025-10-12 21:09:39 | 35%|███▍      | 22/63 [00:28<00:57,  1.40s/it]
2025-10-12 21:09:39 | [A
2025-10-12 21:09:40 | 37%|███▋      | 23/63 [00:29<00:56,  1.41s/it]
2025-10-12 21:09:40 | [A
2025-10-12 21:09:42 | 38%|███▊      | 24/63 [00:30<00:54,  1.40s/it]
2025-10-12 21:09:42 | [A
2025-10-12 21:09:43 | 40%|███▉      | 25/63 [00:32<00:53,  1.40s/it]
2025-10-12 21:09:43 | [A
2025-10-12 21:09:44 | 41%|████▏     | 26/63 [00:33<00:51,  1.40s/it]
2025-10-12 21:09:44 | [A
2025-10-12 21:09:46 | 43%|████▎     | 27/63 [00:35<00:50,  1.39s/it]
2025-10-12 21:09:46 | [A
2025-10-12 21:09:47 | 44%|████▍     | 28/63 [00:36<00:48,  1.38s/it]
2025-10-12 21:09:47 | [A
2025-10-12 21:09:49 | 46%|████▌     | 29/63 [00:38<00:50,  1.50s/it]
2025-10-12 21:09:49 | [A
2025-10-12 21:09:51 | 48%|████▊     | 30/63 [00:40<00:52,  1.60s/it]
2025-10-12 21:09:51 | [A
2025-10-12 21:09:52 | 49%|████▉     | 31/63 [00:41<00:50,  1.59s/it]
2025-10-12 21:09:52 | [A
2025-10-12 21:09:54 | 51%|█████     | 32/63 [00:42<00:46,  1.51s/it]
2025-10-12 21:09:54 | [A
2025-10-12 21:09:55 | 52%|█████▏    | 33/63 [00:44<00:48,  1.63s/it]
2025-10-12 21:09:55 | [A
2025-10-12 21:09:57 | 54%|█████▍    | 34/63 [00:46<00:44,  1.53s/it]
2025-10-12 21:09:57 | [A
2025-10-12 21:09:58 | 56%|█████▌    | 35/63 [00:47<00:40,  1.44s/it]
2025-10-12 21:09:58 | [A
2025-10-12 21:09:59 | 57%|█████▋    | 36/63 [00:48<00:37,  1.41s/it]
2025-10-12 21:09:59 | [A
2025-10-12 21:10:01 | 59%|█████▊    | 37/63 [00:50<00:37,  1.44s/it]
2025-10-12 21:10:01 | [A
2025-10-12 21:10:02 | 60%|██████    | 38/63 [00:51<00:37,  1.51s/it]
2025-10-12 21:10:02 | [A
2025-10-12 21:10:04 | 62%|██████▏   | 39/63 [00:53<00:37,  1.57s/it]
2025-10-12 21:10:04 | [A
2025-10-12 21:10:06 | 63%|██████▎   | 40/63 [00:55<00:36,  1.58s/it]
2025-10-12 21:10:06 | [A
2025-10-12 21:10:08 | 65%|██████▌   | 41/63 [00:57<00:35,  1.63s/it]
2025-10-12 21:10:08 | [A
2025-10-12 21:10:09 | 67%|██████▋   | 42/63 [00:58<00:34,  1.62s/it]
2025-10-12 21:10:09 | [A
2025-10-12 21:10:11 | 68%|██████▊   | 43/63 [01:00<00:30,  1.55s/it]
2025-10-12 21:10:11 | [A
2025-10-12 21:10:12 | 70%|██████▉   | 44/63 [01:01<00:28,  1.50s/it]
2025-10-12 21:10:12 | [A
2025-10-12 21:10:14 | 71%|███████▏  | 45/63 [01:03<00:28,  1.58s/it]
2025-10-12 21:10:14 | [A
2025-10-12 21:10:15 | 73%|███████▎  | 46/63 [01:04<00:26,  1.59s/it]
2025-10-12 21:10:15 | [A
2025-10-12 21:10:17 | 75%|███████▍  | 47/63 [01:06<00:24,  1.52s/it]
2025-10-12 21:10:17 | [A
2025-10-12 21:10:18 | 76%|███████▌  | 48/63 [01:07<00:22,  1.47s/it]
2025-10-12 21:10:18 | [A
2025-10-12 21:10:19 | 78%|███████▊  | 49/63 [01:08<00:20,  1.44s/it]
2025-10-12 21:10:19 | [A
2025-10-12 21:10:21 | 79%|███████▉  | 50/63 [01:10<00:18,  1.42s/it]
2025-10-12 21:10:21 | [A
2025-10-12 21:10:22 | 81%|████████  | 51/63 [01:11<00:16,  1.40s/it]
2025-10-12 21:10:22 | [A
2025-10-12 21:10:23 | 83%|████████▎ | 52/63 [01:12<00:15,  1.39s/it]
2025-10-12 21:10:23 | [A
2025-10-12 21:10:25 | 84%|████████▍ | 53/63 [01:14<00:13,  1.38s/it]
2025-10-12 21:10:25 | [A
2025-10-12 21:10:26 | 86%|████████▌ | 54/63 [01:15<00:12,  1.38s/it]
2025-10-12 21:10:26 | [A
2025-10-12 21:10:28 | 87%|████████▋ | 55/63 [01:17<00:12,  1.56s/it]
2025-10-12 21:10:28 | [A
2025-10-12 21:10:30 | 89%|████████▉ | 56/63 [01:19<00:10,  1.52s/it]
2025-10-12 21:10:30 | [A
2025-10-12 21:10:31 | 90%|█████████ | 57/63 [01:20<00:08,  1.48s/it]
2025-10-12 21:10:31 | [A
2025-10-12 21:10:32 | 92%|█████████▏| 58/63 [01:21<00:07,  1.45s/it]
2025-10-12 21:10:32 | [A
2025-10-12 21:10:34 | 94%|█████████▎| 59/63 [01:23<00:05,  1.41s/it]
2025-10-12 21:10:34 | [A
2025-10-12 21:10:35 | 95%|█████████▌| 60/63 [01:24<00:04,  1.38s/it]
2025-10-12 21:10:35 | [A
2025-10-12 21:10:37 | 97%|█████████▋| 61/63 [01:26<00:02,  1.43s/it]
2025-10-12 21:10:37 | [A
2025-10-12 21:10:38 | 98%|█████████▊| 62/63 [01:27<00:01,  1.43s/it]
2025-10-12 21:10:38 | [A
2025-10-12 21:10:39 | 100%|██████████| 63/63 [01:28<00:00,  1.36s/it]
2025-10-12 21:10:39 | [A
2025-10-12 21:10:39 | [A
2025-10-12 21:10:39 | {'eval_loss': 1.4561810493469238, 'eval_rouge1': 0.4139675411971033, 'eval_rouge2': 0.2566087180363384, 'eval_rougeL': 0.40686549202329453, 'eval_rouge_sum': 1.0774417512567362, 'eval_runtime': 89.9542, 'eval_samples_per_second': 5.547, 'eval_steps_per_second': 0.7, 'epoch': 1.0}
2025-10-12 21:10:39 | 100%|██████████| 1558/1558 [03:40<00:00, 15.66it/s]
2025-10-12 21:10:39 | [A
2025-10-12 21:10:39 | [A
2025-10-12 21:10:41 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-12 21:10:41 | {'train_runtime': 222.2585, 'train_samples_per_second': 56.047, 'train_steps_per_second': 7.01, 'train_loss': 1.7073234048826245, 'epoch': 1.0}
2025-10-12 21:10:41 | 100%|██████████| 1558/1558 [03:42<00:00, 15.66it/s]
2025-10-12 21:10:41 | 최종 모델 저장 중...
2025-10-12 21:10:42 | → 모델 저장 위치: experiments/20251012/20251012_210652_test_full_pipeline_success/model_0_kobart/default/final_model
2025-10-12 21:10:42 | 최종 평가 중...
2025-10-12 21:10:44 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 21:10:46 | 3%|▎         | 2/63 [00:01<00:50,  1.22it/s]
2025-10-12 21:10:47 | 5%|▍         | 3/63 [00:03<01:06,  1.11s/it]
2025-10-12 21:10:49 | 6%|▋         | 4/63 [00:04<01:11,  1.21s/it]
2025-10-12 21:10:50 | 8%|▊         | 5/63 [00:05<01:13,  1.27s/it]
2025-10-12 21:10:52 | 10%|▉         | 6/63 [00:07<01:14,  1.31s/it]
2025-10-12 21:10:53 | 11%|█         | 7/63 [00:08<01:13,  1.32s/it]
2025-10-12 21:10:54 | 13%|█▎        | 8/63 [00:09<01:12,  1.32s/it]
2025-10-12 21:10:56 | 14%|█▍        | 9/63 [00:11<01:11,  1.33s/it]
2025-10-12 21:10:57 | 16%|█▌        | 10/63 [00:12<01:10,  1.33s/it]
2025-10-12 21:10:58 | 17%|█▋        | 11/63 [00:13<01:09,  1.33s/it]
2025-10-12 21:11:00 | 19%|█▉        | 12/63 [00:15<01:08,  1.33s/it]
2025-10-12 21:11:02 | 21%|██        | 13/63 [00:17<01:16,  1.54s/it]
2025-10-12 21:11:03 | 22%|██▏       | 14/63 [00:18<01:14,  1.51s/it]
2025-10-12 21:11:04 | 24%|██▍       | 15/63 [00:20<01:10,  1.48s/it]
2025-10-12 21:11:06 | 25%|██▌       | 16/63 [00:21<01:07,  1.45s/it]
2025-10-12 21:11:07 | 27%|██▋       | 17/63 [00:22<01:06,  1.44s/it]
2025-10-12 21:11:09 | 29%|██▊       | 18/63 [00:24<01:04,  1.42s/it]
2025-10-12 21:11:10 | 30%|███       | 19/63 [00:25<01:02,  1.42s/it]
2025-10-12 21:11:11 | 32%|███▏      | 20/63 [00:27<01:00,  1.40s/it]
2025-10-12 21:11:13 | 33%|███▎      | 21/63 [00:28<00:58,  1.40s/it]
2025-10-12 21:11:14 | 35%|███▍      | 22/63 [00:29<00:57,  1.39s/it]
2025-10-12 21:11:16 | 37%|███▋      | 23/63 [00:31<00:55,  1.39s/it]
2025-10-12 21:11:17 | 38%|███▊      | 24/63 [00:32<00:53,  1.38s/it]
2025-10-12 21:11:18 | 40%|███▉      | 25/63 [00:33<00:51,  1.37s/it]
2025-10-12 21:11:20 | 41%|████▏     | 26/63 [00:35<00:49,  1.35s/it]
2025-10-12 21:11:21 | 43%|████▎     | 27/63 [00:36<00:51,  1.43s/it]
2025-10-12 21:11:23 | 44%|████▍     | 28/63 [00:38<00:52,  1.49s/it]
2025-10-12 21:11:24 | 46%|████▌     | 29/63 [00:39<00:49,  1.47s/it]
2025-10-12 21:11:26 | 48%|████▊     | 30/63 [00:41<00:48,  1.48s/it]
2025-10-12 21:11:27 | 49%|████▉     | 31/63 [00:42<00:46,  1.45s/it]
2025-10-12 21:11:28 | 51%|█████     | 32/63 [00:44<00:44,  1.42s/it]
2025-10-12 21:11:30 | 52%|█████▏    | 33/63 [00:45<00:42,  1.40s/it]
2025-10-12 21:11:31 | 54%|█████▍    | 34/63 [00:46<00:40,  1.40s/it]
2025-10-12 21:11:33 | 56%|█████▌    | 35/63 [00:48<00:38,  1.39s/it]
2025-10-12 21:11:34 | 57%|█████▋    | 36/63 [00:50<00:42,  1.56s/it]
2025-10-12 21:11:36 | 59%|█████▊    | 37/63 [00:51<00:39,  1.51s/it]
2025-10-12 21:11:37 | 60%|██████    | 38/63 [00:53<00:36,  1.47s/it]
2025-10-12 21:11:39 | 62%|██████▏   | 39/63 [00:54<00:34,  1.45s/it]
2025-10-12 21:11:40 | 63%|██████▎   | 40/63 [00:55<00:33,  1.44s/it]
2025-10-12 21:11:42 | 65%|██████▌   | 41/63 [00:57<00:32,  1.47s/it]
2025-10-12 21:11:43 | 67%|██████▋   | 42/63 [00:59<00:32,  1.56s/it]
2025-10-12 21:11:45 | 68%|██████▊   | 43/63 [01:00<00:30,  1.54s/it]
2025-10-12 21:11:46 | 70%|██████▉   | 44/63 [01:02<00:28,  1.48s/it]
2025-10-12 21:11:48 | 71%|███████▏  | 45/63 [01:03<00:25,  1.44s/it]
2025-10-12 21:11:49 | 73%|███████▎  | 46/63 [01:04<00:25,  1.49s/it]
2025-10-12 21:11:51 | 75%|███████▍  | 47/63 [01:06<00:23,  1.45s/it]
2025-10-12 21:11:52 | 76%|███████▌  | 48/63 [01:07<00:21,  1.42s/it]
2025-10-12 21:11:53 | 78%|███████▊  | 49/63 [01:08<00:19,  1.38s/it]
2025-10-12 21:11:55 | 79%|███████▉  | 50/63 [01:10<00:17,  1.37s/it]
2025-10-12 21:11:56 | 81%|████████  | 51/63 [01:12<00:17,  1.47s/it]
2025-10-12 21:11:58 | 83%|████████▎ | 52/63 [01:13<00:16,  1.46s/it]
2025-10-12 21:11:59 | 84%|████████▍ | 53/63 [01:14<00:14,  1.43s/it]
2025-10-12 21:12:00 | 86%|████████▌ | 54/63 [01:16<00:12,  1.41s/it]
2025-10-12 21:12:02 | 87%|████████▋ | 55/63 [01:17<00:12,  1.51s/it]
2025-10-12 21:12:04 | 89%|████████▉ | 56/63 [01:19<00:10,  1.52s/it]
2025-10-12 21:12:05 | 90%|█████████ | 57/63 [01:20<00:08,  1.47s/it]
2025-10-12 21:12:07 | 92%|█████████▏| 58/63 [01:22<00:08,  1.60s/it]
2025-10-12 21:12:08 | 94%|█████████▎| 59/63 [01:24<00:06,  1.52s/it]
2025-10-12 21:12:10 | 95%|█████████▌| 60/63 [01:25<00:04,  1.46s/it]
2025-10-12 21:12:11 | 97%|█████████▋| 61/63 [01:26<00:02,  1.48s/it]
2025-10-12 21:12:13 | 98%|█████████▊| 62/63 [01:28<00:01,  1.50s/it]
2025-10-12 21:12:14 | 100%|██████████| 63/63 [01:29<00:00,  1.45s/it]
2025-10-12 21:12:14 | 최종 평가 결과:
2025-10-12 21:12:14 | eval_rouge1: 0.4140
2025-10-12 21:12:14 | eval_rouge2: 0.2566
2025-10-12 21:12:14 | eval_rougeL: 0.4069
2025-10-12 21:12:14 | eval_rouge_sum: 1.0774
2025-10-12 21:12:14 | ============================================================
2025-10-12 21:12:14 | ✅ 학습 완료!
2025-10-12 21:12:14 | ============================================================
2025-10-12 21:12:14 | ✅ kobart 학습 완료
2025-10-12 21:12:14 | ==================================================
2025-10-12 21:12:14 | 모델 2/6: llama-3.2-korean-3b
2025-10-12 21:12:14 | ==================================================
2025-10-12 21:12:14 | 모델 타입: causal_lm
2025-10-12 21:12:14 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-12 21:12:14 | 모델 로딩 중...
2025-10-12 21:12:14 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-12 21:12:14 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-12 21:12:16 | Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.89s/it]
2025-10-12 21:12:17 | Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]
2025-10-12 21:12:17 | 토크나이저 로딩 중...
2025-10-12 21:12:18 | 패딩 토큰 설정: <|eot_id|>
2025-10-12 21:12:18 | LoRA 설정 적용 중...
2025-10-12 21:12:19 | ✅ LoRA 적용 완료
2025-10-12 21:12:19 | 학습 가능 파라미터: 24,313,856 (0.75%)
2025-10-12 21:12:19 | 전체 파라미터: 3,237,063,680
2025-10-12 21:12:19 | Input require grads 활성화 (LoRA + Gradient Checkpointing)
2025-10-12 21:12:19 | ✅ Gradient Checkpointing 활성화
2025-10-12 21:12:19 | ✅ Causal LM 로드 완료
2025-10-12 21:12:19 | ============================================================
2025-10-12 21:12:19 | 모델 학습 시작
2025-10-12 21:12:19 | ============================================================
2025-10-12 21:12:19 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 21:12:19 | The model is already on multiple devices. Skipping the move to device specified in `args`.
2025-10-12 21:12:19 | 학습 진행 중...
2025-10-12 21:12:19 | The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
2025-10-12 21:12:19 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 21:17:49 | 1%|          | 8/1558 [05:29<6:01:06, 13.98s/it]
2025-10-12 21:17:55 | {'loss': 1.6248, 'grad_norm': 2.0260937213897705, 'learning_rate': 9e-08, 'epoch': 0.01}
2025-10-12 21:17:55 | 1%|          | 10/1558 [05:35<3:33:48,  8.29s/it]
2025-10-12 21:18:28 | {'loss': 1.5723, 'grad_norm': 2.1121692657470703, 'learning_rate': 1.9e-07, 'epoch': 0.01}
2025-10-12 21:18:28 | 1%|▏         | 20/1558 [06:08<1:23:32,  3.26s/it]
2025-10-12 21:18:43 | 2%|▏         | 24/1558 [06:23<1:35:24,  3.73s/it]
2025-10-12 21:19:04 | {'loss': 1.6231, 'grad_norm': 1.6558647155761719, 'learning_rate': 2.9000000000000003e-07, 'epoch': 0.02}
2025-10-12 21:19:04 | 2%|▏         | 30/1558 [06:44<1:29:17,  3.51s/it]
2025-10-12 21:19:38 | 3%|▎         | 39/1558 [07:18<1:30:53,  3.59s/it]
2025-10-12 21:19:41 | {'loss': 1.6449, 'grad_norm': 1.982552409172058, 'learning_rate': 3.9e-07, 'epoch': 0.03}
2025-10-12 21:19:41 | 3%|▎         | 40/1558 [07:21<1:28:46,  3.51s/it]
2025-10-12 21:20:15 | {'loss': 1.5791, 'grad_norm': 1.8338807821273804, 'learning_rate': 4.900000000000001e-07, 'epoch': 0.03}
2025-10-12 21:20:15 | 3%|▎         | 50/1558 [07:55<1:18:57,  3.14s/it]
2025-10-12 21:20:30 | 4%|▎         | 55/1558 [08:10<1:15:24,  3.01s/it]
2025-10-12 21:20:45 | {'loss': 1.6087, 'grad_norm': 1.7342654466629028, 'learning_rate': 5.900000000000001e-07, 'epoch': 0.04}
2025-10-12 21:20:45 | 4%|▍         | 60/1558 [08:25<1:12:43,  2.91s/it]
2025-10-12 21:21:14 | {'loss': 1.6157, 'grad_norm': 2.483124017715454, 'learning_rate': 6.900000000000001e-07, 'epoch': 0.04}
2025-10-12 21:21:14 | 4%|▍         | 70/1558 [08:55<1:12:14,  2.91s/it]
2025-10-12 21:21:17 | 5%|▍         | 71/1558 [08:57<1:12:07,  2.91s/it]
2025-10-12 21:21:44 | {'loss': 1.6359, 'grad_norm': 2.1355130672454834, 'learning_rate': 7.900000000000001e-07, 'epoch': 0.05}
2025-10-12 21:21:44 | 5%|▌         | 80/1558 [09:24<1:11:57,  2.92s/it]
2025-10-12 21:22:02 | 6%|▌         | 86/1558 [09:42<1:14:47,  3.05s/it]
2025-10-12 21:22:14 | {'loss': 1.566, 'grad_norm': 2.1057934761047363, 'learning_rate': 8.900000000000001e-07, 'epoch': 0.06}
2025-10-12 21:22:14 | 6%|▌         | 90/1558 [09:54<1:11:45,  2.93s/it]
2025-10-12 21:22:44 | {'loss': 1.6224, 'grad_norm': 2.015709400177002, 'learning_rate': 9.9e-07, 'epoch': 0.06}
2025-10-12 21:22:44 | 6%|▋         | 100/1558 [10:24<1:11:38,  2.95s/it]
2025-10-12 21:22:49 | 7%|▋         | 102/1558 [10:29<1:11:03,  2.93s/it]
2025-10-12 21:23:13 | {'loss': 1.5647, 'grad_norm': 1.6748429536819458, 'learning_rate': 1.0900000000000002e-06, 'epoch': 0.07}
2025-10-12 21:23:13 | 7%|▋         | 110/1558 [10:53<1:11:36,  2.97s/it]
2025-10-12 21:23:34 | 8%|▊         | 117/1558 [11:14<1:09:57,  2.91s/it]
2025-10-12 21:23:43 | {'loss': 1.5591, 'grad_norm': 1.9124680757522583, 'learning_rate': 1.19e-06, 'epoch': 0.08}
2025-10-12 21:23:43 | 8%|▊         | 120/1558 [11:23<1:15:33,  3.15s/it]
2025-10-12 21:24:15 | {'loss': 1.5636, 'grad_norm': 1.8828574419021606, 'learning_rate': 1.2900000000000001e-06, 'epoch': 0.08}
2025-10-12 21:24:15 | 8%|▊         | 130/1558 [11:55<1:19:19,  3.33s/it]
2025-10-12 21:24:24 | 9%|▊         | 133/1558 [12:04<1:13:27,  3.09s/it]
2025-10-12 21:24:46 | {'loss': 1.4501, 'grad_norm': 1.7867604494094849, 'learning_rate': 1.3900000000000002e-06, 'epoch': 0.09}
2025-10-12 21:24:46 | 9%|▉         | 140/1558 [12:26<1:17:00,  3.26s/it]
2025-10-12 21:25:14 | 10%|▉         | 149/1558 [12:54<1:13:04,  3.11s/it]
2025-10-12 21:25:18 | {'loss': 1.5337, 'grad_norm': 1.7558077573776245, 'learning_rate': 1.4900000000000001e-06, 'epoch': 0.1}
2025-10-12 21:25:18 | 10%|▉         | 150/1558 [12:58<1:18:26,  3.34s/it]
2025-10-12 21:25:47 | {'loss': 1.411, 'grad_norm': 1.825000524520874, 'learning_rate': 1.5900000000000002e-06, 'epoch': 0.1}
2025-10-12 21:25:47 | 10%|█         | 160/1558 [13:27<1:07:58,  2.92s/it]
2025-10-12 21:25:59 | 11%|█         | 164/1558 [13:40<1:09:13,  2.98s/it]
2025-10-12 21:26:17 | {'loss': 1.4298, 'grad_norm': 1.9290547370910645, 'learning_rate': 1.6900000000000003e-06, 'epoch': 0.11}
2025-10-12 21:26:17 | 11%|█         | 170/1558 [13:57<1:07:15,  2.91s/it]
2025-10-12 21:26:47 | 12%|█▏        | 180/1558 [14:27<1:06:56,  2.92s/it]
2025-10-12 21:26:47 | {'loss': 1.369, 'grad_norm': 1.9755674600601196, 'learning_rate': 1.79e-06, 'epoch': 0.12}
2025-10-12 21:26:47 | 12%|█▏        | 180/1558 [14:27<1:06:56,  2.92s/it]
2025-10-12 21:27:21 | {'loss': 1.3959, 'grad_norm': 2.018749713897705, 'learning_rate': 1.8900000000000001e-06, 'epoch': 0.12}
2025-10-12 21:27:21 | 12%|█▏        | 190/1558 [15:01<1:23:10,  3.65s/it]
2025-10-12 21:27:37 | 13%|█▎        | 195/1558 [15:17<1:12:05,  3.17s/it]
2025-10-12 21:27:53 | {'loss': 1.3611, 'grad_norm': 1.7554312944412231, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.13}
2025-10-12 21:27:53 | 13%|█▎        | 200/1558 [15:33<1:11:19,  3.15s/it]
2025-10-12 21:28:25 | {'loss': 1.4014, 'grad_norm': 1.555174469947815, 'learning_rate': 2.09e-06, 'epoch': 0.13}
2025-10-12 21:28:25 | 13%|█▎        | 210/1558 [16:05<1:11:04,  3.16s/it]
2025-10-12 21:28:28 | 14%|█▎        | 211/1558 [16:08<1:09:43,  3.11s/it]
2025-10-12 21:28:55 | {'loss': 1.4433, 'grad_norm': 2.096745491027832, 'learning_rate': 2.19e-06, 'epoch': 0.14}
2025-10-12 21:28:55 | 14%|█▍        | 220/1558 [16:35<1:06:29,  2.98s/it]
2025-10-12 21:29:14 | 15%|█▍        | 226/1558 [16:54<1:08:23,  3.08s/it]
2025-10-12 21:29:27 | {'loss': 1.3526, 'grad_norm': 1.9017237424850464, 'learning_rate': 2.29e-06, 'epoch': 0.15}
2025-10-12 21:29:27 | 15%|█▍        | 230/1558 [17:07<1:10:38,  3.19s/it]
2025-10-12 21:30:00 | {'loss': 1.4157, 'grad_norm': 1.548293948173523, 'learning_rate': 2.39e-06, 'epoch': 0.15}
2025-10-12 21:30:00 | 15%|█▌        | 240/1558 [17:40<1:08:27,  3.12s/it]
2025-10-12 21:30:07 | 16%|█▌        | 242/1558 [17:47<1:09:16,  3.16s/it]
2025-10-12 21:30:32 | {'loss': 1.3324, 'grad_norm': 1.7229104042053223, 'learning_rate': 2.4900000000000003e-06, 'epoch': 0.16}
2025-10-12 21:30:32 | 16%|█▌        | 250/1558 [18:12<1:05:13,  2.99s/it]
2025-10-12 21:30:58 | 17%|█▋        | 258/1558 [18:38<1:09:17,  3.20s/it]
2025-10-12 21:31:04 | {'loss': 1.2984, 'grad_norm': 1.9131561517715454, 'learning_rate': 2.59e-06, 'epoch': 0.17}
2025-10-12 21:31:04 | 17%|█▋        | 260/1558 [18:44<1:08:33,  3.17s/it]
2025-10-12 21:31:35 | {'loss': 1.3497, 'grad_norm': 2.1612422466278076, 'learning_rate': 2.6900000000000005e-06, 'epoch': 0.17}
2025-10-12 21:31:35 | 17%|█▋        | 270/1558 [19:15<1:05:22,  3.05s/it]
2025-10-12 21:31:45 | 18%|█▊        | 273/1558 [19:25<1:05:47,  3.07s/it]
2025-10-12 21:32:07 | {'loss': 1.3468, 'grad_norm': 1.5572922229766846, 'learning_rate': 2.7900000000000004e-06, 'epoch': 0.18}
2025-10-12 21:32:07 | 18%|█▊        | 280/1558 [19:47<1:07:28,  3.17s/it]
2025-10-12 21:32:36 | 19%|█▊        | 289/1558 [20:16<1:07:18,  3.18s/it]
2025-10-12 21:32:39 | {'loss': 1.3282, 'grad_norm': 1.9271619319915771, 'learning_rate': 2.89e-06, 'epoch': 0.19}
2025-10-12 21:32:39 | 19%|█▊        | 290/1558 [20:19<1:09:09,  3.27s/it]
2025-10-12 21:33:12 | {'loss': 1.3433, 'grad_norm': 1.7323131561279297, 'learning_rate': 2.99e-06, 'epoch': 0.19}
2025-10-12 21:33:12 | 19%|█▉        | 300/1558 [20:52<1:07:15,  3.21s/it]
2025-10-12 21:33:26 | 20%|█▉        | 304/1558 [21:06<1:11:14,  3.41s/it]
2025-10-12 21:33:45 | {'loss': 1.2584, 'grad_norm': 1.6165350675582886, 'learning_rate': 3.09e-06, 'epoch': 0.2}
2025-10-12 21:33:45 | 20%|█▉        | 310/1558 [21:25<1:03:56,  3.07s/it]
2025-10-12 21:34:20 | 21%|██        | 320/1558 [22:00<1:07:17,  3.26s/it]
2025-10-12 21:34:20 | {'loss': 1.2807, 'grad_norm': 2.049516439437866, 'learning_rate': 3.1900000000000004e-06, 'epoch': 0.21}
2025-10-12 21:34:20 | 21%|██        | 320/1558 [22:00<1:07:17,  3.26s/it]
2025-10-12 21:34:51 | {'loss': 1.3373, 'grad_norm': 2.235142707824707, 'learning_rate': 3.2900000000000003e-06, 'epoch': 0.21}
2025-10-12 21:34:51 | 21%|██        | 330/1558 [22:31<1:02:39,  3.06s/it]
2025-10-12 21:35:07 | 22%|██▏       | 335/1558 [22:47<1:05:20,  3.21s/it]
2025-10-12 21:35:23 | {'loss': 1.2708, 'grad_norm': 2.0826990604400635, 'learning_rate': 3.3900000000000006e-06, 'epoch': 0.22}
2025-10-12 21:35:23 | 22%|██▏       | 340/1558 [23:03<1:03:12,  3.11s/it]
2025-10-12 21:35:55 | {'loss': 1.3154, 'grad_norm': 2.0919530391693115, 'learning_rate': 3.49e-06, 'epoch': 0.22}
2025-10-12 21:35:55 | 22%|██▏       | 350/1558 [23:35<1:02:05,  3.08s/it]
2025-10-12 21:35:58 | 23%|██▎       | 351/1558 [23:38<1:01:29,  3.06s/it]
2025-10-12 21:36:27 | {'loss': 1.3374, 'grad_norm': 2.1606290340423584, 'learning_rate': 3.5900000000000004e-06, 'epoch': 0.23}
2025-10-12 21:36:27 | 23%|██▎       | 360/1558 [24:07<1:06:25,  3.33s/it]
2025-10-12 21:36:50 | 24%|██▎       | 367/1558 [24:30<1:05:01,  3.28s/it]
2025-10-12 21:36:59 | {'loss': 1.2634, 'grad_norm': 1.8016483783721924, 'learning_rate': 3.6900000000000002e-06, 'epoch': 0.24}
2025-10-12 21:36:59 | 24%|██▎       | 370/1558 [24:39<1:04:17,  3.25s/it]
2025-10-12 21:37:33 | {'loss': 1.2743, 'grad_norm': 1.9884898662567139, 'learning_rate': 3.79e-06, 'epoch': 0.24}
2025-10-12 21:37:33 | 24%|██▍       | 380/1558 [25:13<1:04:54,  3.31s/it]
2025-10-12 21:37:40 | 25%|██▍       | 382/1558 [25:20<1:04:16,  3.28s/it]
2025-10-12 21:38:07 | {'loss': 1.2711, 'grad_norm': 2.756213426589966, 'learning_rate': 3.89e-06, 'epoch': 0.25}
2025-10-12 21:38:07 | 25%|██▌       | 390/1558 [25:47<1:08:19,  3.51s/it]
2025-10-12 21:38:32 | 26%|██▌       | 398/1558 [26:12<1:01:48,  3.20s/it]
2025-10-12 21:38:38 | {'loss': 1.2614, 'grad_norm': 2.1957600116729736, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.26}
2025-10-12 21:38:38 | 26%|██▌       | 400/1558 [26:18<1:00:20,  3.13s/it]
2025-10-12 21:39:09 | {'loss': 1.2993, 'grad_norm': 2.3474626541137695, 'learning_rate': 4.09e-06, 'epoch': 0.26}
2025-10-12 21:39:09 | 26%|██▋       | 410/1558 [26:49<59:13,  3.10s/it]
2025-10-12 21:39:18 | 27%|██▋       | 413/1558 [26:58<58:41,  3.08s/it]
2025-10-12 21:39:41 | {'loss': 1.1924, 'grad_norm': 2.0271358489990234, 'learning_rate': 4.1900000000000005e-06, 'epoch': 0.27}
2025-10-12 21:39:41 | 27%|██▋       | 420/1558 [27:21<1:02:46,  3.31s/it]
2025-10-12 21:40:11 | 28%|██▊       | 429/1558 [27:51<1:03:25,  3.37s/it]
2025-10-12 21:40:14 | {'loss': 1.1651, 'grad_norm': 1.7672876119613647, 'learning_rate': 4.2900000000000004e-06, 'epoch': 0.28}
2025-10-12 21:40:14 | 28%|██▊       | 430/1558 [27:54<1:02:05,  3.30s/it]
2025-10-12 21:40:47 | {'loss': 1.1854, 'grad_norm': 1.9559288024902344, 'learning_rate': 4.39e-06, 'epoch': 0.28}
2025-10-12 21:40:47 | 28%|██▊       | 440/1558 [28:27<1:01:12,  3.28s/it]
2025-10-12 21:41:03 | 29%|██▊       | 445/1558 [28:43<1:00:35,  3.27s/it]
2025-10-12 21:41:19 | {'loss': 1.2245, 'grad_norm': 2.146660804748535, 'learning_rate': 4.49e-06, 'epoch': 0.29}
2025-10-12 21:41:19 | 29%|██▉       | 450/1558 [28:59<1:00:09,  3.26s/it]
2025-10-12 21:41:52 | 30%|██▉       | 460/1558 [29:32<1:01:26,  3.36s/it]
2025-10-12 21:41:52 | {'loss': 1.2121, 'grad_norm': 1.879392385482788, 'learning_rate': 4.590000000000001e-06, 'epoch': 0.3}
2025-10-12 21:41:52 | 30%|██▉       | 460/1558 [29:32<1:01:26,  3.36s/it]
2025-10-12 21:42:27 | {'loss': 1.2096, 'grad_norm': 2.3265671730041504, 'learning_rate': 4.69e-06, 'epoch': 0.3}
2025-10-12 21:42:27 | 30%|███       | 470/1558 [30:07<1:01:32,  3.39s/it]
