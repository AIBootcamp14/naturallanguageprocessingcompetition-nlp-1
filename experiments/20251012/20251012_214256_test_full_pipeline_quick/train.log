2025-10-12 21:42:56 | >> 표준 출력 및 오류를 로그 파일로 리디렉션 시작
2025-10-12 21:42:58 | 📊 FULL 모드 실행 중...
2025-10-12 21:42:58 | ============================================================
2025-10-12 21:42:58 | = FULL PIPELINE 실행 시작
2025-10-12 21:42:58 | =대상 모델: kobart, llama-3.2-korean-3b, qwen3-4b, solar-10.7b, polyglot-ko-12.8b, kullm-v2
2025-10-12 21:42:58 | =앙상블 앙상블 전략: stacking
2025-10-12 21:42:58 | = TTA 사용: True
2025-10-12 21:42:58 | ============================================================
2025-10-12 21:42:58 | [1/6] 데이터 로딩...
2025-10-12 21:42:58 | ✅ 학습 데이터: 12457개
2025-10-12 21:42:58 | ✅ 검증 데이터: 499개
2025-10-12 21:42:58 | [2/6] 다중 모델 학습 (6 모델)...
2025-10-12 21:42:58 | ==================================================
2025-10-12 21:42:58 | 모델 1/6: kobart
2025-10-12 21:42:58 | ==================================================
2025-10-12 21:42:58 | 모델 타입: encoder_decoder
2025-10-12 21:42:58 | ============================================================
2025-10-12 21:42:58 | 모델 및 토크나이저 로딩 시작
2025-10-12 21:42:58 | ============================================================
2025-10-12 21:42:58 | 토크나이저 로딩: digit82/kobart-summarization
2025-10-12 21:42:58 | 모델 로딩: digit82/kobart-summarization
2025-10-12 21:42:59 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 21:43:00 | → 디바이스: cuda
2025-10-12 21:43:00 | → 전체 파라미터: 123,859,968
2025-10-12 21:43:00 | → 학습 가능 파라미터: 123,859,968
2025-10-12 21:43:00 | ============================================================
2025-10-12 21:43:00 | ✅ 모델 및 토크나이저 로딩 완료
2025-10-12 21:43:00 | ============================================================
2025-10-12 21:43:00 | ============================================================
2025-10-12 21:43:00 | 모델 학습 시작
2025-10-12 21:43:00 | ============================================================
2025-10-12 21:43:00 | /home/ieyeppo/AI_Lab/natural-language-processing-competition/src/training/trainer.py:218: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
2025-10-12 21:43:00 | 학습 진행 중...
2025-10-12 21:43:00 | 0%|          | 0/1558 [00:00<?, ?it/s]
2025-10-12 21:43:01 | 1%|          | 9/1558 [00:00<01:51, 13.83it/s]
2025-10-12 21:43:02 | 2%|▏         | 24/1558 [00:01<01:13, 20.94it/s]
2025-10-12 21:43:03 | 3%|▎         | 39/1558 [00:02<01:10, 21.50it/s]
2025-10-12 21:43:03 | 4%|▎         | 57/1558 [00:03<01:06, 22.56it/s]
2025-10-12 21:43:04 | 5%|▍         | 72/1558 [00:03<01:07, 21.92it/s]
2025-10-12 21:43:05 | 6%|▌         | 87/1558 [00:04<01:02, 23.38it/s]
2025-10-12 21:43:05 | {'loss': 2.747, 'grad_norm': 8.181581497192383, 'learning_rate': 9.9e-07, 'epoch': 0.06}
2025-10-12 21:43:05 | 6%|▋         | 100/1558 [00:04<01:02, 23.27it/s]
2025-10-12 21:43:05 | 7%|▋         | 102/1558 [00:04<01:05, 22.39it/s]
2025-10-12 21:43:06 | 8%|▊         | 117/1558 [00:05<01:04, 22.47it/s]
2025-10-12 21:43:07 | 9%|▊         | 135/1558 [00:06<01:04, 21.97it/s]
2025-10-12 21:43:07 | 10%|▉         | 150/1558 [00:07<01:01, 22.95it/s]
2025-10-12 21:43:08 | 11%|█         | 165/1558 [00:07<00:58, 23.63it/s]
2025-10-12 21:43:09 | 12%|█▏        | 180/1558 [00:08<00:58, 23.75it/s]
2025-10-12 21:43:09 | 13%|█▎        | 195/1558 [00:09<00:59, 23.09it/s]
2025-10-12 21:43:10 | {'loss': 2.0335, 'grad_norm': 10.255390167236328, 'learning_rate': 1.9900000000000004e-06, 'epoch': 0.13}
2025-10-12 21:43:10 | 13%|█▎        | 200/1558 [00:09<01:00, 22.28it/s]
2025-10-12 21:43:10 | 14%|█▎        | 213/1558 [00:09<00:57, 23.36it/s]
2025-10-12 21:43:11 | 15%|█▍        | 228/1558 [00:10<00:55, 23.77it/s]
2025-10-12 21:43:11 | 16%|█▌        | 243/1558 [00:11<00:58, 22.41it/s]
2025-10-12 21:43:12 | 17%|█▋        | 258/1558 [00:11<00:56, 22.92it/s]
2025-10-12 21:43:13 | 18%|█▊        | 273/1558 [00:12<00:53, 23.86it/s]
2025-10-12 21:43:14 | 19%|█▊        | 291/1558 [00:13<00:56, 22.44it/s]
2025-10-12 21:43:14 | {'loss': 1.854, 'grad_norm': 6.36118745803833, 'learning_rate': 2.99e-06, 'epoch': 0.19}
2025-10-12 21:43:14 | 19%|█▉        | 300/1558 [00:13<00:57, 21.78it/s]
2025-10-12 21:43:14 | 20%|█▉        | 306/1558 [00:13<00:56, 22.24it/s]
2025-10-12 21:43:15 | 21%|██        | 321/1558 [00:14<00:53, 23.24it/s]
2025-10-12 21:43:16 | 22%|██▏       | 336/1558 [00:15<00:53, 22.66it/s]
2025-10-12 21:43:16 | 23%|██▎       | 351/1558 [00:15<00:55, 21.89it/s]
2025-10-12 21:43:17 | 24%|██▎       | 369/1558 [00:16<00:54, 21.90it/s]
2025-10-12 21:43:18 | 25%|██▍       | 384/1558 [00:17<00:53, 22.14it/s]
2025-10-12 21:43:18 | 26%|██▌       | 399/1558 [00:18<00:51, 22.42it/s]
2025-10-12 21:43:18 | {'loss': 1.7595, 'grad_norm': 6.68107795715332, 'learning_rate': 3.990000000000001e-06, 'epoch': 0.26}
2025-10-12 21:43:18 | 26%|██▌       | 400/1558 [00:18<00:51, 22.42it/s]
2025-10-12 21:43:19 | 27%|██▋       | 414/1558 [00:18<00:50, 22.79it/s]
2025-10-12 21:43:20 | 28%|██▊       | 429/1558 [00:19<00:53, 20.96it/s]
2025-10-12 21:43:21 | 29%|██▊       | 447/1558 [00:20<00:50, 22.15it/s]
2025-10-12 21:43:21 | 30%|██▉       | 462/1558 [00:20<00:48, 22.79it/s]
2025-10-12 21:43:22 | 31%|███       | 477/1558 [00:21<00:48, 22.34it/s]
2025-10-12 21:43:23 | 32%|███▏      | 492/1558 [00:22<01:42, 10.37it/s]
2025-10-12 21:43:24 | {'loss': 1.6645, 'grad_norm': 5.663431644439697, 'learning_rate': 4.9900000000000005e-06, 'epoch': 0.32}
2025-10-12 21:43:24 | 32%|███▏      | 500/1558 [00:23<01:09, 15.14it/s]
2025-10-12 21:43:24 | 33%|███▎      | 509/1558 [00:23<00:57, 18.20it/s]
2025-10-12 21:43:25 | 34%|███▎      | 524/1558 [00:24<00:45, 22.50it/s]
2025-10-12 21:43:25 | 35%|███▍      | 539/1558 [00:25<00:44, 22.94it/s]
2025-10-12 21:43:26 | 36%|███▌      | 554/1558 [00:25<00:45, 22.11it/s]
2025-10-12 21:43:27 | 37%|███▋      | 569/1558 [00:26<00:41, 24.09it/s]
2025-10-12 21:43:28 | 38%|███▊      | 587/1558 [00:27<00:43, 22.36it/s]
2025-10-12 21:43:28 | {'loss': 1.6315, 'grad_norm': 6.636142253875732, 'learning_rate': 4.532136105860114e-06, 'epoch': 0.39}
2025-10-12 21:43:28 | 39%|███▊      | 600/1558 [00:27<00:42, 22.54it/s]
2025-10-12 21:43:29 | 40%|███▉      | 617/1558 [00:28<00:39, 23.81it/s]
2025-10-12 21:43:29 | 41%|████      | 632/1558 [00:29<00:40, 23.09it/s]
2025-10-12 21:43:30 | 42%|████▏     | 647/1558 [00:29<00:40, 22.42it/s]
2025-10-12 21:43:31 | 43%|████▎     | 665/1558 [00:30<00:39, 22.80it/s]
2025-10-12 21:43:32 | 44%|████▎     | 680/1558 [00:31<00:38, 22.52it/s]
2025-10-12 21:43:32 | 45%|████▍     | 695/1558 [00:31<00:38, 22.29it/s]
2025-10-12 21:43:33 | {'loss': 1.6049, 'grad_norm': 7.678301811218262, 'learning_rate': 4.059546313799622e-06, 'epoch': 0.45}
2025-10-12 21:43:33 | 45%|████▍     | 700/1558 [00:32<00:37, 22.69it/s]
2025-10-12 21:43:33 | 46%|████▌     | 710/1558 [00:32<00:36, 23.17it/s]
2025-10-12 21:43:34 | 47%|████▋     | 725/1558 [00:33<00:38, 21.87it/s]
2025-10-12 21:43:34 | 48%|████▊     | 743/1558 [00:34<00:37, 21.91it/s]
2025-10-12 21:43:35 | 49%|████▊     | 758/1558 [00:34<00:37, 21.59it/s]
2025-10-12 21:43:36 | 50%|████▉     | 773/1558 [00:35<00:35, 21.96it/s]
2025-10-12 21:43:36 | 51%|█████     | 788/1558 [00:36<00:33, 22.84it/s]
2025-10-12 21:43:37 | {'loss': 1.5706, 'grad_norm': 5.508754730224609, 'learning_rate': 3.5869565217391305e-06, 'epoch': 0.51}
2025-10-12 21:43:37 | 51%|█████▏    | 800/1558 [00:36<00:32, 23.56it/s]
2025-10-12 21:43:37 | 52%|█████▏    | 803/1558 [00:36<00:31, 23.65it/s]
2025-10-12 21:43:38 | 53%|█████▎    | 818/1558 [00:37<00:30, 24.18it/s]
2025-10-12 21:43:39 | 54%|█████▎    | 836/1558 [00:38<00:32, 22.53it/s]
2025-10-12 21:43:39 | 55%|█████▍    | 851/1558 [00:38<00:32, 21.88it/s]
2025-10-12 21:43:40 | 56%|█████▌    | 866/1558 [00:39<00:28, 24.29it/s]
2025-10-12 21:43:40 | 57%|█████▋    | 881/1558 [00:40<00:28, 23.64it/s]
2025-10-12 21:43:41 | 58%|█████▊    | 896/1558 [00:40<00:29, 22.42it/s]
2025-10-12 21:43:41 | {'loss': 1.5792, 'grad_norm': 6.100878715515137, 'learning_rate': 3.114366729678639e-06, 'epoch': 0.58}
2025-10-12 21:43:41 | 58%|█████▊    | 900/1558 [00:41<00:28, 22.95it/s]
2025-10-12 21:43:42 | 59%|█████▊    | 914/1558 [00:41<00:27, 23.05it/s]
2025-10-12 21:43:43 | 60%|█████▉    | 929/1558 [00:42<00:27, 22.95it/s]
2025-10-12 21:43:43 | 61%|██████    | 944/1558 [00:42<00:27, 22.55it/s]
2025-10-12 21:43:44 | 62%|██████▏   | 959/1558 [00:43<00:28, 21.22it/s]
2025-10-12 21:43:45 | 63%|██████▎   | 974/1558 [00:44<00:26, 21.98it/s]
2025-10-12 21:43:45 | 64%|██████▎   | 992/1558 [00:45<00:25, 22.59it/s]
2025-10-12 21:43:46 | {'loss': 1.5576, 'grad_norm': 5.244472026824951, 'learning_rate': 2.641776937618148e-06, 'epoch': 0.64}
2025-10-12 21:43:46 | 64%|██████▍   | 1000/1558 [00:45<00:24, 22.94it/s]
2025-10-12 21:43:46 | 65%|██████▍   | 1007/1558 [00:45<00:24, 22.04it/s]
2025-10-12 21:43:47 | 66%|██████▌   | 1022/1558 [00:46<00:24, 22.14it/s]
2025-10-12 21:43:47 | 67%|██████▋   | 1037/1558 [00:47<00:22, 22.87it/s]
2025-10-12 21:43:48 | 68%|██████▊   | 1052/1558 [00:47<00:22, 22.61it/s]
2025-10-12 21:43:49 | 69%|██████▊   | 1070/1558 [00:48<00:22, 21.99it/s]
2025-10-12 21:43:50 | 70%|██████▉   | 1085/1558 [00:49<00:21, 22.48it/s]
2025-10-12 21:43:50 | 71%|███████   | 1100/1558 [00:49<00:20, 22.52it/s]
2025-10-12 21:43:50 | {'loss': 1.5503, 'grad_norm': 5.7333173751831055, 'learning_rate': 2.169187145557656e-06, 'epoch': 0.71}
2025-10-12 21:43:50 | 71%|███████   | 1100/1558 [00:49<00:20, 22.52it/s]
2025-10-12 21:43:51 | 72%|███████▏  | 1115/1558 [00:50<00:19, 22.72it/s]
2025-10-12 21:43:52 | 73%|███████▎  | 1130/1558 [00:51<00:18, 22.70it/s]
2025-10-12 21:43:52 | 74%|███████▎  | 1148/1558 [00:51<00:17, 24.00it/s]
2025-10-12 21:43:53 | 75%|███████▍  | 1163/1558 [00:52<00:16, 24.01it/s]
2025-10-12 21:43:54 | 76%|███████▌  | 1178/1558 [00:53<00:16, 23.55it/s]
2025-10-12 21:43:54 | 77%|███████▋  | 1193/1558 [00:53<00:15, 22.89it/s]
2025-10-12 21:43:55 | {'loss': 1.5246, 'grad_norm': 4.4816203117370605, 'learning_rate': 1.6965973534971647e-06, 'epoch': 0.77}
2025-10-12 21:43:55 | 77%|███████▋  | 1200/1558 [00:54<00:15, 22.69it/s]
2025-10-12 21:43:55 | 78%|███████▊  | 1208/1558 [00:54<00:15, 22.84it/s]
2025-10-12 21:43:56 | 79%|███████▊  | 1226/1558 [00:56<00:25, 12.87it/s]
2025-10-12 21:43:57 | 80%|███████▉  | 1241/1558 [00:56<00:15, 20.61it/s]
2025-10-12 21:43:58 | 81%|████████  | 1256/1558 [00:57<00:13, 22.93it/s]
2025-10-12 21:43:58 | 82%|████████▏ | 1271/1558 [00:58<00:12, 22.82it/s]
2025-10-12 21:43:59 | 83%|████████▎ | 1286/1558 [00:58<00:12, 22.36it/s]
2025-10-12 21:44:00 | {'loss': 1.5155, 'grad_norm': 5.404562473297119, 'learning_rate': 1.224007561436673e-06, 'epoch': 0.83}
2025-10-12 21:44:00 | 83%|████████▎ | 1300/1558 [00:59<00:11, 22.06it/s]
2025-10-12 21:44:00 | 84%|████████▎ | 1301/1558 [00:59<00:11, 22.28it/s]
2025-10-12 21:44:00 | 85%|████████▍ | 1319/1558 [01:00<00:10, 23.06it/s]
2025-10-12 21:44:01 | 86%|████████▌ | 1334/1558 [01:00<00:09, 22.73it/s]
2025-10-12 21:44:02 | 87%|████████▋ | 1349/1558 [01:01<00:09, 22.56it/s]
2025-10-12 21:44:03 | 88%|████████▊ | 1364/1558 [01:02<00:08, 22.14it/s]
2025-10-12 21:44:03 | 89%|████████▊ | 1379/1558 [01:02<00:08, 22.05it/s]
2025-10-12 21:44:04 | 90%|████████▉ | 1397/1558 [01:03<00:06, 24.29it/s]
2025-10-12 21:44:04 | {'loss': 1.5504, 'grad_norm': 5.750985145568848, 'learning_rate': 7.514177693761815e-07, 'epoch': 0.9}
2025-10-12 21:44:04 | 90%|████████▉ | 1400/1558 [01:03<00:06, 23.49it/s]
2025-10-12 21:44:05 | 91%|█████████ | 1412/1558 [01:04<00:06, 23.53it/s]
2025-10-12 21:44:05 | 92%|█████████▏| 1427/1558 [01:04<00:05, 24.80it/s]
2025-10-12 21:44:06 | 93%|█████████▎| 1442/1558 [01:05<00:04, 24.85it/s]
2025-10-12 21:44:06 | 94%|█████████▎| 1457/1558 [01:06<00:04, 24.78it/s]
2025-10-12 21:44:07 | 95%|█████████▍| 1475/1558 [01:06<00:03, 22.82it/s]
2025-10-12 21:44:08 | 96%|█████████▌| 1490/1558 [01:07<00:02, 23.02it/s]
2025-10-12 21:44:08 | {'loss': 1.5458, 'grad_norm': 4.620875835418701, 'learning_rate': 2.7882797731569e-07, 'epoch': 0.96}
2025-10-12 21:44:08 | 96%|█████████▋| 1500/1558 [01:07<00:02, 22.03it/s]
2025-10-12 21:44:09 | 97%|█████████▋| 1505/1558 [01:08<00:02, 22.10it/s]
2025-10-12 21:44:09 | 98%|█████████▊| 1520/1558 [01:08<00:01, 21.84it/s]
2025-10-12 21:44:10 | 99%|█████████▊| 1535/1558 [01:09<00:01, 22.03it/s]
2025-10-12 21:44:11 | 100%|█████████▉| 1553/1558 [01:10<00:00, 22.95it/s]
2025-10-12 21:44:12 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 21:44:12 | [A
2025-10-12 21:44:13 | 3%|▎         | 2/63 [00:00<00:25,  2.36it/s]
2025-10-12 21:44:13 | [A
2025-10-12 21:44:14 | 5%|▍         | 3/63 [00:01<00:36,  1.65it/s]
2025-10-12 21:44:14 | [A
2025-10-12 21:44:15 | 6%|▋         | 4/63 [00:02<00:42,  1.40it/s]
2025-10-12 21:44:15 | [A
2025-10-12 21:44:15 | 8%|▊         | 5/63 [00:03<00:44,  1.30it/s]
2025-10-12 21:44:15 | [A
2025-10-12 21:44:16 | 10%|▉         | 6/63 [00:04<00:43,  1.32it/s]
2025-10-12 21:44:16 | [A
2025-10-12 21:44:17 | 11%|█         | 7/63 [00:05<00:43,  1.28it/s]
2025-10-12 21:44:17 | [A
2025-10-12 21:44:18 | 13%|█▎        | 8/63 [00:05<00:43,  1.26it/s]
2025-10-12 21:44:18 | [A
2025-10-12 21:44:19 | 14%|█▍        | 9/63 [00:06<00:44,  1.21it/s]
2025-10-12 21:44:19 | [A
2025-10-12 21:44:20 | 16%|█▌        | 10/63 [00:07<00:44,  1.20it/s]
2025-10-12 21:44:20 | [A
2025-10-12 21:44:20 | 17%|█▋        | 11/63 [00:08<00:42,  1.22it/s]
2025-10-12 21:44:20 | [A
2025-10-12 21:44:21 | 19%|█▉        | 12/63 [00:09<00:41,  1.22it/s]
2025-10-12 21:44:21 | [A
2025-10-12 21:44:22 | 100%|██████████| 1558/1558 [01:21<00:00, 22.94it/s]
2025-10-12 21:44:22 | 21%|██        | 13/63 [00:10<00:41,  1.20it/s]
2025-10-12 21:44:22 | [A
2025-10-12 21:44:23 | 22%|██▏       | 14/63 [00:10<00:40,  1.21it/s]
2025-10-12 21:44:23 | [A
2025-10-12 21:44:24 | 24%|██▍       | 15/63 [00:11<00:38,  1.23it/s]
2025-10-12 21:44:24 | [A
2025-10-12 21:44:24 | 25%|██▌       | 16/63 [00:12<00:37,  1.27it/s]
2025-10-12 21:44:24 | [A
2025-10-12 21:44:25 | 27%|██▋       | 17/63 [00:13<00:36,  1.26it/s]
2025-10-12 21:44:25 | [A
2025-10-12 21:44:26 | 29%|██▊       | 18/63 [00:13<00:35,  1.26it/s]
2025-10-12 21:44:26 | [A
2025-10-12 21:44:27 | 30%|███       | 19/63 [00:14<00:35,  1.23it/s]
2025-10-12 21:44:27 | [A
2025-10-12 21:44:28 | 32%|███▏      | 20/63 [00:15<00:34,  1.25it/s]
2025-10-12 21:44:28 | [A
2025-10-12 21:44:29 | 33%|███▎      | 21/63 [00:17<00:43,  1.05s/it]
2025-10-12 21:44:29 | [A
2025-10-12 21:44:30 | 35%|███▍      | 22/63 [00:18<00:41,  1.01s/it]
2025-10-12 21:44:30 | [A
2025-10-12 21:44:31 | 37%|███▋      | 23/63 [00:18<00:37,  1.06it/s]
2025-10-12 21:44:31 | [A
2025-10-12 21:44:32 | 38%|███▊      | 24/63 [00:19<00:34,  1.14it/s]
2025-10-12 21:44:32 | [A
2025-10-12 21:44:32 | 40%|███▉      | 25/63 [00:20<00:31,  1.20it/s]
2025-10-12 21:44:32 | [A
2025-10-12 21:44:33 | 41%|████▏     | 26/63 [00:21<00:30,  1.21it/s]
2025-10-12 21:44:33 | [A
2025-10-12 21:44:34 | 43%|████▎     | 27/63 [00:21<00:28,  1.26it/s]
2025-10-12 21:44:34 | [A
2025-10-12 21:44:35 | 44%|████▍     | 28/63 [00:22<00:28,  1.25it/s]
2025-10-12 21:44:35 | [A
2025-10-12 21:44:36 | 46%|████▌     | 29/63 [00:23<00:28,  1.18it/s]
2025-10-12 21:44:36 | [A
2025-10-12 21:44:36 | 48%|████▊     | 30/63 [00:24<00:27,  1.21it/s]
2025-10-12 21:44:36 | [A
2025-10-12 21:44:37 | 49%|████▉     | 31/63 [00:25<00:26,  1.21it/s]
2025-10-12 21:44:37 | [A
2025-10-12 21:44:38 | 51%|█████     | 32/63 [00:26<00:25,  1.20it/s]
2025-10-12 21:44:38 | [A
2025-10-12 21:44:39 | 52%|█████▏    | 33/63 [00:26<00:24,  1.22it/s]
2025-10-12 21:44:39 | [A
2025-10-12 21:44:40 | 54%|█████▍    | 34/63 [00:27<00:23,  1.22it/s]
2025-10-12 21:44:40 | [A
2025-10-12 21:44:40 | 56%|█████▌    | 35/63 [00:28<00:22,  1.24it/s]
2025-10-12 21:44:40 | [A
2025-10-12 21:44:41 | 57%|█████▋    | 36/63 [00:29<00:21,  1.26it/s]
2025-10-12 21:44:41 | [A
2025-10-12 21:44:42 | 59%|█████▊    | 37/63 [00:30<00:19,  1.31it/s]
2025-10-12 21:44:42 | [A
2025-10-12 21:44:43 | 60%|██████    | 38/63 [00:30<00:20,  1.23it/s]
2025-10-12 21:44:43 | [A
2025-10-12 21:44:44 | 62%|██████▏   | 39/63 [00:31<00:20,  1.19it/s]
2025-10-12 21:44:44 | [A
2025-10-12 21:44:45 | 63%|██████▎   | 40/63 [00:32<00:19,  1.18it/s]
2025-10-12 21:44:45 | [A
2025-10-12 21:44:46 | 65%|██████▌   | 41/63 [00:33<00:18,  1.16it/s]
2025-10-12 21:44:46 | [A
2025-10-12 21:44:46 | 67%|██████▋   | 42/63 [00:34<00:18,  1.14it/s]
2025-10-12 21:44:46 | [A
2025-10-12 21:44:47 | 68%|██████▊   | 43/63 [00:35<00:17,  1.18it/s]
2025-10-12 21:44:47 | [A
2025-10-12 21:44:48 | 70%|██████▉   | 44/63 [00:36<00:15,  1.23it/s]
2025-10-12 21:44:48 | [A
2025-10-12 21:44:49 | 71%|███████▏  | 45/63 [00:36<00:14,  1.21it/s]
2025-10-12 21:44:49 | [A
2025-10-12 21:44:50 | 73%|███████▎  | 46/63 [00:37<00:13,  1.22it/s]
2025-10-12 21:44:50 | [A
2025-10-12 21:44:50 | 75%|███████▍  | 47/63 [00:38<00:13,  1.20it/s]
2025-10-12 21:44:50 | [A
2025-10-12 21:44:51 | 76%|███████▌  | 48/63 [00:39<00:12,  1.22it/s]
2025-10-12 21:44:51 | [A
2025-10-12 21:44:52 | 78%|███████▊  | 49/63 [00:40<00:11,  1.23it/s]
2025-10-12 21:44:52 | [A
2025-10-12 21:44:53 | 79%|███████▉  | 50/63 [00:40<00:10,  1.28it/s]
2025-10-12 21:44:53 | [A
2025-10-12 21:44:54 | 81%|████████  | 51/63 [00:41<00:09,  1.31it/s]
2025-10-12 21:44:54 | [A
2025-10-12 21:44:54 | 83%|████████▎ | 52/63 [00:42<00:08,  1.33it/s]
2025-10-12 21:44:54 | [A
2025-10-12 21:44:55 | 84%|████████▍ | 53/63 [00:43<00:07,  1.29it/s]
2025-10-12 21:44:55 | [A
2025-10-12 21:44:56 | 86%|████████▌ | 54/63 [00:43<00:07,  1.28it/s]
2025-10-12 21:44:56 | [A
2025-10-12 21:44:57 | 87%|████████▋ | 55/63 [00:44<00:06,  1.29it/s]
2025-10-12 21:44:57 | [A
2025-10-12 21:44:57 | 89%|████████▉ | 56/63 [00:45<00:05,  1.29it/s]
2025-10-12 21:44:57 | [A
2025-10-12 21:44:58 | 90%|█████████ | 57/63 [00:46<00:04,  1.29it/s]
2025-10-12 21:44:58 | [A
2025-10-12 21:44:59 | 92%|█████████▏| 58/63 [00:47<00:03,  1.28it/s]
2025-10-12 21:44:59 | [A
2025-10-12 21:45:00 | 94%|█████████▎| 59/63 [00:47<00:03,  1.26it/s]
2025-10-12 21:45:00 | [A
2025-10-12 21:45:01 | 95%|█████████▌| 60/63 [00:48<00:02,  1.24it/s]
2025-10-12 21:45:01 | [A
2025-10-12 21:45:02 | 97%|█████████▋| 61/63 [00:50<00:02,  1.01s/it]
2025-10-12 21:45:02 | [A
2025-10-12 21:45:03 | 98%|█████████▊| 62/63 [00:50<00:00,  1.07it/s]
2025-10-12 21:45:03 | [A
2025-10-12 21:45:04 | 100%|██████████| 63/63 [00:51<00:00,  1.13it/s]
2025-10-12 21:45:04 | [A
2025-10-12 21:45:04 | [A
2025-10-12 21:45:04 | {'eval_loss': 1.4561351537704468, 'eval_rouge1': 0.4127758033305283, 'eval_rouge2': 0.2559301241189449, 'eval_rougeL': 0.40585506916769387, 'eval_rouge_sum': 1.074560996617167, 'eval_runtime': 52.7473, 'eval_samples_per_second': 9.46, 'eval_steps_per_second': 1.194, 'epoch': 1.0}
2025-10-12 21:45:04 | 100%|██████████| 1558/1558 [02:03<00:00, 22.94it/s]
2025-10-12 21:45:04 | [A
2025-10-12 21:45:04 | [A
2025-10-12 21:45:05 | There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
2025-10-12 21:45:05 | {'train_runtime': 125.0346, 'train_samples_per_second': 99.628, 'train_steps_per_second': 12.461, 'train_loss': 1.7073171760059596, 'epoch': 1.0}
2025-10-12 21:45:05 | 100%|██████████| 1558/1558 [02:05<00:00, 22.94it/s]
2025-10-12 21:45:05 | 최종 모델 저장 중...
2025-10-12 21:45:06 | → 모델 저장 위치: experiments/20251012/20251012_214256_test_full_pipeline_quick/model_0_kobart/default/final_model
2025-10-12 21:45:06 | 최종 평가 중...
2025-10-12 21:45:07 | 0%|          | 0/63 [00:00<?, ?it/s]
2025-10-12 21:45:08 | 3%|▎         | 2/63 [00:00<00:22,  2.74it/s]
2025-10-12 21:45:09 | 5%|▍         | 3/63 [00:01<00:35,  1.71it/s]
2025-10-12 21:45:10 | 6%|▋         | 4/63 [00:02<00:40,  1.47it/s]
2025-10-12 21:45:10 | 8%|▊         | 5/63 [00:03<00:39,  1.45it/s]
2025-10-12 21:45:11 | 10%|▉         | 6/63 [00:03<00:41,  1.36it/s]
2025-10-12 21:45:12 | 11%|█         | 7/63 [00:04<00:39,  1.40it/s]
2025-10-12 21:45:13 | 13%|█▎        | 8/63 [00:05<00:40,  1.37it/s]
2025-10-12 21:45:13 | 14%|█▍        | 9/63 [00:06<00:40,  1.33it/s]
2025-10-12 21:45:14 | 16%|█▌        | 10/63 [00:06<00:38,  1.38it/s]
2025-10-12 21:45:15 | 17%|█▋        | 11/63 [00:07<00:38,  1.36it/s]
2025-10-12 21:45:16 | 19%|█▉        | 12/63 [00:08<00:39,  1.28it/s]
2025-10-12 21:45:16 | 21%|██        | 13/63 [00:09<00:38,  1.30it/s]
2025-10-12 21:45:17 | 22%|██▏       | 14/63 [00:10<00:38,  1.28it/s]
2025-10-12 21:45:18 | 24%|██▍       | 15/63 [00:10<00:37,  1.29it/s]
2025-10-12 21:45:19 | 25%|██▌       | 16/63 [00:11<00:36,  1.28it/s]
2025-10-12 21:45:20 | 27%|██▋       | 17/63 [00:12<00:36,  1.27it/s]
2025-10-12 21:45:20 | 29%|██▊       | 18/63 [00:13<00:33,  1.32it/s]
2025-10-12 21:45:21 | 30%|███       | 19/63 [00:13<00:34,  1.26it/s]
2025-10-12 21:45:22 | 32%|███▏      | 20/63 [00:14<00:34,  1.26it/s]
2025-10-12 21:45:23 | 33%|███▎      | 21/63 [00:15<00:34,  1.23it/s]
2025-10-12 21:45:24 | 35%|███▍      | 22/63 [00:16<00:34,  1.20it/s]
2025-10-12 21:45:24 | 37%|███▋      | 23/63 [00:17<00:32,  1.22it/s]
2025-10-12 21:45:25 | 38%|███▊      | 24/63 [00:18<00:31,  1.22it/s]
2025-10-12 21:45:26 | 40%|███▉      | 25/63 [00:18<00:30,  1.26it/s]
2025-10-12 21:45:27 | 41%|████▏     | 26/63 [00:19<00:28,  1.31it/s]
2025-10-12 21:45:27 | 43%|████▎     | 27/63 [00:20<00:26,  1.34it/s]
2025-10-12 21:45:28 | 44%|████▍     | 28/63 [00:21<00:26,  1.32it/s]
2025-10-12 21:45:29 | 46%|████▌     | 29/63 [00:21<00:25,  1.35it/s]
2025-10-12 21:45:30 | 48%|████▊     | 30/63 [00:22<00:24,  1.37it/s]
2025-10-12 21:45:30 | 49%|████▉     | 31/63 [00:23<00:23,  1.37it/s]
2025-10-12 21:45:31 | 51%|█████     | 32/63 [00:23<00:23,  1.32it/s]
2025-10-12 21:45:32 | 52%|█████▏    | 33/63 [00:24<00:23,  1.26it/s]
2025-10-12 21:45:33 | 54%|█████▍    | 34/63 [00:25<00:22,  1.27it/s]
2025-10-12 21:45:34 | 56%|█████▌    | 35/63 [00:26<00:21,  1.29it/s]
2025-10-12 21:45:34 | 57%|█████▋    | 36/63 [00:27<00:20,  1.31it/s]
2025-10-12 21:45:36 | 59%|█████▊    | 37/63 [00:28<00:24,  1.04it/s]
2025-10-12 21:45:36 | 60%|██████    | 38/63 [00:29<00:21,  1.15it/s]
2025-10-12 21:45:37 | 62%|██████▏   | 39/63 [00:29<00:19,  1.22it/s]
2025-10-12 21:45:38 | 63%|██████▎   | 40/63 [00:30<00:18,  1.24it/s]
2025-10-12 21:45:39 | 65%|██████▌   | 41/63 [00:31<00:17,  1.29it/s]
2025-10-12 21:45:39 | 67%|██████▋   | 42/63 [00:32<00:16,  1.26it/s]
2025-10-12 21:45:40 | 68%|██████▊   | 43/63 [00:32<00:15,  1.26it/s]
2025-10-12 21:45:41 | 70%|██████▉   | 44/63 [00:33<00:14,  1.28it/s]
2025-10-12 21:45:42 | 71%|███████▏  | 45/63 [00:34<00:14,  1.25it/s]
2025-10-12 21:45:43 | 73%|███████▎  | 46/63 [00:35<00:13,  1.27it/s]
2025-10-12 21:45:43 | 75%|███████▍  | 47/63 [00:36<00:12,  1.28it/s]
2025-10-12 21:45:44 | 76%|███████▌  | 48/63 [00:36<00:11,  1.31it/s]
2025-10-12 21:45:45 | 78%|███████▊  | 49/63 [00:37<00:10,  1.35it/s]
2025-10-12 21:45:45 | 79%|███████▉  | 50/63 [00:38<00:09,  1.36it/s]
2025-10-12 21:45:46 | 81%|████████  | 51/63 [00:39<00:08,  1.36it/s]
2025-10-12 21:45:47 | 83%|████████▎ | 52/63 [00:39<00:08,  1.35it/s]
2025-10-12 21:45:48 | 84%|████████▍ | 53/63 [00:40<00:07,  1.39it/s]
2025-10-12 21:45:48 | 86%|████████▌ | 54/63 [00:41<00:06,  1.39it/s]
2025-10-12 21:45:49 | 87%|████████▋ | 55/63 [00:41<00:06,  1.32it/s]
2025-10-12 21:45:50 | 89%|████████▉ | 56/63 [00:42<00:05,  1.30it/s]
2025-10-12 21:45:51 | 90%|█████████ | 57/63 [00:43<00:04,  1.29it/s]
2025-10-12 21:45:51 | 92%|█████████▏| 58/63 [00:44<00:03,  1.31it/s]
2025-10-12 21:45:52 | 94%|█████████▎| 59/63 [00:45<00:03,  1.32it/s]
2025-10-12 21:45:53 | 95%|█████████▌| 60/63 [00:45<00:02,  1.30it/s]
2025-10-12 21:45:54 | 97%|█████████▋| 61/63 [00:46<00:01,  1.28it/s]
2025-10-12 21:45:55 | 98%|█████████▊| 62/63 [00:47<00:00,  1.30it/s]
2025-10-12 21:45:55 | 100%|██████████| 63/63 [00:48<00:00,  1.34it/s]
2025-10-12 21:45:55 | 최종 평가 결과:
2025-10-12 21:45:55 | eval_rouge1: 0.4128
2025-10-12 21:45:55 | eval_rouge2: 0.2559
2025-10-12 21:45:55 | eval_rougeL: 0.4059
2025-10-12 21:45:55 | eval_rouge_sum: 1.0746
2025-10-12 21:45:55 | ============================================================
2025-10-12 21:45:55 | ✅ 학습 완료!
2025-10-12 21:45:55 | ============================================================
2025-10-12 21:45:55 | ✅ kobart 학습 완료
2025-10-12 21:45:55 | ==================================================
2025-10-12 21:45:55 | 모델 2/6: llama-3.2-korean-3b
2025-10-12 21:45:55 | ==================================================
2025-10-12 21:45:55 | 모델 타입: causal_lm
2025-10-12 21:45:55 | Loading Causal LM: Bllossom/llama-3.2-Korean-Bllossom-3B
2025-10-12 21:45:55 | 모델 로딩 중...
2025-10-12 21:45:56 | `torch_dtype` is deprecated! Use `dtype` instead!
2025-10-12 21:45:56 | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-12 21:45:57 | Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.45s/it]
2025-10-12 21:45:58 | Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]
2025-10-12 21:45:58 | 토크나이저 로딩 중...
2025-10-12 21:45:59 | 패딩 토큰 설정: <|eot_id|>
2025-10-12 21:45:59 | LoRA 설정 적용 중...
2025-10-12 21:45:59 | ✅ LoRA 적용 완료
2025-10-12 21:45:59 | 학습 가능 파라미터: 24,313,856 (0.75%)
2025-10-12 21:45:59 | 전체 파라미터: 3,237,063,680
2025-10-12 21:45:59 | Input require grads 활성화 (LoRA + Gradient Checkpointing)
2025-10-12 21:45:59 | ✅ Gradient Checkpointing 활성화
2025-10-12 21:45:59 | ✅ Causal LM 로드 완료
2025-10-12 21:46:00 | ============================================================
2025-10-12 21:46:00 | 모델 학습 시작
2025-10-12 21:46:00 | ============================================================
2025-10-12 21:46:00 | WandB 로그인 상태: ieyeppo-job
2025-10-12 21:46:00 | wandb: Currently logged in as: ieyeppo-job (kimsunmin0227-hufs) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
2025-10-12 21:46:01 | wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
2025-10-12 21:46:01 | ❌ llama-3.2-korean-3b 학습 실패: AttributeError: 'Logger' object has no attribute 'isatty'
2025-10-12 21:46:01 | 오류 로그 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick/errors/llama-3.2-korean-3b_error.log
2025-10-12 21:46:01 | ==================================================
2025-10-12 21:46:01 | 모델 3/6: qwen3-4b
2025-10-12 21:46:01 | ==================================================
2025-10-12 21:46:02 | 모델 타입: causal_lm
2025-10-12 21:46:02 | Loading Causal LM: Qwen/Qwen3-4B-Instruct-2507
2025-10-12 21:46:02 | 모델 로딩 중...
2025-10-12 21:46:02 | Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2025-10-12 21:46:05 | Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.28s/it]
2025-10-12 21:46:09 | Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.65s/it]
2025-10-12 21:46:09 | Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.42s/it]
2025-10-12 21:46:09 | 토크나이저 로딩 중...
2025-10-12 21:46:10 | LoRA 설정 적용 중...
2025-10-12 21:46:10 | ✅ LoRA 적용 완료
2025-10-12 21:46:10 | 학습 가능 파라미터: 33,030,144 (0.81%)
2025-10-12 21:46:10 | 전체 파라미터: 4,055,498,240
2025-10-12 21:46:10 | Input require grads 활성화 (LoRA + Gradient Checkpointing)
2025-10-12 21:46:10 | ✅ Gradient Checkpointing 활성화
2025-10-12 21:46:10 | ✅ Causal LM 로드 완료
2025-10-12 21:46:11 | ============================================================
2025-10-12 21:46:11 | 모델 학습 시작
2025-10-12 21:46:11 | ============================================================
2025-10-12 21:46:11 | WandB 로그인 상태: ieyeppo-job
2025-10-12 21:46:12 | ❌ qwen3-4b 학습 실패: AttributeError: 'Logger' object has no attribute 'isatty'
2025-10-12 21:46:12 | 오류 로그 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick/errors/qwen3-4b_error.log
2025-10-12 21:46:12 | ==================================================
2025-10-12 21:46:12 | 모델 4/6: solar-10.7b
2025-10-12 21:46:12 | ==================================================
2025-10-12 21:46:12 | 모델 타입: causal_lm
2025-10-12 21:46:12 | Loading Causal LM: upstage/solar-10.7b-instruct-v1.0
2025-10-12 21:46:12 | 모델 로딩 중...
2025-10-12 21:46:12 | Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
2025-10-12 21:46:15 | Loading checkpoint shards:  20%|██        | 1/5 [00:02<00:11,  2.76s/it]
2025-10-12 21:46:18 | Loading checkpoint shards:  40%|████      | 2/5 [00:06<00:09,  3.23s/it]
2025-10-12 21:46:20 | Loading checkpoint shards:  60%|██████    | 3/5 [00:08<00:05,  2.62s/it]
2025-10-12 21:46:20 | Loading checkpoint shards: 100%|██████████| 5/5 [00:08<00:00,  1.64s/it]
2025-10-12 21:46:21 | WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.
2025-10-12 21:46:21 | 토크나이저 로딩 중...
2025-10-12 21:46:22 | LoRA 설정 적용 중...
2025-10-12 21:46:23 | ✅ LoRA 적용 완료
2025-10-12 21:46:23 | 학습 가능 파라미터: 62,914,560 (0.58%)
2025-10-12 21:46:23 | 전체 파라미터: 10,794,438,656
2025-10-12 21:46:23 | Input require grads 활성화 (LoRA + Gradient Checkpointing)
2025-10-12 21:46:23 | ✅ Gradient Checkpointing 활성화
2025-10-12 21:46:23 | ✅ Causal LM 로드 완료
2025-10-12 21:46:23 | ============================================================
2025-10-12 21:46:23 | 모델 학습 시작
2025-10-12 21:46:23 | ============================================================
2025-10-12 21:46:23 | WandB 로그인 상태: ieyeppo-job
2025-10-12 21:46:24 | ❌ solar-10.7b 학습 실패: AttributeError: 'Logger' object has no attribute 'isatty'
2025-10-12 21:46:24 | 오류 로그 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick/errors/solar-10.7b_error.log
2025-10-12 21:46:24 | ==================================================
2025-10-12 21:46:24 | 모델 5/6: polyglot-ko-12.8b
2025-10-12 21:46:24 | ==================================================
2025-10-12 21:46:24 | 모델 타입: causal_lm
2025-10-12 21:46:24 | Loading Causal LM: EleutherAI/polyglot-ko-12.8b
2025-10-12 21:46:24 | 모델 로딩 중...
2025-10-12 21:46:24 | Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]
2025-10-12 21:46:25 | Loading checkpoint shards:   4%|▎         | 1/28 [00:01<00:35,  1.32s/it]
2025-10-12 21:46:26 | Loading checkpoint shards:   7%|▋         | 2/28 [00:02<00:27,  1.07s/it]
2025-10-12 21:46:27 | Loading checkpoint shards:  11%|█         | 3/28 [00:02<00:21,  1.17it/s]
2025-10-12 21:46:28 | Loading checkpoint shards:  14%|█▍        | 4/28 [00:03<00:17,  1.39it/s]
2025-10-12 21:46:28 | Loading checkpoint shards:  18%|█▊        | 5/28 [00:03<00:14,  1.60it/s]
2025-10-12 21:46:29 | Loading checkpoint shards:  21%|██▏       | 6/28 [00:04<00:13,  1.66it/s]
2025-10-12 21:46:29 | Loading checkpoint shards:  25%|██▌       | 7/28 [00:04<00:11,  1.79it/s]
2025-10-12 21:46:30 | Loading checkpoint shards:  29%|██▊       | 8/28 [00:05<00:11,  1.76it/s]
2025-10-12 21:46:30 | Loading checkpoint shards:  32%|███▏      | 9/28 [00:05<00:10,  1.88it/s]
2025-10-12 21:46:31 | Loading checkpoint shards:  36%|███▌      | 10/28 [00:07<00:13,  1.30it/s]
2025-10-12 21:46:32 | Loading checkpoint shards:  39%|███▉      | 11/28 [00:07<00:10,  1.58it/s]
2025-10-12 21:46:32 | Loading checkpoint shards: 100%|██████████| 28/28 [00:07<00:00,  3.71it/s]
2025-10-12 21:46:32 | WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.
2025-10-12 21:46:32 | 토크나이저 로딩 중...
2025-10-12 21:46:33 | LoRA 설정 적용 중...
2025-10-12 21:46:33 | ❌ polyglot-ko-12.8b 학습 실패: ValueError: Target modules ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'] not found in the base model. Please check the target modules and try again.
2025-10-12 21:46:33 | 오류 로그 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick/errors/polyglot-ko-12.8b_error.log
2025-10-12 21:46:33 | ==================================================
2025-10-12 21:46:33 | 모델 6/6: kullm-v2
2025-10-12 21:46:33 | ==================================================
2025-10-12 21:46:33 | 모델 타입: causal_lm
2025-10-12 21:46:33 | Loading Causal LM: nlpai-lab/kullm-polyglot-12.8b-v2
2025-10-12 21:46:33 | 모델 로딩 중...
2025-10-12 21:46:33 | Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2025-10-12 21:46:33 | Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00, 17.21it/s]
2025-10-12 21:46:33 | Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 20.49it/s]
2025-10-12 21:46:34 | generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]
2025-10-12 21:46:34 | generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 1.37MB/s]
2025-10-12 21:46:34 | 토크나이저 로딩 중...
2025-10-12 21:46:34 | tokenizer_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]
2025-10-12 21:46:34 | tokenizer_config.json: 100%|██████████| 210/210 [00:00<00:00, 4.61MB/s]
2025-10-12 21:46:35 | tokenizer.json: 0.00B [00:00, ?B/s]
2025-10-12 21:46:35 | tokenizer.json: 1.65MB [00:00, 35.9MB/s]
2025-10-12 21:46:36 | special_tokens_map.json:   0%|          | 0.00/185 [00:00<?, ?B/s]
2025-10-12 21:46:36 | special_tokens_map.json: 100%|██████████| 185/185 [00:00<00:00, 3.53MB/s]
2025-10-12 21:46:36 | LoRA 설정 적용 중...
2025-10-12 21:46:36 | ❌ kullm-v2 학습 실패: ValueError: Target modules ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'] not found in the base model. Please check the target modules and try again.
2025-10-12 21:46:36 | 오류 로그 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick/errors/kullm-v2_error.log
2025-10-12 21:46:36 | ==================================================
2025-10-12 21:46:36 | 모델 학습 결과 요약
2025-10-12 21:46:36 | ==================================================
2025-10-12 21:46:36 | ✅ 성공: 1/6 모델
2025-10-12 21:46:36 | ❌ 실패: 5/6 모델
2025-10-12 21:46:36 | 실패한 모델 목록:
2025-10-12 21:46:36 | - llama-3.2-korean-3b: AttributeError
2025-10-12 21:46:36 | - qwen3-4b: AttributeError
2025-10-12 21:46:36 | - solar-10.7b: AttributeError
2025-10-12 21:46:36 | - polyglot-ko-12.8b: ValueError
2025-10-12 21:46:36 | - kullm-v2: ValueError
2025-10-12 21:46:36 | [3/6] 앙상블 생성...
2025-10-12 21:46:36 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 21:46:37 | ModelManager 초기화
2025-10-12 21:46:37 | 앙상블 생성: voting
2025-10-12 21:46:37 | VotingEnsemble 초기화: 1개 모델
2025-10-12 21:46:37 | - 투표 방식: hard
2025-10-12 21:46:37 | - 입력 데이터: 100개
2025-10-12 21:46:37 | - 모델 수: 1개
2025-10-12 21:46:37 | 앙상블 평가 오류 발생: The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)
2025-10-12 21:46:37 | [4/6] Solar API 통합...
2025-10-12 21:46:37 | Solar API processing 50 samples ...
2025-10-12 21:46:37 | [5/6] TTA 적용...
2025-10-12 21:46:37 | TTA 전략: paraphrase, reorder, synonym, mask
2025-10-12 21:46:37 | 증강 횟수: 1
2025-10-12 21:46:37 | TTA 기능은 아직 구현 중입니다.
2025-10-12 21:46:37 | [6/6] 추론 및 제출 파일 생성...
2025-10-12 21:46:37 | 테스트 데이터 로드: data/raw/test.csv
2025-10-12 21:46:37 | 테스트 샘플 수: 499
2025-10-12 21:46:37 | 사용 모델: experiments/20251012/20251012_214256_test_full_pipeline_quick/model_0_kobart/default/final_model
2025-10-12 21:46:37 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 21:46:37 | 배치 크기: 32
2025-10-12 21:52:31 | 진행: 320/499
2025-10-12 21:55:58 | ❌ 추론 오류 발생: 'id'
2025-10-12 21:55:58 | 상세: Traceback (most recent call last):
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pandas/_libs/index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'id'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ieyeppo/AI_Lab/natural-language-processing-competition/src/trainers/full_pipeline_trainer.py", line 533, in _create_submission
    'id': test_df['id'],
          ~~~~~~~^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/pandas/core/frame.py", line 4113, in __getitem__
    indexer = self.columns.get_loc(key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ieyeppo/.pyenv/versions/nlp_py3_11_9/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3819, in get_loc
    raise KeyError(key) from err
KeyError: 'id'
2025-10-12 21:55:58 | ============================================================
2025-10-12 21:55:58 | FULL PIPELINE 완료!
2025-10-12 21:55:58 | =요약 개별 모델 결과:
2025-10-12 21:55:58 | kobart:
2025-10-12 21:55:58 | eval_rouge1: 0.4128
2025-10-12 21:55:58 | eval_rouge2: 0.2559
2025-10-12 21:55:58 | eval_rougeL: 0.4059
2025-10-12 21:55:58 | eval_rouge_sum: 1.0746
2025-10-12 21:55:58 | llama-3.2-korean-3b:
2025-10-12 21:55:58 | qwen3-4b:
2025-10-12 21:55:58 | solar-10.7b:
2025-10-12 21:55:58 | polyglot-ko-12.8b:
2025-10-12 21:55:58 | kullm-v2:
2025-10-12 21:55:58 | =요약 앙상블 결과:
2025-10-12 21:55:58 | =요약 Solar API 결과:
2025-10-12 21:55:58 | solar_rouge_1_f1: 0.2272
2025-10-12 21:55:58 | solar_rouge_2_f1: 0.0765
2025-10-12 21:55:58 | solar_rouge_l_f1: 0.2177
2025-10-12 21:55:58 | n_samples: 50.0000
2025-10-12 21:55:58 | ============================================================
2025-10-12 21:55:58 | =저장 결과 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick/full_pipeline_results.json
2025-10-12 21:55:58 | 📋 학습 로그 백업: logs/20251012/train/20251012_215558_full_kobart_ep1_aug_tta.log
2025-10-12 21:55:58 | 🔧 추론 최적화 시작 (PRD 17)...
2025-10-12 21:55:58 | You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.
2025-10-12 21:55:58 | ============================================================
2025-10-12 21:55:58 | 🚀 추론 최적화 시작
2025-10-12 21:55:58 | 방법: quantization
2025-10-12 21:55:58 | ============================================================
2025-10-12 21:55:58 | 🔧 모델 양자화 시작 (8bit)...
2025-10-12 21:55:59 | ✅ INT8 동적 양자화 완료
2025-10-12 21:55:59 | 🔍 최적 배치 크기 탐색 중...
2025-10-12 21:56:00 | ✅ 배치 크기 1 성공
2025-10-12 21:56:02 | ✅ 배치 크기 2 성공
2025-10-12 21:56:03 | ✅ 배치 크기 4 성공
2025-10-12 21:56:04 | ✅ 배치 크기 8 성공
2025-10-12 21:56:06 | ✅ 배치 크기 16 성공
2025-10-12 21:56:07 | ✅ 배치 크기 32 성공
2025-10-12 21:56:08 | ✅ 배치 크기 64 성공
2025-10-12 21:56:08 | 🎯 최적 배치 크기: 64
2025-10-12 21:56:08 | ============================================================
2025-10-12 21:56:08 | ✅ 추론 최적화 완료!
2025-10-12 21:56:08 | ============================================================
2025-10-12 21:56:08 | ✅ 추론 최적화 완료!
2025-10-12 21:56:08 | 📁 최적화 모델: experiments/20251012/20251012_214256_test_full_pipeline_quick/optimized/quantized_8bit
2025-10-12 21:56:08 | 📈 시각화 생성 중...
2025-10-12 21:56:08 | ✅ 나눔고딕 폰트 로드 성공
2025-10-12 21:56:08 | ⚠️ 시각화 모듈 없음 (추후 구현 예정)
2025-10-12 21:56:08 | ============================================================
2025-10-12 21:56:08 | ✅ 학습 완료!
2025-10-12 21:56:08 | 📁 결과 저장: experiments/20251012/20251012_214256_test_full_pipeline_quick
2025-10-12 21:56:08 | 🔧 추론 최적화 적용됨
2025-10-12 21:56:08 | ============================================================
2025-10-12 21:56:08 | >> 로그 리디렉션 중료.
