{
  "best_global_step": 125,
  "best_metric": 0.2974736101555579,
  "best_model_checkpoint": "experiments/20251013/20251013_133516_test_llama_overflow_fix/model_0_llama_3.2_korean_3b/llama_3.2_3b_qlora/checkpoint-125",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 2.0472397804260254,
      "learning_rate": 3.6e-07,
      "loss": 1.5596,
      "step": 10
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6747387647628784,
      "learning_rate": 7.6e-07,
      "loss": 1.6292,
      "step": 20
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.458857774734497,
      "learning_rate": 1.1600000000000001e-06,
      "loss": 1.5432,
      "step": 30
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.2587523460388184,
      "learning_rate": 1.56e-06,
      "loss": 1.5794,
      "step": 40
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.784534215927124,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 1.6887,
      "step": 50
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.82529616355896,
      "learning_rate": 2.3600000000000003e-06,
      "loss": 1.5432,
      "step": 60
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.69929838180542,
      "learning_rate": 2.7600000000000003e-06,
      "loss": 1.4923,
      "step": 70
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.611172676086426,
      "learning_rate": 3.1600000000000002e-06,
      "loss": 1.4271,
      "step": 80
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.265550136566162,
      "learning_rate": 3.5600000000000002e-06,
      "loss": 1.5112,
      "step": 90
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0066676139831543,
      "learning_rate": 3.96e-06,
      "loss": 1.3468,
      "step": 100
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8659244775772095,
      "learning_rate": 4.360000000000001e-06,
      "loss": 1.3311,
      "step": 110
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4910774230957031,
      "learning_rate": 4.76e-06,
      "loss": 1.366,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3466014862060547,
      "eval_rouge1": 0.11139249378995252,
      "eval_rouge2": 0.07468862257565287,
      "eval_rougeL": 0.11139249378995252,
      "eval_rouge_sum": 0.2974736101555579,
      "eval_runtime": 378.0101,
      "eval_samples_per_second": 1.32,
      "eval_steps_per_second": 0.167,
      "step": 125
    }
  ],
  "logging_steps": 10,
  "max_steps": 125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7467768307712e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
