{
  "best_global_step": 3895,
  "best_metric": 1.2368815721912005,
  "best_model_checkpoint": "experiments/20251013/20251013_111525_strategy1_kobart_optimized/model_0_kobart/default/checkpoint-3895",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 3895,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12836970474967907,
      "grad_norm": 4.910407066345215,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.1642,
      "step": 100
    },
    {
      "epoch": 0.25673940949935814,
      "grad_norm": 4.00030517578125,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.6761,
      "step": 200
    },
    {
      "epoch": 0.3851091142490372,
      "grad_norm": 4.072445392608643,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.5537,
      "step": 300
    },
    {
      "epoch": 0.5134788189987163,
      "grad_norm": 3.905674934387207,
      "learning_rate": 3.99e-05,
      "loss": 1.5038,
      "step": 400
    },
    {
      "epoch": 0.6418485237483954,
      "grad_norm": 3.789917469024658,
      "learning_rate": 4.99e-05,
      "loss": 1.4924,
      "step": 500
    },
    {
      "epoch": 0.7702182284980744,
      "grad_norm": 3.134007692337036,
      "learning_rate": 4.91364270760642e-05,
      "loss": 1.451,
      "step": 600
    },
    {
      "epoch": 0.8985879332477535,
      "grad_norm": 3.37524151802063,
      "learning_rate": 4.826413119330077e-05,
      "loss": 1.4411,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3518974781036377,
      "eval_rouge1": 0.39891850173455917,
      "eval_rouge2": 0.25544497624803747,
      "eval_rougeL": 0.39400698243900867,
      "eval_rouge_sum": 1.0483704604216053,
      "eval_runtime": 27.835,
      "eval_samples_per_second": 17.927,
      "eval_steps_per_second": 1.15,
      "step": 779
    },
    {
      "epoch": 1.0269576379974326,
      "grad_norm": 3.4528720378875732,
      "learning_rate": 4.7391835310537334e-05,
      "loss": 1.3944,
      "step": 800
    },
    {
      "epoch": 1.1553273427471118,
      "grad_norm": 3.592982053756714,
      "learning_rate": 4.65195394277739e-05,
      "loss": 1.2159,
      "step": 900
    },
    {
      "epoch": 1.2836970474967908,
      "grad_norm": 3.203165292739868,
      "learning_rate": 4.564724354501047e-05,
      "loss": 1.2263,
      "step": 1000
    },
    {
      "epoch": 1.4120667522464698,
      "grad_norm": 3.645782470703125,
      "learning_rate": 4.477494766224704e-05,
      "loss": 1.215,
      "step": 1100
    },
    {
      "epoch": 1.540436456996149,
      "grad_norm": 3.3047902584075928,
      "learning_rate": 4.39026517794836e-05,
      "loss": 1.2095,
      "step": 1200
    },
    {
      "epoch": 1.6688061617458279,
      "grad_norm": 3.0813138484954834,
      "learning_rate": 4.303035589672017e-05,
      "loss": 1.2196,
      "step": 1300
    },
    {
      "epoch": 1.797175866495507,
      "grad_norm": 2.997793436050415,
      "learning_rate": 4.2158060013956734e-05,
      "loss": 1.2039,
      "step": 1400
    },
    {
      "epoch": 1.925545571245186,
      "grad_norm": 3.406224250793457,
      "learning_rate": 4.1285764131193306e-05,
      "loss": 1.202,
      "step": 1500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2862839698791504,
      "eval_rouge1": 0.43120555783823494,
      "eval_rouge2": 0.27430573139150743,
      "eval_rougeL": 0.42401523566035254,
      "eval_rouge_sum": 1.129526524890095,
      "eval_runtime": 25.5983,
      "eval_samples_per_second": 19.493,
      "eval_steps_per_second": 1.25,
      "step": 1558
    },
    {
      "epoch": 2.053915275994865,
      "grad_norm": 3.0007991790771484,
      "learning_rate": 4.041346824842987e-05,
      "loss": 1.0799,
      "step": 1600
    },
    {
      "epoch": 2.1822849807445444,
      "grad_norm": 3.3692786693573,
      "learning_rate": 3.954117236566644e-05,
      "loss": 0.9411,
      "step": 1700
    },
    {
      "epoch": 2.3106546854942236,
      "grad_norm": 3.106840133666992,
      "learning_rate": 3.8668876482903e-05,
      "loss": 0.9567,
      "step": 1800
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 3.455874443054199,
      "learning_rate": 3.779658060013957e-05,
      "loss": 0.9638,
      "step": 1900
    },
    {
      "epoch": 2.5673940949935816,
      "grad_norm": 3.4473516941070557,
      "learning_rate": 3.6924284717376134e-05,
      "loss": 0.9834,
      "step": 2000
    },
    {
      "epoch": 2.6957637997432604,
      "grad_norm": 3.5157554149627686,
      "learning_rate": 3.605198883461271e-05,
      "loss": 0.9612,
      "step": 2100
    },
    {
      "epoch": 2.8241335044929397,
      "grad_norm": 3.3594770431518555,
      "learning_rate": 3.5179692951849266e-05,
      "loss": 0.9615,
      "step": 2200
    },
    {
      "epoch": 2.952503209242619,
      "grad_norm": 3.222034454345703,
      "learning_rate": 3.430739706908583e-05,
      "loss": 0.9607,
      "step": 2300
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3126003742218018,
      "eval_rouge1": 0.43961427778686474,
      "eval_rouge2": 0.2822726843341434,
      "eval_rougeL": 0.43371322669837997,
      "eval_rouge_sum": 1.155600188819388,
      "eval_runtime": 29.9246,
      "eval_samples_per_second": 16.675,
      "eval_steps_per_second": 1.069,
      "step": 2337
    },
    {
      "epoch": 3.0808729139922977,
      "grad_norm": 2.941213369369507,
      "learning_rate": 3.3435101186322404e-05,
      "loss": 0.8416,
      "step": 2400
    },
    {
      "epoch": 3.209242618741977,
      "grad_norm": 3.2655303478240967,
      "learning_rate": 3.256280530355897e-05,
      "loss": 0.7502,
      "step": 2500
    },
    {
      "epoch": 3.337612323491656,
      "grad_norm": 3.3202340602874756,
      "learning_rate": 3.1690509420795535e-05,
      "loss": 0.7649,
      "step": 2600
    },
    {
      "epoch": 3.465982028241335,
      "grad_norm": 3.4088239669799805,
      "learning_rate": 3.08182135380321e-05,
      "loss": 0.7629,
      "step": 2700
    },
    {
      "epoch": 3.594351732991014,
      "grad_norm": 3.162749767303467,
      "learning_rate": 2.994591765526867e-05,
      "loss": 0.782,
      "step": 2800
    },
    {
      "epoch": 3.7227214377406934,
      "grad_norm": 3.4565823078155518,
      "learning_rate": 2.9073621772505232e-05,
      "loss": 0.7798,
      "step": 2900
    },
    {
      "epoch": 3.851091142490372,
      "grad_norm": 3.5984084606170654,
      "learning_rate": 2.8201325889741804e-05,
      "loss": 0.7725,
      "step": 3000
    },
    {
      "epoch": 3.9794608472400514,
      "grad_norm": 3.3943629264831543,
      "learning_rate": 2.7329030006978366e-05,
      "loss": 0.7727,
      "step": 3100
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3730920553207397,
      "eval_rouge1": 0.4534925511874766,
      "eval_rouge2": 0.2922898228613995,
      "eval_rougeL": 0.44675010702312984,
      "eval_rouge_sum": 1.192532481072006,
      "eval_runtime": 29.674,
      "eval_samples_per_second": 16.816,
      "eval_steps_per_second": 1.078,
      "step": 3116
    },
    {
      "epoch": 4.10783055198973,
      "grad_norm": 3.2648487091064453,
      "learning_rate": 2.6456734124214932e-05,
      "loss": 0.629,
      "step": 3200
    },
    {
      "epoch": 4.2362002567394095,
      "grad_norm": 3.280116558074951,
      "learning_rate": 2.55844382414515e-05,
      "loss": 0.606,
      "step": 3300
    },
    {
      "epoch": 4.364569961489089,
      "grad_norm": 8.222102165222168,
      "learning_rate": 2.4712142358688067e-05,
      "loss": 0.6109,
      "step": 3400
    },
    {
      "epoch": 4.492939666238768,
      "grad_norm": 2.6953046321868896,
      "learning_rate": 2.3839846475924636e-05,
      "loss": 0.6118,
      "step": 3500
    },
    {
      "epoch": 4.621309370988447,
      "grad_norm": 3.291280508041382,
      "learning_rate": 2.29675505931612e-05,
      "loss": 0.6218,
      "step": 3600
    },
    {
      "epoch": 4.7496790757381255,
      "grad_norm": 3.445495128631592,
      "learning_rate": 2.2095254710397767e-05,
      "loss": 0.6286,
      "step": 3700
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 3.3885796070098877,
      "learning_rate": 2.1222958827634336e-05,
      "loss": 0.6207,
      "step": 3800
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.4201492071151733,
      "eval_rouge1": 0.46995988186216936,
      "eval_rouge2": 0.3055783140148465,
      "eval_rougeL": 0.4613433763141848,
      "eval_rouge_sum": 1.2368815721912005,
      "eval_runtime": 26.078,
      "eval_samples_per_second": 19.135,
      "eval_steps_per_second": 1.227,
      "step": 3895
    }
  ],
  "logging_steps": 100,
  "max_steps": 6232,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.89887176507392e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
