{
  "best_global_step": 500,
  "best_metric": 0.3900908448734579,
  "best_model_checkpoint": "experiments/20251013/20251013_161056_test_strategy3_triple/model_2_qwen3_4b/qwen3_4b_qlora/checkpoint-500",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 5.219465732574463,
      "learning_rate": 3.6e-07,
      "loss": 2.6867,
      "step": 10
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.060288906097412,
      "learning_rate": 7.6e-07,
      "loss": 2.652,
      "step": 20
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.689502239227295,
      "learning_rate": 1.1600000000000001e-06,
      "loss": 2.4888,
      "step": 30
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.698619365692139,
      "learning_rate": 1.56e-06,
      "loss": 2.5933,
      "step": 40
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.577315330505371,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 2.4075,
      "step": 50
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.662926197052002,
      "learning_rate": 2.3600000000000003e-06,
      "loss": 2.2907,
      "step": 60
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.411892890930176,
      "learning_rate": 2.7600000000000003e-06,
      "loss": 2.0832,
      "step": 70
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.899998188018799,
      "learning_rate": 3.1600000000000002e-06,
      "loss": 1.9917,
      "step": 80
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.316915512084961,
      "learning_rate": 3.5600000000000002e-06,
      "loss": 1.7619,
      "step": 90
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.136754035949707,
      "learning_rate": 3.96e-06,
      "loss": 1.5077,
      "step": 100
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.8974263668060303,
      "learning_rate": 4.360000000000001e-06,
      "loss": 1.2613,
      "step": 110
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.496217131614685,
      "learning_rate": 4.76e-06,
      "loss": 1.1567,
      "step": 120
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6571550369262695,
      "learning_rate": 5.1600000000000006e-06,
      "loss": 1.1073,
      "step": 130
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.366770625114441,
      "learning_rate": 5.560000000000001e-06,
      "loss": 0.9612,
      "step": 140
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0838371515274048,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.8971,
      "step": 150
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1195037364959717,
      "learning_rate": 6.360000000000001e-06,
      "loss": 1.0086,
      "step": 160
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1731027364730835,
      "learning_rate": 6.760000000000001e-06,
      "loss": 0.9374,
      "step": 170
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8574673533439636,
      "learning_rate": 7.16e-06,
      "loss": 0.9263,
      "step": 180
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0490968227386475,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.9018,
      "step": 190
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.172115683555603,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.9415,
      "step": 200
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1097921133041382,
      "learning_rate": 8.36e-06,
      "loss": 0.9336,
      "step": 210
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9464194178581238,
      "learning_rate": 8.76e-06,
      "loss": 0.9149,
      "step": 220
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.202623724937439,
      "learning_rate": 9.16e-06,
      "loss": 0.917,
      "step": 230
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.063131332397461,
      "learning_rate": 9.56e-06,
      "loss": 0.9064,
      "step": 240
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0535645484924316,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.8924,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8998599648475647,
      "eval_rouge1": 0.14323703974594323,
      "eval_rouge2": 0.09660626548273236,
      "eval_rougeL": 0.14323703974594323,
      "eval_rouge_sum": 0.38308034497461885,
      "eval_runtime": 4852.3231,
      "eval_samples_per_second": 0.103,
      "eval_steps_per_second": 0.01,
      "step": 250
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9299185872077942,
      "learning_rate": 1.036e-05,
      "loss": 0.8357,
      "step": 260
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.150640845298767,
      "learning_rate": 1.0760000000000002e-05,
      "loss": 0.8826,
      "step": 270
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.1538403034210205,
      "learning_rate": 1.1160000000000002e-05,
      "loss": 0.8945,
      "step": 280
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.0407363176345825,
      "learning_rate": 1.156e-05,
      "loss": 0.8667,
      "step": 290
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.1468778848648071,
      "learning_rate": 1.196e-05,
      "loss": 0.8704,
      "step": 300
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2907413244247437,
      "learning_rate": 1.236e-05,
      "loss": 0.8816,
      "step": 310
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.2124745845794678,
      "learning_rate": 1.2760000000000001e-05,
      "loss": 0.8375,
      "step": 320
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.2730255126953125,
      "learning_rate": 1.3160000000000001e-05,
      "loss": 0.86,
      "step": 330
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.2308787107467651,
      "learning_rate": 1.3560000000000002e-05,
      "loss": 0.857,
      "step": 340
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.245546579360962,
      "learning_rate": 1.396e-05,
      "loss": 0.8425,
      "step": 350
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1828057765960693,
      "learning_rate": 1.4360000000000001e-05,
      "loss": 0.8533,
      "step": 360
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2992143630981445,
      "learning_rate": 1.4760000000000001e-05,
      "loss": 0.8612,
      "step": 370
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3112467527389526,
      "learning_rate": 1.516e-05,
      "loss": 0.8444,
      "step": 380
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2499650716781616,
      "learning_rate": 1.556e-05,
      "loss": 0.8573,
      "step": 390
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.1306487321853638,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.8068,
      "step": 400
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.2790778875350952,
      "learning_rate": 1.636e-05,
      "loss": 0.8377,
      "step": 410
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.5981974601745605,
      "learning_rate": 1.6760000000000002e-05,
      "loss": 0.8543,
      "step": 420
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.216884732246399,
      "learning_rate": 1.7160000000000002e-05,
      "loss": 0.8942,
      "step": 430
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4500758647918701,
      "learning_rate": 1.756e-05,
      "loss": 0.8063,
      "step": 440
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.1671009063720703,
      "learning_rate": 1.796e-05,
      "loss": 0.8237,
      "step": 450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.3589142560958862,
      "learning_rate": 1.8360000000000004e-05,
      "loss": 0.837,
      "step": 460
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.203302025794983,
      "learning_rate": 1.876e-05,
      "loss": 0.8253,
      "step": 470
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.6929939985275269,
      "learning_rate": 1.916e-05,
      "loss": 0.8643,
      "step": 480
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.567584753036499,
      "learning_rate": 1.9560000000000002e-05,
      "loss": 0.8963,
      "step": 490
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.4189558029174805,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.7881,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.851283073425293,
      "eval_rouge1": 0.14578767859353217,
      "eval_rouge2": 0.09851548768639361,
      "eval_rougeL": 0.14578767859353217,
      "eval_rouge_sum": 0.3900908448734579,
      "eval_runtime": 2699.1784,
      "eval_samples_per_second": 0.185,
      "eval_steps_per_second": 0.019,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.126361726976e+17,
  "train_batch_size": 10,
  "trial_name": null,
  "trial_params": null
}
