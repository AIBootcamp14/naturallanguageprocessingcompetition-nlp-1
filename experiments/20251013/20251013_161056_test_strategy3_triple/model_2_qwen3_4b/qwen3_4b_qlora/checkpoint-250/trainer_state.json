{
  "best_global_step": 250,
  "best_metric": 0.38308034497461885,
  "best_model_checkpoint": "experiments/20251013/20251013_161056_test_strategy3_triple/model_2_qwen3_4b/qwen3_4b_qlora/checkpoint-250",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 5.219465732574463,
      "learning_rate": 3.6e-07,
      "loss": 2.6867,
      "step": 10
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.060288906097412,
      "learning_rate": 7.6e-07,
      "loss": 2.652,
      "step": 20
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.689502239227295,
      "learning_rate": 1.1600000000000001e-06,
      "loss": 2.4888,
      "step": 30
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.698619365692139,
      "learning_rate": 1.56e-06,
      "loss": 2.5933,
      "step": 40
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.577315330505371,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 2.4075,
      "step": 50
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.662926197052002,
      "learning_rate": 2.3600000000000003e-06,
      "loss": 2.2907,
      "step": 60
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.411892890930176,
      "learning_rate": 2.7600000000000003e-06,
      "loss": 2.0832,
      "step": 70
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.899998188018799,
      "learning_rate": 3.1600000000000002e-06,
      "loss": 1.9917,
      "step": 80
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.316915512084961,
      "learning_rate": 3.5600000000000002e-06,
      "loss": 1.7619,
      "step": 90
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.136754035949707,
      "learning_rate": 3.96e-06,
      "loss": 1.5077,
      "step": 100
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.8974263668060303,
      "learning_rate": 4.360000000000001e-06,
      "loss": 1.2613,
      "step": 110
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.496217131614685,
      "learning_rate": 4.76e-06,
      "loss": 1.1567,
      "step": 120
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6571550369262695,
      "learning_rate": 5.1600000000000006e-06,
      "loss": 1.1073,
      "step": 130
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.366770625114441,
      "learning_rate": 5.560000000000001e-06,
      "loss": 0.9612,
      "step": 140
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0838371515274048,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.8971,
      "step": 150
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1195037364959717,
      "learning_rate": 6.360000000000001e-06,
      "loss": 1.0086,
      "step": 160
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1731027364730835,
      "learning_rate": 6.760000000000001e-06,
      "loss": 0.9374,
      "step": 170
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8574673533439636,
      "learning_rate": 7.16e-06,
      "loss": 0.9263,
      "step": 180
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0490968227386475,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.9018,
      "step": 190
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.172115683555603,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.9415,
      "step": 200
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1097921133041382,
      "learning_rate": 8.36e-06,
      "loss": 0.9336,
      "step": 210
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9464194178581238,
      "learning_rate": 8.76e-06,
      "loss": 0.9149,
      "step": 220
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.202623724937439,
      "learning_rate": 9.16e-06,
      "loss": 0.917,
      "step": 230
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.063131332397461,
      "learning_rate": 9.56e-06,
      "loss": 0.9064,
      "step": 240
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0535645484924316,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.8924,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8998599648475647,
      "eval_rouge1": 0.14323703974594323,
      "eval_rouge2": 0.09660626548273236,
      "eval_rougeL": 0.14323703974594323,
      "eval_rouge_sum": 0.38308034497461885,
      "eval_runtime": 4852.3231,
      "eval_samples_per_second": 0.103,
      "eval_steps_per_second": 0.01,
      "step": 250
    }
  ],
  "logging_steps": 10,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.63180863488e+16,
  "train_batch_size": 10,
  "trial_name": null,
  "trial_params": null
}
