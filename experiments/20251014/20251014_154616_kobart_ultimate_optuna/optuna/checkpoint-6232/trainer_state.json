{
  "best_global_step": 3895,
  "best_metric": 1.2179890080651559,
  "best_model_checkpoint": "experiments/20251014/20251014_154616_kobart_ultimate_optuna/optuna/checkpoint-3895",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 6232,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12836970474967907,
      "grad_norm": 4.853784084320068,
      "learning_rate": 7.953985636344983e-06,
      "loss": 2.2038,
      "step": 100
    },
    {
      "epoch": 0.25673940949935814,
      "grad_norm": 4.193289756774902,
      "learning_rate": 1.5988314561945976e-05,
      "loss": 1.6953,
      "step": 200
    },
    {
      "epoch": 0.3851091142490372,
      "grad_norm": 4.187561988830566,
      "learning_rate": 2.4022643487546967e-05,
      "loss": 1.566,
      "step": 300
    },
    {
      "epoch": 0.5134788189987163,
      "grad_norm": 3.8635079860687256,
      "learning_rate": 3.205697241314796e-05,
      "loss": 1.5127,
      "step": 400
    },
    {
      "epoch": 0.6418485237483954,
      "grad_norm": 3.7268128395080566,
      "learning_rate": 4.0091301338748956e-05,
      "loss": 1.4982,
      "step": 500
    },
    {
      "epoch": 0.7702182284980744,
      "grad_norm": 3.178403854370117,
      "learning_rate": 3.947782173579064e-05,
      "loss": 1.4591,
      "step": 600
    },
    {
      "epoch": 0.8985879332477535,
      "grad_norm": 3.6180436611175537,
      "learning_rate": 3.877699053153375e-05,
      "loss": 1.4483,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3545100688934326,
      "eval_rouge1": 0.39151434617087283,
      "eval_rouge2": 0.2542481300525252,
      "eval_rougeL": 0.3868466067636855,
      "eval_rouge_sum": 1.0326090829870835,
      "eval_runtime": 27.0739,
      "eval_samples_per_second": 18.431,
      "eval_steps_per_second": 1.182,
      "step": 779
    },
    {
      "epoch": 1.0269576379974326,
      "grad_norm": 3.3116300106048584,
      "learning_rate": 3.807615932727686e-05,
      "loss": 1.4031,
      "step": 800
    },
    {
      "epoch": 1.1553273427471118,
      "grad_norm": 3.6472525596618652,
      "learning_rate": 3.737532812301997e-05,
      "loss": 1.2415,
      "step": 900
    },
    {
      "epoch": 1.2836970474967908,
      "grad_norm": 3.419543504714966,
      "learning_rate": 3.6674496918763084e-05,
      "loss": 1.249,
      "step": 1000
    },
    {
      "epoch": 1.4120667522464698,
      "grad_norm": 3.8838658332824707,
      "learning_rate": 3.597366571450619e-05,
      "loss": 1.2365,
      "step": 1100
    },
    {
      "epoch": 1.540436456996149,
      "grad_norm": 3.394847869873047,
      "learning_rate": 3.5272834510249305e-05,
      "loss": 1.2299,
      "step": 1200
    },
    {
      "epoch": 1.6688061617458279,
      "grad_norm": 3.138421058654785,
      "learning_rate": 3.457200330599241e-05,
      "loss": 1.2418,
      "step": 1300
    },
    {
      "epoch": 1.797175866495507,
      "grad_norm": 3.1301143169403076,
      "learning_rate": 3.387117210173552e-05,
      "loss": 1.2249,
      "step": 1400
    },
    {
      "epoch": 1.925545571245186,
      "grad_norm": 3.4183571338653564,
      "learning_rate": 3.317034089747863e-05,
      "loss": 1.2208,
      "step": 1500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2917762994766235,
      "eval_rouge1": 0.43396419045328927,
      "eval_rouge2": 0.27921891832623513,
      "eval_rougeL": 0.42779700515446606,
      "eval_rouge_sum": 1.1409801139339906,
      "eval_runtime": 27.4417,
      "eval_samples_per_second": 18.184,
      "eval_steps_per_second": 1.166,
      "step": 1558
    },
    {
      "epoch": 2.053915275994865,
      "grad_norm": 3.197613477706909,
      "learning_rate": 3.246950969322174e-05,
      "loss": 1.1138,
      "step": 1600
    },
    {
      "epoch": 2.1822849807445444,
      "grad_norm": 3.210344076156616,
      "learning_rate": 3.1768678488964845e-05,
      "loss": 0.9918,
      "step": 1700
    },
    {
      "epoch": 2.3106546854942236,
      "grad_norm": 3.2544009685516357,
      "learning_rate": 3.106784728470796e-05,
      "loss": 1.0035,
      "step": 1800
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 3.1776230335235596,
      "learning_rate": 3.0367016080451067e-05,
      "loss": 1.0014,
      "step": 1900
    },
    {
      "epoch": 2.5673940949935816,
      "grad_norm": 3.6453797817230225,
      "learning_rate": 2.9666184876194174e-05,
      "loss": 1.012,
      "step": 2000
    },
    {
      "epoch": 2.6957637997432604,
      "grad_norm": 3.4667820930480957,
      "learning_rate": 2.896535367193729e-05,
      "loss": 0.9943,
      "step": 2100
    },
    {
      "epoch": 2.8241335044929397,
      "grad_norm": 3.3208415508270264,
      "learning_rate": 2.8264522467680396e-05,
      "loss": 0.9989,
      "step": 2200
    },
    {
      "epoch": 2.952503209242619,
      "grad_norm": 3.299968957901001,
      "learning_rate": 2.7563691263423503e-05,
      "loss": 1.001,
      "step": 2300
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3001456260681152,
      "eval_rouge1": 0.43274278530906335,
      "eval_rouge2": 0.2770096359462398,
      "eval_rougeL": 0.4266194448199325,
      "eval_rouge_sum": 1.1363718660752355,
      "eval_runtime": 29.8677,
      "eval_samples_per_second": 16.707,
      "eval_steps_per_second": 1.071,
      "step": 2337
    },
    {
      "epoch": 3.0808729139922977,
      "grad_norm": 2.987555503845215,
      "learning_rate": 2.6862860059166617e-05,
      "loss": 0.8938,
      "step": 2400
    },
    {
      "epoch": 3.209242618741977,
      "grad_norm": 3.4140396118164062,
      "learning_rate": 2.6162028854909725e-05,
      "loss": 0.8121,
      "step": 2500
    },
    {
      "epoch": 3.337612323491656,
      "grad_norm": 3.4006028175354004,
      "learning_rate": 2.5461197650652832e-05,
      "loss": 0.8281,
      "step": 2600
    },
    {
      "epoch": 3.465982028241335,
      "grad_norm": 3.308950185775757,
      "learning_rate": 2.4760366446395943e-05,
      "loss": 0.8229,
      "step": 2700
    },
    {
      "epoch": 3.594351732991014,
      "grad_norm": 3.4004452228546143,
      "learning_rate": 2.4059535242139054e-05,
      "loss": 0.8417,
      "step": 2800
    },
    {
      "epoch": 3.7227214377406934,
      "grad_norm": 3.8159217834472656,
      "learning_rate": 2.335870403788216e-05,
      "loss": 0.8401,
      "step": 2900
    },
    {
      "epoch": 3.851091142490372,
      "grad_norm": 3.7556653022766113,
      "learning_rate": 2.265787283362527e-05,
      "loss": 0.8302,
      "step": 3000
    },
    {
      "epoch": 3.9794608472400514,
      "grad_norm": 3.4574391841888428,
      "learning_rate": 2.195704162936838e-05,
      "loss": 0.8318,
      "step": 3100
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3465967178344727,
      "eval_rouge1": 0.44922926191720747,
      "eval_rouge2": 0.28864885648877653,
      "eval_rougeL": 0.44313316122665475,
      "eval_rouge_sum": 1.1810112796326386,
      "eval_runtime": 29.5511,
      "eval_samples_per_second": 16.886,
      "eval_steps_per_second": 1.083,
      "step": 3116
    },
    {
      "epoch": 4.10783055198973,
      "grad_norm": 3.4403858184814453,
      "learning_rate": 2.125621042511149e-05,
      "loss": 0.7029,
      "step": 3200
    },
    {
      "epoch": 4.2362002567394095,
      "grad_norm": 3.344799518585205,
      "learning_rate": 2.05553792208546e-05,
      "loss": 0.681,
      "step": 3300
    },
    {
      "epoch": 4.364569961489089,
      "grad_norm": 3.6291024684906006,
      "learning_rate": 1.9854548016597708e-05,
      "loss": 0.6868,
      "step": 3400
    },
    {
      "epoch": 4.492939666238768,
      "grad_norm": 3.1607909202575684,
      "learning_rate": 1.915371681234082e-05,
      "loss": 0.6894,
      "step": 3500
    },
    {
      "epoch": 4.621309370988447,
      "grad_norm": 3.561340570449829,
      "learning_rate": 1.845288560808393e-05,
      "loss": 0.6976,
      "step": 3600
    },
    {
      "epoch": 4.7496790757381255,
      "grad_norm": 3.4850809574127197,
      "learning_rate": 1.7752054403827037e-05,
      "loss": 0.7048,
      "step": 3700
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 3.4920904636383057,
      "learning_rate": 1.7051223199570147e-05,
      "loss": 0.696,
      "step": 3800
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3788566589355469,
      "eval_rouge1": 0.4640684467489107,
      "eval_rouge2": 0.3010018477110556,
      "eval_rougeL": 0.45291871360518954,
      "eval_rouge_sum": 1.2179890080651559,
      "eval_runtime": 26.8173,
      "eval_samples_per_second": 18.607,
      "eval_steps_per_second": 1.193,
      "step": 3895
    },
    {
      "epoch": 5.006418485237484,
      "grad_norm": 3.446899890899658,
      "learning_rate": 1.6350391995313258e-05,
      "loss": 0.703,
      "step": 3900
    },
    {
      "epoch": 5.134788189987163,
      "grad_norm": 3.024078607559204,
      "learning_rate": 1.5649560791056366e-05,
      "loss": 0.5782,
      "step": 4000
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 3.407186985015869,
      "learning_rate": 1.4948729586799475e-05,
      "loss": 0.5795,
      "step": 4100
    },
    {
      "epoch": 5.391527599486521,
      "grad_norm": 3.102543354034424,
      "learning_rate": 1.4247898382542585e-05,
      "loss": 0.5911,
      "step": 4200
    },
    {
      "epoch": 5.5198973042362,
      "grad_norm": 3.429455518722534,
      "learning_rate": 1.3547067178285694e-05,
      "loss": 0.5895,
      "step": 4300
    },
    {
      "epoch": 5.648267008985879,
      "grad_norm": 3.519929885864258,
      "learning_rate": 1.2846235974028804e-05,
      "loss": 0.6066,
      "step": 4400
    },
    {
      "epoch": 5.7766367137355585,
      "grad_norm": 3.6948673725128174,
      "learning_rate": 1.2145404769771913e-05,
      "loss": 0.6051,
      "step": 4500
    },
    {
      "epoch": 5.905006418485238,
      "grad_norm": 3.3696954250335693,
      "learning_rate": 1.1444573565515023e-05,
      "loss": 0.5942,
      "step": 4600
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.420929193496704,
      "eval_rouge1": 0.45559095822215956,
      "eval_rouge2": 0.29447008284481996,
      "eval_rougeL": 0.4458197306099868,
      "eval_rouge_sum": 1.1958807716769662,
      "eval_runtime": 26.4942,
      "eval_samples_per_second": 18.834,
      "eval_steps_per_second": 1.208,
      "step": 4674
    },
    {
      "epoch": 6.033376123234916,
      "grad_norm": 4.728013038635254,
      "learning_rate": 1.074374236125813e-05,
      "loss": 0.5774,
      "step": 4700
    },
    {
      "epoch": 6.161745827984595,
      "grad_norm": 2.865344524383545,
      "learning_rate": 1.0042911157001241e-05,
      "loss": 0.5112,
      "step": 4800
    },
    {
      "epoch": 6.290115532734275,
      "grad_norm": 3.414278984069824,
      "learning_rate": 9.34207995274435e-06,
      "loss": 0.5205,
      "step": 4900
    },
    {
      "epoch": 6.418485237483954,
      "grad_norm": 3.2660505771636963,
      "learning_rate": 8.641248748487461e-06,
      "loss": 0.5187,
      "step": 5000
    },
    {
      "epoch": 6.546854942233633,
      "grad_norm": 3.0864391326904297,
      "learning_rate": 7.94041754423057e-06,
      "loss": 0.5182,
      "step": 5100
    },
    {
      "epoch": 6.675224646983312,
      "grad_norm": 3.1216845512390137,
      "learning_rate": 7.239586339973679e-06,
      "loss": 0.519,
      "step": 5200
    },
    {
      "epoch": 6.803594351732991,
      "grad_norm": 2.948829412460327,
      "learning_rate": 6.5387551357167885e-06,
      "loss": 0.5245,
      "step": 5300
    },
    {
      "epoch": 6.93196405648267,
      "grad_norm": 3.6478271484375,
      "learning_rate": 5.8379239314598975e-06,
      "loss": 0.5162,
      "step": 5400
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.4471133947372437,
      "eval_rouge1": 0.4591203866823757,
      "eval_rouge2": 0.29434134659275346,
      "eval_rougeL": 0.4510817636814752,
      "eval_rouge_sum": 1.2045434969566045,
      "eval_runtime": 30.4865,
      "eval_samples_per_second": 16.368,
      "eval_steps_per_second": 1.05,
      "step": 5453
    },
    {
      "epoch": 7.060333761232349,
      "grad_norm": 2.5828866958618164,
      "learning_rate": 5.137092727203008e-06,
      "loss": 0.4977,
      "step": 5500
    },
    {
      "epoch": 7.188703465982028,
      "grad_norm": 2.9783973693847656,
      "learning_rate": 4.436261522946117e-06,
      "loss": 0.4683,
      "step": 5600
    },
    {
      "epoch": 7.317073170731708,
      "grad_norm": 2.4646072387695312,
      "learning_rate": 3.735430318689227e-06,
      "loss": 0.474,
      "step": 5700
    },
    {
      "epoch": 7.445442875481387,
      "grad_norm": 3.2309811115264893,
      "learning_rate": 3.0345991144323363e-06,
      "loss": 0.4725,
      "step": 5800
    },
    {
      "epoch": 7.573812580231065,
      "grad_norm": 3.0867416858673096,
      "learning_rate": 2.3337679101754454e-06,
      "loss": 0.4681,
      "step": 5900
    },
    {
      "epoch": 7.702182284980744,
      "grad_norm": 3.007303476333618,
      "learning_rate": 1.632936705918555e-06,
      "loss": 0.4713,
      "step": 6000
    },
    {
      "epoch": 7.830551989730424,
      "grad_norm": 3.160212278366089,
      "learning_rate": 9.321055016616644e-07,
      "loss": 0.4758,
      "step": 6100
    },
    {
      "epoch": 7.958921694480103,
      "grad_norm": 2.7316982746124268,
      "learning_rate": 2.3127429740477389e-07,
      "loss": 0.4642,
      "step": 6200
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.4637062549591064,
      "eval_rouge1": 0.4613169303278624,
      "eval_rouge2": 0.29852450805517927,
      "eval_rougeL": 0.45304666779380914,
      "eval_rouge_sum": 1.2128881061768508,
      "eval_runtime": 26.6374,
      "eval_samples_per_second": 18.733,
      "eval_steps_per_second": 1.201,
      "step": 6232
    }
  ],
  "logging_steps": 100,
  "max_steps": 6232,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.038194824118272e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
