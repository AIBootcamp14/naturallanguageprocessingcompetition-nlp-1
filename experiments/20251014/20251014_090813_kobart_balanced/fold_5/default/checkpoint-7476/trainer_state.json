{
  "best_global_step": 7476,
  "best_metric": 1.2075369932887692,
  "best_model_checkpoint": "experiments/20251014/20251014_090813_kobart_balanced/fold_5/default/checkpoint-7476",
  "epoch": 12.0,
  "eval_steps": 500,
  "global_step": 7476,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.651334285736084,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.1403,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 4.068536281585693,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.638,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.6712734699249268,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.5847,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.8082823753356934,
      "learning_rate": 3.99e-05,
      "loss": 1.5251,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.929732322692871,
      "learning_rate": 4.99e-05,
      "loss": 1.4886,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.6515393257141113,
      "learning_rate": 4.944036178631996e-05,
      "loss": 1.4626,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3998587131500244,
      "eval_rouge1": 0.40913237620947773,
      "eval_rouge2": 0.25859741770338934,
      "eval_rougeL": 0.40028080109699093,
      "eval_rouge_sum": 1.068010595009858,
      "eval_runtime": 344.5778,
      "eval_samples_per_second": 7.229,
      "eval_steps_per_second": 0.453,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.510146379470825,
      "learning_rate": 4.887507066139062e-05,
      "loss": 1.3098,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 3.542646884918213,
      "learning_rate": 4.830977953646128e-05,
      "loss": 1.2431,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.5275816917419434,
      "learning_rate": 4.774448841153194e-05,
      "loss": 1.2531,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.16302490234375,
      "learning_rate": 4.71791972866026e-05,
      "loss": 1.2658,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 3.0322582721710205,
      "learning_rate": 4.661390616167327e-05,
      "loss": 1.2408,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.275099039077759,
      "learning_rate": 4.604861503674392e-05,
      "loss": 1.2444,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3382233381271362,
      "eval_rouge1": 0.4101297059949803,
      "eval_rouge2": 0.2592480728047338,
      "eval_rougeL": 0.4018269951702185,
      "eval_rouge_sum": 1.0712047739699326,
      "eval_runtime": 344.4336,
      "eval_samples_per_second": 7.232,
      "eval_steps_per_second": 0.453,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 3.424136161804199,
      "learning_rate": 4.5483323911814584e-05,
      "loss": 1.0858,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 3.2489113807678223,
      "learning_rate": 4.491803278688525e-05,
      "loss": 0.9686,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.9313442707061768,
      "learning_rate": 4.435274166195591e-05,
      "loss": 0.9691,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 3.651634693145752,
      "learning_rate": 4.378745053702657e-05,
      "loss": 0.9765,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.4265055656433105,
      "learning_rate": 4.322215941209723e-05,
      "loss": 0.9841,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.771947145462036,
      "learning_rate": 4.2656868287167893e-05,
      "loss": 0.9803,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.356278419494629,
      "eval_rouge1": 0.44150569841261716,
      "eval_rouge2": 0.28178241603476883,
      "eval_rougeL": 0.4311062624024268,
      "eval_rouge_sum": 1.1543943768498126,
      "eval_runtime": 345.2262,
      "eval_samples_per_second": 7.216,
      "eval_steps_per_second": 0.452,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 3.424267292022705,
      "learning_rate": 4.2091577162238555e-05,
      "loss": 0.929,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.1767051219940186,
      "learning_rate": 4.152628603730922e-05,
      "loss": 0.7397,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 3.1695756912231445,
      "learning_rate": 4.096099491237988e-05,
      "loss": 0.7546,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 3.207671642303467,
      "learning_rate": 4.039570378745054e-05,
      "loss": 0.7722,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 3.2666022777557373,
      "learning_rate": 3.98304126625212e-05,
      "loss": 0.7728,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.40486741065979,
      "learning_rate": 3.926512153759186e-05,
      "loss": 0.7784,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.4181015491485596,
      "eval_rouge1": 0.43582177856475013,
      "eval_rouge2": 0.2740778066378397,
      "eval_rougeL": 0.4253992638633854,
      "eval_rouge_sum": 1.1352988490659752,
      "eval_runtime": 346.6002,
      "eval_samples_per_second": 7.187,
      "eval_steps_per_second": 0.45,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 3.3860244750976562,
      "learning_rate": 3.8699830412662526e-05,
      "loss": 0.7749,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 3.5742759704589844,
      "learning_rate": 3.813453928773318e-05,
      "loss": 0.5892,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 3.080670118331909,
      "learning_rate": 3.756924816280384e-05,
      "loss": 0.5859,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 2.806656837463379,
      "learning_rate": 3.700395703787451e-05,
      "loss": 0.602,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 3.8350155353546143,
      "learning_rate": 3.6438665912945167e-05,
      "loss": 0.5981,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.282836675643921,
      "learning_rate": 3.587337478801583e-05,
      "loss": 0.6072,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 3.863685131072998,
      "learning_rate": 3.530808366308649e-05,
      "loss": 0.6247,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.4948773384094238,
      "eval_rouge1": 0.4398370735889078,
      "eval_rouge2": 0.27859549848076726,
      "eval_rougeL": 0.42989015062147773,
      "eval_rouge_sum": 1.1483227226911528,
      "eval_runtime": 348.8782,
      "eval_samples_per_second": 7.14,
      "eval_steps_per_second": 0.447,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.8160595893859863,
      "learning_rate": 3.474279253815715e-05,
      "loss": 0.4791,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 3.2989814281463623,
      "learning_rate": 3.4177501413227814e-05,
      "loss": 0.4674,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 3.078261375427246,
      "learning_rate": 3.3612210288298476e-05,
      "loss": 0.4659,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 2.5509228706359863,
      "learning_rate": 3.304691916336914e-05,
      "loss": 0.4725,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 3.040972948074341,
      "learning_rate": 3.24816280384398e-05,
      "loss": 0.4844,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 3.133127450942993,
      "learning_rate": 3.191633691351046e-05,
      "loss": 0.4872,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.5592522621154785,
      "eval_rouge1": 0.44377602069770394,
      "eval_rouge2": 0.28322468010121066,
      "eval_rougeL": 0.43440008452963436,
      "eval_rouge_sum": 1.1614007853285488,
      "eval_runtime": 358.2797,
      "eval_samples_per_second": 6.953,
      "eval_steps_per_second": 0.435,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 2.884824275970459,
      "learning_rate": 3.1351045788581116e-05,
      "loss": 0.4022,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 3.315859794616699,
      "learning_rate": 3.0785754663651785e-05,
      "loss": 0.3626,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 3.0668561458587646,
      "learning_rate": 3.0220463538722443e-05,
      "loss": 0.3661,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 3.339646339416504,
      "learning_rate": 2.96551724137931e-05,
      "loss": 0.3722,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 3.0659148693084717,
      "learning_rate": 2.9089881288863767e-05,
      "loss": 0.3791,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 3.237544536590576,
      "learning_rate": 2.852459016393443e-05,
      "loss": 0.3852,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.6221129894256592,
      "eval_rouge1": 0.4432917519014602,
      "eval_rouge2": 0.28382998038676926,
      "eval_rougeL": 0.43274912253019404,
      "eval_rouge_sum": 1.1598708548184236,
      "eval_runtime": 363.344,
      "eval_samples_per_second": 6.856,
      "eval_steps_per_second": 0.429,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 2.774444580078125,
      "learning_rate": 2.7959299039005087e-05,
      "loss": 0.3457,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 3.346095085144043,
      "learning_rate": 2.739400791407575e-05,
      "loss": 0.2851,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.974510669708252,
      "learning_rate": 2.6828716789146414e-05,
      "loss": 0.2904,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 3.0178279876708984,
      "learning_rate": 2.6263425664217072e-05,
      "loss": 0.2925,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 2.9425601959228516,
      "learning_rate": 2.5698134539287734e-05,
      "loss": 0.3007,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 3.7797744274139404,
      "learning_rate": 2.51328434143584e-05,
      "loss": 0.3035,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.6891127824783325,
      "eval_rouge1": 0.4479867599550867,
      "eval_rouge2": 0.28508454102381375,
      "eval_rougeL": 0.4364823829532349,
      "eval_rouge_sum": 1.1695536839321354,
      "eval_runtime": 366.8707,
      "eval_samples_per_second": 6.79,
      "eval_steps_per_second": 0.425,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 2.3665239810943604,
      "learning_rate": 2.4567552289429058e-05,
      "loss": 0.2909,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 2.200967311859131,
      "learning_rate": 2.4002261164499716e-05,
      "loss": 0.227,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 2.4560112953186035,
      "learning_rate": 2.343697003957038e-05,
      "loss": 0.2316,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 2.8689870834350586,
      "learning_rate": 2.287167891464104e-05,
      "loss": 0.2393,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 3.240206718444824,
      "learning_rate": 2.2306387789711702e-05,
      "loss": 0.2379,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 2.474205493927002,
      "learning_rate": 2.1741096664782364e-05,
      "loss": 0.237,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 2.855858087539673,
      "learning_rate": 2.1175805539853025e-05,
      "loss": 0.2399,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.7172625064849854,
      "eval_rouge1": 0.44733482248803397,
      "eval_rouge2": 0.28554395891273243,
      "eval_rougeL": 0.4375388275493617,
      "eval_rouge_sum": 1.1704176089501281,
      "eval_runtime": 371.4192,
      "eval_samples_per_second": 6.707,
      "eval_steps_per_second": 0.42,
      "step": 5607
    },
    {
      "epoch": 9.149277688603531,
      "grad_norm": 2.5248165130615234,
      "learning_rate": 2.0610514414923687e-05,
      "loss": 0.186,
      "step": 5700
    },
    {
      "epoch": 9.309791332263242,
      "grad_norm": 2.8135576248168945,
      "learning_rate": 2.0045223289994346e-05,
      "loss": 0.1864,
      "step": 5800
    },
    {
      "epoch": 9.470304975922954,
      "grad_norm": 2.8073832988739014,
      "learning_rate": 1.947993216506501e-05,
      "loss": 0.1899,
      "step": 5900
    },
    {
      "epoch": 9.630818619582664,
      "grad_norm": 2.4601972103118896,
      "learning_rate": 1.891464104013567e-05,
      "loss": 0.1871,
      "step": 6000
    },
    {
      "epoch": 9.791332263242376,
      "grad_norm": 2.2433629035949707,
      "learning_rate": 1.834934991520633e-05,
      "loss": 0.1938,
      "step": 6100
    },
    {
      "epoch": 9.951845906902086,
      "grad_norm": 2.637812376022339,
      "learning_rate": 1.7784058790276993e-05,
      "loss": 0.1912,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.7730377912521362,
      "eval_rouge1": 0.4583364033586011,
      "eval_rouge2": 0.29052875768750047,
      "eval_rougeL": 0.44697696435634166,
      "eval_rouge_sum": 1.1958421254024432,
      "eval_runtime": 360.8038,
      "eval_samples_per_second": 6.904,
      "eval_steps_per_second": 0.432,
      "step": 6230
    },
    {
      "epoch": 10.112359550561798,
      "grad_norm": 2.2762510776519775,
      "learning_rate": 1.7218767665347655e-05,
      "loss": 0.1581,
      "step": 6300
    },
    {
      "epoch": 10.272873194221509,
      "grad_norm": 1.8716620206832886,
      "learning_rate": 1.6653476540418316e-05,
      "loss": 0.1515,
      "step": 6400
    },
    {
      "epoch": 10.43338683788122,
      "grad_norm": 2.1104094982147217,
      "learning_rate": 1.6088185415488978e-05,
      "loss": 0.1526,
      "step": 6500
    },
    {
      "epoch": 10.593900481540931,
      "grad_norm": 2.7101898193359375,
      "learning_rate": 1.552289429055964e-05,
      "loss": 0.1527,
      "step": 6600
    },
    {
      "epoch": 10.754414125200642,
      "grad_norm": 2.2953414916992188,
      "learning_rate": 1.4957603165630298e-05,
      "loss": 0.1583,
      "step": 6700
    },
    {
      "epoch": 10.914927768860354,
      "grad_norm": 2.319990396499634,
      "learning_rate": 1.4392312040700962e-05,
      "loss": 0.1555,
      "step": 6800
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.8171112537384033,
      "eval_rouge1": 0.45878016050964276,
      "eval_rouge2": 0.29277581663375396,
      "eval_rougeL": 0.44542844624093075,
      "eval_rouge_sum": 1.1969844233843274,
      "eval_runtime": 358.7712,
      "eval_samples_per_second": 6.943,
      "eval_steps_per_second": 0.435,
      "step": 6853
    },
    {
      "epoch": 11.075441412520064,
      "grad_norm": 2.6244499683380127,
      "learning_rate": 1.3827020915771624e-05,
      "loss": 0.1461,
      "step": 6900
    },
    {
      "epoch": 11.235955056179776,
      "grad_norm": 2.5422866344451904,
      "learning_rate": 1.3261729790842284e-05,
      "loss": 0.1258,
      "step": 7000
    },
    {
      "epoch": 11.396468699839486,
      "grad_norm": 2.0110700130462646,
      "learning_rate": 1.2696438665912946e-05,
      "loss": 0.1265,
      "step": 7100
    },
    {
      "epoch": 11.556982343499197,
      "grad_norm": 2.008241891860962,
      "learning_rate": 1.2131147540983608e-05,
      "loss": 0.1272,
      "step": 7200
    },
    {
      "epoch": 11.717495987158909,
      "grad_norm": 2.1403377056121826,
      "learning_rate": 1.156585641605427e-05,
      "loss": 0.1268,
      "step": 7300
    },
    {
      "epoch": 11.87800963081862,
      "grad_norm": 1.962826132774353,
      "learning_rate": 1.100056529112493e-05,
      "loss": 0.1295,
      "step": 7400
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.8521900177001953,
      "eval_rouge1": 0.4615091211783212,
      "eval_rouge2": 0.29599805686718206,
      "eval_rougeL": 0.45002981524326585,
      "eval_rouge_sum": 1.2075369932887692,
      "eval_runtime": 358.8294,
      "eval_samples_per_second": 6.942,
      "eval_steps_per_second": 0.435,
      "step": 7476
    }
  ],
  "logging_steps": 100,
  "max_steps": 9345,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.645980125691904e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
