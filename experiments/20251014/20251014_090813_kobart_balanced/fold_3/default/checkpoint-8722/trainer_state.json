{
  "best_global_step": 6853,
  "best_metric": 1.226395664849036,
  "best_model_checkpoint": "experiments/20251014/20251014_090813_kobart_balanced/fold_3/default/checkpoint-6853",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 8722,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.314073085784912,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.1503,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 4.289769172668457,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.6416,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 4.612136363983154,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.5598,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.9981653690338135,
      "learning_rate": 3.99e-05,
      "loss": 1.5346,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.4102582931518555,
      "learning_rate": 4.99e-05,
      "loss": 1.5059,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.5190682411193848,
      "learning_rate": 4.944036178631996e-05,
      "loss": 1.4629,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.391784906387329,
      "eval_rouge1": 0.40044381042512794,
      "eval_rouge2": 0.25002921848558846,
      "eval_rougeL": 0.39318764084677915,
      "eval_rouge_sum": 1.0436606697574955,
      "eval_runtime": 313.8759,
      "eval_samples_per_second": 7.936,
      "eval_steps_per_second": 0.497,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.410689115524292,
      "learning_rate": 4.887507066139062e-05,
      "loss": 1.306,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 3.970885992050171,
      "learning_rate": 4.830977953646128e-05,
      "loss": 1.263,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.8668227195739746,
      "learning_rate": 4.774448841153194e-05,
      "loss": 1.2653,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 16.553613662719727,
      "learning_rate": 4.71791972866026e-05,
      "loss": 1.2287,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 4.41334342956543,
      "learning_rate": 4.661390616167327e-05,
      "loss": 1.2452,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.4679551124572754,
      "learning_rate": 4.604861503674392e-05,
      "loss": 1.2591,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3371732234954834,
      "eval_rouge1": 0.41421705585439367,
      "eval_rouge2": 0.2624120112984969,
      "eval_rougeL": 0.4062799192369652,
      "eval_rouge_sum": 1.0829089863898558,
      "eval_runtime": 313.6644,
      "eval_samples_per_second": 7.942,
      "eval_steps_per_second": 0.497,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 3.2149977684020996,
      "learning_rate": 4.5483323911814584e-05,
      "loss": 1.085,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 3.2011401653289795,
      "learning_rate": 4.491803278688525e-05,
      "loss": 0.9752,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.3737547397613525,
      "learning_rate": 4.435274166195591e-05,
      "loss": 0.9953,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 3.306830883026123,
      "learning_rate": 4.378745053702657e-05,
      "loss": 0.9646,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.182112216949463,
      "learning_rate": 4.322215941209723e-05,
      "loss": 0.9944,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.212055206298828,
      "learning_rate": 4.2656868287167893e-05,
      "loss": 0.9873,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3487823009490967,
      "eval_rouge1": 0.4288564500587998,
      "eval_rouge2": 0.274424365278506,
      "eval_rougeL": 0.42085119371765933,
      "eval_rouge_sum": 1.1241320090549651,
      "eval_runtime": 313.2191,
      "eval_samples_per_second": 7.953,
      "eval_steps_per_second": 0.498,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 3.025322198867798,
      "learning_rate": 4.2091577162238555e-05,
      "loss": 0.9034,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.68784236907959,
      "learning_rate": 4.152628603730922e-05,
      "loss": 0.7452,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 3.9345579147338867,
      "learning_rate": 4.096099491237988e-05,
      "loss": 0.7551,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 3.77604079246521,
      "learning_rate": 4.039570378745054e-05,
      "loss": 0.7686,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 3.256580352783203,
      "learning_rate": 3.98304126625212e-05,
      "loss": 0.7685,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.1612887382507324,
      "learning_rate": 3.926512153759186e-05,
      "loss": 0.7931,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.4079314470291138,
      "eval_rouge1": 0.4434460874243459,
      "eval_rouge2": 0.28203746947729713,
      "eval_rougeL": 0.43396161909047953,
      "eval_rouge_sum": 1.1594451759921225,
      "eval_runtime": 314.398,
      "eval_samples_per_second": 7.923,
      "eval_steps_per_second": 0.496,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.7055463790893555,
      "learning_rate": 3.8699830412662526e-05,
      "loss": 0.7779,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 3.4591715335845947,
      "learning_rate": 3.813453928773318e-05,
      "loss": 0.5743,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 3.3411507606506348,
      "learning_rate": 3.756924816280384e-05,
      "loss": 0.5909,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 3.5047287940979004,
      "learning_rate": 3.700395703787451e-05,
      "loss": 0.6,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 3.050433874130249,
      "learning_rate": 3.6438665912945167e-05,
      "loss": 0.6077,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.0760626792907715,
      "learning_rate": 3.587337478801583e-05,
      "loss": 0.6107,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 3.199930191040039,
      "learning_rate": 3.530808366308649e-05,
      "loss": 0.6213,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.4835114479064941,
      "eval_rouge1": 0.4450022204854732,
      "eval_rouge2": 0.2849970861073512,
      "eval_rougeL": 0.43578431001266826,
      "eval_rouge_sum": 1.1657836166054927,
      "eval_runtime": 313.2818,
      "eval_samples_per_second": 7.951,
      "eval_steps_per_second": 0.498,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 2.85304594039917,
      "learning_rate": 3.474279253815715e-05,
      "loss": 0.4753,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 3.181858777999878,
      "learning_rate": 3.4177501413227814e-05,
      "loss": 0.4558,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 3.152881383895874,
      "learning_rate": 3.3612210288298476e-05,
      "loss": 0.4632,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 3.110886335372925,
      "learning_rate": 3.304691916336914e-05,
      "loss": 0.4721,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 3.1620185375213623,
      "learning_rate": 3.24816280384398e-05,
      "loss": 0.4839,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 2.928189992904663,
      "learning_rate": 3.191633691351046e-05,
      "loss": 0.4864,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.5503826141357422,
      "eval_rouge1": 0.44297111386274846,
      "eval_rouge2": 0.2857012153235078,
      "eval_rougeL": 0.43351994813123995,
      "eval_rouge_sum": 1.1621922773174962,
      "eval_runtime": 315.2383,
      "eval_samples_per_second": 7.902,
      "eval_steps_per_second": 0.495,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 3.065396308898926,
      "learning_rate": 3.1351045788581116e-05,
      "loss": 0.4039,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 2.5986571311950684,
      "learning_rate": 3.0785754663651785e-05,
      "loss": 0.3587,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 2.7397758960723877,
      "learning_rate": 3.0220463538722443e-05,
      "loss": 0.3657,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 3.2426137924194336,
      "learning_rate": 2.96551724137931e-05,
      "loss": 0.367,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 3.1636335849761963,
      "learning_rate": 2.9089881288863767e-05,
      "loss": 0.3753,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 4.25323486328125,
      "learning_rate": 2.852459016393443e-05,
      "loss": 0.3784,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.6250367164611816,
      "eval_rouge1": 0.44665727679084966,
      "eval_rouge2": 0.2829208789860473,
      "eval_rougeL": 0.4371173623424355,
      "eval_rouge_sum": 1.1666955181193326,
      "eval_runtime": 318.3748,
      "eval_samples_per_second": 7.824,
      "eval_steps_per_second": 0.49,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 3.4123950004577637,
      "learning_rate": 2.7959299039005087e-05,
      "loss": 0.3457,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 2.6170945167541504,
      "learning_rate": 2.739400791407575e-05,
      "loss": 0.2775,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.5443294048309326,
      "learning_rate": 2.6828716789146414e-05,
      "loss": 0.2903,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 3.6643435955047607,
      "learning_rate": 2.6263425664217072e-05,
      "loss": 0.2936,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 3.010754346847534,
      "learning_rate": 2.5698134539287734e-05,
      "loss": 0.2965,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 3.5431289672851562,
      "learning_rate": 2.51328434143584e-05,
      "loss": 0.3014,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.6782944202423096,
      "eval_rouge1": 0.46159756552782866,
      "eval_rouge2": 0.29304189362371896,
      "eval_rougeL": 0.4509144146040165,
      "eval_rouge_sum": 1.205553873755564,
      "eval_runtime": 316.6439,
      "eval_samples_per_second": 7.867,
      "eval_steps_per_second": 0.493,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 2.2987189292907715,
      "learning_rate": 2.4567552289429058e-05,
      "loss": 0.2924,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 2.3798601627349854,
      "learning_rate": 2.4002261164499716e-05,
      "loss": 0.2256,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 2.5452301502227783,
      "learning_rate": 2.343697003957038e-05,
      "loss": 0.2274,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 2.785989284515381,
      "learning_rate": 2.287167891464104e-05,
      "loss": 0.236,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 2.870187520980835,
      "learning_rate": 2.2306387789711702e-05,
      "loss": 0.234,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 2.638998508453369,
      "learning_rate": 2.1741096664782364e-05,
      "loss": 0.235,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 2.5254387855529785,
      "learning_rate": 2.1175805539853025e-05,
      "loss": 0.2373,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.7276428937911987,
      "eval_rouge1": 0.44875898994537267,
      "eval_rouge2": 0.28688052066283587,
      "eval_rougeL": 0.4391322086016937,
      "eval_rouge_sum": 1.1747717192099023,
      "eval_runtime": 316.5262,
      "eval_samples_per_second": 7.87,
      "eval_steps_per_second": 0.493,
      "step": 5607
    },
    {
      "epoch": 9.149277688603531,
      "grad_norm": 2.6843554973602295,
      "learning_rate": 2.0610514414923687e-05,
      "loss": 0.1836,
      "step": 5700
    },
    {
      "epoch": 9.309791332263242,
      "grad_norm": 2.6541688442230225,
      "learning_rate": 2.0045223289994346e-05,
      "loss": 0.1848,
      "step": 5800
    },
    {
      "epoch": 9.470304975922954,
      "grad_norm": 2.6224987506866455,
      "learning_rate": 1.947993216506501e-05,
      "loss": 0.1868,
      "step": 5900
    },
    {
      "epoch": 9.630818619582664,
      "grad_norm": 2.642625093460083,
      "learning_rate": 1.891464104013567e-05,
      "loss": 0.1891,
      "step": 6000
    },
    {
      "epoch": 9.791332263242376,
      "grad_norm": 2.4269328117370605,
      "learning_rate": 1.834934991520633e-05,
      "loss": 0.1924,
      "step": 6100
    },
    {
      "epoch": 9.951845906902086,
      "grad_norm": 2.5876662731170654,
      "learning_rate": 1.7784058790276993e-05,
      "loss": 0.1883,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.7849719524383545,
      "eval_rouge1": 0.4673043028189116,
      "eval_rouge2": 0.2994002589605897,
      "eval_rougeL": 0.45603496740355653,
      "eval_rouge_sum": 1.2227395291830578,
      "eval_runtime": 317.0691,
      "eval_samples_per_second": 7.856,
      "eval_steps_per_second": 0.492,
      "step": 6230
    },
    {
      "epoch": 10.112359550561798,
      "grad_norm": 2.531646490097046,
      "learning_rate": 1.7218767665347655e-05,
      "loss": 0.158,
      "step": 6300
    },
    {
      "epoch": 10.272873194221509,
      "grad_norm": 2.8234705924987793,
      "learning_rate": 1.6653476540418316e-05,
      "loss": 0.151,
      "step": 6400
    },
    {
      "epoch": 10.43338683788122,
      "grad_norm": 2.039577007293701,
      "learning_rate": 1.6088185415488978e-05,
      "loss": 0.1522,
      "step": 6500
    },
    {
      "epoch": 10.593900481540931,
      "grad_norm": 1.9757193326950073,
      "learning_rate": 1.552289429055964e-05,
      "loss": 0.1541,
      "step": 6600
    },
    {
      "epoch": 10.754414125200642,
      "grad_norm": 2.2070846557617188,
      "learning_rate": 1.4957603165630298e-05,
      "loss": 0.1538,
      "step": 6700
    },
    {
      "epoch": 10.914927768860354,
      "grad_norm": 2.4647605419158936,
      "learning_rate": 1.4392312040700962e-05,
      "loss": 0.1525,
      "step": 6800
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.8239377737045288,
      "eval_rouge1": 0.4693847868789896,
      "eval_rouge2": 0.2991398235849619,
      "eval_rougeL": 0.45787105438508446,
      "eval_rouge_sum": 1.226395664849036,
      "eval_runtime": 318.9602,
      "eval_samples_per_second": 7.81,
      "eval_steps_per_second": 0.489,
      "step": 6853
    },
    {
      "epoch": 11.075441412520064,
      "grad_norm": 2.3594610691070557,
      "learning_rate": 1.3827020915771624e-05,
      "loss": 0.1399,
      "step": 6900
    },
    {
      "epoch": 11.235955056179776,
      "grad_norm": 2.068671226501465,
      "learning_rate": 1.3261729790842284e-05,
      "loss": 0.1219,
      "step": 7000
    },
    {
      "epoch": 11.396468699839486,
      "grad_norm": 1.6963233947753906,
      "learning_rate": 1.2696438665912946e-05,
      "loss": 0.1243,
      "step": 7100
    },
    {
      "epoch": 11.556982343499197,
      "grad_norm": 2.1291587352752686,
      "learning_rate": 1.2131147540983608e-05,
      "loss": 0.1245,
      "step": 7200
    },
    {
      "epoch": 11.717495987158909,
      "grad_norm": 2.1927554607391357,
      "learning_rate": 1.156585641605427e-05,
      "loss": 0.1263,
      "step": 7300
    },
    {
      "epoch": 11.87800963081862,
      "grad_norm": 2.226623058319092,
      "learning_rate": 1.100056529112493e-05,
      "loss": 0.1271,
      "step": 7400
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.8572896718978882,
      "eval_rouge1": 0.4656085481156391,
      "eval_rouge2": 0.2971952251765783,
      "eval_rougeL": 0.4555747494840285,
      "eval_rouge_sum": 1.218378522776246,
      "eval_runtime": 319.2591,
      "eval_samples_per_second": 7.802,
      "eval_steps_per_second": 0.489,
      "step": 7476
    },
    {
      "epoch": 12.038523274478331,
      "grad_norm": 2.14213228225708,
      "learning_rate": 1.0435274166195591e-05,
      "loss": 0.1209,
      "step": 7500
    },
    {
      "epoch": 12.199036918138042,
      "grad_norm": 2.113856792449951,
      "learning_rate": 9.869983041266251e-06,
      "loss": 0.1042,
      "step": 7600
    },
    {
      "epoch": 12.359550561797754,
      "grad_norm": 1.7449593544006348,
      "learning_rate": 9.304691916336913e-06,
      "loss": 0.106,
      "step": 7700
    },
    {
      "epoch": 12.520064205457464,
      "grad_norm": 1.7783935070037842,
      "learning_rate": 8.739400791407577e-06,
      "loss": 0.1037,
      "step": 7800
    },
    {
      "epoch": 12.680577849117174,
      "grad_norm": 1.967507004737854,
      "learning_rate": 8.174109666478237e-06,
      "loss": 0.1086,
      "step": 7900
    },
    {
      "epoch": 12.841091492776886,
      "grad_norm": 2.184154748916626,
      "learning_rate": 7.608818541548899e-06,
      "loss": 0.1082,
      "step": 8000
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.88104248046875,
      "eval_rouge1": 0.46145367845182395,
      "eval_rouge2": 0.29554030591293723,
      "eval_rougeL": 0.4515227756358736,
      "eval_rouge_sum": 1.2085167600006348,
      "eval_runtime": 319.7931,
      "eval_samples_per_second": 7.789,
      "eval_steps_per_second": 0.488,
      "step": 8099
    },
    {
      "epoch": 13.001605136436597,
      "grad_norm": 1.8251198530197144,
      "learning_rate": 7.04352741661956e-06,
      "loss": 0.1056,
      "step": 8100
    },
    {
      "epoch": 13.162118780096309,
      "grad_norm": 2.072206497192383,
      "learning_rate": 6.478236291690221e-06,
      "loss": 0.0902,
      "step": 8200
    },
    {
      "epoch": 13.32263242375602,
      "grad_norm": 1.7051960229873657,
      "learning_rate": 5.912945166760882e-06,
      "loss": 0.0904,
      "step": 8300
    },
    {
      "epoch": 13.48314606741573,
      "grad_norm": 1.5238585472106934,
      "learning_rate": 5.347654041831543e-06,
      "loss": 0.0912,
      "step": 8400
    },
    {
      "epoch": 13.643659711075442,
      "grad_norm": 2.3466975688934326,
      "learning_rate": 4.782362916902205e-06,
      "loss": 0.0899,
      "step": 8500
    },
    {
      "epoch": 13.804173354735152,
      "grad_norm": 2.0059802532196045,
      "learning_rate": 4.217071791972866e-06,
      "loss": 0.0919,
      "step": 8600
    },
    {
      "epoch": 13.964686998394864,
      "grad_norm": 1.7821807861328125,
      "learning_rate": 3.651780667043528e-06,
      "loss": 0.0909,
      "step": 8700
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.9057300090789795,
      "eval_rouge1": 0.46703948851962085,
      "eval_rouge2": 0.3020785924054995,
      "eval_rougeL": 0.45634664548433396,
      "eval_rouge_sum": 1.2254647264094543,
      "eval_runtime": 317.9351,
      "eval_samples_per_second": 7.835,
      "eval_steps_per_second": 0.491,
      "step": 8722
    }
  ],
  "logging_steps": 100,
  "max_steps": 9345,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.253643479973888e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
