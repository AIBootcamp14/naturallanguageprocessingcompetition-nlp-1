{
  "best_global_step": 7476,
  "best_metric": 1.2232781684716527,
  "best_model_checkpoint": "experiments/20251014/20251014_090813_kobart_balanced/fold_1/default/checkpoint-7476",
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 9345,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.489185810089111,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.1531,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 3.7915103435516357,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.6514,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 4.011915683746338,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.5723,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.339083194732666,
      "learning_rate": 3.99e-05,
      "loss": 1.5336,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 3.9378459453582764,
      "learning_rate": 4.99e-05,
      "loss": 1.4978,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.7429141998291016,
      "learning_rate": 4.944036178631996e-05,
      "loss": 1.4464,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.392896056175232,
      "eval_rouge1": 0.39583326629121923,
      "eval_rouge2": 0.24555791702206087,
      "eval_rougeL": 0.3875504756578239,
      "eval_rouge_sum": 1.028941658971104,
      "eval_runtime": 294.3602,
      "eval_samples_per_second": 8.466,
      "eval_steps_per_second": 0.53,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.6839802265167236,
      "learning_rate": 4.887507066139062e-05,
      "loss": 1.314,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 3.2839434146881104,
      "learning_rate": 4.830977953646128e-05,
      "loss": 1.2675,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.7500452995300293,
      "learning_rate": 4.774448841153194e-05,
      "loss": 1.2493,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.9722676277160645,
      "learning_rate": 4.71791972866026e-05,
      "loss": 1.2833,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 3.352959632873535,
      "learning_rate": 4.661390616167327e-05,
      "loss": 1.2366,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.9990293979644775,
      "learning_rate": 4.604861503674392e-05,
      "loss": 1.2517,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3375699520111084,
      "eval_rouge1": 0.40962063130718634,
      "eval_rouge2": 0.2620776594134463,
      "eval_rougeL": 0.4029189658100632,
      "eval_rouge_sum": 1.0746172565306957,
      "eval_runtime": 311.9451,
      "eval_samples_per_second": 7.989,
      "eval_steps_per_second": 0.5,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 2.910457134246826,
      "learning_rate": 4.5483323911814584e-05,
      "loss": 1.0911,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 3.0870282649993896,
      "learning_rate": 4.491803278688525e-05,
      "loss": 0.9631,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.932147979736328,
      "learning_rate": 4.435274166195591e-05,
      "loss": 0.985,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 3.2362172603607178,
      "learning_rate": 4.378745053702657e-05,
      "loss": 0.9919,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.571103096008301,
      "learning_rate": 4.322215941209723e-05,
      "loss": 0.9972,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.2972359657287598,
      "learning_rate": 4.2656868287167893e-05,
      "loss": 0.9922,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.344132661819458,
      "eval_rouge1": 0.4316859420707987,
      "eval_rouge2": 0.2747540685384241,
      "eval_rougeL": 0.42300971984341956,
      "eval_rouge_sum": 1.1294497304526423,
      "eval_runtime": 320.2133,
      "eval_samples_per_second": 7.782,
      "eval_steps_per_second": 0.487,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 3.5688228607177734,
      "learning_rate": 4.2091577162238555e-05,
      "loss": 0.9398,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.608423948287964,
      "learning_rate": 4.152628603730922e-05,
      "loss": 0.7645,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 3.7278053760528564,
      "learning_rate": 4.096099491237988e-05,
      "loss": 0.7675,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 3.097214698791504,
      "learning_rate": 4.039570378745054e-05,
      "loss": 0.7706,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 3.4168243408203125,
      "learning_rate": 3.98304126625212e-05,
      "loss": 0.7777,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.4093806743621826,
      "learning_rate": 3.926512153759186e-05,
      "loss": 0.7897,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.4103279113769531,
      "eval_rouge1": 0.44529357263304176,
      "eval_rouge2": 0.2826772605058427,
      "eval_rougeL": 0.4355270611302739,
      "eval_rouge_sum": 1.1634978942691583,
      "eval_runtime": 316.2495,
      "eval_samples_per_second": 7.88,
      "eval_steps_per_second": 0.493,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.9626846313476562,
      "learning_rate": 3.8699830412662526e-05,
      "loss": 0.7726,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 4.1365437507629395,
      "learning_rate": 3.813453928773318e-05,
      "loss": 0.5841,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 4.459263801574707,
      "learning_rate": 3.756924816280384e-05,
      "loss": 0.5981,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 3.432373046875,
      "learning_rate": 3.700395703787451e-05,
      "loss": 0.596,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 6.0225911140441895,
      "learning_rate": 3.6438665912945167e-05,
      "loss": 0.6139,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.086092233657837,
      "learning_rate": 3.587337478801583e-05,
      "loss": 0.6229,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 3.342611789703369,
      "learning_rate": 3.530808366308649e-05,
      "loss": 0.6301,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.47602379322052,
      "eval_rouge1": 0.44185717686542875,
      "eval_rouge2": 0.2786862883267776,
      "eval_rougeL": 0.43153257418375585,
      "eval_rouge_sum": 1.1520760393759621,
      "eval_runtime": 326.4902,
      "eval_samples_per_second": 7.633,
      "eval_steps_per_second": 0.478,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 3.312227725982666,
      "learning_rate": 3.474279253815715e-05,
      "loss": 0.4864,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 3.0194363594055176,
      "learning_rate": 3.4177501413227814e-05,
      "loss": 0.4667,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 3.3658955097198486,
      "learning_rate": 3.3612210288298476e-05,
      "loss": 0.4813,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 3.7881274223327637,
      "learning_rate": 3.304691916336914e-05,
      "loss": 0.4782,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 3.570544958114624,
      "learning_rate": 3.24816280384398e-05,
      "loss": 0.4825,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 3.6214921474456787,
      "learning_rate": 3.191633691351046e-05,
      "loss": 0.4926,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.5393247604370117,
      "eval_rouge1": 0.4391882478944783,
      "eval_rouge2": 0.2820638949170777,
      "eval_rougeL": 0.4308145088905421,
      "eval_rouge_sum": 1.152066651702098,
      "eval_runtime": 348.3504,
      "eval_samples_per_second": 7.154,
      "eval_steps_per_second": 0.448,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 3.1918914318084717,
      "learning_rate": 3.1351045788581116e-05,
      "loss": 0.4095,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 3.0745151042938232,
      "learning_rate": 3.0785754663651785e-05,
      "loss": 0.3628,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 2.846791982650757,
      "learning_rate": 3.0220463538722443e-05,
      "loss": 0.3828,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 2.7377655506134033,
      "learning_rate": 2.96551724137931e-05,
      "loss": 0.3818,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 3.4611546993255615,
      "learning_rate": 2.9089881288863767e-05,
      "loss": 0.3874,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 2.8316755294799805,
      "learning_rate": 2.852459016393443e-05,
      "loss": 0.3802,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.6151819229125977,
      "eval_rouge1": 0.45581088982766105,
      "eval_rouge2": 0.2891347298781442,
      "eval_rougeL": 0.4441621204397436,
      "eval_rouge_sum": 1.189107740145549,
      "eval_runtime": 366.3939,
      "eval_samples_per_second": 6.801,
      "eval_steps_per_second": 0.426,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 2.3611669540405273,
      "learning_rate": 2.7959299039005087e-05,
      "loss": 0.3465,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 2.750584602355957,
      "learning_rate": 2.739400791407575e-05,
      "loss": 0.29,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.9528920650482178,
      "learning_rate": 2.6828716789146414e-05,
      "loss": 0.2977,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 3.5012831687927246,
      "learning_rate": 2.6263425664217072e-05,
      "loss": 0.3011,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 2.7560012340545654,
      "learning_rate": 2.5698134539287734e-05,
      "loss": 0.3003,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 2.9484691619873047,
      "learning_rate": 2.51328434143584e-05,
      "loss": 0.3065,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.67362642288208,
      "eval_rouge1": 0.44733159642073517,
      "eval_rouge2": 0.2872476069874094,
      "eval_rougeL": 0.4369426349848502,
      "eval_rouge_sum": 1.1715218383929948,
      "eval_runtime": 354.8039,
      "eval_samples_per_second": 7.024,
      "eval_steps_per_second": 0.44,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 5.490448951721191,
      "learning_rate": 2.4567552289429058e-05,
      "loss": 0.296,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 2.4418323040008545,
      "learning_rate": 2.4002261164499716e-05,
      "loss": 0.2238,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 2.7151408195495605,
      "learning_rate": 2.343697003957038e-05,
      "loss": 0.2348,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 3.213239908218384,
      "learning_rate": 2.287167891464104e-05,
      "loss": 0.2374,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 3.0437374114990234,
      "learning_rate": 2.2306387789711702e-05,
      "loss": 0.2423,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 2.816304922103882,
      "learning_rate": 2.1741096664782364e-05,
      "loss": 0.2473,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 2.639594793319702,
      "learning_rate": 2.1175805539853025e-05,
      "loss": 0.2467,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.7135964632034302,
      "eval_rouge1": 0.46230180004178956,
      "eval_rouge2": 0.29788742317738104,
      "eval_rougeL": 0.4507008890779583,
      "eval_rouge_sum": 1.210890112297129,
      "eval_runtime": 356.3885,
      "eval_samples_per_second": 6.992,
      "eval_steps_per_second": 0.438,
      "step": 5607
    },
    {
      "epoch": 9.149277688603531,
      "grad_norm": 2.4778997898101807,
      "learning_rate": 2.0610514414923687e-05,
      "loss": 0.1884,
      "step": 5700
    },
    {
      "epoch": 9.309791332263242,
      "grad_norm": 2.6228678226470947,
      "learning_rate": 2.0045223289994346e-05,
      "loss": 0.1924,
      "step": 5800
    },
    {
      "epoch": 9.470304975922954,
      "grad_norm": 2.3802731037139893,
      "learning_rate": 1.947993216506501e-05,
      "loss": 0.1869,
      "step": 5900
    },
    {
      "epoch": 9.630818619582664,
      "grad_norm": 2.1081719398498535,
      "learning_rate": 1.891464104013567e-05,
      "loss": 0.193,
      "step": 6000
    },
    {
      "epoch": 9.791332263242376,
      "grad_norm": 2.3111860752105713,
      "learning_rate": 1.834934991520633e-05,
      "loss": 0.193,
      "step": 6100
    },
    {
      "epoch": 9.951845906902086,
      "grad_norm": 2.428452968597412,
      "learning_rate": 1.7784058790276993e-05,
      "loss": 0.1969,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.7667138576507568,
      "eval_rouge1": 0.4567754285325296,
      "eval_rouge2": 0.2911703795306811,
      "eval_rougeL": 0.4467762700227013,
      "eval_rouge_sum": 1.194722078085912,
      "eval_runtime": 355.8531,
      "eval_samples_per_second": 7.003,
      "eval_steps_per_second": 0.438,
      "step": 6230
    },
    {
      "epoch": 10.112359550561798,
      "grad_norm": 2.3005788326263428,
      "learning_rate": 1.7218767665347655e-05,
      "loss": 0.1627,
      "step": 6300
    },
    {
      "epoch": 10.272873194221509,
      "grad_norm": 2.728832721710205,
      "learning_rate": 1.6653476540418316e-05,
      "loss": 0.1505,
      "step": 6400
    },
    {
      "epoch": 10.43338683788122,
      "grad_norm": 2.4417247772216797,
      "learning_rate": 1.6088185415488978e-05,
      "loss": 0.1535,
      "step": 6500
    },
    {
      "epoch": 10.593900481540931,
      "grad_norm": 2.572190999984741,
      "learning_rate": 1.552289429055964e-05,
      "loss": 0.1568,
      "step": 6600
    },
    {
      "epoch": 10.754414125200642,
      "grad_norm": 2.1269900798797607,
      "learning_rate": 1.4957603165630298e-05,
      "loss": 0.1587,
      "step": 6700
    },
    {
      "epoch": 10.914927768860354,
      "grad_norm": 2.272793769836426,
      "learning_rate": 1.4392312040700962e-05,
      "loss": 0.1593,
      "step": 6800
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.807669997215271,
      "eval_rouge1": 0.4630051794830225,
      "eval_rouge2": 0.2930134862637478,
      "eval_rougeL": 0.45148830220035874,
      "eval_rouge_sum": 1.207506967947129,
      "eval_runtime": 320.9287,
      "eval_samples_per_second": 7.765,
      "eval_steps_per_second": 0.486,
      "step": 6853
    },
    {
      "epoch": 11.075441412520064,
      "grad_norm": 2.0203866958618164,
      "learning_rate": 1.3827020915771624e-05,
      "loss": 0.1434,
      "step": 6900
    },
    {
      "epoch": 11.235955056179776,
      "grad_norm": 2.0377004146575928,
      "learning_rate": 1.3261729790842284e-05,
      "loss": 0.1279,
      "step": 7000
    },
    {
      "epoch": 11.396468699839486,
      "grad_norm": 2.0124855041503906,
      "learning_rate": 1.2696438665912946e-05,
      "loss": 0.1263,
      "step": 7100
    },
    {
      "epoch": 11.556982343499197,
      "grad_norm": 1.7988698482513428,
      "learning_rate": 1.2131147540983608e-05,
      "loss": 0.1283,
      "step": 7200
    },
    {
      "epoch": 11.717495987158909,
      "grad_norm": 1.9415769577026367,
      "learning_rate": 1.156585641605427e-05,
      "loss": 0.1296,
      "step": 7300
    },
    {
      "epoch": 11.87800963081862,
      "grad_norm": 2.387305736541748,
      "learning_rate": 1.100056529112493e-05,
      "loss": 0.1299,
      "step": 7400
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.840354323387146,
      "eval_rouge1": 0.4684592708472068,
      "eval_rouge2": 0.2978512075108336,
      "eval_rougeL": 0.45696769011361227,
      "eval_rouge_sum": 1.2232781684716527,
      "eval_runtime": 317.5151,
      "eval_samples_per_second": 7.848,
      "eval_steps_per_second": 0.491,
      "step": 7476
    },
    {
      "epoch": 12.038523274478331,
      "grad_norm": 1.9434139728546143,
      "learning_rate": 1.0435274166195591e-05,
      "loss": 0.1249,
      "step": 7500
    },
    {
      "epoch": 12.199036918138042,
      "grad_norm": 1.9816396236419678,
      "learning_rate": 9.869983041266251e-06,
      "loss": 0.106,
      "step": 7600
    },
    {
      "epoch": 12.359550561797754,
      "grad_norm": 1.6186896562576294,
      "learning_rate": 9.304691916336913e-06,
      "loss": 0.1064,
      "step": 7700
    },
    {
      "epoch": 12.520064205457464,
      "grad_norm": 2.3329484462738037,
      "learning_rate": 8.739400791407577e-06,
      "loss": 0.1089,
      "step": 7800
    },
    {
      "epoch": 12.680577849117174,
      "grad_norm": 1.8710182905197144,
      "learning_rate": 8.174109666478237e-06,
      "loss": 0.1075,
      "step": 7900
    },
    {
      "epoch": 12.841091492776886,
      "grad_norm": 2.1796677112579346,
      "learning_rate": 7.608818541548899e-06,
      "loss": 0.11,
      "step": 8000
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.8683029413223267,
      "eval_rouge1": 0.46359066599431,
      "eval_rouge2": 0.2965332173114022,
      "eval_rougeL": 0.45189439238913676,
      "eval_rouge_sum": 1.212018275694849,
      "eval_runtime": 317.6461,
      "eval_samples_per_second": 7.845,
      "eval_steps_per_second": 0.491,
      "step": 8099
    },
    {
      "epoch": 13.001605136436597,
      "grad_norm": 1.8532130718231201,
      "learning_rate": 7.04352741661956e-06,
      "loss": 0.1073,
      "step": 8100
    },
    {
      "epoch": 13.162118780096309,
      "grad_norm": 1.8036068677902222,
      "learning_rate": 6.478236291690221e-06,
      "loss": 0.0954,
      "step": 8200
    },
    {
      "epoch": 13.32263242375602,
      "grad_norm": 1.8107554912567139,
      "learning_rate": 5.912945166760882e-06,
      "loss": 0.0939,
      "step": 8300
    },
    {
      "epoch": 13.48314606741573,
      "grad_norm": 2.0503406524658203,
      "learning_rate": 5.347654041831543e-06,
      "loss": 0.0927,
      "step": 8400
    },
    {
      "epoch": 13.643659711075442,
      "grad_norm": 2.370595693588257,
      "learning_rate": 4.782362916902205e-06,
      "loss": 0.0944,
      "step": 8500
    },
    {
      "epoch": 13.804173354735152,
      "grad_norm": 1.7384443283081055,
      "learning_rate": 4.217071791972866e-06,
      "loss": 0.0909,
      "step": 8600
    },
    {
      "epoch": 13.964686998394864,
      "grad_norm": 1.6027328968048096,
      "learning_rate": 3.651780667043528e-06,
      "loss": 0.0949,
      "step": 8700
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.8891512155532837,
      "eval_rouge1": 0.46097921811283604,
      "eval_rouge2": 0.29392765272135696,
      "eval_rougeL": 0.4498180781048314,
      "eval_rouge_sum": 1.2047249489390244,
      "eval_runtime": 314.7035,
      "eval_samples_per_second": 7.919,
      "eval_steps_per_second": 0.496,
      "step": 8722
    },
    {
      "epoch": 14.125200642054574,
      "grad_norm": 1.6524708271026611,
      "learning_rate": 3.086489542114189e-06,
      "loss": 0.0866,
      "step": 8800
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 1.676949381828308,
      "learning_rate": 2.5211984171848503e-06,
      "loss": 0.084,
      "step": 8900
    },
    {
      "epoch": 14.446227929373997,
      "grad_norm": 1.745793104171753,
      "learning_rate": 1.9559072922555117e-06,
      "loss": 0.0842,
      "step": 9000
    },
    {
      "epoch": 14.606741573033707,
      "grad_norm": 1.860117793083191,
      "learning_rate": 1.390616167326173e-06,
      "loss": 0.0828,
      "step": 9100
    },
    {
      "epoch": 14.76725521669342,
      "grad_norm": 1.5867588520050049,
      "learning_rate": 8.253250423968344e-07,
      "loss": 0.0839,
      "step": 9200
    },
    {
      "epoch": 14.92776886035313,
      "grad_norm": 1.7275705337524414,
      "learning_rate": 2.600339174674958e-07,
      "loss": 0.0824,
      "step": 9300
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.9005203247070312,
      "eval_rouge1": 0.460669848912978,
      "eval_rouge2": 0.29329732811199555,
      "eval_rougeL": 0.4494088960040154,
      "eval_rouge_sum": 1.203376073028989,
      "eval_runtime": 315.3576,
      "eval_samples_per_second": 7.902,
      "eval_steps_per_second": 0.495,
      "step": 9345
    }
  ],
  "logging_steps": 100,
  "max_steps": 9345,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.5570178547712e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
