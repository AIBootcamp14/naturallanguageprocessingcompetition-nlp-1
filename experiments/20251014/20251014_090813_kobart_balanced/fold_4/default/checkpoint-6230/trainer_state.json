{
  "best_global_step": 6230,
  "best_metric": 1.2351995364524684,
  "best_model_checkpoint": "experiments/20251014/20251014_090813_kobart_balanced/fold_4/default/checkpoint-6230",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 6230,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16051364365971107,
      "grad_norm": 4.328639507293701,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.1629,
      "step": 100
    },
    {
      "epoch": 0.32102728731942215,
      "grad_norm": 4.451586723327637,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.6676,
      "step": 200
    },
    {
      "epoch": 0.48154093097913325,
      "grad_norm": 3.8663547039031982,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.5605,
      "step": 300
    },
    {
      "epoch": 0.6420545746388443,
      "grad_norm": 3.718086004257202,
      "learning_rate": 3.99e-05,
      "loss": 1.5225,
      "step": 400
    },
    {
      "epoch": 0.8025682182985554,
      "grad_norm": 4.088637828826904,
      "learning_rate": 4.99e-05,
      "loss": 1.4943,
      "step": 500
    },
    {
      "epoch": 0.9630818619582665,
      "grad_norm": 3.5218002796173096,
      "learning_rate": 4.944036178631996e-05,
      "loss": 1.4856,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3936502933502197,
      "eval_rouge1": 0.3900423208406374,
      "eval_rouge2": 0.242841558240863,
      "eval_rougeL": 0.38222969849459515,
      "eval_rouge_sum": 1.0151135775760955,
      "eval_runtime": 319.9269,
      "eval_samples_per_second": 7.786,
      "eval_steps_per_second": 0.488,
      "step": 623
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 3.025428056716919,
      "learning_rate": 4.887507066139062e-05,
      "loss": 1.2957,
      "step": 700
    },
    {
      "epoch": 1.2841091492776886,
      "grad_norm": 3.2348172664642334,
      "learning_rate": 4.830977953646128e-05,
      "loss": 1.253,
      "step": 800
    },
    {
      "epoch": 1.4446227929373996,
      "grad_norm": 3.6316773891448975,
      "learning_rate": 4.774448841153194e-05,
      "loss": 1.2466,
      "step": 900
    },
    {
      "epoch": 1.6051364365971108,
      "grad_norm": 3.319521903991699,
      "learning_rate": 4.71791972866026e-05,
      "loss": 1.2595,
      "step": 1000
    },
    {
      "epoch": 1.7656500802568218,
      "grad_norm": 3.2523269653320312,
      "learning_rate": 4.661390616167327e-05,
      "loss": 1.2544,
      "step": 1100
    },
    {
      "epoch": 1.9261637239165328,
      "grad_norm": 3.4113781452178955,
      "learning_rate": 4.604861503674392e-05,
      "loss": 1.2776,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3308420181274414,
      "eval_rouge1": 0.4338896627769586,
      "eval_rouge2": 0.27485882342477674,
      "eval_rougeL": 0.42332694469305426,
      "eval_rouge_sum": 1.1320754308947896,
      "eval_runtime": 323.0547,
      "eval_samples_per_second": 7.711,
      "eval_steps_per_second": 0.483,
      "step": 1246
    },
    {
      "epoch": 2.086677367576244,
      "grad_norm": 3.624814510345459,
      "learning_rate": 4.5483323911814584e-05,
      "loss": 1.0804,
      "step": 1300
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 3.297778844833374,
      "learning_rate": 4.491803278688525e-05,
      "loss": 0.9763,
      "step": 1400
    },
    {
      "epoch": 2.407704654895666,
      "grad_norm": 3.608116865158081,
      "learning_rate": 4.435274166195591e-05,
      "loss": 0.9646,
      "step": 1500
    },
    {
      "epoch": 2.568218298555377,
      "grad_norm": 2.895113229751587,
      "learning_rate": 4.378745053702657e-05,
      "loss": 0.9743,
      "step": 1600
    },
    {
      "epoch": 2.7287319422150884,
      "grad_norm": 3.2810819149017334,
      "learning_rate": 4.322215941209723e-05,
      "loss": 0.9929,
      "step": 1700
    },
    {
      "epoch": 2.889245585874799,
      "grad_norm": 3.471489667892456,
      "learning_rate": 4.2656868287167893e-05,
      "loss": 0.9835,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3492239713668823,
      "eval_rouge1": 0.4344960771799422,
      "eval_rouge2": 0.2807464680820718,
      "eval_rougeL": 0.42674231278924823,
      "eval_rouge_sum": 1.1419848580512624,
      "eval_runtime": 323.8543,
      "eval_samples_per_second": 7.692,
      "eval_steps_per_second": 0.482,
      "step": 1869
    },
    {
      "epoch": 3.0497592295345104,
      "grad_norm": 4.020814418792725,
      "learning_rate": 4.2091577162238555e-05,
      "loss": 0.9274,
      "step": 1900
    },
    {
      "epoch": 3.2102728731942216,
      "grad_norm": 3.3748931884765625,
      "learning_rate": 4.152628603730922e-05,
      "loss": 0.7359,
      "step": 2000
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 3.360471248626709,
      "learning_rate": 4.096099491237988e-05,
      "loss": 0.7472,
      "step": 2100
    },
    {
      "epoch": 3.5313001605136436,
      "grad_norm": 3.4647486209869385,
      "learning_rate": 4.039570378745054e-05,
      "loss": 0.7766,
      "step": 2200
    },
    {
      "epoch": 3.691813804173355,
      "grad_norm": 3.2959911823272705,
      "learning_rate": 3.98304126625212e-05,
      "loss": 0.774,
      "step": 2300
    },
    {
      "epoch": 3.8523274478330656,
      "grad_norm": 3.7131943702697754,
      "learning_rate": 3.926512153759186e-05,
      "loss": 0.7954,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.412736177444458,
      "eval_rouge1": 0.4499980934230757,
      "eval_rouge2": 0.28566049790740655,
      "eval_rougeL": 0.43756343523525437,
      "eval_rouge_sum": 1.1732220265657367,
      "eval_runtime": 327.6965,
      "eval_samples_per_second": 7.602,
      "eval_steps_per_second": 0.476,
      "step": 2492
    },
    {
      "epoch": 4.012841091492777,
      "grad_norm": 2.888242244720459,
      "learning_rate": 3.8699830412662526e-05,
      "loss": 0.7736,
      "step": 2500
    },
    {
      "epoch": 4.173354735152488,
      "grad_norm": 3.200859308242798,
      "learning_rate": 3.813453928773318e-05,
      "loss": 0.5731,
      "step": 2600
    },
    {
      "epoch": 4.333868378812199,
      "grad_norm": 3.4119462966918945,
      "learning_rate": 3.756924816280384e-05,
      "loss": 0.5922,
      "step": 2700
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 3.3940823078155518,
      "learning_rate": 3.700395703787451e-05,
      "loss": 0.5975,
      "step": 2800
    },
    {
      "epoch": 4.654895666131621,
      "grad_norm": 3.1590332984924316,
      "learning_rate": 3.6438665912945167e-05,
      "loss": 0.605,
      "step": 2900
    },
    {
      "epoch": 4.815409309791332,
      "grad_norm": 3.5258777141571045,
      "learning_rate": 3.587337478801583e-05,
      "loss": 0.6222,
      "step": 3000
    },
    {
      "epoch": 4.975922953451043,
      "grad_norm": 3.2095141410827637,
      "learning_rate": 3.530808366308649e-05,
      "loss": 0.6137,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.492132306098938,
      "eval_rouge1": 0.4625684013097557,
      "eval_rouge2": 0.29584446133314507,
      "eval_rougeL": 0.44776875613746414,
      "eval_rouge_sum": 1.206181618780365,
      "eval_runtime": 330.6041,
      "eval_samples_per_second": 7.535,
      "eval_steps_per_second": 0.472,
      "step": 3115
    },
    {
      "epoch": 5.136436597110754,
      "grad_norm": 3.0265748500823975,
      "learning_rate": 3.474279253815715e-05,
      "loss": 0.4724,
      "step": 3200
    },
    {
      "epoch": 5.296950240770466,
      "grad_norm": 3.2384159564971924,
      "learning_rate": 3.4177501413227814e-05,
      "loss": 0.4627,
      "step": 3300
    },
    {
      "epoch": 5.457463884430177,
      "grad_norm": 3.5412185192108154,
      "learning_rate": 3.3612210288298476e-05,
      "loss": 0.4734,
      "step": 3400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 3.067727565765381,
      "learning_rate": 3.304691916336914e-05,
      "loss": 0.4734,
      "step": 3500
    },
    {
      "epoch": 5.778491171749598,
      "grad_norm": 3.571559190750122,
      "learning_rate": 3.24816280384398e-05,
      "loss": 0.4865,
      "step": 3600
    },
    {
      "epoch": 5.93900481540931,
      "grad_norm": 3.6559104919433594,
      "learning_rate": 3.191633691351046e-05,
      "loss": 0.481,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.5466996431350708,
      "eval_rouge1": 0.45739694076083864,
      "eval_rouge2": 0.29167333494616643,
      "eval_rougeL": 0.44661933417135974,
      "eval_rouge_sum": 1.195689609878365,
      "eval_runtime": 330.7368,
      "eval_samples_per_second": 7.532,
      "eval_steps_per_second": 0.472,
      "step": 3738
    },
    {
      "epoch": 6.099518459069021,
      "grad_norm": 2.5939784049987793,
      "learning_rate": 3.1351045788581116e-05,
      "loss": 0.4065,
      "step": 3800
    },
    {
      "epoch": 6.260032102728732,
      "grad_norm": 2.961459159851074,
      "learning_rate": 3.0785754663651785e-05,
      "loss": 0.3563,
      "step": 3900
    },
    {
      "epoch": 6.420545746388443,
      "grad_norm": 3.3761112689971924,
      "learning_rate": 3.0220463538722443e-05,
      "loss": 0.3685,
      "step": 4000
    },
    {
      "epoch": 6.581059390048154,
      "grad_norm": 3.391608238220215,
      "learning_rate": 2.96551724137931e-05,
      "loss": 0.3709,
      "step": 4100
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 3.112426280975342,
      "learning_rate": 2.9089881288863767e-05,
      "loss": 0.3814,
      "step": 4200
    },
    {
      "epoch": 6.902086677367576,
      "grad_norm": 3.0274438858032227,
      "learning_rate": 2.852459016393443e-05,
      "loss": 0.3821,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.6207855939865112,
      "eval_rouge1": 0.4613149703599126,
      "eval_rouge2": 0.2961810632696011,
      "eval_rougeL": 0.4496483809226929,
      "eval_rouge_sum": 1.2071444145522066,
      "eval_runtime": 331.2834,
      "eval_samples_per_second": 7.519,
      "eval_steps_per_second": 0.471,
      "step": 4361
    },
    {
      "epoch": 7.062600321027287,
      "grad_norm": 2.7114572525024414,
      "learning_rate": 2.7959299039005087e-05,
      "loss": 0.3433,
      "step": 4400
    },
    {
      "epoch": 7.223113964686998,
      "grad_norm": 2.9396777153015137,
      "learning_rate": 2.739400791407575e-05,
      "loss": 0.2813,
      "step": 4500
    },
    {
      "epoch": 7.38362760834671,
      "grad_norm": 2.9981260299682617,
      "learning_rate": 2.6828716789146414e-05,
      "loss": 0.2898,
      "step": 4600
    },
    {
      "epoch": 7.544141252006421,
      "grad_norm": 2.6565287113189697,
      "learning_rate": 2.6263425664217072e-05,
      "loss": 0.2955,
      "step": 4700
    },
    {
      "epoch": 7.704654895666131,
      "grad_norm": 2.6825435161590576,
      "learning_rate": 2.5698134539287734e-05,
      "loss": 0.2933,
      "step": 4800
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 3.015878677368164,
      "learning_rate": 2.51328434143584e-05,
      "loss": 0.3033,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.6720725297927856,
      "eval_rouge1": 0.46885379839274993,
      "eval_rouge2": 0.3026880446712482,
      "eval_rougeL": 0.4564478796973685,
      "eval_rouge_sum": 1.2279897227613668,
      "eval_runtime": 330.5402,
      "eval_samples_per_second": 7.536,
      "eval_steps_per_second": 0.472,
      "step": 4984
    },
    {
      "epoch": 8.025682182985554,
      "grad_norm": 2.317526340484619,
      "learning_rate": 2.4567552289429058e-05,
      "loss": 0.2922,
      "step": 5000
    },
    {
      "epoch": 8.186195826645266,
      "grad_norm": 2.419520139694214,
      "learning_rate": 2.4002261164499716e-05,
      "loss": 0.2273,
      "step": 5100
    },
    {
      "epoch": 8.346709470304976,
      "grad_norm": 2.883922815322876,
      "learning_rate": 2.343697003957038e-05,
      "loss": 0.2285,
      "step": 5200
    },
    {
      "epoch": 8.507223113964686,
      "grad_norm": 2.6958703994750977,
      "learning_rate": 2.287167891464104e-05,
      "loss": 0.2356,
      "step": 5300
    },
    {
      "epoch": 8.667736757624398,
      "grad_norm": 2.8900105953216553,
      "learning_rate": 2.2306387789711702e-05,
      "loss": 0.2342,
      "step": 5400
    },
    {
      "epoch": 8.828250401284109,
      "grad_norm": 2.7898001670837402,
      "learning_rate": 2.1741096664782364e-05,
      "loss": 0.24,
      "step": 5500
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 2.974248170852661,
      "learning_rate": 2.1175805539853025e-05,
      "loss": 0.2411,
      "step": 5600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.7214535474777222,
      "eval_rouge1": 0.469228917501182,
      "eval_rouge2": 0.29802000385790983,
      "eval_rougeL": 0.45574774268318397,
      "eval_rouge_sum": 1.2229966640422758,
      "eval_runtime": 333.6428,
      "eval_samples_per_second": 7.466,
      "eval_steps_per_second": 0.468,
      "step": 5607
    },
    {
      "epoch": 9.149277688603531,
      "grad_norm": 2.2281577587127686,
      "learning_rate": 2.0610514414923687e-05,
      "loss": 0.1831,
      "step": 5700
    },
    {
      "epoch": 9.309791332263242,
      "grad_norm": 3.2785067558288574,
      "learning_rate": 2.0045223289994346e-05,
      "loss": 0.189,
      "step": 5800
    },
    {
      "epoch": 9.470304975922954,
      "grad_norm": 2.0083837509155273,
      "learning_rate": 1.947993216506501e-05,
      "loss": 0.1834,
      "step": 5900
    },
    {
      "epoch": 9.630818619582664,
      "grad_norm": 2.3687846660614014,
      "learning_rate": 1.891464104013567e-05,
      "loss": 0.1901,
      "step": 6000
    },
    {
      "epoch": 9.791332263242376,
      "grad_norm": 2.5102391242980957,
      "learning_rate": 1.834934991520633e-05,
      "loss": 0.1967,
      "step": 6100
    },
    {
      "epoch": 9.951845906902086,
      "grad_norm": 2.2071218490600586,
      "learning_rate": 1.7784058790276993e-05,
      "loss": 0.189,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.7765341997146606,
      "eval_rouge1": 0.4723193027565001,
      "eval_rouge2": 0.303826890023047,
      "eval_rougeL": 0.45905334367292117,
      "eval_rouge_sum": 1.2351995364524684,
      "eval_runtime": 333.8197,
      "eval_samples_per_second": 7.462,
      "eval_steps_per_second": 0.467,
      "step": 6230
    }
  ],
  "logging_steps": 100,
  "max_steps": 9345,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.03831677140992e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
