{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¥ Full Pipeline - ëª¨ë“  ê¸°ë²• í†µí•©\n",
    "> PRD ê³„íšì— ë”°ë¥¸ ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© ì‹¤í–‰\n",
    "\n",
    "**ëª©í‘œ ì„±ëŠ¥**: ROUGE-F1 85+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /home/ieyeppo/AI_Lab/natural-language-processing-competition\n",
      "Current Dir: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH\n",
      "âœ… ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë¡œë“œ ì„±ê³µ\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent.parent  # 3ë²ˆë§Œ parent ì‚¬ìš©!\n",
    "\n",
    "# ë‹¤ë¥¸ í”„ë¡œì íŠ¸ ê²½ë¡œ ì œê±°í•˜ê³  í˜„ì¬ í”„ë¡œì íŠ¸ ê²½ë¡œë§Œ ì¶”ê°€\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„í¬íŠ¸ - 04_multi_model_ensemble.ipynbì—ì„œ ì°¸ê³ \n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "from src.utils.visualizations.training_viz import TrainingVisualizer\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FULL PIPELINE CONFIGURATION\n",
      "==================================================\n",
      "Pipeline Stages: 9\n",
      "  âœ“ data_quality_check\n",
      "  âœ“ data_preprocessing\n",
      "  âœ“ data_augmentation\n",
      "  âœ“ model_training\n",
      "  âœ“ cross_validation\n",
      "  âœ“ ensemble\n",
      "  âœ“ hyperparameter_optimization\n",
      "  âœ“ inference_optimization\n",
      "  âœ“ final_prediction\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "config_path = notebook_dir / 'configs' / 'config_full_pipeline.yaml'\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FULL PIPELINE CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Pipeline Stages: {len(config['pipeline']['stages'])}\")\n",
    "for stage in config['pipeline']['stages']:\n",
    "    print(f\"  âœ“ {stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Directory: logs/full_pipeline\n",
      "==================================================\n",
      "FULL PIPELINE EXECUTION STARTED\n",
      "Timestamp: 20251010_092701\n",
      "Config: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/configs/config_full_pipeline.yaml\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "log_dir = Path(config['paths']['log_dir'])\n",
    "print(f\"Log Directory: {log_dir}\")\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# ë¡œê±° ì´ˆê¸°í™”\n",
    "log_file = log_dir / f'full_pipeline_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('='*50)\n",
    "logger.write('FULL PIPELINE EXECUTION STARTED')\n",
    "logger.write(f'Timestamp: {timestamp}')\n",
    "logger.write(f'Config: {config_path}')\n",
    "logger.write('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tier: LOW\n",
      "Auto-optimization enabled\n",
      "Finding optimal batch size...\n"
     ]
    }
   ],
   "source": [
    "# GPU ìµœì í™” ì²´í¬\n",
    "# í•„ìš”í•œ ëª¨ë“ˆ import\n",
    "if 'check_gpu_tier' not in globals():\n",
    "    try:\n",
    "        from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "    except ImportError:\n",
    "        print(\"Warning: Could not import check_gpu_tier\")\n",
    "        def check_gpu_tier():\n",
    "            return \"UNKNOWN\"\n",
    "\n",
    "# configê°€ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "if 'config' not in globals():\n",
    "    print(\"Warning: config not loaded. Please run cell 2 first.\")\n",
    "else:\n",
    "    if config['gpu']['auto_optimization']['enabled']:\n",
    "        gpu_tier = check_gpu_tier()\n",
    "        if 'logger' in globals():\n",
    "            logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "            logger.write(f\"Auto-optimization enabled\")\n",
    "            \n",
    "            if config['gpu']['auto_optimization']['find_optimal_batch_size']:\n",
    "                logger.write(\"Finding optimal batch size...\")\n",
    "                # ìµœì  ë°°ì¹˜ í¬ê¸° íƒìƒ‰ ì½”ë“œ\n",
    "        else:\n",
    "            print(f\"GPU Tier: {gpu_tier}\")\n",
    "            print(f\"Auto-optimization enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PERFORMANCE TARGETS\n",
      "==================================================\n",
      "ROUGE-1: 0.45\n",
      "ROUGE-2: 0.3\n",
      "ROUGE-L: 0.4\n",
      "Overall Target: 0.85\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì„±ëŠ¥ ëª©í‘œ í™•ì¸\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PERFORMANCE TARGETS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ROUGE-1: {config['performance_targets']['rouge_1']}\")\n",
    "print(f\"ROUGE-2: {config['performance_targets']['rouge_2']}\")\n",
    "print(f\"ROUGE-L: {config['performance_targets']['rouge_l']}\")\n",
    "print(f\"Overall Target: {config['performance_targets']['overall']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_quality_check            : pending\n",
      "data_preprocessing            : pending\n",
      "data_augmentation             : pending\n",
      "model_training                : pending\n",
      "cross_validation              : pending\n",
      "ensemble                      : pending\n",
      "hyperparameter_optimization   : pending\n",
      "inference_optimization        : pending\n",
      "final_prediction              : pending\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœ ì¶”ì \n",
    "# configê°€ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "if 'config' not in globals():\n",
    "    print(\"Error: config not loaded. Please run cell 2 first.\")\n",
    "else:\n",
    "    pipeline_status = {}\n",
    "    for stage in config['pipeline']['stages']:\n",
    "        pipeline_status[stage] = 'pending'\n",
    "\n",
    "    def update_status(stage, status):\n",
    "        pipeline_status[stage] = status\n",
    "        if 'logger' in globals():\n",
    "            logger.write(f\"[{stage}] Status: {status}\")\n",
    "        else:\n",
    "            print(f\"[{stage}] Status: {status}\")\n",
    "        \n",
    "    # ìƒíƒœ í‘œì‹œ\n",
    "    for stage, status in pipeline_status.items():\n",
    "        print(f\"{stage:30s}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data_quality_check] Status: running\n",
      "\n",
      "=== Data Quality Check ===\n",
      "Loaded 12457 training samples\n",
      "Null values: 0\n",
      "[data_quality_check] Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "if 'data_quality_check' in config['pipeline']['stages']:\n",
    "    update_status('data_quality_check', 'running')\n",
    "    logger.write(\"\\n=== Data Quality Check ===\")\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    train_df = pd.read_csv(config['paths']['train_file'])\n",
    "    logger.write(f\"Loaded {len(train_df)} training samples\")\n",
    "    \n",
    "    # í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰\n",
    "    if config['data_quality']['enabled']:\n",
    "        # êµ¬ì¡°ì  ê²€ì¦\n",
    "        if config['data_quality']['checks']['structural']['check_nulls']:\n",
    "            null_count = train_df.isnull().sum().sum()\n",
    "            logger.write(f\"Null values: {null_count}\")\n",
    "    \n",
    "    update_status('data_quality_check', 'completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data_quality_check] Status: running\n",
      "\n",
      "=== Data Quality Check ===\n",
      "Loading data from config paths:\n",
      "  - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv\n",
      "  - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv\n",
      "  - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv\n",
      "Loaded 12457 training samples\n",
      "Loaded 499 dev samples\n",
      "Loaded 499 test samples\n",
      "Null values: 0\n",
      "Duplicate rows: 0\n",
      "[data_quality_check] Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ë¡œë“œ\n",
    "# í•„ìš”í•œ import\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# notebook_dir í™•ì¸\n",
    "if 'notebook_dir' not in globals():\n",
    "    notebook_dir = Path.cwd()\n",
    "\n",
    "# configì™€ í•„ìš”í•œ í•¨ìˆ˜ í™•ì¸\n",
    "if 'config' not in globals():\n",
    "    print(\"Error: config not loaded. Please run cell 2 first.\")\n",
    "elif 'update_status' not in globals():\n",
    "    print(\"Error: update_status function not defined. Please run cell 6 first.\")\n",
    "else:\n",
    "    if 'data_quality_check' in config['pipeline']['stages']:\n",
    "        update_status('data_quality_check', 'running')\n",
    "        \n",
    "        if 'logger' in globals():\n",
    "            logger.write(\"\\n=== Data Quality Check ===\")\n",
    "        else:\n",
    "            print(\"\\n=== Data Quality Check ===\")\n",
    "        \n",
    "        # config íŒŒì¼ì˜ ê²½ë¡œ ì‚¬ìš©\n",
    "        def get_data_path(path_str):\n",
    "            \"\"\"configì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜\"\"\"\n",
    "            path = Path(path_str)\n",
    "            if not path.is_absolute():\n",
    "                path = notebook_dir / path\n",
    "            return path\n",
    "        \n",
    "        # configì—ì„œ ë°ì´í„° ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "        train_path = get_data_path(config['paths']['train_file'])\n",
    "        dev_path = get_data_path(config['paths']['dev_file'])\n",
    "        test_path = get_data_path(config['paths']['test_file'])\n",
    "        \n",
    "        log_msg = f\"Loading data from config paths:\\n  - Train: {train_path}\\n  - Dev: {dev_path}\\n  - Test: {test_path}\"\n",
    "        if 'logger' in globals():\n",
    "            logger.write(log_msg)\n",
    "        else:\n",
    "            print(log_msg)\n",
    "        \n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        dev_df = pd.read_csv(dev_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        log_msg = f\"Loaded {len(train_df)} training samples\\nLoaded {len(dev_df)} dev samples\\nLoaded {len(test_df)} test samples\"\n",
    "        if 'logger' in globals():\n",
    "            logger.write(log_msg)\n",
    "        else:\n",
    "            print(log_msg)\n",
    "        \n",
    "        # í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰\n",
    "        if config['data_quality']['enabled']:\n",
    "            # êµ¬ì¡°ì  ê²€ì¦\n",
    "            if config['data_quality']['checks']['structural']['check_nulls']:\n",
    "                null_count = train_df.isnull().sum().sum()\n",
    "                log_msg = f\"Null values: {null_count}\"\n",
    "                if 'logger' in globals():\n",
    "                    logger.write(log_msg)\n",
    "                else:\n",
    "                    print(log_msg)\n",
    "            \n",
    "            if config['data_quality']['checks']['structural']['check_duplicates']:\n",
    "                dup_count = train_df.duplicated().sum()\n",
    "                log_msg = f\"Duplicate rows: {dup_count}\"\n",
    "                if 'logger' in globals():\n",
    "                    logger.write(log_msg)\n",
    "                else:\n",
    "                    print(log_msg)\n",
    "        \n",
    "        update_status('data_quality_check', 'completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations will be saved to: ../logs/full_pipeline/visualizations\n"
     ]
    }
   ],
   "source": [
    "# ì‹œê°í™” ì„¤ì •\n",
    "if config['visualization']['enabled']:\n",
    "    viz = TrainingVisualizer()\n",
    "    viz_dir = Path(config['visualization']['save_path'])\n",
    "    viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.write(f\"Visualizations will be saved to: {viz_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mieyeppo-job\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_092702-tbqfvhya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ieyeppo/nlp-competition/runs/tbqfvhya' target=\"_blank\">full-pipeline-integrated</a></strong> to <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ieyeppo/nlp-competition/runs/tbqfvhya' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition/runs/tbqfvhya</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB initialized for full pipeline tracking\n"
     ]
    }
   ],
   "source": [
    "# WandB ì´ˆê¸°í™” (ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¶”ì )\n",
    "if config['wandb']['mode'] != 'disabled':\n",
    "    wandb.init(\n",
    "        project=config['wandb']['project'],\n",
    "        entity=config['wandb']['entity'],\n",
    "        name=config['wandb']['name'],\n",
    "        tags=config['wandb']['tags'],\n",
    "        config=config\n",
    "    )\n",
    "    logger.write(\"WandB initialized for full pipeline tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì½”ë“œëŠ” config íŒŒì¼ ì„¤ì •ì— ë”°ë¼ êµ¬í˜„\n",
    "\n",
    "### ì‹¤í–‰ ë‹¨ê³„:\n",
    "1. ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°•\n",
    "3. ëª¨ë¸ í•™ìŠµ (Multi-model)\n",
    "4. K-Fold êµì°¨ ê²€ì¦\n",
    "5. Optuna ìµœì í™”\n",
    "6. ì•™ìƒë¸” + TTA\n",
    "7. ì¶”ë¡  ìµœì í™”\n",
    "8. ìµœì¢… ì˜ˆì¸¡ ë° ì œì¶œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
