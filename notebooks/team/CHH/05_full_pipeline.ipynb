{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔥 Full Pipeline - 모든 기법 통합\n",
    "> PRD 계획에 따른 전체 파이프라인 통합 실행\n",
    "\n",
    "**목표 성능**: ROUGE-F1 85+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /home/ieyeppo/AI_Lab/natural-language-processing-competition\n",
      "Current Dir: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH\n",
      "✅ 나눔고딕 폰트 로드 성공\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent.parent  # 3번만 parent 사용!\n",
    "\n",
    "# 다른 프로젝트 경로 제거하고 현재 프로젝트 경로만 추가\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "# 커스텀 모듈 임포트 - 04_multi_model_ensemble.ipynb에서 참고\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "from src.utils.visualizations.training_viz import TrainingVisualizer\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FULL PIPELINE CONFIGURATION\n",
      "==================================================\n",
      "Pipeline Stages: 9\n",
      "  ✓ data_quality_check\n",
      "  ✓ data_preprocessing\n",
      "  ✓ data_augmentation\n",
      "  ✓ model_training\n",
      "  ✓ cross_validation\n",
      "  ✓ ensemble\n",
      "  ✓ hyperparameter_optimization\n",
      "  ✓ inference_optimization\n",
      "  ✓ final_prediction\n"
     ]
    }
   ],
   "source": [
    "# 설정 파일 로드\n",
    "config_path = notebook_dir / 'configs' / 'config_full_pipeline.yaml'\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FULL PIPELINE CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Pipeline Stages: {len(config['pipeline']['stages'])}\")\n",
    "for stage in config['pipeline']['stages']:\n",
    "    print(f\"  ✓ {stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Directory: logs/full_pipeline\n",
      "==================================================\n",
      "FULL PIPELINE EXECUTION STARTED\n",
      "Timestamp: 20251010_092701\n",
      "Config: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/configs/config_full_pipeline.yaml\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 로그 디렉토리 생성\n",
    "log_dir = Path(config['paths']['log_dir'])\n",
    "print(f\"Log Directory: {log_dir}\")\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 타임스탬프 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 로거 초기화\n",
    "log_file = log_dir / f'full_pipeline_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('='*50)\n",
    "logger.write('FULL PIPELINE EXECUTION STARTED')\n",
    "logger.write(f'Timestamp: {timestamp}')\n",
    "logger.write(f'Config: {config_path}')\n",
    "logger.write('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tier: LOW\n",
      "Auto-optimization enabled\n",
      "Finding optimal batch size...\n"
     ]
    }
   ],
   "source": [
    "# GPU 최적화 체크\n",
    "# 필요한 모듈 import\n",
    "if 'check_gpu_tier' not in globals():\n",
    "    try:\n",
    "        from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "    except ImportError:\n",
    "        print(\"Warning: Could not import check_gpu_tier\")\n",
    "        def check_gpu_tier():\n",
    "            return \"UNKNOWN\"\n",
    "\n",
    "# config가 로드되어 있는지 확인\n",
    "if 'config' not in globals():\n",
    "    print(\"Warning: config not loaded. Please run cell 2 first.\")\n",
    "else:\n",
    "    if config['gpu']['auto_optimization']['enabled']:\n",
    "        gpu_tier = check_gpu_tier()\n",
    "        if 'logger' in globals():\n",
    "            logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "            logger.write(f\"Auto-optimization enabled\")\n",
    "            \n",
    "            if config['gpu']['auto_optimization']['find_optimal_batch_size']:\n",
    "                logger.write(\"Finding optimal batch size...\")\n",
    "                # 최적 배치 크기 탐색 코드\n",
    "        else:\n",
    "            print(f\"GPU Tier: {gpu_tier}\")\n",
    "            print(f\"Auto-optimization enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PERFORMANCE TARGETS\n",
      "==================================================\n",
      "ROUGE-1: 0.45\n",
      "ROUGE-2: 0.3\n",
      "ROUGE-L: 0.4\n",
      "Overall Target: 0.85\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 성능 목표 확인\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PERFORMANCE TARGETS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ROUGE-1: {config['performance_targets']['rouge_1']}\")\n",
    "print(f\"ROUGE-2: {config['performance_targets']['rouge_2']}\")\n",
    "print(f\"ROUGE-L: {config['performance_targets']['rouge_l']}\")\n",
    "print(f\"Overall Target: {config['performance_targets']['overall']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_quality_check            : pending\n",
      "data_preprocessing            : pending\n",
      "data_augmentation             : pending\n",
      "model_training                : pending\n",
      "cross_validation              : pending\n",
      "ensemble                      : pending\n",
      "hyperparameter_optimization   : pending\n",
      "inference_optimization        : pending\n",
      "final_prediction              : pending\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 실행 상태 추적\n",
    "# config가 로드되어 있는지 확인\n",
    "if 'config' not in globals():\n",
    "    print(\"Error: config not loaded. Please run cell 2 first.\")\n",
    "else:\n",
    "    pipeline_status = {}\n",
    "    for stage in config['pipeline']['stages']:\n",
    "        pipeline_status[stage] = 'pending'\n",
    "\n",
    "    def update_status(stage, status):\n",
    "        pipeline_status[stage] = status\n",
    "        if 'logger' in globals():\n",
    "            logger.write(f\"[{stage}] Status: {status}\")\n",
    "        else:\n",
    "            print(f\"[{stage}] Status: {status}\")\n",
    "        \n",
    "    # 상태 표시\n",
    "    for stage, status in pipeline_status.items():\n",
    "        print(f\"{stage:30s}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data_quality_check] Status: running\n",
      "\n",
      "=== Data Quality Check ===\n",
      "Loaded 12457 training samples\n",
      "Null values: 0\n",
      "[data_quality_check] Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: 데이터 품질 검증\n",
    "if 'data_quality_check' in config['pipeline']['stages']:\n",
    "    update_status('data_quality_check', 'running')\n",
    "    logger.write(\"\\n=== Data Quality Check ===\")\n",
    "    \n",
    "    # 데이터 로드\n",
    "    train_df = pd.read_csv(config['paths']['train_file'])\n",
    "    logger.write(f\"Loaded {len(train_df)} training samples\")\n",
    "    \n",
    "    # 품질 검증 실행\n",
    "    if config['data_quality']['enabled']:\n",
    "        # 구조적 검증\n",
    "        if config['data_quality']['checks']['structural']['check_nulls']:\n",
    "            null_count = train_df.isnull().sum().sum()\n",
    "            logger.write(f\"Null values: {null_count}\")\n",
    "    \n",
    "    update_status('data_quality_check', 'completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data_quality_check] Status: running\n",
      "\n",
      "=== Data Quality Check ===\n",
      "Loading data from config paths:\n",
      "  - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv\n",
      "  - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv\n",
      "  - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv\n",
      "Loaded 12457 training samples\n",
      "Loaded 499 dev samples\n",
      "Loaded 499 test samples\n",
      "Null values: 0\n",
      "Duplicate rows: 0\n",
      "[data_quality_check] Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: 데이터 품질 검증 및 로드\n",
    "# 필요한 import\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# notebook_dir 확인\n",
    "if 'notebook_dir' not in globals():\n",
    "    notebook_dir = Path.cwd()\n",
    "\n",
    "# config와 필요한 함수 확인\n",
    "if 'config' not in globals():\n",
    "    print(\"Error: config not loaded. Please run cell 2 first.\")\n",
    "elif 'update_status' not in globals():\n",
    "    print(\"Error: update_status function not defined. Please run cell 6 first.\")\n",
    "else:\n",
    "    if 'data_quality_check' in config['pipeline']['stages']:\n",
    "        update_status('data_quality_check', 'running')\n",
    "        \n",
    "        if 'logger' in globals():\n",
    "            logger.write(\"\\n=== Data Quality Check ===\")\n",
    "        else:\n",
    "            print(\"\\n=== Data Quality Check ===\")\n",
    "        \n",
    "        # config 파일의 경로 사용\n",
    "        def get_data_path(path_str):\n",
    "            \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "            path = Path(path_str)\n",
    "            if not path.is_absolute():\n",
    "                path = notebook_dir / path\n",
    "            return path\n",
    "        \n",
    "        # config에서 데이터 경로 가져오기\n",
    "        train_path = get_data_path(config['paths']['train_file'])\n",
    "        dev_path = get_data_path(config['paths']['dev_file'])\n",
    "        test_path = get_data_path(config['paths']['test_file'])\n",
    "        \n",
    "        log_msg = f\"Loading data from config paths:\\n  - Train: {train_path}\\n  - Dev: {dev_path}\\n  - Test: {test_path}\"\n",
    "        if 'logger' in globals():\n",
    "            logger.write(log_msg)\n",
    "        else:\n",
    "            print(log_msg)\n",
    "        \n",
    "        # 데이터 로드\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        dev_df = pd.read_csv(dev_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        log_msg = f\"Loaded {len(train_df)} training samples\\nLoaded {len(dev_df)} dev samples\\nLoaded {len(test_df)} test samples\"\n",
    "        if 'logger' in globals():\n",
    "            logger.write(log_msg)\n",
    "        else:\n",
    "            print(log_msg)\n",
    "        \n",
    "        # 품질 검증 실행\n",
    "        if config['data_quality']['enabled']:\n",
    "            # 구조적 검증\n",
    "            if config['data_quality']['checks']['structural']['check_nulls']:\n",
    "                null_count = train_df.isnull().sum().sum()\n",
    "                log_msg = f\"Null values: {null_count}\"\n",
    "                if 'logger' in globals():\n",
    "                    logger.write(log_msg)\n",
    "                else:\n",
    "                    print(log_msg)\n",
    "            \n",
    "            if config['data_quality']['checks']['structural']['check_duplicates']:\n",
    "                dup_count = train_df.duplicated().sum()\n",
    "                log_msg = f\"Duplicate rows: {dup_count}\"\n",
    "                if 'logger' in globals():\n",
    "                    logger.write(log_msg)\n",
    "                else:\n",
    "                    print(log_msg)\n",
    "        \n",
    "        update_status('data_quality_check', 'completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations will be saved to: ../logs/full_pipeline/visualizations\n"
     ]
    }
   ],
   "source": [
    "# 시각화 설정\n",
    "if config['visualization']['enabled']:\n",
    "    viz = TrainingVisualizer()\n",
    "    viz_dir = Path(config['visualization']['save_path'])\n",
    "    viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.write(f\"Visualizations will be saved to: {viz_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mieyeppo-job\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_092702-tbqfvhya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ieyeppo/nlp-competition/runs/tbqfvhya' target=\"_blank\">full-pipeline-integrated</a></strong> to <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ieyeppo/nlp-competition/runs/tbqfvhya' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition/runs/tbqfvhya</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB initialized for full pipeline tracking\n"
     ]
    }
   ],
   "source": [
    "# WandB 초기화 (전체 파이프라인 추적)\n",
    "if config['wandb']['mode'] != 'disabled':\n",
    "    wandb.init(\n",
    "        project=config['wandb']['project'],\n",
    "        entity=config['wandb']['entity'],\n",
    "        name=config['wandb']['name'],\n",
    "        tags=config['wandb']['tags'],\n",
    "        config=config\n",
    "    )\n",
    "    logger.write(\"WandB initialized for full pipeline tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 파이프라인 실행 코드는 config 파일 설정에 따라 구현\n",
    "\n",
    "### 실행 단계:\n",
    "1. 데이터 품질 검증\n",
    "2. 데이터 전처리 및 증강\n",
    "3. 모델 학습 (Multi-model)\n",
    "4. K-Fold 교차 검증\n",
    "5. Optuna 최적화\n",
    "6. 앙상블 + TTA\n",
    "7. 추론 최적화\n",
    "8. 최종 예측 및 제출"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
