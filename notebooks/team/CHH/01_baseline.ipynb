{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ ë² ì´ìŠ¤ë¼ì¸ êµ¬í˜„ - KoBART ê¸°ë°˜ ëŒ€í™” ìš”ì•½\n",
    "> PRD ê³„íšì— ë”°ë¥¸ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ êµ¬í˜„\n",
    "\n",
    "**ëª©í‘œ ì„±ëŠ¥**: ROUGE-F1 47+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /home/ieyeppo/AI_Lab/natural-language-processing-competition\n",
      "Current Dir: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "notebook_dir = Path.cwd()\n",
    "# notebooks/team/CHH -> notebooks -> team -> natural-language-processing-competition\n",
    "project_root = notebook_dir.parent.parent.parent  # 3ë²ˆë§Œ parent ì‚¬ìš©!\n",
    "\n",
    "# ë‹¤ë¥¸ í”„ë¡œì íŠ¸ ê²½ë¡œ ì œê±°í•˜ê³  í˜„ì¬ í”„ë¡œì íŠ¸ ê²½ë¡œë§Œ ì¶”ê°€\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "from rouge import Rouge\n",
    "import wandb\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: digit82/kobart-summarization\n",
      "Batch Size: 16\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì • ë¡œë“œ\n",
    "config_path = notebook_dir / 'configs' / 'config_baseline.yaml'\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Batch Size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Experiment Started ===\n"
     ]
    }
   ],
   "source": [
    "# ë¡œê±° ì´ˆê¸°í™”\n",
    "# configì˜ ë¡œê·¸ ê²½ë¡œ ì‚¬ìš©\n",
    "def get_path(path_str):\n",
    "    \"\"\"configì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "log_dir = get_path(config['paths']['log_dir'])\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# ë¡œê±° ì´ˆê¸°í™”\n",
    "log_file = log_dir / f'baseline_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('=== Baseline Experiment Started ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tier: LOW\n",
      "GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# GPU ì²´í¬\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tier = check_gpu_tier()\n",
    "    logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "    logger.write(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from config paths:\n",
      "  - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv\n",
      "  - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv\n",
      "  - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv\n",
      "Data loaded successfully!\n",
      "Train samples: 12457\n",
      "Dev samples: 499\n",
      "Test samples: 499\n",
      "\n",
      "Sample data:\n",
      "     fname                                           dialogue  \\\n",
      "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
      "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
      "\n",
      "                                             summary  topic  \n",
      "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...   ê±´ê°•ê²€ì§„  \n",
      "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...  ë°±ì‹  ì ‘ì¢…  \n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì • ë° ë¡œë“œ\n",
    "# config íŒŒì¼ì˜ ê²½ë¡œ ì‚¬ìš©\n",
    "def get_data_path(path_str):\n",
    "    \"\"\"configì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "# configì—ì„œ ë°ì´í„° ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "train_path = get_data_path(config['paths']['train_file'])\n",
    "dev_path = get_data_path(config['paths']['dev_file'])\n",
    "test_path = get_data_path(config['paths']['test_file'])\n",
    "\n",
    "logger.write(f\"Loading data from config paths:\")\n",
    "logger.write(f\"  - Train: {train_path}\")\n",
    "logger.write(f\"  - Dev: {dev_path}\")\n",
    "logger.write(f\"  - Test: {test_path}\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df = pd.read_csv(dev_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "logger.write(f\"Data loaded successfully!\")\n",
    "logger.write(f\"Train samples: {len(train_df)}\")\n",
    "logger.write(f\"Dev samples: {len(dev_df)}\")\n",
    "logger.write(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nSample data:\")\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mieyeppo-job\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_095540-r1fpk5vb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb' target=\"_blank\">baseline-kobart</a></strong> to <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7669762cbe50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB ì´ˆê¸°í™”\n",
    "wandb.init(\n",
    "    project=config['wandb']['project'],\n",
    "    entity=config['wandb']['entity'],\n",
    "    name=config['wandb']['name'],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: digit82/kobart-summarization\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\n",
    "model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n",
    "\n",
    "logger.write(f\"Model loaded: {config['model']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì „ì²˜ë¦¬ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
      "Sample preprocessed dialogue (first 200 chars):\n",
      "í™”ì1: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¬´ìŠ¨ ì¼ë¡œ ì˜¤ì…¨ì–´ìš”? \n",
      "í™”ì2: ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ë ¤ê³  ì™”ì–´ìš”. \n",
      "í™”ì1: ë„¤, 5ë…„ ë™ì•ˆ ê²€ì§„ì„ ì•ˆ ë°›ìœ¼ì…¨ë„¤ìš”. ë§¤ë…„ í•œ ë²ˆì”© ë°›ìœ¼ì…”ì•¼ í•´ìš”. \n",
      "í™”ì2: ì•Œì£ . íŠ¹ë³„íˆ ì•„í”ˆ ë°ê°€ ì—†ìœ¼ë©´ êµ³ì´ ê°ˆ í•„ìš”ê°€ ì—†ë‹¤ê³  ìƒê°í–ˆì–´ìš”. \n",
      "í™”ì1: ìŒ, ì‹¬ê°í•œ ì§ˆë³‘ì„ í”¼í•˜ë ¤ë©´ ë¯¸ë¦¬ ë°œê²¬í•˜ëŠ” ê²Œ \n",
      "Data preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def preprocess_dialogue(text):\n",
    "    \"\"\"ëŒ€í™” í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\"\"\"\n",
    "    # ë…¸ì´ì¦ˆ ì œê±°\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    text = text.replace('<br>', '\\n')\n",
    "    \n",
    "    # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”\n",
    "    text = text.strip()\n",
    "    \n",
    "    # #Person íƒœê·¸ ìµœì í™” (ë” ëª…í™•í•˜ê²Œ)\n",
    "    import re\n",
    "    text = re.sub(r'#Person(\\d+)#:', r'í™”ì\\1:', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_summary(text):\n",
    "    \"\"\"ìš”ì•½ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ì ìš©\n",
    "train_df['dialogue_preprocessed'] = train_df['dialogue'].apply(preprocess_dialogue)\n",
    "train_df['summary_preprocessed'] = train_df['summary'].apply(preprocess_summary)\n",
    "\n",
    "dev_df['dialogue_preprocessed'] = dev_df['dialogue'].apply(preprocess_dialogue)\n",
    "dev_df['summary_preprocessed'] = dev_df['summary'].apply(preprocess_summary)\n",
    "\n",
    "test_df['dialogue_preprocessed'] = test_df['dialogue'].apply(preprocess_dialogue)\n",
    "\n",
    "print(f\"ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"Sample preprocessed dialogue (first 200 chars):\")\n",
    "print(train_df['dialogue_preprocessed'].iloc[0][:200])\n",
    "logger.write(\"Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created - Train: 12457, Val: 499, Test: 499\n",
      "Dataset shapes:\n",
      "  Train: 12457\n",
      "  Val: 499\n",
      "  Test: 499\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset í´ë˜ìŠ¤ ì •ì˜\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DialogueSummaryDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_len=512, max_target_len=128, is_test=False):\n",
    "        \"\"\"\n",
    "        ëŒ€í™” ìš”ì•½ ë°ì´í„°ì…‹\n",
    "        \n",
    "        Args:\n",
    "            dataframe: ë°ì´í„°í”„ë ˆì„\n",
    "            tokenizer: í† í¬ë‚˜ì´ì €\n",
    "            max_input_len: ìµœëŒ€ ì…ë ¥ ê¸¸ì´\n",
    "            max_target_len: ìµœëŒ€ íƒ€ê²Ÿ ê¸¸ì´\n",
    "            is_test: í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # ì…ë ¥ í…ìŠ¤íŠ¸\n",
    "        dialogue = row['dialogue_preprocessed']\n",
    "        \n",
    "        # ì…ë ¥ í† í°í™”\n",
    "        inputs = self.tokenizer(\n",
    "            dialogue,\n",
    "            max_length=self.max_input_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš° íƒ€ê²Ÿë„ ì²˜ë¦¬\n",
    "        if not self.is_test:\n",
    "            summary = row['summary_preprocessed']\n",
    "            \n",
    "            # íƒ€ê²Ÿ í† í°í™”\n",
    "            targets = self.tokenizer(\n",
    "                summary,\n",
    "                max_length=self.max_target_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'labels': targets['input_ids'].squeeze()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'idx': idx\n",
    "            }\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = DialogueSummaryDataset(\n",
    "    train_df, \n",
    "    tokenizer, \n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length']\n",
    ")\n",
    "\n",
    "val_dataset = DialogueSummaryDataset(\n",
    "    dev_df,\n",
    "    tokenizer,\n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length']\n",
    ")\n",
    "\n",
    "test_dataset = DialogueSummaryDataset(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length'],\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "logger.write(f\"Dataset created - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Val: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader created:\n",
      "  Train batches: 779\n",
      "  Val batches: 32\n",
      "  Test batches: 32\n"
     ]
    }
   ],
   "source": [
    "# DataLoader ìƒì„±\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "logger.write(f\"Using device: {device}\")\n",
    "\n",
    "# ROUGE í‰ê°€ í•¨ìˆ˜\n",
    "def compute_rouge_scores(predictions, references):\n",
    "    \"\"\"ROUGE ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬\n",
    "    predictions = [p if p else \"empty\" for p in predictions]\n",
    "    references = [r if r else \"empty\" for r in references]\n",
    "    \n",
    "    try:\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        return {\n",
    "            'rouge-1': scores['rouge-1']['f'],\n",
    "            'rouge-2': scores['rouge-2']['f'],\n",
    "            'rouge-l': scores['rouge-l']['f']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.write(f\"Error computing ROUGE: {e}\")\n",
    "        return {'rouge-1': 0, 'rouge-2': 0, 'rouge-l': 0}\n",
    "\n",
    "# í•™ìŠµ í•¨ìˆ˜\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    \"\"\"í•œ ì—í­ í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # ì˜µí‹°ë§ˆì´ì € ìŠ¤í…\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # WandB ë¡œê¹…\n",
    "        wandb.log({\n",
    "            'train_loss': loss.item(),\n",
    "            'learning_rate': scheduler.get_last_lr()[0]\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# ê²€ì¦ í•¨ìˆ˜\n",
    "def evaluate(model, data_loader, tokenizer, device, num_samples=None):\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Evaluating')\n",
    "        \n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            if num_samples and i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Loss ê³„ì‚°\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # ì˜ˆì¸¡ ìƒì„± - config í‚¤ ìˆ˜ì •\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=config['model']['max_target_length'],\n",
    "                num_beams=config['evaluation']['num_beams'],  # config í‚¤ ìˆ˜ì •\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=config['evaluation']['no_repeat_ngram_size']\n",
    "            )\n",
    "            \n",
    "            # ë””ì½”ë”©\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            references.extend(refs)\n",
    "    \n",
    "    # ROUGE ì ìˆ˜ ê³„ì‚°\n",
    "    rouge_scores = compute_rouge_scores(predictions, references)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return avg_loss, rouge_scores, predictions[:5]  # ìƒ˜í”Œ ì˜ˆì¸¡ ë°˜í™˜\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate converted from string to float: 5e-05\n",
      "Optimizer and scheduler initialized\n",
      "Learning rate: 5e-05\n",
      "Total training steps: 7790\n",
      "Warmup steps: 779\n",
      "==================================================\n",
      "Starting training...\n",
      "==================================================\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b50697c9e456080c2de813f05130a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.5061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf67cc92bd0e429fa0b55de95462ab2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5410\n",
      "ROUGE-1 F1: 0.1548\n",
      "ROUGE-2 F1: 0.0446\n",
      "ROUGE-L F1: 0.1490\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person1#ì€ ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ë§í•˜ë©°, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ì œì•ˆí•©ë‹ˆë‹¤.\n",
      "ì„¸ìš”?\n",
      "ì–´.\n",
      "!\n",
      "ã—¡ê¹Œìš”?\n",
      "...\n",
      "  Sample 2: #Person1#ì€ Jimmyì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•˜ê³ , JammiëŠ” í† ìš”ì¼ì— ìš´ë™í•˜ìê³  ì œì•ˆí•œë‹¤. ê·¸ë“¤ì€ ì˜¤í›„ 3ì‹œ 30ë¶„ì— ì²´ìœ¡ê´€ì—ì„œ ë§Œë‚˜ê¸°ë¡œ í•œë‹¤. ê·¸ë“¤ì€ ì²´ìœ¡ê´€ ìš´ë™ì— ...\n",
      "âœ“ New best model saved! (ROUGE-L: 0.1490)\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658e88cb27154897bcd76505d3d1bbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f648a651a9e4f6a839616e1b912a39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5106\n",
      "ROUGE-1 F1: 0.1448\n",
      "ROUGE-2 F1: 0.0416\n",
      "ROUGE-L F1: 0.1372\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person2#ëŠ” ìˆ¨ì‰¬ê¸° í˜ë“¤ë‹¤ê³  í˜¸ì†Œí•˜ë©°, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "ì–´.\n",
      "ì„¸ìš”?\n",
      "!\n",
      "ì–´ìš”?\n",
      "ê¹Œìš”?\n",
      " \n",
      "ì˜ˆìš”.\n",
      "ì–´ìš”.\n",
      "ê² ìŠµë‹ˆë‹¤.\n",
      "ìŠµë‹ˆë‹¤.\n",
      "ì£ ?\n",
      "ã—¡ë”...\n",
      "  Sample 2: #Person1#ì´ Jimmyì—ê²Œ ìš´ë™ ë‚ ì§œë¥¼ ë¬¼ì–´ë³´ê³ , ê·¸ë“¤ì€ ì˜¤í›„ 3ì‹œ 30ë¶„ì— ì²´ìœ¡ê´€ì—ì„œ ìš´ë™í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.\n",
      "ì–´.\n",
      "ì„¸ìš”?\n",
      "!\n",
      "ì–´ìš”?\n",
      "ê¹Œìš”?\n",
      "ì˜ˆìš”.\n",
      "ê² ìŠµë‹ˆë‹¤.\n",
      " \n",
      "ì–´ìš”.\n",
      "ì£ ?...\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb283404cf95428aa7af02b173567623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb03fb6e204049d3b368c3c93355ae29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5182\n",
      "ROUGE-1 F1: 0.1382\n",
      "ROUGE-2 F1: 0.0389\n",
      "ROUGE-L F1: 0.1315\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person2#ëŠ” ìµœê·¼ ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìœ¼ë©°, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ë°©ë¬¸í•  ê²ƒì„ ê¶Œì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ì‚¬ëŠ” ì²œì‹ì„ ê²€ì‚¬í•˜ê¸° ìœ„í•´ ì˜ì‚¬ë¥¼ ë°©ë¬¸í•´ì•¼ í•œë‹¤ê³  ì•ˆë‚´í•©ë‹ˆ...\n",
      "  Sample 2: #Person1#ì´ Jimmyì—ê²Œ ìš´ë™ì„ í•˜ìê³  ì œì•ˆí•˜ì§€ë§Œ, ê·¸ë…€ëŠ” ë‹¤ë¦¬ê°€ ì•„íŒŒì„œ ê±°ì ˆí•œë‹¤. #MyëŠ” ì£¼ê°„ ì¼ì •ì„ ë³€ê²½í•˜ìê³  ì œì•ˆí•˜ê³ , JammiëŠ” ì´ë¥¼ ìˆ˜ë½í•œë‹¤. ê²°êµ­ ê·¸ë“¤ì€ 3...\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61949f327f2f4458bbeef7e149010d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e693ec1c853c42fa9c5b9894e2a33354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5443\n",
      "ROUGE-1 F1: 0.1215\n",
      "ROUGE-2 F1: 0.0329\n",
      "ROUGE-L F1: 0.1162\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person2#ëŠ” ìµœê·¼ ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìœ¼ë©°, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.ì„¸ìš”?\n",
      "ì–´ìš”?\n",
      "ì–´.\n",
      "ê¹Œìš”?\n",
      " \n",
      "!\n",
      "ì–´ìš”.\n",
      "ê² ìŠµë‹ˆë‹¤.\n",
      "ì˜ˆìš”.\n",
      ".\n",
      "ë”ë¼.\n",
      "...\n",
      "  Sample 2: #Person1#ì´ Jimmyì—ê²Œ ìš´ë™ ì¼ì •ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³ , ê²°êµ­ ê·¸ë“¤ì€ 3ì‹œ 30ë¶„ì— ì²´ìœ¡ê´€ì—ì„œ í•¨ê»˜ ìš´ë™í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤.ì„¸ìš”?\n",
      "ì–´ìš”?\n",
      " \n",
      "ê¹Œìš”?\n",
      "ê² ìŠµë‹ˆë‹¤.\n",
      "ì–´.\n",
      "ì–´ìš”.\n",
      "!\n",
      "....\n",
      "Early stopping triggered after 4 epochs\n",
      "\n",
      "==================================================\n",
      "Training completed!\n",
      "Best ROUGE-L: 0.1490\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "# config ê°’ë“¤ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°\n",
    "num_epochs = config['training'].get('num_epochs', config['training'].get('epochs', 3))\n",
    "learning_rate = config['training']['learning_rate']\n",
    "# learning_rateê°€ ë¬¸ìì—´ì¸ ê²½ìš° floatë¡œ ë³€í™˜\n",
    "if isinstance(learning_rate, str):\n",
    "    learning_rate = float(learning_rate)\n",
    "    print(f\"Learning rate converted from string to float: {learning_rate}\")\n",
    "\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,  # ì´ë¯¸ floatë¡œ ë³€í™˜ë¨\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(num_training_steps * config['training']['warmup_ratio']),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "logger.write(f\"Optimizer and scheduler initialized\")\n",
    "logger.write(f\"Learning rate: {learning_rate}\")\n",
    "logger.write(f\"Total training steps: {num_training_steps}\")\n",
    "logger.write(f\"Warmup steps: {int(num_training_steps * config['training']['warmup_ratio'])}\")\n",
    "\n",
    "# í•™ìŠµ ê¸°ë¡ ì €ì¥\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'rouge_1': [],\n",
    "    'rouge_2': [],\n",
    "    'rouge_l': []\n",
    "}\n",
    "\n",
    "# Early Stopping ì„¤ì •\n",
    "best_rouge_l = 0\n",
    "patience = config['training']['early_stopping_patience']\n",
    "patience_counter = 0\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ ê²½ë¡œ - configì˜ ê²½ë¡œ ì‚¬ìš©\n",
    "model_dir = get_path(config['paths']['output_dir'])\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_model_path = model_dir / 'best_model.pt'\n",
    "\n",
    "logger.write(\"=\" * 50)\n",
    "logger.write(\"Starting training...\")\n",
    "logger.write(\"=\" * 50)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "for epoch in range(num_epochs):\n",
    "    logger.write(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    logger.write(\"-\" * 30)\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    logger.write(f\"Average training loss: {train_loss:.4f}\")\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # ê²€ì¦\n",
    "    val_loss, rouge_scores, sample_preds = evaluate(model, val_loader, tokenizer, device)\n",
    "    \n",
    "    logger.write(f\"Validation loss: {val_loss:.4f}\")\n",
    "    logger.write(f\"ROUGE-1 F1: {rouge_scores['rouge-1']:.4f}\")\n",
    "    logger.write(f\"ROUGE-2 F1: {rouge_scores['rouge-2']:.4f}\")\n",
    "    logger.write(f\"ROUGE-L F1: {rouge_scores['rouge-l']:.4f}\")\n",
    "    \n",
    "    # í•™ìŠµ ê¸°ë¡ ì €ì¥\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['rouge_1'].append(rouge_scores['rouge-1'])\n",
    "    training_history['rouge_2'].append(rouge_scores['rouge-2'])\n",
    "    training_history['rouge_l'].append(rouge_scores['rouge-l'])\n",
    "    \n",
    "    # WandB ë¡œê¹…\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss_epoch': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'rouge_1': rouge_scores['rouge-1'],\n",
    "        'rouge_2': rouge_scores['rouge-2'],\n",
    "        'rouge_l': rouge_scores['rouge-l']\n",
    "    })\n",
    "    \n",
    "    # ìƒ˜í”Œ ì˜ˆì¸¡ ì¶œë ¥\n",
    "    logger.write(\"\\nSample predictions:\")\n",
    "    for i, pred in enumerate(sample_preds[:2]):\n",
    "        logger.write(f\"  Sample {i+1}: {pred[:100]}...\")\n",
    "    \n",
    "    # Best model ì €ì¥\n",
    "    if rouge_scores['rouge-l'] > best_rouge_l:\n",
    "        best_rouge_l = rouge_scores['rouge-l']\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # ëª¨ë¸ ì €ì¥\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'rouge_scores': rouge_scores,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        logger.write(f\"âœ“ New best model saved! (ROUGE-L: {best_rouge_l:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            logger.write(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "logger.write(\"\\n\" + \"=\" * 50)\n",
    "logger.write(f\"Training completed!\")\n",
    "logger.write(f\"Best ROUGE-L: {best_rouge_l:.4f}\")\n",
    "logger.write(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1\n",
      "Best ROUGE scores: {'rouge-1': 0.154792565273082, 'rouge-2': 0.04464649129948705, 'rouge-l': 0.1490111431801561}\n",
      "\n",
      "Generating predictions for test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7077f128617e412a852d421a9d8c6e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predictions:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 499 predictions\n",
      "\n",
      "Sample test predictions:\n",
      "Test 1: #Person1#ì€ Ms. Dawsonì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•´ë‹¬ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤. MrsyëŠ” ë©”ì‹œì§€ë¥¼ ê³„ì† ì‚¬ìš©í•˜ë©´ ê²½ê³  í›„ ì‹œì • ì¡°ì¹˜ê°€ ë‚´ë ¤ì§ˆ ìˆ˜ ìˆë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤.\n",
      "ì–´.\n",
      "ì„¸ìš”?\n",
      "!\n",
      "ã—¡ê¹Œìš”?\n",
      "...\n",
      "--------------------------------------------------\n",
      "Test 2: #Person1#ì€ ì¶œí‡´ê·¼ ì‹œê°„ì— êµí†µì²´ì¦ìœ¼ë¡œ ì¸í•´ êµí†µ ì²´ì¦ ë•Œë¬¸ì— ëŒ€ì¤‘êµí†µì„ ì´ìš©í•´ì•¼ í•œë‹¤ê³  ë§í•©ë‹ˆë‹¤. ê·¸ë“¤ì€ í™˜ê²½ì—ë„ ë„ì›€ì´ ë  ê²ƒì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.ì–´.\n",
      "\n",
      "ì„¸ìš”?\n",
      "ã—¡!\n",
      "ê¹Œìš”?\n",
      "...\n",
      "--------------------------------------------------\n",
      "Test 3: KateëŠ” #Person1#ì—ê²Œ Mashaì™€ Heroê°€ ë‘ ë‹¬ ë™ì•ˆ ë³„ê±° ì¤‘ì´ë©° ì´í˜¼ì„ í–ˆë‹¤ê³  ë§í•©ë‹ˆë‹¤. KataëŠ” ì´ë¥¼ ë¯¿ê¸° ì–´ë µë‹¤ê³  ìƒê°í•˜ì§€ë§Œ, Mishaê°€ ì–‘ìœ¡ê¶Œì„ ê°€ì§€ê¸°ë¡œ í–ˆë‹¤ê³  ì „í•©ë‹ˆë‹¤.\n",
      "ì„¸ìš”?\n",
      "ì–´.\n",
      "ã—¡!\n",
      "ê¹Œìš”?\n",
      "...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ìµœì  ëª¨ë¸ ë¡œë“œ\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "logger.write(f\"Best model loaded from epoch {checkpoint['epoch'] + 1}\")\n",
    "logger.write(f\"Best ROUGE scores: {checkpoint['rouge_scores']}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "def generate_predictions(model, data_loader, tokenizer, device):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìƒì„±\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Generating predictions')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            indices = batch['idx']\n",
    "            \n",
    "            # ì˜ˆì¸¡ ìƒì„±\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=config['inference']['max_length'],\n",
    "                num_beams=config['inference']['num_beams'],\n",
    "                early_stopping=config['inference']['early_stopping'],\n",
    "                no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                length_penalty=config['inference']['length_penalty'],\n",
    "                temperature=config['inference']['temperature']\n",
    "            )\n",
    "            \n",
    "            # ë””ì½”ë”©\n",
    "            predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_indices.extend(indices.tolist())\n",
    "    \n",
    "    # ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
    "    sorted_predictions = [pred for _, pred in sorted(zip(all_indices, all_predictions))]\n",
    "    \n",
    "    return sorted_predictions\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "logger.write(\"\\nGenerating predictions for test set...\")\n",
    "test_predictions = generate_predictions(model, test_loader, tokenizer, device)\n",
    "logger.write(f\"Generated {len(test_predictions)} predictions\")\n",
    "\n",
    "# ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nSample test predictions:\")\n",
    "for i in range(min(3, len(test_predictions))):\n",
    "    print(f\"Test {i+1}: {test_predictions[i][:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file saved: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/submissions/baseline/baseline_submission_20251010_101823.csv\n",
      "\n",
      "Submission file created: baseline_submission_20251010_101823.csv\n",
      "Shape: (499, 2)\n",
      "\n",
      "First 3 submissions:\n",
      "    fname                                            summary\n",
      "0  test_0  #Person1#ì€ Ms. Dawsonì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•´ë‹¬ë¼ê³  ìš”ì²­í•©...\n",
      "1  test_1  #Person1#ì€ ì¶œí‡´ê·¼ ì‹œê°„ì— êµí†µì²´ì¦ìœ¼ë¡œ ì¸í•´ êµí†µ ì²´ì¦ ë•Œë¬¸ì— ëŒ€ì¤‘êµí†µì„ ì´...\n",
      "2  test_2  KateëŠ” #Person1#ì—ê²Œ Mashaì™€ Heroê°€ ë‘ ë‹¬ ë™ì•ˆ ë³„ê±° ì¤‘ì´ë©° ì´...\n",
      "\n",
      "==================================================\n",
      "BASELINE EXPERIMENT SUMMARY\n",
      "==================================================\n",
      "Model: digit82/kobart-summarization\n",
      "Best ROUGE-L: 0.1490\n",
      "Training epochs: 4\n",
      "Final train loss: 0.3052\n",
      "Final val loss: 0.5443\n",
      "Submission file: baseline_submission_20251010_101823.csv\n",
      "==================================================\n",
      "\n",
      "âœ… Baseline experiment completed successfully!\n",
      "Log file: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/logs/baseline/baseline.log\n"
     ]
    }
   ],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission_df = pd.DataFrame({\n",
    "    'fname': test_df['fname'],\n",
    "    'summary': test_predictions\n",
    "})\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ì €ì¥ - configì˜ ê²½ë¡œ ì‚¬ìš©\n",
    "submission_dir = get_path(config['paths']['submission_dir'])\n",
    "submission_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "submission_filename = f'baseline_submission_{timestamp}.csv'\n",
    "submission_path = submission_dir / submission_filename\n",
    "\n",
    "# index=Trueë¡œ ì„¤ì •í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ í¬í•¨ì‹œí‚´\n",
    "submission_df.to_csv(submission_path, index=True, encoding='utf-8')  # index=False -> index=Trueë¡œ ë³€ê²½\n",
    "logger.write(f\"\\nSubmission file saved: {submission_path}\")\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ í™•ì¸\n",
    "print(f\"\\nSubmission file created: {submission_filename}\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst 3 submissions:\")\n",
    "print(submission_df.head(3))\n",
    "\n",
    "# ìµœì¢… ìš”ì•½ í†µê³„\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BASELINE EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Best ROUGE-L: {best_rouge_l:.4f}\")\n",
    "print(f\"Training epochs: {len(training_history['train_loss'])}\")\n",
    "print(f\"Final train loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final val loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Submission file: {submission_filename}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# WandB ì‹¤í—˜ ì¢…ë£Œ\n",
    "wandb.finish()\n",
    "\n",
    "logger.write(\"\\nâœ… Baseline experiment completed successfully!\")\n",
    "logger.write(f\"Log file: {log_dir / 'baseline.log'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
