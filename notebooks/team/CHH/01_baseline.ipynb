{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 베이스라인 구현 - KoBART 기반 대화 요약\n",
    "> PRD 계획에 따른 베이스라인 모델 구현\n",
    "\n",
    "**목표 성능**: ROUGE-F1 47+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /home/ieyeppo/AI_Lab/natural-language-processing-competition\n",
      "Current Dir: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "notebook_dir = Path.cwd()\n",
    "# notebooks/team/CHH -> notebooks -> team -> natural-language-processing-competition\n",
    "project_root = notebook_dir.parent.parent.parent  # 3번만 parent 사용!\n",
    "\n",
    "# 다른 프로젝트 경로 제거하고 현재 프로젝트 경로만 추가\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "from rouge import Rouge\n",
    "import wandb\n",
    "\n",
    "# 커스텀 모듈 임포트\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: digit82/kobart-summarization\n",
      "Batch Size: 16\n"
     ]
    }
   ],
   "source": [
    "# 설정 로드\n",
    "config_path = notebook_dir / 'configs' / 'config_baseline.yaml'\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Batch Size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 로거 초기화\n# config의 로그 경로 사용\ndef get_path(path_str):\n    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n    path = Path(path_str)\n    if not path.is_absolute():\n        path = notebook_dir / path\n    return path\n\nlog_dir = get_path(config['paths']['log_dir'])\nlog_dir.mkdir(parents=True, exist_ok=True)\n\nlogger = NotebookLogger(\n    log_path=str(log_dir / 'baseline.log'),\n    print_also=True\n)\nlogger.write('=== Baseline Experiment Started ===')"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tier: LOW\n",
      "GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# GPU 체크\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tier = check_gpu_tier()\n",
    "    logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "    logger.write(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 데이터 경로 설정 및 로드\n# config 파일의 경로 사용\ndef get_data_path(path_str):\n    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n    path = Path(path_str)\n    if not path.is_absolute():\n        path = notebook_dir / path\n    return path\n\n# config에서 데이터 경로 가져오기\ntrain_path = get_data_path(config['paths']['train_file'])\ndev_path = get_data_path(config['paths']['dev_file'])\ntest_path = get_data_path(config['paths']['test_file'])\n\nlogger.write(f\"Loading data from config paths:\")\nlogger.write(f\"  - Train: {train_path}\")\nlogger.write(f\"  - Dev: {dev_path}\")\nlogger.write(f\"  - Test: {test_path}\")\n\n# 데이터 로드\ntrain_df = pd.read_csv(train_path)\ndev_df = pd.read_csv(dev_path)\ntest_df = pd.read_csv(test_path)\n\nlogger.write(f\"Data loaded successfully!\")\nlogger.write(f\"Train samples: {len(train_df)}\")\nlogger.write(f\"Dev samples: {len(dev_df)}\")\nlogger.write(f\"Test samples: {len(test_df)}\")\n\n# 데이터 샘플 출력\nprint(\"\\nSample data:\")\nprint(train_df.head(2))"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mieyeppo-job\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_084132-fwz26up1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ieyeppo/nlp-competition/runs/fwz26up1' target=\"_blank\">baseline-kobart</a></strong> to <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ieyeppo/nlp-competition/runs/fwz26up1' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition/runs/fwz26up1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ieyeppo/nlp-competition/runs/fwz26up1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x77c23b29bbd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB 초기화\n",
    "wandb.init(\n",
    "    project=config['wandb']['project'],\n",
    "    entity=config['wandb']['entity'],\n",
    "    name=config['wandb']['name'],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: digit82/kobart-summarization\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\n",
    "model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n",
    "\n",
    "logger.write(f\"Model loaded: {config['model']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 코드는 config 파일 설정에 따라 구현"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}