{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 베이스라인 구현 - KoBART 기반 대화 요약\n",
    "> PRD 계획에 따른 베이스라인 모델 구현\n",
    "\n",
    "**목표 성능**: ROUGE-F1 47+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /home/ieyeppo/AI_Lab/natural-language-processing-competition\n",
      "Current Dir: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "notebook_dir = Path.cwd()\n",
    "# notebooks/team/CHH -> notebooks -> team -> natural-language-processing-competition\n",
    "project_root = notebook_dir.parent.parent.parent  # 3번만 parent 사용!\n",
    "\n",
    "# 다른 프로젝트 경로 제거하고 현재 프로젝트 경로만 추가\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "from rouge import Rouge\n",
    "import wandb\n",
    "\n",
    "# 커스텀 모듈 임포트\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: digit82/kobart-summarization\n",
      "Batch Size: 16\n"
     ]
    }
   ],
   "source": [
    "# 설정 로드\n",
    "config_path = notebook_dir / 'configs' / 'config_baseline.yaml'\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Batch Size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Experiment Started ===\n"
     ]
    }
   ],
   "source": [
    "# 로거 초기화\n",
    "# config의 로그 경로 사용\n",
    "def get_path(path_str):\n",
    "    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "log_dir = get_path(config['paths']['log_dir'])\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 타임스탬프 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 로거 초기화\n",
    "log_file = log_dir / f'baseline_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('=== Baseline Experiment Started ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tier: LOW\n",
      "GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# GPU 체크\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tier = check_gpu_tier()\n",
    "    logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "    logger.write(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from config paths:\n",
      "  - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv\n",
      "  - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv\n",
      "  - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv\n",
      "Data loaded successfully!\n",
      "Train samples: 12457\n",
      "Dev samples: 499\n",
      "Test samples: 499\n",
      "\n",
      "Sample data:\n",
      "     fname                                           dialogue  \\\n",
      "0  train_0  #Person1#: 안녕하세요, Mr. Smith. 저는 Dr. Hawkins입니다...   \n",
      "1  train_1  #Person1#: 안녕하세요, Mrs. Parker. 잘 지내셨나요?\\n#Pers...   \n",
      "\n",
      "                                             summary  topic  \n",
      "0  Mr. Smith는 Dr. Hawkins에게 건강검진을 받으러 와서, 매년 검진 필...   건강검진  \n",
      "1  Mrs. Parker가 Ricky와 함께 백신 접종을 위해 방문하였고, Dr. Pe...  백신 접종  \n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로 설정 및 로드\n",
    "# config 파일의 경로 사용\n",
    "def get_data_path(path_str):\n",
    "    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "# config에서 데이터 경로 가져오기\n",
    "train_path = get_data_path(config['paths']['train_file'])\n",
    "dev_path = get_data_path(config['paths']['dev_file'])\n",
    "test_path = get_data_path(config['paths']['test_file'])\n",
    "\n",
    "logger.write(f\"Loading data from config paths:\")\n",
    "logger.write(f\"  - Train: {train_path}\")\n",
    "logger.write(f\"  - Dev: {dev_path}\")\n",
    "logger.write(f\"  - Test: {test_path}\")\n",
    "\n",
    "# 데이터 로드\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df = pd.read_csv(dev_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "logger.write(f\"Data loaded successfully!\")\n",
    "logger.write(f\"Train samples: {len(train_df)}\")\n",
    "logger.write(f\"Dev samples: {len(dev_df)}\")\n",
    "logger.write(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# 데이터 샘플 출력\n",
    "print(\"\\nSample data:\")\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mieyeppo-job\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_095540-r1fpk5vb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb' target=\"_blank\">baseline-kobart</a></strong> to <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ieyeppo/nlp-competition' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb' target=\"_blank\">https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ieyeppo/nlp-competition/runs/r1fpk5vb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7669762cbe50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB 초기화\n",
    "wandb.init(\n",
    "    project=config['wandb']['project'],\n",
    "    entity=config['wandb']['entity'],\n",
    "    name=config['wandb']['name'],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: digit82/kobart-summarization\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\n",
    "model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n",
    "\n",
    "logger.write(f\"Model loaded: {config['model']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료!\n",
      "Sample preprocessed dialogue (first 200 chars):\n",
      "화자1: 안녕하세요, Mr. Smith. 저는 Dr. Hawkins입니다. 오늘 무슨 일로 오셨어요? \n",
      "화자2: 건강검진을 받으려고 왔어요. \n",
      "화자1: 네, 5년 동안 검진을 안 받으셨네요. 매년 한 번씩 받으셔야 해요. \n",
      "화자2: 알죠. 특별히 아픈 데가 없으면 굳이 갈 필요가 없다고 생각했어요. \n",
      "화자1: 음, 심각한 질병을 피하려면 미리 발견하는 게 \n",
      "Data preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_dialogue(text):\n",
    "    \"\"\"대화 텍스트 전처리\"\"\"\n",
    "    # 노이즈 제거\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    text = text.replace('<br>', '\\n')\n",
    "    \n",
    "    # 특수문자 정규화\n",
    "    text = text.strip()\n",
    "    \n",
    "    # #Person 태그 최적화 (더 명확하게)\n",
    "    import re\n",
    "    text = re.sub(r'#Person(\\d+)#:', r'화자\\1:', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_summary(text):\n",
    "    \"\"\"요약 텍스트 전처리\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# 데이터 전처리 적용\n",
    "train_df['dialogue_preprocessed'] = train_df['dialogue'].apply(preprocess_dialogue)\n",
    "train_df['summary_preprocessed'] = train_df['summary'].apply(preprocess_summary)\n",
    "\n",
    "dev_df['dialogue_preprocessed'] = dev_df['dialogue'].apply(preprocess_dialogue)\n",
    "dev_df['summary_preprocessed'] = dev_df['summary'].apply(preprocess_summary)\n",
    "\n",
    "test_df['dialogue_preprocessed'] = test_df['dialogue'].apply(preprocess_dialogue)\n",
    "\n",
    "print(f\"전처리 완료!\")\n",
    "print(f\"Sample preprocessed dialogue (first 200 chars):\")\n",
    "print(train_df['dialogue_preprocessed'].iloc[0][:200])\n",
    "logger.write(\"Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created - Train: 12457, Val: 499, Test: 499\n",
      "Dataset shapes:\n",
      "  Train: 12457\n",
      "  Val: 499\n",
      "  Test: 499\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset 클래스 정의\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DialogueSummaryDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_len=512, max_target_len=128, is_test=False):\n",
    "        \"\"\"\n",
    "        대화 요약 데이터셋\n",
    "        \n",
    "        Args:\n",
    "            dataframe: 데이터프레임\n",
    "            tokenizer: 토크나이저\n",
    "            max_input_len: 최대 입력 길이\n",
    "            max_target_len: 최대 타겟 길이\n",
    "            is_test: 테스트 모드 여부\n",
    "        \"\"\"\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # 입력 텍스트\n",
    "        dialogue = row['dialogue_preprocessed']\n",
    "        \n",
    "        # 입력 토큰화\n",
    "        inputs = self.tokenizer(\n",
    "            dialogue,\n",
    "            max_length=self.max_input_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # 테스트 모드가 아닌 경우 타겟도 처리\n",
    "        if not self.is_test:\n",
    "            summary = row['summary_preprocessed']\n",
    "            \n",
    "            # 타겟 토큰화\n",
    "            targets = self.tokenizer(\n",
    "                summary,\n",
    "                max_length=self.max_target_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'labels': targets['input_ids'].squeeze()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'idx': idx\n",
    "            }\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = DialogueSummaryDataset(\n",
    "    train_df, \n",
    "    tokenizer, \n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length']\n",
    ")\n",
    "\n",
    "val_dataset = DialogueSummaryDataset(\n",
    "    dev_df,\n",
    "    tokenizer,\n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length']\n",
    ")\n",
    "\n",
    "test_dataset = DialogueSummaryDataset(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length'],\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "logger.write(f\"Dataset created - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Val: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader created:\n",
      "  Train batches: 779\n",
      "  Val batches: 32\n",
      "  Test batches: 32\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "logger.write(f\"Using device: {device}\")\n",
    "\n",
    "# ROUGE 평가 함수\n",
    "def compute_rouge_scores(predictions, references):\n",
    "    \"\"\"ROUGE 점수 계산\"\"\"\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # 빈 문자열 처리\n",
    "    predictions = [p if p else \"empty\" for p in predictions]\n",
    "    references = [r if r else \"empty\" for r in references]\n",
    "    \n",
    "    try:\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        return {\n",
    "            'rouge-1': scores['rouge-1']['f'],\n",
    "            'rouge-2': scores['rouge-2']['f'],\n",
    "            'rouge-l': scores['rouge-l']['f']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.write(f\"Error computing ROUGE: {e}\")\n",
    "        return {'rouge-1': 0, 'rouge-2': 0, 'rouge-l': 0}\n",
    "\n",
    "# 학습 함수\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    \"\"\"한 에폭 학습\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # 데이터를 디바이스로 이동\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # 옵티마이저 스텝\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 프로그레스 바 업데이트\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # WandB 로깅\n",
    "        wandb.log({\n",
    "            'train_loss': loss.item(),\n",
    "            'learning_rate': scheduler.get_last_lr()[0]\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# 검증 함수\n",
    "def evaluate(model, data_loader, tokenizer, device, num_samples=None):\n",
    "    \"\"\"모델 평가\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Evaluating')\n",
    "        \n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            if num_samples and i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Loss 계산\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # 예측 생성 - config 키 수정\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=config['model']['max_target_length'],\n",
    "                num_beams=config['evaluation']['num_beams'],  # config 키 수정\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=config['evaluation']['no_repeat_ngram_size']\n",
    "            )\n",
    "            \n",
    "            # 디코딩\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            references.extend(refs)\n",
    "    \n",
    "    # ROUGE 점수 계산\n",
    "    rouge_scores = compute_rouge_scores(predictions, references)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return avg_loss, rouge_scores, predictions[:5]  # 샘플 예측 반환\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate converted from string to float: 5e-05\n",
      "Optimizer and scheduler initialized\n",
      "Learning rate: 5e-05\n",
      "Total training steps: 7790\n",
      "Warmup steps: 779\n",
      "==================================================\n",
      "Starting training...\n",
      "==================================================\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b50697c9e456080c2de813f05130a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.5061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf67cc92bd0e429fa0b55de95462ab2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5410\n",
      "ROUGE-1 F1: 0.1548\n",
      "ROUGE-2 F1: 0.0446\n",
      "ROUGE-L F1: 0.1490\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person1#은 감기에 걸렸다고 말하며, 천식 검사를 위해 폐 전문의에게 가보라고 제안합니다.\n",
      "세요?\n",
      "어.\n",
      "!\n",
      "㗡까요?\n",
      "...\n",
      "  Sample 2: #Person1#은 Jimmy에게 운동하러 가자고 제안하고, Jammi는 토요일에 운동하자고 제안한다. 그들은 오후 3시 30분에 체육관에서 만나기로 한다. 그들은 체육관 운동에 ...\n",
      "✓ New best model saved! (ROUGE-L: 0.1490)\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658e88cb27154897bcd76505d3d1bbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f648a651a9e4f6a839616e1b912a39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5106\n",
      "ROUGE-1 F1: 0.1448\n",
      "ROUGE-2 F1: 0.0416\n",
      "ROUGE-L F1: 0.1372\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person2#는 숨쉬기 힘들다고 호소하며, 천식 검사를 위해 폐 전문의에게 가볼 것을 권장합니다.\n",
      "어.\n",
      "세요?\n",
      "!\n",
      "어요?\n",
      "까요?\n",
      " \n",
      "예요.\n",
      "어요.\n",
      "겠습니다.\n",
      "습니다.\n",
      "죠?\n",
      "㗡더...\n",
      "  Sample 2: #Person1#이 Jimmy에게 운동 날짜를 물어보고, 그들은 오후 3시 30분에 체육관에서 운동하기로 결정한다.\n",
      "어.\n",
      "세요?\n",
      "!\n",
      "어요?\n",
      "까요?\n",
      "예요.\n",
      "겠습니다.\n",
      " \n",
      "어요.\n",
      "죠?...\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb283404cf95428aa7af02b173567623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb03fb6e204049d3b368c3c93355ae29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5182\n",
      "ROUGE-1 F1: 0.1382\n",
      "ROUGE-2 F1: 0.0389\n",
      "ROUGE-L F1: 0.1315\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person2#는 최근 숨쉬기 어려움을 겪고 있으며, 천식 검사를 위해 폐 전문의에게 방문할 것을 권장하고 있습니다. 의사는 천식을 검사하기 위해 의사를 방문해야 한다고 안내합니...\n",
      "  Sample 2: #Person1#이 Jimmy에게 운동을 하자고 제안하지만, 그녀는 다리가 아파서 거절한다. #My는 주간 일정을 변경하자고 제안하고, Jammi는 이를 수락한다. 결국 그들은 3...\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61949f327f2f4458bbeef7e149010d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e693ec1c853c42fa9c5b9894e2a33354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5443\n",
      "ROUGE-1 F1: 0.1215\n",
      "ROUGE-2 F1: 0.0329\n",
      "ROUGE-L F1: 0.1162\n",
      "\n",
      "Sample predictions:\n",
      "  Sample 1: #Person2#는 최근 숨쉬기 어려움을 겪고 있으며, 천식 검사를 위해 폐 전문의에게 가볼 것을 권장합니다.세요?\n",
      "어요?\n",
      "어.\n",
      "까요?\n",
      " \n",
      "!\n",
      "어요.\n",
      "겠습니다.\n",
      "예요.\n",
      ".\n",
      "더라.\n",
      "...\n",
      "  Sample 2: #Person1#이 Jimmy에게 운동 일정에 대해 물어보고, 결국 그들은 3시 30분에 체육관에서 함께 운동하기로 결정한다.세요?\n",
      "어요?\n",
      " \n",
      "까요?\n",
      "겠습니다.\n",
      "어.\n",
      "어요.\n",
      "!\n",
      "....\n",
      "Early stopping triggered after 4 epochs\n",
      "\n",
      "==================================================\n",
      "Training completed!\n",
      "Best ROUGE-L: 0.1490\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 스케줄러 설정\n",
    "# config 값들을 안전하게 가져오기\n",
    "num_epochs = config['training'].get('num_epochs', config['training'].get('epochs', 3))\n",
    "learning_rate = config['training']['learning_rate']\n",
    "# learning_rate가 문자열인 경우 float로 변환\n",
    "if isinstance(learning_rate, str):\n",
    "    learning_rate = float(learning_rate)\n",
    "    print(f\"Learning rate converted from string to float: {learning_rate}\")\n",
    "\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,  # 이미 float로 변환됨\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(num_training_steps * config['training']['warmup_ratio']),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "logger.write(f\"Optimizer and scheduler initialized\")\n",
    "logger.write(f\"Learning rate: {learning_rate}\")\n",
    "logger.write(f\"Total training steps: {num_training_steps}\")\n",
    "logger.write(f\"Warmup steps: {int(num_training_steps * config['training']['warmup_ratio'])}\")\n",
    "\n",
    "# 학습 기록 저장\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'rouge_1': [],\n",
    "    'rouge_2': [],\n",
    "    'rouge_l': []\n",
    "}\n",
    "\n",
    "# Early Stopping 설정\n",
    "best_rouge_l = 0\n",
    "patience = config['training']['early_stopping_patience']\n",
    "patience_counter = 0\n",
    "\n",
    "# 모델 저장 경로 - config의 경로 사용\n",
    "model_dir = get_path(config['paths']['output_dir'])\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_model_path = model_dir / 'best_model.pt'\n",
    "\n",
    "logger.write(\"=\" * 50)\n",
    "logger.write(\"Starting training...\")\n",
    "logger.write(\"=\" * 50)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    logger.write(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    logger.write(\"-\" * 30)\n",
    "    \n",
    "    # 학습\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    logger.write(f\"Average training loss: {train_loss:.4f}\")\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # 검증\n",
    "    val_loss, rouge_scores, sample_preds = evaluate(model, val_loader, tokenizer, device)\n",
    "    \n",
    "    logger.write(f\"Validation loss: {val_loss:.4f}\")\n",
    "    logger.write(f\"ROUGE-1 F1: {rouge_scores['rouge-1']:.4f}\")\n",
    "    logger.write(f\"ROUGE-2 F1: {rouge_scores['rouge-2']:.4f}\")\n",
    "    logger.write(f\"ROUGE-L F1: {rouge_scores['rouge-l']:.4f}\")\n",
    "    \n",
    "    # 학습 기록 저장\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['rouge_1'].append(rouge_scores['rouge-1'])\n",
    "    training_history['rouge_2'].append(rouge_scores['rouge-2'])\n",
    "    training_history['rouge_l'].append(rouge_scores['rouge-l'])\n",
    "    \n",
    "    # WandB 로깅\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss_epoch': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'rouge_1': rouge_scores['rouge-1'],\n",
    "        'rouge_2': rouge_scores['rouge-2'],\n",
    "        'rouge_l': rouge_scores['rouge-l']\n",
    "    })\n",
    "    \n",
    "    # 샘플 예측 출력\n",
    "    logger.write(\"\\nSample predictions:\")\n",
    "    for i, pred in enumerate(sample_preds[:2]):\n",
    "        logger.write(f\"  Sample {i+1}: {pred[:100]}...\")\n",
    "    \n",
    "    # Best model 저장\n",
    "    if rouge_scores['rouge-l'] > best_rouge_l:\n",
    "        best_rouge_l = rouge_scores['rouge-l']\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'rouge_scores': rouge_scores,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        logger.write(f\"✓ New best model saved! (ROUGE-L: {best_rouge_l:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            logger.write(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # 메모리 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "logger.write(\"\\n\" + \"=\" * 50)\n",
    "logger.write(f\"Training completed!\")\n",
    "logger.write(f\"Best ROUGE-L: {best_rouge_l:.4f}\")\n",
    "logger.write(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 예측 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1\n",
      "Best ROUGE scores: {'rouge-1': 0.154792565273082, 'rouge-2': 0.04464649129948705, 'rouge-l': 0.1490111431801561}\n",
      "\n",
      "Generating predictions for test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7077f128617e412a852d421a9d8c6e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predictions:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 499 predictions\n",
      "\n",
      "Sample test predictions:\n",
      "Test 1: #Person1#은 Ms. Dawson에게 사내 메모를 작성하고 배포해달라고 요청합니다. Mrsy는 메시지를 계속 사용하면 경고 후 시정 조치가 내려질 수 있다고 설명합니다.\n",
      "어.\n",
      "세요?\n",
      "!\n",
      "㗡까요?\n",
      "...\n",
      "--------------------------------------------------\n",
      "Test 2: #Person1#은 출퇴근 시간에 교통체증으로 인해 교통 체증 때문에 대중교통을 이용해야 한다고 말합니다. 그들은 환경에도 도움이 될 것이라고 생각합니다.어.\n",
      "\n",
      "세요?\n",
      "㗡!\n",
      "까요?\n",
      "...\n",
      "--------------------------------------------------\n",
      "Test 3: Kate는 #Person1#에게 Masha와 Hero가 두 달 동안 별거 중이며 이혼을 했다고 말합니다. Kata는 이를 믿기 어렵다고 생각하지만, Misha가 양육권을 가지기로 했다고 전합니다.\n",
      "세요?\n",
      "어.\n",
      "㗡!\n",
      "까요?\n",
      "...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델 로드\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "logger.write(f\"Best model loaded from epoch {checkpoint['epoch'] + 1}\")\n",
    "logger.write(f\"Best ROUGE scores: {checkpoint['rouge_scores']}\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "def generate_predictions(model, data_loader, tokenizer, device):\n",
    "    \"\"\"테스트 데이터에 대한 예측 생성\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Generating predictions')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            indices = batch['idx']\n",
    "            \n",
    "            # 예측 생성\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=config['inference']['max_length'],\n",
    "                num_beams=config['inference']['num_beams'],\n",
    "                early_stopping=config['inference']['early_stopping'],\n",
    "                no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                length_penalty=config['inference']['length_penalty'],\n",
    "                temperature=config['inference']['temperature']\n",
    "            )\n",
    "            \n",
    "            # 디코딩\n",
    "            predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_indices.extend(indices.tolist())\n",
    "    \n",
    "    # 인덱스 순서대로 정렬\n",
    "    sorted_predictions = [pred for _, pred in sorted(zip(all_indices, all_predictions))]\n",
    "    \n",
    "    return sorted_predictions\n",
    "\n",
    "# 예측 수행\n",
    "logger.write(\"\\nGenerating predictions for test set...\")\n",
    "test_predictions = generate_predictions(model, test_loader, tokenizer, device)\n",
    "logger.write(f\"Generated {len(test_predictions)} predictions\")\n",
    "\n",
    "# 샘플 출력\n",
    "print(\"\\nSample test predictions:\")\n",
    "for i in range(min(3, len(test_predictions))):\n",
    "    print(f\"Test {i+1}: {test_predictions[i][:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file saved: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/submissions/baseline/baseline_submission_20251010_101823.csv\n",
      "\n",
      "Submission file created: baseline_submission_20251010_101823.csv\n",
      "Shape: (499, 2)\n",
      "\n",
      "First 3 submissions:\n",
      "    fname                                            summary\n",
      "0  test_0  #Person1#은 Ms. Dawson에게 사내 메모를 작성하고 배포해달라고 요청합...\n",
      "1  test_1  #Person1#은 출퇴근 시간에 교통체증으로 인해 교통 체증 때문에 대중교통을 이...\n",
      "2  test_2  Kate는 #Person1#에게 Masha와 Hero가 두 달 동안 별거 중이며 이...\n",
      "\n",
      "==================================================\n",
      "BASELINE EXPERIMENT SUMMARY\n",
      "==================================================\n",
      "Model: digit82/kobart-summarization\n",
      "Best ROUGE-L: 0.1490\n",
      "Training epochs: 4\n",
      "Final train loss: 0.3052\n",
      "Final val loss: 0.5443\n",
      "Submission file: baseline_submission_20251010_101823.csv\n",
      "==================================================\n",
      "\n",
      "✅ Baseline experiment completed successfully!\n",
      "Log file: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/logs/baseline/baseline.log\n"
     ]
    }
   ],
   "source": [
    "# 제출 파일 생성\n",
    "submission_df = pd.DataFrame({\n",
    "    'fname': test_df['fname'],\n",
    "    'summary': test_predictions\n",
    "})\n",
    "\n",
    "# 제출 파일 저장 - config의 경로 사용\n",
    "submission_dir = get_path(config['paths']['submission_dir'])\n",
    "submission_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "submission_filename = f'baseline_submission_{timestamp}.csv'\n",
    "submission_path = submission_dir / submission_filename\n",
    "\n",
    "# index=True로 설정하여 인덱스를 포함시킴\n",
    "submission_df.to_csv(submission_path, index=True, encoding='utf-8')  # index=False -> index=True로 변경\n",
    "logger.write(f\"\\nSubmission file saved: {submission_path}\")\n",
    "\n",
    "# 제출 파일 확인\n",
    "print(f\"\\nSubmission file created: {submission_filename}\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst 3 submissions:\")\n",
    "print(submission_df.head(3))\n",
    "\n",
    "# 최종 요약 통계\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BASELINE EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Best ROUGE-L: {best_rouge_l:.4f}\")\n",
    "print(f\"Training epochs: {len(training_history['train_loss'])}\")\n",
    "print(f\"Final train loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final val loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Submission file: {submission_filename}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# WandB 실험 종료\n",
    "wandb.finish()\n",
    "\n",
    "logger.write(\"\\n✅ Baseline experiment completed successfully!\")\n",
    "logger.write(f\"Log file: {log_dir / 'baseline.log'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
