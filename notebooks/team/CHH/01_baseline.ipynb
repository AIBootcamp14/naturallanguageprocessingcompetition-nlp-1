{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 베이스라인 구현 - KoBART 기반 대화 요약\n",
    "> PRD 계획에 따른 베이스라인 모델 구현\n",
    "\n",
    "**목표 성능**: ROUGE-F1 47+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "notebook_dir = Path.cwd()\n",
    "# notebooks/team/CHH -> notebooks -> team -> natural-language-processing-competition\n",
    "project_root = notebook_dir.parent.parent.parent  # 3번만 parent 사용!\n",
    "\n",
    "# 다른 프로젝트 경로 제거하고 현재 프로젝트 경로만 추가\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "from rouge import Rouge\n",
    "import wandb\n",
    "\n",
    "# 커스텀 모듈 임포트\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정 로드\n",
    "config_path = notebook_dir / 'configs' / 'config_baseline.yaml'\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Batch Size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로거 초기화\n",
    "# config의 로그 경로 사용\n",
    "def get_path(path_str):\n",
    "    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "log_dir = get_path(config['paths']['log_dir'])\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 타임스탬프 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 로거 초기화\n",
    "log_file = log_dir / f'baseline_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('=== Baseline Experiment Started ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 체크\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tier = check_gpu_tier()\n",
    "    logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "    logger.write(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정 및 로드\n",
    "# config 파일의 경로 사용\n",
    "def get_data_path(path_str):\n",
    "    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "# config에서 데이터 경로 가져오기\n",
    "train_path = get_data_path(config['paths']['train_file'])\n",
    "dev_path = get_data_path(config['paths']['dev_file'])\n",
    "test_path = get_data_path(config['paths']['test_file'])\n",
    "\n",
    "logger.write(f\"Loading data from config paths:\")\n",
    "logger.write(f\"  - Train: {train_path}\")\n",
    "logger.write(f\"  - Dev: {dev_path}\")\n",
    "logger.write(f\"  - Test: {test_path}\")\n",
    "\n",
    "# 데이터 로드\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df = pd.read_csv(dev_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "logger.write(f\"Data loaded successfully!\")\n",
    "logger.write(f\"Train samples: {len(train_df)}\")\n",
    "logger.write(f\"Dev samples: {len(dev_df)}\")\n",
    "logger.write(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# 데이터 샘플 출력\n",
    "print(\"\\nSample data:\")\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 품질 검증 시스템 (PRD 16_데이터_품질_검증_시스템.md)\n",
    "logger.write(\"\\n=== Data Quality Validation ===\")\n",
    "\n",
    "class DataQualityValidator:\n",
    "    \"\"\"데이터 품질 검증 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.quality_report = {}\n",
    "    \n",
    "    def validate_structure(self, df):\n",
    "        \"\"\"구조적 검증\"\"\"\n",
    "        checks = {\n",
    "            'null_values': df.isnull().sum().sum(),\n",
    "            'duplicates': df.duplicated().sum(),\n",
    "            'empty_dialogues': (df['dialogue'].str.len() == 0).sum(),\n",
    "            'empty_summaries': (df['summary'].str.len() == 0).sum() if 'summary' in df.columns else 0\n",
    "        }\n",
    "        self.quality_report['structure'] = checks\n",
    "        return checks\n",
    "    \n",
    "    def validate_content(self, df):\n",
    "        \"\"\"내용 검증\"\"\"\n",
    "        dialogue_lengths = df['dialogue'].str.len()\n",
    "        summary_lengths = df['summary'].str.len() if 'summary' in df.columns else pd.Series([0])\n",
    "        \n",
    "        checks = {\n",
    "            'avg_dialogue_length': dialogue_lengths.mean(),\n",
    "            'min_dialogue_length': dialogue_lengths.min(),\n",
    "            'max_dialogue_length': dialogue_lengths.max(),\n",
    "            'avg_summary_length': summary_lengths.mean(),\n",
    "            'summary_ratio': (summary_lengths / dialogue_lengths).mean() if 'summary' in df.columns else 0\n",
    "        }\n",
    "        self.quality_report['content'] = checks\n",
    "        return checks\n",
    "    \n",
    "    def validate_consistency(self, df):\n",
    "        \"\"\"일관성 검증\"\"\"\n",
    "        checks = {\n",
    "            'person_tags_consistent': all(df['dialogue'].str.contains('#Person')),\n",
    "            'encoding_issues': df['dialogue'].str.contains('\\\\?\\\\?\\\\?').sum(),\n",
    "            'special_chars': df['dialogue'].str.contains('[^\\w\\s#:.,!?가-힣]').sum()\n",
    "        }\n",
    "        self.quality_report['consistency'] = checks\n",
    "        return checks\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"품질 보고서 생성\"\"\"\n",
    "        return self.quality_report\n",
    "\n",
    "# 데이터 품질 검증 실행\n",
    "validator = DataQualityValidator()\n",
    "\n",
    "# 구조 검증\n",
    "structure_checks = validator.validate_structure(train_df)\n",
    "logger.write(f\"Structure validation:\")\n",
    "for key, value in structure_checks.items():\n",
    "    logger.write(f\"  - {key}: {value}\")\n",
    "\n",
    "# 내용 검증\n",
    "content_checks = validator.validate_content(train_df)\n",
    "logger.write(f\"Content validation:\")\n",
    "logger.write(f\"  - Avg dialogue length: {content_checks['avg_dialogue_length']:.1f}\")\n",
    "logger.write(f\"  - Summary ratio: {content_checks.get('summary_ratio', 0):.2%}\")\n",
    "\n",
    "# 일관성 검증\n",
    "consistency_checks = validator.validate_consistency(train_df)\n",
    "logger.write(f\"Consistency validation:\")\n",
    "logger.write(f\"  - Person tags consistent: {consistency_checks['person_tags_consistent']}\")\n",
    "logger.write(f\"  - Encoding issues: {consistency_checks['encoding_issues']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solar API 교차 검증 시스템 (PRD 09_Solar_API_최적화.md, 10_교차_검증_시스템.md)\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class SolarAPIOptimizer:\n",
    "    \"\"\"Solar API 최적화 클래스\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.upstage.ai/v1/solar\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def optimize_prompt(self, dialogue: str) -> str:\n",
    "        \"\"\"프롬프트 최적화 - 토큰 절약\"\"\"\n",
    "        # 불필요한 공백 제거\n",
    "        dialogue = ' '.join(dialogue.split())\n",
    "        \n",
    "        # 핵심 정보만 추출하는 프롬프트\n",
    "        optimized_prompt = f\"\"\"다음 대화를 한국어로 간결하게 요약하세요. 핵심 내용만 포함하세요:\n",
    "{dialogue[:1000]}  # 토큰 제한\n",
    "요약:\"\"\"\n",
    "        \n",
    "        return optimized_prompt\n",
    "    \n",
    "    def generate_summary(self, dialogue: str, max_tokens: int = 150) -> Optional[str]:\n",
    "        \"\"\"Solar API로 요약 생성\"\"\"\n",
    "        try:\n",
    "            prompt = self.optimize_prompt(dialogue)\n",
    "            \n",
    "            payload = {\n",
    "                \"model\": \"solar-1-mini-chat\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 대화 요약 전문가입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": 0.3,\n",
    "                \"top_p\": 0.9\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                headers=self.headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result['choices'][0]['message']['content']\n",
    "            else:\n",
    "                logger.write(f\"Solar API error: {response.status_code}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.write(f\"Solar API exception: {e}\")\n",
    "            return None\n",
    "\n",
    "class DualSummarizationSystem:\n",
    "    \"\"\"모델과 API 듀얼 요약 시스템\"\"\"\n",
    "    def __init__(self, model, tokenizer, solar_api: SolarAPIOptimizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.solar_api = solar_api\n",
    "        self.device = next(model.parameters()).device\n",
    "    \n",
    "    def compare_summaries(self, dialogue: str, reference: str = None) -> Dict:\n",
    "        \"\"\"모델과 API 요약 비교\"\"\"\n",
    "        # 모델 예측\n",
    "        inputs = self.tokenizer(\n",
    "            dialogue,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = self.model.generate(\n",
    "                **inputs,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        model_summary = self.tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # API 예측\n",
    "        api_summary = self.solar_api.generate_summary(dialogue)\n",
    "        \n",
    "        # ROUGE 점수 계산\n",
    "        result = {\n",
    "            'model_summary': model_summary,\n",
    "            'api_summary': api_summary\n",
    "        }\n",
    "        \n",
    "        if reference:\n",
    "            rouge = Rouge()\n",
    "            try:\n",
    "                model_scores = rouge.get_scores(model_summary, reference)[0]\n",
    "                api_scores = rouge.get_scores(api_summary, reference)[0] if api_summary else None\n",
    "                \n",
    "                result['model_rouge'] = model_scores['rouge-l']['f']\n",
    "                result['api_rouge'] = api_scores['rouge-l']['f'] if api_scores else 0\n",
    "                result['best'] = 'model' if result['model_rouge'] > result.get('api_rouge', 0) else 'api'\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Solar API 초기화 (config에서 API 키 가져오기)\n",
    "if 'solar_api' in config and 'api_key' in config['solar_api']:\n",
    "    solar_optimizer = SolarAPIOptimizer(config['solar_api']['api_key'])\n",
    "    dual_system = DualSummarizationSystem(model, tokenizer, solar_optimizer)\n",
    "    logger.write(\"Solar API dual system initialized\")\n",
    "else:\n",
    "    logger.write(\"Solar API key not found in config\")\n",
    "    solar_optimizer = None\n",
    "    dual_system = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB 초기화\n",
    "wandb.init(\n",
    "    project=config['wandb']['project'],\n",
    "    entity=config['wandb']['entity'],\n",
    "    name=config['wandb']['name'],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\n",
    "model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n",
    "\n",
    "logger.write(f\"Model loaded: {config['model']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_dialogue(text):\n",
    "    \"\"\"대화 텍스트 전처리\"\"\"\n",
    "    # 노이즈 제거\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    text = text.replace('<br>', '\\n')\n",
    "    \n",
    "    # 특수문자 정규화\n",
    "    text = text.strip()\n",
    "    \n",
    "    # #Person 태그 최적화 (더 명확하게)\n",
    "    import re\n",
    "    text = re.sub(r'#Person(\\d+)#:', r'화자\\1:', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_summary(text):\n",
    "    \"\"\"요약 텍스트 전처리\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# 데이터 전처리 적용\n",
    "train_df['dialogue_preprocessed'] = train_df['dialogue'].apply(preprocess_dialogue)\n",
    "train_df['summary_preprocessed'] = train_df['summary'].apply(preprocess_summary)\n",
    "\n",
    "dev_df['dialogue_preprocessed'] = dev_df['dialogue'].apply(preprocess_dialogue)\n",
    "dev_df['summary_preprocessed'] = dev_df['summary'].apply(preprocess_summary)\n",
    "\n",
    "test_df['dialogue_preprocessed'] = test_df['dialogue'].apply(preprocess_dialogue)\n",
    "\n",
    "print(f\"전처리 완료!\")\n",
    "print(f\"Sample preprocessed dialogue (first 200 chars):\")\n",
    "print(train_df['dialogue_preprocessed'].iloc[0][:200])\n",
    "logger.write(\"Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset 클래스 정의\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DialogueSummaryDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_len=512, max_target_len=128, is_test=False):\n",
    "        \"\"\"\n",
    "        대화 요약 데이터셋\n",
    "        \n",
    "        Args:\n",
    "            dataframe: 데이터프레임\n",
    "            tokenizer: 토크나이저\n",
    "            max_input_len: 최대 입력 길이\n",
    "            max_target_len: 최대 타겟 길이\n",
    "            is_test: 테스트 모드 여부\n",
    "        \"\"\"\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # 입력 텍스트\n",
    "        dialogue = row['dialogue_preprocessed']\n",
    "        \n",
    "        # 입력 토큰화\n",
    "        inputs = self.tokenizer(\n",
    "            dialogue,\n",
    "            max_length=self.max_input_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # 테스트 모드가 아닌 경우 타겟도 처리\n",
    "        if not self.is_test:\n",
    "            summary = row['summary_preprocessed']\n",
    "            \n",
    "            # 타겟 토큰화\n",
    "            targets = self.tokenizer(\n",
    "                summary,\n",
    "                max_length=self.max_target_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'labels': targets['input_ids'].squeeze()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': inputs['input_ids'].squeeze(),\n",
    "                'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "                'idx': idx\n",
    "            }\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = DialogueSummaryDataset(\n",
    "    train_df, \n",
    "    tokenizer, \n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length']\n",
    ")\n",
    "\n",
    "val_dataset = DialogueSummaryDataset(\n",
    "    dev_df,\n",
    "    tokenizer,\n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length']\n",
    ")\n",
    "\n",
    "test_dataset = DialogueSummaryDataset(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    max_input_len=config['model']['max_input_length'],\n",
    "    max_target_len=config['model']['max_target_length'],\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "logger.write(f\"Dataset created - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Dataset shapes:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Val: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "logger.write(f\"Using device: {device}\")\n",
    "\n",
    "# ROUGE 평가 함수\n",
    "def compute_rouge_scores(predictions, references):\n",
    "    \"\"\"ROUGE 점수 계산\"\"\"\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # 빈 문자열 처리\n",
    "    predictions = [p if p else \"empty\" for p in predictions]\n",
    "    references = [r if r else \"empty\" for r in references]\n",
    "    \n",
    "    try:\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        return {\n",
    "            'rouge-1': scores['rouge-1']['f'],\n",
    "            'rouge-2': scores['rouge-2']['f'],\n",
    "            'rouge-l': scores['rouge-l']['f']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.write(f\"Error computing ROUGE: {e}\")\n",
    "        return {'rouge-1': 0, 'rouge-2': 0, 'rouge-l': 0}\n",
    "\n",
    "# 학습 함수\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    \"\"\"한 에폭 학습\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # 데이터를 디바이스로 이동\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # 옵티마이저 스텝\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 프로그레스 바 업데이트\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # WandB 로깅\n",
    "        wandb.log({\n",
    "            'train_loss': loss.item(),\n",
    "            'learning_rate': scheduler.get_last_lr()[0]\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# 검증 함수\n",
    "def evaluate(model, data_loader, tokenizer, device, num_samples=None):\n",
    "    \"\"\"모델 평가\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Evaluating')\n",
    "        \n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            if num_samples and i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Loss 계산\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # 예측 생성 - config 키 수정\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=config['model']['max_target_length'],\n",
    "                num_beams=config['evaluation']['num_beams'],  # config 키 수정\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=config['evaluation']['no_repeat_ngram_size']\n",
    "            )\n",
    "            \n",
    "            # 디코딩\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            references.extend(refs)\n",
    "    \n",
    "    # ROUGE 점수 계산\n",
    "    rouge_scores = compute_rouge_scores(predictions, references)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return avg_loss, rouge_scores, predictions[:5]  # 샘플 예측 반환\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 및 스케줄러 설정\n",
    "# config 값들을 안전하게 가져오기\n",
    "num_epochs = config['training'].get('num_epochs', config['training'].get('epochs', 3))\n",
    "learning_rate = config['training']['learning_rate']\n",
    "# learning_rate가 문자열인 경우 float로 변환\n",
    "if isinstance(learning_rate, str):\n",
    "    learning_rate = float(learning_rate)\n",
    "    print(f\"Learning rate converted from string to float: {learning_rate}\")\n",
    "\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,  # 이미 float로 변환됨\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(num_training_steps * config['training']['warmup_ratio']),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "logger.write(f\"Optimizer and scheduler initialized\")\n",
    "logger.write(f\"Learning rate: {learning_rate}\")\n",
    "logger.write(f\"Total training steps: {num_training_steps}\")\n",
    "logger.write(f\"Warmup steps: {int(num_training_steps * config['training']['warmup_ratio'])}\")\n",
    "\n",
    "# 학습 기록 저장\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'rouge_1': [],\n",
    "    'rouge_2': [],\n",
    "    'rouge_l': []\n",
    "}\n",
    "\n",
    "# Early Stopping 설정\n",
    "best_rouge_l = 0\n",
    "patience = config['training']['early_stopping_patience']\n",
    "patience_counter = 0\n",
    "\n",
    "# 모델 저장 경로 - config의 경로 사용\n",
    "model_dir = get_path(config['paths']['output_dir'])\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_model_path = model_dir / 'best_model.pt'\n",
    "\n",
    "logger.write(\"=\" * 50)\n",
    "logger.write(\"Starting training...\")\n",
    "logger.write(\"=\" * 50)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    logger.write(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    logger.write(\"-\" * 30)\n",
    "    \n",
    "    # 학습\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    logger.write(f\"Average training loss: {train_loss:.4f}\")\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # 검증\n",
    "    val_loss, rouge_scores, sample_preds = evaluate(model, val_loader, tokenizer, device)\n",
    "    \n",
    "    logger.write(f\"Validation loss: {val_loss:.4f}\")\n",
    "    logger.write(f\"ROUGE-1 F1: {rouge_scores['rouge-1']:.4f}\")\n",
    "    logger.write(f\"ROUGE-2 F1: {rouge_scores['rouge-2']:.4f}\")\n",
    "    logger.write(f\"ROUGE-L F1: {rouge_scores['rouge-l']:.4f}\")\n",
    "    \n",
    "    # 학습 기록 저장\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['rouge_1'].append(rouge_scores['rouge-1'])\n",
    "    training_history['rouge_2'].append(rouge_scores['rouge-2'])\n",
    "    training_history['rouge_l'].append(rouge_scores['rouge-l'])\n",
    "    \n",
    "    # WandB 로깅\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss_epoch': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'rouge_1': rouge_scores['rouge-1'],\n",
    "        'rouge_2': rouge_scores['rouge-2'],\n",
    "        'rouge_l': rouge_scores['rouge-l']\n",
    "    })\n",
    "    \n",
    "    # 샘플 예측 출력\n",
    "    logger.write(\"\\nSample predictions:\")\n",
    "    for i, pred in enumerate(sample_preds[:2]):\n",
    "        logger.write(f\"  Sample {i+1}: {pred[:100]}...\")\n",
    "    \n",
    "    # Best model 저장\n",
    "    if rouge_scores['rouge-l'] > best_rouge_l:\n",
    "        best_rouge_l = rouge_scores['rouge-l']\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'rouge_scores': rouge_scores,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        logger.write(f\"✓ New best model saved! (ROUGE-L: {best_rouge_l:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            logger.write(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # 메모리 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "logger.write(\"\\n\" + \"=\" * 50)\n",
    "logger.write(f\"Training completed!\")\n",
    "logger.write(f\"Best ROUGE-L: {best_rouge_l:.4f}\")\n",
    "logger.write(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 예측 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델 로드\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "logger.write(f\"Best model loaded from epoch {checkpoint['epoch'] + 1}\")\n",
    "logger.write(f\"Best ROUGE scores: {checkpoint['rouge_scores']}\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "def generate_predictions(model, data_loader, tokenizer, device):\n",
    "    \"\"\"테스트 데이터에 대한 예측 생성\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Generating predictions')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            indices = batch['idx']\n",
    "            \n",
    "            # 예측 생성\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=config['inference']['max_length'],\n",
    "                num_beams=config['inference']['num_beams'],\n",
    "                early_stopping=config['inference']['early_stopping'],\n",
    "                no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                length_penalty=config['inference']['length_penalty'],\n",
    "                temperature=config['inference']['temperature']\n",
    "            )\n",
    "            \n",
    "            # 디코딩\n",
    "            predictions = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_indices.extend(indices.tolist())\n",
    "    \n",
    "    # 인덱스 순서대로 정렬\n",
    "    sorted_predictions = [pred for _, pred in sorted(zip(all_indices, all_predictions))]\n",
    "    \n",
    "    return sorted_predictions\n",
    "\n",
    "# 예측 수행\n",
    "logger.write(\"\\nGenerating predictions for test set...\")\n",
    "test_predictions = generate_predictions(model, test_loader, tokenizer, device)\n",
    "logger.write(f\"Generated {len(test_predictions)} predictions\")\n",
    "\n",
    "# 샘플 출력\n",
    "print(\"\\nSample test predictions:\")\n",
    "for i in range(min(3, len(test_predictions))):\n",
    "    print(f\"Test {i+1}: {test_predictions[i][:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "submission_df = pd.DataFrame({\n",
    "    'fname': test_df['fname'],\n",
    "    'summary': test_predictions\n",
    "})\n",
    "\n",
    "# 제출 파일 저장 - config의 경로 사용\n",
    "submission_dir = get_path(config['paths']['submission_dir'])\n",
    "submission_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "submission_filename = f'baseline_submission_{timestamp}.csv'\n",
    "submission_path = submission_dir / submission_filename\n",
    "\n",
    "# index=True로 설정하여 인덱스를 포함시킴\n",
    "submission_df.to_csv(submission_path, index=True, encoding='utf-8')  # index=False -> index=True로 변경\n",
    "logger.write(f\"\\nSubmission file saved: {submission_path}\")\n",
    "\n",
    "# 제출 파일 확인\n",
    "print(f\"\\nSubmission file created: {submission_filename}\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst 3 submissions:\")\n",
    "print(submission_df.head(3))\n",
    "\n",
    "# 최종 요약 통계\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BASELINE EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Best ROUGE-L: {best_rouge_l:.4f}\")\n",
    "print(f\"Training epochs: {len(training_history['train_loss'])}\")\n",
    "print(f\"Final train loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final val loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Submission file: {submission_filename}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# WandB 실험 종료\n",
    "wandb.finish()\n",
    "\n",
    "logger.write(\"\\n✅ Baseline experiment completed successfully!\")\n",
    "logger.write(f\"Log file: {log_dir / 'baseline.log'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
