[2025-10-10 09:06:07] ==================================================
[2025-10-10 09:06:07] Multi-Model Ensemble Experiment
[2025-10-10 09:06:07] Timestamp: 20251010_090607
[2025-10-10 09:06:07] Models: ['solar', 'polyglot', 'kullm', 'kobart', 'koalpaca']
[2025-10-10 09:06:07] Ensemble Method: weighted_average
[2025-10-10 09:06:07] ==================================================
[2025-10-10 09:06:07] 
TTA Configuration:
[2025-10-10 09:06:07]   - Augmentations: 3
[2025-10-10 09:06:07]   - Aggregation: mean
[2025-10-10 09:06:07]   - paraphrase: enabled
[2025-10-10 09:06:07]   - reorder: enabled
[2025-10-10 09:06:07] 
GPU: NVIDIA GeForce RTX 4090
[2025-10-10 09:06:07] GPU Tier: LOW
[2025-10-10 09:06:07] Will clear GPU cache between models
[2025-10-10 09:06:07] Weight visualization saved to /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/logs/multi_model/visualizations
[2025-10-10 09:06:07] 
Solar API Comparison Settings:
[2025-10-10 09:06:07]   - API Key: up_rMJWNzz...
[2025-10-10 09:06:07]   - Use as baseline: True
[2025-10-10 09:06:07]   - Include in ensemble: False
[2025-10-10 09:06:07] 
Optuna Weight Optimization:
[2025-10-10 09:06:07]   - Trials: 50
[2025-10-10 09:06:07]   - Study: ensemble_weight_optimization
[2025-10-10 09:06:07]   - Metric: rouge_l
[2025-10-10 09:06:07] 
=== Data Loading ===
[2025-10-10 09:06:07] Loading data from config paths:
[2025-10-10 09:06:07]   - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv
[2025-10-10 09:06:07]   - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv
[2025-10-10 09:06:07]   - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv
[2025-10-10 09:06:07] 
Data loaded successfully!
[2025-10-10 09:06:07]   - Train samples: 12457
[2025-10-10 09:06:07]   - Dev samples: 499
[2025-10-10 09:06:07]   - Test samples: 499
[2025-10-10 09:06:07] 
=== solar Model ===
[2025-10-10 09:06:07]   - Model: upstage/SOLAR-10.7B-Instruct-v1.0
[2025-10-10 09:06:07]   - Weight: 0.3
[2025-10-10 09:06:07]   - LoRA: r=16, alpha=32
[2025-10-10 09:06:07] 
=== polyglot Model ===
[2025-10-10 09:06:07]   - Model: EleutherAI/polyglot-ko-12.8b
[2025-10-10 09:06:07]   - Weight: 0.25
[2025-10-10 09:06:07]   - LoRA: r=8, alpha=16
[2025-10-10 09:06:07] 
=== kullm Model ===
[2025-10-10 09:06:07]   - Model: nlpai-lab/kullm-v2
[2025-10-10 09:06:07]   - Weight: 0.2
[2025-10-10 09:06:07]   - LoRA: r=8, alpha=16
[2025-10-10 09:06:07] 
=== kobart Model ===
[2025-10-10 09:06:07]   - Model: digit82/kobart-summarization
[2025-10-10 09:06:07]   - Weight: 0.15
[2025-10-10 09:06:07] 
=== koalpaca Model ===
[2025-10-10 09:06:07]   - Model: beomi/KoAlpaca-Polyglot-12.8B
[2025-10-10 09:06:07]   - Weight: 0.1
[2025-10-10 09:06:07]   - LoRA: r=8, alpha=16
[2025-10-10 09:06:07] 
=== TTA Implementation ===
[2025-10-10 09:06:07] Paraphrase augmentation enabled
[2025-10-10 09:06:07]   - Model: lcw99/t5-base-korean-paraphrase
[2025-10-10 09:06:07]   - Variants: 2
