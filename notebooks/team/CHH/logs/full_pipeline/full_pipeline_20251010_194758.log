[2025-10-10 19:47:58] ==================================================
[2025-10-10 19:47:58] FULL PIPELINE EXECUTION STARTED
[2025-10-10 19:47:58] Timestamp: 20251010_194758
[2025-10-10 19:47:58] Config: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/configs/config_full_pipeline.yaml
[2025-10-10 19:47:58] ==================================================
[2025-10-10 19:47:58] GPU Tier: LOW
[2025-10-10 19:47:58] Auto-optimization enabled
[2025-10-10 19:47:58] Finding optimal batch size...
[2025-10-10 19:47:58] [data_quality_check] Status: running
[2025-10-10 19:47:58] 
=== Data Quality Check ===
[2025-10-10 19:47:58] Loading data from config paths:
[2025-10-10 19:47:58]   - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv
[2025-10-10 19:47:58]   - Dev: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/dev.csv
[2025-10-10 19:47:58]   - Test: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/test.csv
[2025-10-10 19:47:58] ‚úÖ Loaded 12457 training samples
[2025-10-10 19:47:58] ‚úÖ Loaded 499 dev samples
[2025-10-10 19:47:58] ‚úÖ Loaded 499 test samples
[2025-10-10 19:47:58] Null values - Train: 0, Dev: 0, Test: 0
[2025-10-10 19:47:58] Duplicate rows in training data: 0
[2025-10-10 19:47:58] ‚úÖ Data loading completed successfully!
[2025-10-10 19:47:58] [data_quality_check] Status: completed
[2025-10-10 19:47:58] 
=== Comprehensive Data Quality Validation ===
[2025-10-10 19:47:58] 
üìä Data Quality Report:
[2025-10-10 19:47:58] 
Structural Validation:
[2025-10-10 19:47:58]   - Train shape: (12457, 4)
[2025-10-10 19:47:58]   - Dev shape: (499, 4)
[2025-10-10 19:47:58]   - Test shape: (499, 2)
[2025-10-10 19:47:58]   - Column match: True
[2025-10-10 19:47:58] 
Text Quality:
[2025-10-10 19:47:58]   - Avg dialogue length: 406.1
[2025-10-10 19:47:58]   - Compression ratio: 23.23%
[2025-10-10 19:47:58]   - Encoding issues: 0
[2025-10-10 19:47:58]   - Special chars: 12455
[2025-10-10 19:47:58] 
Label Distribution:
[2025-10-10 19:47:58]   - Unique topics: 9235
[2025-10-10 19:47:58]   - Imbalance ratio: 130.00
[2025-10-10 19:47:58] 
Outlier Detection:
[2025-10-10 19:47:58]   - Outlier count: 355
[2025-10-10 19:47:58]   - Outlier ratio: 2.85%
[2025-10-10 19:47:58] 
üìã Recommendations:
[2025-10-10 19:47:58]   ‚úì Clean special characters from text
[2025-10-10 19:47:58]   ‚úì Consider data augmentation for underrepresented topics
[2025-10-10 19:47:58] ‚ö†Ô∏è Error during data validation: You must call wandb.init() before wandb.log()
[2025-10-10 19:47:58]    Skipping detailed validation. Please check data loading in cell 7.
[2025-10-10 19:47:58] Visualizations will be saved to: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/logs/full_pipeline/visualizations
[2025-10-10 19:48:01] WandB initialized for full pipeline tracking
[2025-10-10 19:48:01] [data_preprocessing] Status: running
[2025-10-10 19:48:01] 
=== Data Preprocessing ===
[2025-10-10 19:48:01] Preprocessed 12457 training samples
[2025-10-10 19:48:01] Preprocessed 499 dev samples
[2025-10-10 19:48:01] Preprocessed 499 test samples
[2025-10-10 19:48:01] 
Text Length Statistics:
[2025-10-10 19:48:01]   Dialogue - Mean: 347.3, Max: 1952
[2025-10-10 19:48:01]   Summary - Mean: 85.8, Max: 376
[2025-10-10 19:48:01] [data_preprocessing] Status: completed
[2025-10-10 19:48:01] [hyperparameter_optimization] Status: running
[2025-10-10 19:48:01] 
======================================================================
[2025-10-10 19:48:01] üéØ HYPERPARAMETER OPTIMIZATION STAGE
[2025-10-10 19:48:01] ======================================================================
[2025-10-10 19:48:01] ‚úÖ Optimization ENABLED with 100 trials
[2025-10-10 19:48:01] 
============================================================
[2025-10-10 19:48:01] üéØ OPTUNA HYPERPARAMETER OPTIMIZATION STARTING
[2025-10-10 19:48:01] ============================================================
[2025-10-10 19:48:01] Number of trials: 100
[2025-10-10 19:48:01] Optimization metric: rouge_l
[2025-10-10 19:48:01] 
üöÄ Starting optimization...
[2025-10-10 19:48:01] 
Trial 0: {'learning_rate': 5.6115164153345e-05, 'batch_size': 4, 'lora_r': 12, 'lora_alpha': 24, 'num_beams': 2, 'temperature': 0.8795585311974417, 'warmup_ratio': 0.12022300234864176, 'weight_decay': 0.07080725777960455, 'top_p': 0.8041168988591605}
[2025-10-10 19:48:01] 
Trial 1: {'learning_rate': 0.0008706020878304854, 'batch_size': 4, 'lora_r': 12, 'lora_alpha': 40, 'num_beams': 5, 'temperature': 0.48875051677790415, 'warmup_ratio': 0.058245828039608386, 'weight_decay': 0.06118528947223795, 'top_p': 0.8278987721304084}
[2025-10-10 19:48:01] 
Trial 2: {'learning_rate': 3.8396292998041685e-05, 'batch_size': 16, 'lora_r': 16, 'lora_alpha': 72, 'num_beams': 6, 'temperature': 0.14180537144799796, 'warmup_ratio': 0.12150897038028768, 'weight_decay': 0.017052412368729154, 'top_p': 0.813010318597056}
[2025-10-10 19:48:01] 
Trial 3: {'learning_rate': 0.000790261954970823, 'batch_size': 4, 'lora_r': 8, 'lora_alpha': 88, 'num_beams': 5, 'temperature': 0.20983441136030095, 'warmup_ratio': 0.09903538202225404, 'weight_decay': 0.0034388521115218396, 'top_p': 0.9818640804157565}
[2025-10-10 19:48:01] 
Trial 4: {'learning_rate': 3.292759134423613e-05, 'batch_size': 4, 'lora_r': 36, 'lora_alpha': 24, 'num_beams': 8, 'temperature': 0.7976195410250031, 'warmup_ratio': 0.18789978831283782, 'weight_decay': 0.08948273504276488, 'top_p': 0.919579995762217}
[2025-10-10 19:48:01] 
Trial 5: {'learning_rate': 0.0006978281265126031, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 56, 'num_beams': 3, 'temperature': 0.8458637582367364, 'warmup_ratio': 0.07135066533871785, 'weight_decay': 0.02809345096873808, 'top_p': 0.9085392166316497}
[2025-10-10 19:48:01] 
Trial 6: {'learning_rate': 1.913588048769229e-05, 'batch_size': 16, 'lora_r': 52, 'lora_alpha': 32, 'num_beams': 2, 'temperature': 0.8339152856093507, 'warmup_ratio': 0.14137146876952342, 'weight_decay': 0.07290071680409874, 'top_p': 0.9542540693371891}
[2025-10-10 19:48:01] 
Trial 7: {'learning_rate': 1.4063366777718176e-05, 'batch_size': 16, 'lora_r': 40, 'lora_alpha': 48, 'num_beams': 2, 'temperature': 0.379884089544096, 'warmup_ratio': 0.06503666440534941, 'weight_decay': 0.0729606178338064, 'top_p': 0.9275114942710426}
[2025-10-10 19:48:01] 
Trial 8: {'learning_rate': 0.000594874681321977, 'batch_size': 16, 'lora_r': 52, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.5444160367279517, 'warmup_ratio': 0.10454656587639882, 'weight_decay': 0.042754101835854964, 'top_p': 0.8050838253488191}
[2025-10-10 19:48:01] 
Trial 9: {'learning_rate': 1.6435497475111308e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 120, 'num_beams': 3, 'temperature': 0.4693446307320668, 'warmup_ratio': 0.15111022770860974, 'weight_decay': 0.022879816549162248, 'top_p': 0.8153959819657587}
[2025-10-10 19:48:01] 
Trial 10: {'learning_rate': 0.0002509538254778771, 'batch_size': 8, 'lora_r': 64, 'lora_alpha': 128, 'num_beams': 4, 'temperature': 0.37050834074441147, 'warmup_ratio': 0.0031189599316912286, 'weight_decay': 0.03924528921026325, 'top_p': 0.8669590352446472}
[2025-10-10 19:48:01] 
Trial 11: {'learning_rate': 0.0001268908193314921, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 112, 'num_beams': 4, 'temperature': 0.6853920983107693, 'warmup_ratio': 0.18218996750099392, 'weight_decay': 0.02884763734703571, 'top_p': 0.870552883088561}
[2025-10-10 19:48:01] 
Trial 12: {'learning_rate': 0.0001366342322953994, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 128, 'num_beams': 4, 'temperature': 0.6804495294564787, 'warmup_ratio': 0.19775497252335106, 'weight_decay': 0.017513226479741115, 'top_p': 0.8638819469271722}
[2025-10-10 19:48:01] 
Trial 13: {'learning_rate': 0.00012774135799436964, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 104, 'num_beams': 4, 'temperature': 0.673026335116201, 'warmup_ratio': 0.16191281769380567, 'weight_decay': 0.029365930106516, 'top_p': 0.8557360060752296}
[2025-10-10 19:48:01] 
Trial 14: {'learning_rate': 0.0002873243992774126, 'batch_size': 8, 'lora_r': 24, 'lora_alpha': 104, 'num_beams': 3, 'temperature': 0.6861051379380694, 'warmup_ratio': 0.16274515950801005, 'weight_decay': 0.00942912898249821, 'top_p': 0.8819415274615143}
[2025-10-10 19:48:01] 
Trial 15: {'learning_rate': 7.098701732564448e-05, 'batch_size': 8, 'lora_r': 28, 'lora_alpha': 112, 'num_beams': 3, 'temperature': 0.9844175411000242, 'warmup_ratio': 0.1664353605372986, 'weight_decay': 0.054539866073407044, 'top_p': 0.8412652693649235}
[2025-10-10 19:48:01] 
Trial 16: {'learning_rate': 1.0220690547060621e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.36159504454994323, 'warmup_ratio': 0.1791812574800705, 'weight_decay': 0.030577753086104383, 'top_p': 0.8858646544491982}
[2025-10-10 19:48:01] 
Trial 17: {'learning_rate': 1.0431776659459344e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.31165880153953723, 'warmup_ratio': 0.14872829288484227, 'weight_decay': 0.04382305308818561, 'top_p': 0.8951771818787657}
[2025-10-10 19:48:01] 
Trial 18: {'learning_rate': 1.0475949546866002e-05, 'batch_size': 8, 'lora_r': 64, 'lora_alpha': 8, 'num_beams': 6, 'temperature': 0.267790233806356, 'warmup_ratio': 0.1305769338611774, 'weight_decay': 0.04333899885897683, 'top_p': 0.8961230372727941}
[2025-10-10 19:48:01] 
Trial 19: {'learning_rate': 2.6581774791657137e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.32453958500044744, 'warmup_ratio': 0.17794367649964998, 'weight_decay': 0.09844368998597391, 'top_p': 0.9406794405888513}
[2025-10-10 19:48:01] 
Trial 20: {'learning_rate': 2.688218543311814e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 88, 'num_beams': 8, 'temperature': 0.3978502787262694, 'warmup_ratio': 0.17884578788758937, 'weight_decay': 0.09813130867582937, 'top_p': 0.9433438152801837}
[2025-10-10 19:48:01] 
Trial 21: {'learning_rate': 1.0019995846319764e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.2761266716998912, 'warmup_ratio': 0.19782125710027793, 'weight_decay': 0.052289588343975915, 'top_p': 0.893962966855054}
[2025-10-10 19:48:01] 
Trial 22: {'learning_rate': 2.2025631634501318e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.16215469586066458, 'warmup_ratio': 0.19621885998780558, 'weight_decay': 0.08063270091995121, 'top_p': 0.9725294353685165}
[2025-10-10 19:48:01] 
Trial 23: {'learning_rate': 1.4753664108835793e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 64, 'num_beams': 7, 'temperature': 0.26707782768266963, 'warmup_ratio': 0.17669767386567298, 'weight_decay': 0.05734621777118522, 'top_p': 0.9392767360788086}
[2025-10-10 19:48:01] 
Trial 24: {'learning_rate': 4.3882857859821595e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 56, 'num_beams': 7, 'temperature': 0.21905184386159238, 'warmup_ratio': 0.17503348366700297, 'weight_decay': 0.09939255406461125, 'top_p': 0.9507278288981821}
[2025-10-10 19:48:01] 
Trial 25: {'learning_rate': 2.452510912989695e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 64, 'num_beams': 6, 'temperature': 0.10124870877428427, 'warmup_ratio': 0.002779511635803353, 'weight_decay': 0.060950819046436705, 'top_p': 0.9943964868563263}
[2025-10-10 19:48:01] 
Trial 26: {'learning_rate': 1.4654113417205898e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 96, 'num_beams': 8, 'temperature': 0.42784227271692665, 'warmup_ratio': 0.02530453787424712, 'weight_decay': 0.08680986930306499, 'top_p': 0.9355690503791281}
[2025-10-10 19:48:01] 
Trial 27: {'learning_rate': 7.369042628989038e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.3363850357940923, 'warmup_ratio': 0.13669467516643594, 'weight_decay': 0.03392475213927637, 'top_p': 0.9140949701802036}
[2025-10-10 19:48:01] 
Trial 28: {'learning_rate': 1.438331687229236e-05, 'batch_size': 4, 'lora_r': 60, 'lora_alpha': 64, 'num_beams': 6, 'temperature': 0.5835337485261631, 'warmup_ratio': 0.15861374370719616, 'weight_decay': 0.06279118593928239, 'top_p': 0.9540189015281553}
[2025-10-10 19:48:01] 
Trial 29: {'learning_rate': 5.5893987323535186e-05, 'batch_size': 16, 'lora_r': 48, 'lora_alpha': 80, 'num_beams': 8, 'temperature': 0.23625132813375413, 'warmup_ratio': 0.11095690856366275, 'weight_decay': 0.08398384561816133, 'top_p': 0.9720547348259865}
[2025-10-10 19:48:01] 
Trial 30: {'learning_rate': 3.2840645240699206e-05, 'batch_size': 4, 'lora_r': 32, 'lora_alpha': 56, 'num_beams': 5, 'temperature': 0.5352224317503306, 'warmup_ratio': 0.08206244374157927, 'weight_decay': 0.06798303838142448, 'top_p': 0.9338680752958443}
[2025-10-10 19:48:01] 
Trial 31: {'learning_rate': 1.0868588895036043e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 96, 'num_beams': 7, 'temperature': 0.28864287794271093, 'warmup_ratio': 0.1996993375098841, 'weight_decay': 0.04768716160587092, 'top_p': 0.8811002483230744}
[2025-10-10 19:48:01] 
Trial 32: {'learning_rate': 1.9079342372205603e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.4549511428882156, 'warmup_ratio': 0.1739298825060424, 'weight_decay': 0.054553360389188364, 'top_p': 0.9061135854331238}
[2025-10-10 19:48:01] 
Trial 33: {'learning_rate': 1.3022310963804526e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 96, 'num_beams': 6, 'temperature': 0.17566473730121754, 'warmup_ratio': 0.18484334525476098, 'weight_decay': 0.05702982699078547, 'top_p': 0.8878062966159581}
[2025-10-10 19:48:01] 
Trial 34: {'learning_rate': 2.6696491351455477e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.3223089737297057, 'warmup_ratio': 0.18806562642663407, 'weight_decay': 0.03717142165239512, 'top_p': 0.9212948816355899}
[2025-10-10 19:48:01] 
Trial 35: {'learning_rate': 1.8615599587357154e-05, 'batch_size': 4, 'lora_r': 4, 'lora_alpha': 104, 'num_beams': 5, 'temperature': 0.25506716585050265, 'warmup_ratio': 0.12583946624140113, 'weight_decay': 0.07809331303690882, 'top_p': 0.8507101441873117}
[2025-10-10 19:48:01] 
Trial 36: {'learning_rate': 1.0247773294801572e-05, 'batch_size': 8, 'lora_r': 60, 'lora_alpha': 40, 'num_beams': 8, 'temperature': 0.18021716102376167, 'warmup_ratio': 0.17073527070018765, 'weight_decay': 0.09334543532103286, 'top_p': 0.9007783347995721}
[2025-10-10 19:48:01] 
Trial 37: {'learning_rate': 4.0345316324417277e-05, 'batch_size': 16, 'lora_r': 36, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.35183472953709627, 'warmup_ratio': 0.1505553670099571, 'weight_decay': 0.050086591103181685, 'top_p': 0.9708343266480604}
[2025-10-10 19:48:01] 
Trial 38: {'learning_rate': 1.3094608221571627e-05, 'batch_size': 4, 'lora_r': 44, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.41821883934777804, 'warmup_ratio': 0.04438053154799302, 'weight_decay': 0.009674125040046049, 'top_p': 0.9200120739150203}
[2025-10-10 19:48:01] 
Trial 39: {'learning_rate': 3.2304064356010654e-05, 'batch_size': 8, 'lora_r': 16, 'lora_alpha': 48, 'num_beams': 6, 'temperature': 0.10268193070353585, 'warmup_ratio': 0.19115330580279258, 'weight_decay': 0.06701795215989134, 'top_p': 0.9399430871912684}
[2025-10-10 19:48:01] 
Trial 40: {'learning_rate': 2.0499303387076893e-05, 'batch_size': 16, 'lora_r': 52, 'lora_alpha': 96, 'num_beams': 8, 'temperature': 0.4915164192986905, 'warmup_ratio': 0.14534572081633784, 'weight_decay': 0.023404315946808155, 'top_p': 0.9618728696183664}
[2025-10-10 19:48:01] 
Trial 41: {'learning_rate': 2.276100127809706e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.16529115414256013, 'warmup_ratio': 0.19883411136869739, 'weight_decay': 0.07902111408083178, 'top_p': 0.9943290552978787}
[2025-10-10 19:48:01] 
Trial 42: {'learning_rate': 1.7223971161201263e-05, 'batch_size': 8, 'lora_r': 60, 'lora_alpha': 64, 'num_beams': 7, 'temperature': 0.22265201427462858, 'warmup_ratio': 0.19170298296471514, 'weight_decay': 0.09339763150018476, 'top_p': 0.9817238714006381}
[2025-10-10 19:48:01] 
Trial 43: {'learning_rate': 1.2291420918079572e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.2815653428484948, 'warmup_ratio': 0.18075723568334232, 'weight_decay': 0.07982779540868601, 'top_p': 0.9681755603177403}
[2025-10-10 19:48:01] 
Trial 44: {'learning_rate': 1.6147610437346172e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 80, 'num_beams': 8, 'temperature': 0.15449605765915575, 'warmup_ratio': 0.08956036286548051, 'weight_decay': 0.07362506042898428, 'top_p': 0.9279334476435115}
[2025-10-10 19:48:01] 
Trial 45: {'learning_rate': 2.1535907879293594e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.1972261307626211, 'warmup_ratio': 0.15793011164272375, 'weight_decay': 0.04986430469169311, 'top_p': 0.980576826740819}
[2025-10-10 19:48:01] 
Trial 46: {'learning_rate': 2.9793884475798456e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 72, 'num_beams': 6, 'temperature': 0.3746259991827653, 'warmup_ratio': 0.1590814375633413, 'weight_decay': 0.0501914264923425, 'top_p': 0.8732915588244238}
[2025-10-10 19:48:01] 
Trial 47: {'learning_rate': 1.58022179004621e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 56, 'num_beams': 6, 'temperature': 0.30283640008912555, 'warmup_ratio': 0.11458275136605992, 'weight_decay': 0.03506900971621736, 'top_p': 0.9096260604210114}
[2025-10-10 19:48:01] 
Trial 48: {'learning_rate': 5.381111152768832e-05, 'batch_size': 16, 'lora_r': 32, 'lora_alpha': 48, 'num_beams': 5, 'temperature': 0.3206584559065433, 'warmup_ratio': 0.11501476413525163, 'weight_decay': 0.034123776445133744, 'top_p': 0.9096017087620255}
[2025-10-10 19:48:01] 
Trial 49: {'learning_rate': 0.000205080219368981, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 56, 'num_beams': 6, 'temperature': 0.21525657062018538, 'warmup_ratio': 0.09916332333886362, 'weight_decay': 0.020245293218051012, 'top_p': 0.9821674333867153}
[2025-10-10 19:48:01] 
Trial 50: {'learning_rate': 3.882689727908674e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 64, 'num_beams': 6, 'temperature': 0.5962284196744464, 'warmup_ratio': 0.13616552509056828, 'weight_decay': 0.03936386061078691, 'top_p': 0.9466733166013982}
[2025-10-10 19:48:01] 
Trial 51: {'learning_rate': 1.2228966578618948e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.27519923083260445, 'warmup_ratio': 0.16862962842122023, 'weight_decay': 0.026777874270692684, 'top_p': 0.888296941850689}
[2025-10-10 19:48:01] 
Trial 52: {'learning_rate': 1.728619201564104e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 48, 'num_beams': 5, 'temperature': 0.3035925691458784, 'warmup_ratio': 0.15627121499014057, 'weight_decay': 0.04664627354350816, 'top_p': 0.9277026896216644}
[2025-10-10 19:48:01] 
Trial 53: {'learning_rate': 1.5399763366424013e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 32, 'num_beams': 7, 'temperature': 0.3583105713774832, 'warmup_ratio': 0.18085612145722743, 'weight_decay': 0.058104875726261856, 'top_p': 0.9009032108610238}
[2025-10-10 19:48:01] 
Trial 54: {'learning_rate': 1.0138120160969784e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.25032135060929195, 'warmup_ratio': 0.16990204423368407, 'weight_decay': 0.032114519612867334, 'top_p': 0.9601618743829659}
[2025-10-10 19:48:01] 
Trial 55: {'learning_rate': 1.2125711083178009e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 56, 'num_beams': 7, 'temperature': 0.19992631514026968, 'warmup_ratio': 0.18798056915584777, 'weight_decay': 0.012318104517319503, 'top_p': 0.8763931048468517}
[2025-10-10 19:48:01] 
Trial 56: {'learning_rate': 2.2846812601793354e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 112, 'num_beams': 8, 'temperature': 0.1236433233577641, 'warmup_ratio': 0.1785343973141868, 'weight_decay': 0.03723180729782461, 'top_p': 0.9162741108145406}
[2025-10-10 19:48:01] 
Trial 57: {'learning_rate': 1.5172166292192325e-05, 'batch_size': 4, 'lora_r': 44, 'lora_alpha': 40, 'num_beams': 7, 'temperature': 0.4023023736846225, 'warmup_ratio': 0.16517989707002068, 'weight_decay': 0.04156033710871458, 'top_p': 0.8614623060591287}
[2025-10-10 19:48:01] 
Trial 58: {'learning_rate': 0.00046780959898243686, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 96, 'num_beams': 6, 'temperature': 0.504433087666184, 'warmup_ratio': 0.1561907326487859, 'weight_decay': 0.0016883229285894266, 'top_p': 0.8915329855169429}
[2025-10-10 19:48:01] 
Trial 59: {'learning_rate': 8.881354840979176e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 104, 'num_beams': 8, 'temperature': 0.45276666807451055, 'warmup_ratio': 0.13848026062732793, 'weight_decay': 0.052119178265611084, 'top_p': 0.9103743022878698}
[2025-10-10 19:48:01] 
Trial 60: {'learning_rate': 1.8991711359412007e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 72, 'num_beams': 6, 'temperature': 0.2998391966674399, 'warmup_ratio': 0.19241281251090475, 'weight_decay': 0.062388120398682495, 'top_p': 0.9853388229015513}
[2025-10-10 19:48:01] 
Trial 61: {'learning_rate': 1.2907801135602692e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.26392571015315364, 'warmup_ratio': 0.1695377835117051, 'weight_decay': 0.024272394355623436, 'top_p': 0.8819468336639386}
[2025-10-10 19:48:01] 
Trial 62: {'learning_rate': 1.3646566664095992e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 64, 'num_beams': 7, 'temperature': 0.2508655560885898, 'warmup_ratio': 0.05387112300647154, 'weight_decay': 0.025433146235674376, 'top_p': 0.9003152404341961}
[2025-10-10 19:48:01] 
Trial 63: {'learning_rate': 1.1774223667065002e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.19007298126789818, 'warmup_ratio': 0.17386776504566998, 'weight_decay': 0.01461938917380231, 'top_p': 0.8808185353560175}
[2025-10-10 19:48:01] 
Trial 64: {'learning_rate': 0.0009841670344314273, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.35120309706628394, 'warmup_ratio': 0.18517546375322158, 'weight_decay': 0.030832624808664704, 'top_p': 0.8439547380764636}
[2025-10-10 19:48:01] 
Trial 65: {'learning_rate': 2.5243374951175355e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 8, 'num_beams': 4, 'temperature': 0.1358690405864709, 'warmup_ratio': 0.14431183476839515, 'weight_decay': 0.019151521222531318, 'top_p': 0.862954664874302}
[2025-10-10 19:48:02] 
Trial 66: {'learning_rate': 1.5199980861892907e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 56, 'num_beams': 7, 'temperature': 0.38496638067327604, 'warmup_ratio': 0.16170684431937737, 'weight_decay': 0.0065932924040066065, 'top_p': 0.8868647778007276}
[2025-10-10 19:48:02] 
Trial 67: {'learning_rate': 2.8916665618544405e-05, 'batch_size': 16, 'lora_r': 32, 'lora_alpha': 72, 'num_beams': 8, 'temperature': 0.2698798108107492, 'warmup_ratio': 0.17870371354943515, 'weight_decay': 0.04645579667299554, 'top_p': 0.8692061515560723}
[2025-10-10 19:48:02] 
Trial 68: {'learning_rate': 2.1121510712869737e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 64, 'num_beams': 5, 'temperature': 0.7354401612718519, 'warmup_ratio': 0.12191006416829075, 'weight_decay': 0.035372918959341575, 'top_p': 0.9349483462338625}
[2025-10-10 19:48:02] 
Trial 69: {'learning_rate': 1.1028272169798717e-05, 'batch_size': 4, 'lora_r': 48, 'lora_alpha': 88, 'num_beams': 6, 'temperature': 0.24611647595284186, 'warmup_ratio': 0.16729530674276644, 'weight_decay': 0.023236381016346754, 'top_p': 0.8968280744109578}
[2025-10-10 19:48:02] 
Trial 70: {'learning_rate': 4.927042568737133e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.33279498599960156, 'warmup_ratio': 0.1512487155275365, 'weight_decay': 0.041955126349492076, 'top_p': 0.9234675402921142}
[2025-10-10 19:48:02] 
Trial 71: {'learning_rate': 1.2938445729381448e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.2930818748567598, 'warmup_ratio': 0.17038068911097504, 'weight_decay': 0.030369694015950983, 'top_p': 0.88721948075297}
[2025-10-10 19:48:02] 
Trial 72: {'learning_rate': 1.724790790771967e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.9090378584741627, 'warmup_ratio': 0.1935252378826274, 'weight_decay': 0.025444489064790292, 'top_p': 0.8272639205874399}
[2025-10-10 19:48:02] 
Trial 73: {'learning_rate': 1.0001987101424243e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 56, 'num_beams': 7, 'temperature': 0.22966367800125714, 'warmup_ratio': 0.17465551970530882, 'weight_decay': 0.02721597738539809, 'top_p': 0.8764299633975399}
[2025-10-10 19:48:02] 
Trial 74: {'learning_rate': 1.3879007376231482e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 64, 'num_beams': 2, 'temperature': 0.27470355594237367, 'warmup_ratio': 0.07525130503137714, 'weight_decay': 0.06507538567870096, 'top_p': 0.9045452948371131}
[2025-10-10 19:48:02] 
Trial 75: {'learning_rate': 1.9635358682831514e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 80, 'num_beams': 8, 'temperature': 0.19786553402568785, 'warmup_ratio': 0.18443205780905275, 'weight_decay': 0.0207371596263992, 'top_p': 0.8928361693739687}
[2025-10-10 19:48:02] 
Trial 76: {'learning_rate': 1.1447318528090332e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.3240524572617882, 'warmup_ratio': 0.1319460645936094, 'weight_decay': 0.054379167508258684, 'top_p': 0.8828741385523295}
[2025-10-10 19:48:02] 
Trial 77: {'learning_rate': 1.6674131208728842e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 96, 'num_beams': 6, 'temperature': 0.42108933166995494, 'warmup_ratio': 0.10399623809390461, 'weight_decay': 0.05457660094716057, 'top_p': 0.8821984316294449}
[2025-10-10 19:48:02] 
Trial 78: {'learning_rate': 1.1847882519235564e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.3246467175026559, 'warmup_ratio': 0.12746538595104204, 'weight_decay': 0.044720472229777826, 'top_p': 0.9129689665732726}
[2025-10-10 19:48:02] 
Trial 79: {'learning_rate': 1.3951153821862687e-05, 'batch_size': 16, 'lora_r': 28, 'lora_alpha': 104, 'num_beams': 6, 'temperature': 0.34126803438591347, 'warmup_ratio': 0.15420624622016363, 'weight_decay': 0.06059530766207522, 'top_p': 0.855808665105279}
[2025-10-10 19:48:02] 
Trial 80: {'learning_rate': 1.1144912274969546e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 96, 'num_beams': 8, 'temperature': 0.21690277756532256, 'warmup_ratio': 0.1144154062575599, 'weight_decay': 0.05641857806110551, 'top_p': 0.9440507288898781}
[2025-10-10 19:48:02] 
Trial 81: {'learning_rate': 1.2368915117685135e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 80, 'num_beams': 7, 'temperature': 0.2728725454937379, 'warmup_ratio': 0.16447093856634004, 'weight_decay': 0.05264085640959055, 'top_p': 0.891750056898198}
[2025-10-10 19:48:02] 
Trial 82: {'learning_rate': 1.799009565926089e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 64, 'num_beams': 7, 'temperature': 0.3136146335806043, 'warmup_ratio': 0.13323782636044798, 'weight_decay': 0.07070421760935114, 'top_p': 0.8865403650790882}
[2025-10-10 19:48:02] 
Trial 83: {'learning_rate': 1.5100175012833899e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.3728044416887685, 'warmup_ratio': 0.08999569847801783, 'weight_decay': 0.026962233680132192, 'top_p': 0.9054715223591381}
[2025-10-10 19:48:02] 
Trial 84: {'learning_rate': 2.3478797988111304e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.3000283627051902, 'warmup_ratio': 0.17585499866794166, 'weight_decay': 0.03887994979370439, 'top_p': 0.873888227231429}
[2025-10-10 19:48:02] 
Trial 85: {'learning_rate': 1.1346997086020008e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 72, 'num_beams': 7, 'temperature': 0.24072984285633714, 'warmup_ratio': 0.14660794740830918, 'weight_decay': 0.0169844571108326, 'top_p': 0.8811259289464022}
[2025-10-10 19:48:02] 
Trial 86: {'learning_rate': 1.3284681490840258e-05, 'batch_size': 4, 'lora_r': 52, 'lora_alpha': 80, 'num_beams': 6, 'temperature': 0.27481400072421425, 'warmup_ratio': 0.10873479763055678, 'weight_decay': 0.05040903454917071, 'top_p': 0.9625520232401278}
[2025-10-10 19:48:02] 
Trial 87: {'learning_rate': 0.00015954137529739114, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 56, 'num_beams': 8, 'temperature': 0.39409685781154763, 'warmup_ratio': 0.1683553284723591, 'weight_decay': 0.03298238306688632, 'top_p': 0.8672804092255155}
[2025-10-10 19:48:02] 
Trial 88: {'learning_rate': 1.0000300958850058e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 88, 'num_beams': 7, 'temperature': 0.17391406273846993, 'warmup_ratio': 0.18861221149113222, 'weight_decay': 0.05902645604976761, 'top_p': 0.9548559452036219}
[2025-10-10 19:48:02] 
Trial 89: {'learning_rate': 2.0832274440997075e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 48, 'num_beams': 7, 'temperature': 0.35047719417745105, 'warmup_ratio': 0.19677052792979238, 'weight_decay': 0.04836257908231241, 'top_p': 0.8968783354496135}
[2025-10-10 19:48:02] 
Trial 90: {'learning_rate': 1.5877720246572917e-05, 'batch_size': 8, 'lora_r': 56, 'lora_alpha': 104, 'num_beams': 6, 'temperature': 0.25906810312098216, 'warmup_ratio': 0.1612636173410914, 'weight_decay': 0.028614135387493717, 'top_p': 0.9987224893514031}
[2025-10-10 19:48:02] 
Trial 91: {'learning_rate': 1.4526807531170059e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 32, 'num_beams': 7, 'temperature': 0.3625654596713352, 'warmup_ratio': 0.18137424646351952, 'weight_decay': 0.05850397204624286, 'top_p': 0.9036113779452}
[2025-10-10 19:48:02] 
Trial 92: {'learning_rate': 1.2298544582322887e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.29035150346745364, 'warmup_ratio': 0.18316168849961503, 'weight_decay': 0.06412647972403117, 'top_p': 0.8983672296424358}
[2025-10-10 19:48:02] 
Trial 93: {'learning_rate': 1.6606249750617458e-05, 'batch_size': 8, 'lora_r': 40, 'lora_alpha': 40, 'num_beams': 7, 'temperature': 0.3182735929038959, 'warmup_ratio': 0.174366405398617, 'weight_decay': 0.05604964595585944, 'top_p': 0.8923931588197728}
[2025-10-10 19:48:02] 
Trial 94: {'learning_rate': 1.1289379698660349e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 24, 'num_beams': 7, 'temperature': 0.22785786795725807, 'warmup_ratio': 0.14188574234263557, 'weight_decay': 0.04454905123816038, 'top_p': 0.8842831645977117}
[2025-10-10 19:48:02] 
Trial 95: {'learning_rate': 3.513419056590812e-05, 'batch_size': 8, 'lora_r': 44, 'lora_alpha': 96, 'num_beams': 8, 'temperature': 0.4463000077422233, 'warmup_ratio': 0.17851467725100786, 'weight_decay': 0.06908812667645772, 'top_p': 0.9158574331885635}
[2025-10-10 19:48:02] 
Trial 96: {'learning_rate': 6.656035213850297e-05, 'batch_size': 8, 'lora_r': 48, 'lora_alpha': 64, 'num_beams': 7, 'temperature': 0.3406737151544309, 'warmup_ratio': 0.18650067990023764, 'weight_decay': 0.07385788996348544, 'top_p': 0.8778270974644905}
[2025-10-10 19:48:02] 
Trial 97: {'learning_rate': 1.8784308056633254e-05, 'batch_size': 16, 'lora_r': 16, 'lora_alpha': 16, 'num_beams': 7, 'temperature': 0.40108842250441906, 'warmup_ratio': 0.19513289095620817, 'weight_decay': 0.05313332813954088, 'top_p': 0.9780558069141525}
[2025-10-10 19:48:02] 
Trial 98: {'learning_rate': 1.4499400330623384e-05, 'batch_size': 8, 'lora_r': 36, 'lora_alpha': 32, 'num_beams': 6, 'temperature': 0.36170773004979073, 'warmup_ratio': 0.11886460774314118, 'weight_decay': 0.03495875293944997, 'top_p': 0.9322982461965844}
[2025-10-10 19:48:02] 
Trial 99: {'learning_rate': 2.6339617050759985e-05, 'batch_size': 8, 'lora_r': 52, 'lora_alpha': 80, 'num_beams': 6, 'temperature': 0.2017077274674261, 'warmup_ratio': 0.16651543473380126, 'weight_decay': 0.021825250175773712, 'top_p': 0.9016155797753844}
[2025-10-10 19:48:02] 
============================================================
[2025-10-10 19:48:02] ‚úÖ OPTIMIZATION COMPLETED!
[2025-10-10 19:48:02] ============================================================
[2025-10-10 19:48:02] Best score: 0.8933
[2025-10-10 19:48:02] Best parameters:
[2025-10-10 19:48:02]   - learning_rate: 1.0220690547060621e-05
[2025-10-10 19:48:02]   - batch_size: 8
[2025-10-10 19:48:02]   - lora_r: 48
[2025-10-10 19:48:02]   - lora_alpha: 88
[2025-10-10 19:48:02]   - num_beams: 6
[2025-10-10 19:48:02]   - temperature: 0.36159504454994323
[2025-10-10 19:48:02]   - warmup_ratio: 0.1791812574800705
[2025-10-10 19:48:02]   - weight_decay: 0.030577753086104383
[2025-10-10 19:48:02]   - top_p: 0.8858646544491982
[2025-10-10 19:48:02] 
üìä Top 5 trials:
[2025-10-10 19:48:02] 1. Score: 0.8933
[2025-10-10 19:48:02] 
‚úÖ Config updated with optimal hyperparameters!
[2025-10-10 19:48:02] 
üìÅ Optimization results saved:
[2025-10-10 19:48:02]   - Study: logs/full_pipeline/optuna/optuna_study_20251010_194758.pkl
[2025-10-10 19:48:02]   - CSV: logs/full_pipeline/optuna/optuna_results_20251010_194758.csv
[2025-10-10 19:48:02]   - Best params: logs/full_pipeline/optuna/best_params_20251010_194758.json
[2025-10-10 19:48:02] 
‚úÖ Config has been updated with optimal hyperparameters!
[2025-10-10 19:48:02] [hyperparameter_optimization] Status: completed
[2025-10-10 19:48:02] ‚úÖ Solar API initialized for cross-validation
[2025-10-10 19:48:02] [model_training] Status: running
[2025-10-10 19:48:02] 
=== Model Training (GPU Optimized) ===
[2025-10-10 19:48:04] ‚úÖ Mixed Precision (FP16) Training ENABLED - 40% memory reduction
[2025-10-10 19:48:04] 
üßπ GPU Î©îÎ™®Î¶¨ ÏôÑÏ†Ñ Ï†ïÎ¶¨ Ï§ë...
[2025-10-10 19:48:04] Training primary model: gogamza/kobart-base-v2
[2025-10-10 19:48:06] ‚úÖ Tokenizer loaded
[2025-10-10 19:48:07] ‚úÖ Model loaded to CPU
[2025-10-10 19:48:08] Model moved to cuda
[2025-10-10 19:48:08] GPU Memory - Total: 23.99GB, Reserved: 0.52GB, Allocated: 0.46GB
[2025-10-10 19:48:08] ‚úÖ Gradient Accumulation: 1 steps
[2025-10-10 19:48:08]    Physical batch size: 8
[2025-10-10 19:48:08]    Effective batch size: 8
[2025-10-10 19:48:08] 
‚öôÔ∏è Optimizer Ï¥àÍ∏∞Ìôî Ï§ë...
[2025-10-10 19:48:08] ‚úÖ Optimizer initialized successfully
[2025-10-10 19:48:08] 
======================================================================
[2025-10-10 19:48:08] üöÄ TRAINING START - GPU Optimized
[2025-10-10 19:48:08] ======================================================================
[2025-10-10 19:48:08] Epochs: 1
[2025-10-10 19:48:08] Gradient Accumulation: 1
[2025-10-10 19:48:08] Mixed Precision (FP16): True
[2025-10-10 19:48:08] Gradient Checkpointing: False
[2025-10-10 19:48:08] ======================================================================

[2025-10-10 19:50:07]   Epoch 1: Train Loss = 1.9780
[2025-10-10 19:50:07]   GPU Memory: Allocated=1.46GB, Reserved=4.92GB
[2025-10-10 19:50:08]   ‚úÖ Best model saved (loss: 1.9780)
[2025-10-10 19:50:08] 
======================================================================
[2025-10-10 19:50:08] ‚úÖ Training completed successfully!
[2025-10-10 19:50:08] Best loss: 1.9780
[2025-10-10 19:50:08] Total training steps: 1558
[2025-10-10 19:50:08] ======================================================================

[2025-10-10 19:50:08] [model_training] Status: completed
[2025-10-10 19:50:08] [final_prediction] Status: running
[2025-10-10 19:50:08] 
=== Final Prediction ===
[2025-10-10 19:50:08] Generating predictions for test set...
[2025-10-10 19:51:37] Generated 499 predictions
[2025-10-10 19:51:37] 
=== Solar API Cross-Validation ===
[2025-10-10 19:51:37] 
=== Solar API Cross-Validation ===
[2025-10-10 19:51:50] Comparisons completed: 10 samples
[2025-10-10 19:51:50] Avg model length: 245.6
[2025-10-10 19:51:50] Avg API length: 191.6
[2025-10-10 19:51:50] API calls made: 10
[2025-10-10 19:51:50] Estimated tokens used: 1377
[2025-10-10 19:51:50] ‚úÖ Solar API cross-validation completed
[2025-10-10 19:51:50]    Model avg length: 245.6
[2025-10-10 19:51:50]    API avg length: 191.6
[2025-10-10 19:51:50]    API calls made: 10
[2025-10-10 19:51:50] Submission file saved: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/submissions/full_pipeline/full_pipeline_submission_20251010_194758.csv
[2025-10-10 19:51:50] Shape: (499, 2)
[2025-10-10 19:51:50] [final_prediction] Status: completed
