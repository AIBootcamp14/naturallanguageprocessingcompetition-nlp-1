2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_setup.py:_flush():81] Current SDK version is 0.22.2
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_setup.py:_flush():81] Configure stats pid to 183229
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_setup.py:_flush():81] Loading settings from /home/ieyeppo/.config/wandb/settings
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_setup.py:_flush():81] Loading settings from /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/settings
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_init.py:setup_run_log_directory():705] Logging user logs to /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_125502-l7amqp41/logs/debug.log
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_init.py:setup_run_log_directory():706] Logging internal logs to /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_125502-l7amqp41/logs/debug-internal.log
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_init.py:init():832] calling init triggers
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_init.py:init():837] wandb.init called with sweep_config: {}
config: {'paths': {'data_dir': '../../../data/raw', 'train_file': '../../../data/raw/train.csv', 'dev_file': '../../../data/raw/dev.csv', 'test_file': '../../../data/raw/test.csv', 'output_dir': './models/full_pipeline', 'log_dir': './logs/full_pipeline', 'submission_dir': './submissions/full_pipeline', 'visualization_dir': './logs/full_pipeline/visualizations', 'cache_dir': './cache/full_pipeline', 'preprocessed_data_dir': './data/preprocessed', 'augmented_data_dir': './data/augmented'}, 'pipeline': {'stages': ['data_quality_check', 'data_preprocessing', 'data_augmentation', 'model_training', 'cross_validation', 'ensemble', 'hyperparameter_optimization', 'inference_optimization', 'final_prediction'], 'parallel_stages': [['model_training', 'prompt_optimization'], ['cross_validation', 'tta_preparation']]}, 'data_quality': {'enabled': True, 'checks': {'structural': {'check_nulls': True, 'check_duplicates': True, 'check_encoding': True}, 'semantic': {'min_compression_ratio': 0.1, 'max_compression_ratio': 0.5, 'check_information_loss': True}, 'statistical': {'outlier_detection': True, 'outlier_method': 'isolation_forest', 'outlier_threshold': 0.05}}, 'handle_issues': {'remove_outliers': True, 'fix_encoding': True, 'remove_duplicates': True}}, 'preprocessing': {'noise_removal': {'remove_html_tags': True, 'fix_escaped_chars': True, 'normalize_whitespace': True, 'remove_special_tokens': False}, 'token_normalization': {'person_tokens': {'standardize': True, 'format': '#Person{id}#'}, 'masking_tokens': {'preserve': True, 'tokens': ['#PhoneNumber#', '#Address#', '#SSN#', '#Email#']}}, 'data_split': {'validation_ratio': 0.1, 'stratify': False, 'seed': 42}}, 'augmentation': {'enabled': True, 'target_ratio': 1.5, 'techniques': {'paraphrase': {'enabled': True, 'model': 'lcw99/t5-base-korean-paraphrase', 'num_variants': 2, 'quality_threshold': 0.7}, 'back_translation': {'enabled': True, 'languages': ['en', 'ja'], 'translation_model': 'Helsinki-NLP/opus-mt'}, 'token_replacement': {'enabled': True, 'replacement_ratio': 0.15, 'preserve_entities': True}, 'dialogue_reordering': {'enabled': False}}}, 'models': {'primary_models': [{'name': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'weight': 0.35, 'use_lora': True, 'lora_r': 16, 'lora_alpha': 32}, {'name': 'EleutherAI/polyglot-ko-12.8b', 'weight': 0.3, 'use_lora': True, 'lora_r': 8, 'lora_alpha': 16}, {'name': 'nlpai-lab/kullm-v2', 'weight': 0.2, 'use_lora': True, 'lora_r': 8, 'lora_alpha': 16}], 'auxiliary_models': [{'name': 'digit82/kobart-summarization', 'weight': 0.1, 'model_type': 'seq2seq'}, {'name': 'gogamza/kobart-summarization', 'weight': 0.05, 'model_type': 'seq2seq'}]}, 'prompt_engineering': {'enabled': True, 'templates': {'zero_shot': {'enabled': True, 'template': '다음 대화를 3-5문장으로 요약하세요:\n{dialogue}\n\n요약:\n'}, 'few_shot': {'enabled': True, 'num_examples': 3, 'example_selection': 'random'}, 'chain_of_thought': {'enabled': True, 'template': '다음 대화를 단계적으로 분석하여 요약하세요.\n\n1단계: 주요 주제 파악\n2단계: 핵심 정보 추출\n3단계: 간결한 요약 작성\n\n대화: {dialogue}\n\n분석 및 요약:\n'}}, 'ab_testing': {'enabled': True, 'num_variants': 5, 'selection_metric': 'rouge_l'}}, 'training': {'seed': 42, 'num_epochs': 5, 'batch_size': 4, 'gradient_accumulation_steps': 8, 'learning_rate': '2e-5', 'warmup_ratio': 0.1, 'weight_decay': 0.01, 'max_grad_norm': 0.3, 'gradient_checkpointing': True, 'fp16': True, 'scheduler': 'cosine', 'early_stopping': {'patience': 3, 'threshold': 0.001, 'metric': 'eval_rouge_l'}}, 'cross_validation': {'enabled': True, 'n_splits': 5, 'shuffle': True, 'random_state': 42, 'train_all_folds': True, 'save_all_folds': True, 'ensemble_folds': True}, 'hyperparameter_optimization': {'enabled': True, 'n_trials': 100, 'search_space': {'learning_rate': {'type': 'float', 'low': 1e-05, 'high': 0.001, 'log': True}, 'lora_r': {'type': 'int', 'low': 4, 'high': 64, 'step': 4}, 'lora_alpha': {'type': 'int', 'low': 8, 'high': 128, 'step': 8}, 'batch_size': {'type': 'categorical', 'choices': [4, 8, 16]}, 'num_beams': {'type': 'int', 'low': 2, 'high': 8}, 'temperature': {'type': 'float', 'low': 0.1, 'high': 1.0}}, 'pruner': 'MedianPruner', 'sampler': 'TPESampler', 'direction': 'maximize', 'metric': 'rouge_l'}, 'inference_optimization': {'onnx_conversion': {'enabled': True, 'optimize': True, 'quantization': 'dynamic'}, 'tensorrt': {'enabled': False, 'precision': 'fp16'}, 'batch_inference': {'enabled': True, 'optimal_batch_size': 'auto', 'dynamic_batching': True}}, 'ensemble': {'base_method': 'weighted_average', 'advanced': {'stacking': {'enabled': True, 'meta_learner': 'lgbm', 'cv_folds': 3}, 'blending': {'enabled': False, 'validation_size': 0.2}}, 'test_time_augmentation': {'enabled': True, 'num_augmentations': 5, 'aggregation': 'mean'}}, 'post_processing': {'grammar_correction': {'enabled': True, 'tool': 'py-hanspell'}, 'length_adjustment': {'min_length': 30, 'max_length': 150, 'target_length': 80}, 'quality_check': {'min_rouge_score': 0.3, 'check_coherence': True, 'check_completeness': True}}, 'solar_api': {'enabled': True, 'api_key': 'up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT', 'hybrid_approach': {'use_for_validation': True, 'use_for_difficult_samples': True, 'confidence_threshold': 0.7}, 'optimization': {'batch_size': 10, 'cache_responses': True, 'token_budget': 100000}}, 'wandb': {'project': 'nlp-competition', 'entity': 'ieyeppo', 'name': 'full-pipeline-integrated', 'tags': ['full_pipeline', 'production', 'all_techniques'], 'notes': '모든 기법이 통합된 최종 파이프라인', 'mode': 'online', 'log_artifacts': True, 'log_models': True, 'log_datasets': True}, 'logging': {'level': 'INFO', 'format': '%(asctime)s - [%(pipeline_stage)s] - %(name)s - %(levelname)s - %(message)s', 'save_to_file': True, 'loggers': ['pipeline', 'training', 'evaluation', 'inference'], 'use_notebook_logger': True, 'notebook_logger_path': '../../../src/logging/notebook_logger.py'}, 'gpu': {'device': 'cuda', 'cuda_device': 0, 'mixed_precision': True, 'memory_fraction': 0.95, 'auto_optimization': {'enabled': True, 'find_optimal_batch_size': True, 'gradient_accumulation_auto': True}, 'use_gpu_optimization': True, 'gpu_check_path': '../../../src/utils/gpu_optimization/team_gpu_check.py'}, 'visualization': {'enabled': True, 'save_path': '../logs/full_pipeline/visualizations', 'plots': ['training_curves', 'model_comparison', 'confusion_matrix', 'rouge_distribution', 'sample_difficulty_heatmap', 'ensemble_weights', 'hyperparameter_importance'], 'use_training_viz': True, 'training_viz_path': '../../../src/utils/visualizations/training_viz.py'}, 'experiment': {'name': 'full_pipeline_v1', 'description': '모든 최적화 기법이 적용된 최종 파이프라인', 'version': '1.0.0', 'timestamp': True, 'checkpointing': {'save_every_n_epochs': 1, 'save_best_only': False, 'keep_last_n': 3}, 'save_all_results': True, 'results_format': ['json', 'csv', 'pickle']}, 'reproducibility': {'seed': 42, 'deterministic': True, 'benchmark': False, 'worker_init_fn': True}, 'performance_targets': {'rouge_1': 0.45, 'rouge_2': 0.3, 'rouge_l': 0.4, 'overall': 0.85}, 'deployment': {'serving': {'framework': 'fastapi', 'port': 8000, 'workers': 4}, 'versioning': {'enabled': True, 'registry': 'local'}, 'monitoring': {'enabled': True, 'metrics_port': 9090, 'health_check_interval': 60}}, '_wandb': {}}
2025-10-10 12:55:02,026 INFO    MainThread:183229 [wandb_init.py:init():880] starting backend
2025-10-10 12:55:02,232 INFO    MainThread:183229 [wandb_init.py:init():883] sending inform_init request
2025-10-10 12:55:02,233 INFO    MainThread:183229 [wandb_init.py:init():891] backend started and connected
2025-10-10 12:55:02,235 INFO    MainThread:183229 [wandb_init.py:init():961] updated telemetry
2025-10-10 12:55:02,243 INFO    MainThread:183229 [wandb_init.py:init():985] communicating run to backend with 90.0 second timeout
2025-10-10 12:55:03,046 INFO    MainThread:183229 [wandb_init.py:init():1036] starting run threads in backend
2025-10-10 12:55:03,120 INFO    MainThread:183229 [wandb_run.py:_console_start():2509] atexit reg
2025-10-10 12:55:03,120 INFO    MainThread:183229 [wandb_run.py:_redirect():2357] redirect: wrap_raw
2025-10-10 12:55:03,120 INFO    MainThread:183229 [wandb_run.py:_redirect():2426] Wrapping output streams.
2025-10-10 12:55:03,120 INFO    MainThread:183229 [wandb_run.py:_redirect():2449] Redirects installed.
2025-10-10 12:55:03,123 INFO    MainThread:183229 [wandb_init.py:init():1076] run started, returning control to user process
2025-10-10 12:55:04,068 INFO    wandb-AsyncioManager-main:183229 [service_client.py:_forward_responses():80] Reached EOF.
2025-10-10 12:55:04,068 INFO    wandb-AsyncioManager-main:183229 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
