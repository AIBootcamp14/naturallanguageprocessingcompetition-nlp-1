2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_setup.py:_flush():81] Current SDK version is 0.22.2
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_setup.py:_flush():81] Configure stats pid to 273849
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_setup.py:_flush():81] Loading settings from /home/ieyeppo/.config/wandb/settings
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_setup.py:_flush():81] Loading settings from /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/settings
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_init.py:setup_run_log_directory():705] Logging user logs to /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_183321-5cgjf43z/logs/debug.log
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_init.py:setup_run_log_directory():706] Logging internal logs to /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/wandb/run-20251010_183321-5cgjf43z/logs/debug-internal.log
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_init.py:monkeypatch_ipython():624] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f757f24ed90>
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_init.py:init():832] calling init triggers
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_init.py:init():837] wandb.init called with sweep_config: {}
config: {'augmentation': {'enabled': True, 'target_ratio': 1.5, 'techniques': {'back_translation': {'enabled': True, 'languages': ['en', 'ja'], 'translation_model': 'Helsinki-NLP/opus-mt'}, 'dialogue_reordering': {'enabled': False}, 'paraphrase': {'enabled': True, 'model': 'lcw99/t5-base-korean-paraphrase', 'num_variants': 2, 'quality_threshold': 0.7}, 'token_replacement': {'enabled': True, 'preserve_entities': True, 'replacement_ratio': 0.15}}}, 'cross_validation': {'enabled': True, 'ensemble_folds': True, 'n_splits': 5, 'random_state': 42, 'save_all_folds': True, 'shuffle': True, 'train_all_folds': True}, 'data_quality': {'checks': {'semantic': {'check_information_loss': True, 'max_compression_ratio': 0.5, 'min_compression_ratio': 0.1}, 'statistical': {'outlier_detection': True, 'outlier_method': 'isolation_forest', 'outlier_threshold': 0.05}, 'structural': {'check_duplicates': True, 'check_encoding': True, 'check_nulls': True}}, 'enabled': True, 'handle_issues': {'fix_encoding': True, 'remove_duplicates': True, 'remove_outliers': True}}, 'deployment': {'monitoring': {'enabled': True, 'health_check_interval': 60, 'metrics_port': 9090}, 'serving': {'framework': 'fastapi', 'port': 8000, 'workers': 4}, 'versioning': {'enabled': True, 'registry': 'local'}}, 'ensemble': {'advanced': {'blending': {'enabled': False, 'validation_size': 0.2}, 'stacking': {'cv_folds': 3, 'enabled': True, 'meta_learner': 'lgbm'}}, 'base_method': 'weighted_average', 'test_time_augmentation': {'aggregation': 'mean', 'enabled': True, 'num_augmentations': 5}}, 'experiment': {'checkpointing': {'keep_last_n': 3, 'save_best_only': False, 'save_every_n_epochs': 1}, 'description': '모든 최적화 기법이 적용된 최종 파이프라인', 'name': 'full_pipeline_v1', 'results_format': ['json', 'csv', 'pickle'], 'save_all_results': True, 'timestamp': True, 'version': '1.0.0'}, 'gpu': {'auto_optimization': {'enabled': True, 'find_optimal_batch_size': True, 'gradient_accumulation_auto': True}, 'cuda_device': 0, 'device': 'cuda', 'gpu_check_path': '../../../src/utils/gpu_optimization/team_gpu_check.py', 'memory_fraction': 0.95, 'mixed_precision': True, 'use_gpu_optimization': True}, 'hyperparameter_optimization': {'direction': 'maximize', 'enabled': True, 'metric': 'rouge_l', 'n_trials': 100, 'pruner': 'MedianPruner', 'sampler': 'TPESampler', 'search_space': {'batch_size': {'choices': [4, 8, 16], 'type': 'categorical'}, 'learning_rate': {'high': 0.001, 'log': True, 'low': 1e-05, 'type': 'float'}, 'lora_alpha': {'high': 128, 'low': 8, 'step': 8, 'type': 'int'}, 'lora_r': {'high': 64, 'low': 4, 'step': 4, 'type': 'int'}, 'num_beams': {'high': 8, 'low': 2, 'type': 'int'}, 'temperature': {'high': 1.0, 'low': 0.1, 'type': 'float'}}}, 'inference_optimization': {'batch_inference': {'dynamic_batching': True, 'enabled': True, 'optimal_batch_size': 8}, 'onnx_conversion': {'enabled': False, 'optimize': True, 'quantization': 'dynamic'}, 'tensorrt': {'enabled': False, 'precision': 'fp16'}}, 'inference': {'batch_size': 8, 'max_length': 100, 'min_length': 15, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'repetition_penalty': 1.1, 'length_penalty': 1.0, 'early_stopping': True, 'remove_special_tokens': True}, 'logging': {'format': '%(asctime)s - [%(pipeline_stage)s] - %(name)s - %(levelname)s - %(message)s', 'level': 'INFO', 'loggers': ['pipeline', 'training', 'evaluation', 'inference'], 'notebook_logger_path': '../../../src/logging/notebook_logger.py', 'save_to_file': True, 'use_notebook_logger': True}, 'models': {'auxiliary_models': [{'model_type': 'seq2seq', 'name': 'digit82/kobart-summarization', 'weight': 0.1}, {'model_type': 'seq2seq', 'name': 'gogamza/kobart-summarization', 'weight': 0.05}], 'primary_models': [{'max_input_length': 1024, 'max_target_length': 200, 'name': 'gogamza/kobart-base-v2', 'use_lora': False, 'weight': 1.0}]}, 'paths': {'augmented_data_dir': './data/augmented', 'cache_dir': './cache/full_pipeline', 'data_dir': '../../../data/raw', 'dev_file': '../../../data/raw/dev.csv', 'log_dir': './logs/full_pipeline', 'output_dir': './models/full_pipeline', 'preprocessed_data_dir': './data/preprocessed', 'submission_dir': './submissions/full_pipeline', 'test_file': '../../../data/raw/test.csv', 'train_file': '../../../data/raw/train.csv', 'visualization_dir': './logs/full_pipeline/visualizations'}, 'performance_targets': {'overall': 0.85, 'rouge_1': 0.45, 'rouge_2': 0.3, 'rouge_l': 0.4}, 'pipeline': {'parallel_stages': [['model_training', 'prompt_optimization'], ['cross_validation', 'tta_preparation']], 'stages': ['data_quality_check', 'data_preprocessing', 'data_augmentation', 'model_training', 'cross_validation', 'ensemble', 'hyperparameter_optimization', 'inference_optimization', 'final_prediction']}, 'post_processing': {'grammar_correction': {'enabled': True, 'tool': 'py-hanspell'}, 'length_adjustment': {'max_length': 150, 'min_length': 30, 'target_length': 80}, 'quality_check': {'check_coherence': True, 'check_completeness': True, 'min_rouge_score': 0.3}}, 'preprocessing': {'data_split': {'seed': 42, 'stratify': False, 'validation_ratio': 0.1}, 'noise_removal': {'fix_escaped_chars': True, 'normalize_whitespace': True, 'remove_html_tags': True, 'remove_special_tokens': False}, 'token_normalization': {'masking_tokens': {'preserve': True, 'tokens': ['#PhoneNumber#', '#Address#', '#SSN#', '#Email#']}, 'person_tokens': {'format': '#Person{id}#', 'standardize': True}}}, 'prompt_engineering': {'ab_testing': {'enabled': True, 'num_variants': 5, 'selection_metric': 'rouge_l'}, 'enabled': True, 'templates': {'chain_of_thought': {'enabled': True, 'template': '다음 대화를 단계적으로 분석하여 요약하세요.\n\n1단계: 주요 주제 파악\n2단계: 핵심 정보 추출\n3단계: 간결한 요약 작성\n\n대화: {dialogue}\n\n분석 및 요약:\n'}, 'few_shot': {'enabled': True, 'example_selection': 'random', 'num_examples': 3}, 'zero_shot': {'enabled': True, 'template': '다음 대화를 3-5문장으로 요약하세요:\n{dialogue}\n\n요약:\n'}}}, 'reproducibility': {'benchmark': False, 'deterministic': True, 'seed': 42, 'worker_init_fn': True}, 'solar_api': {'api_key': 'up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT', 'enabled': True, 'hybrid_approach': {'confidence_threshold': 0.7, 'use_for_difficult_samples': True, 'use_for_validation': True}, 'optimization': {'batch_size': 10, 'cache_responses': True, 'token_budget': 100000}}, 'training': {'batch_size': 8, 'early_stopping': {'metric': 'eval_rouge_sum', 'patience': 3, 'threshold': 0.001}, 'fp16': True, 'gradient_accumulation_steps': 1, 'gradient_checkpointing': False, 'learning_rate': '5e-5', 'max_grad_norm': 1.0, 'num_epochs': 10, 'scheduler': 'linear', 'seed': 42, 'use_sample': False, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'predict_with_generate': True, 'generation_max_length': 100, 'generation_num_beams': 4, 'generation_no_repeat_ngram_size': 2, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': True, 'metric_for_best_model': 'rouge_sum', 'greater_is_better': True, 'save_total_limit': 2}, 'visualization': {'enabled': True, 'plots': ['training_curves', 'model_comparison', 'confusion_matrix', 'rouge_distribution', 'sample_difficulty_heatmap', 'ensemble_weights', 'hyperparameter_importance'], 'save_path': './logs/full_pipeline/visualizations', 'training_viz_path': '../../../src/utils/visualizations/training_viz.py', 'use_training_viz': True}, 'wandb': {'entity': 'ieyeppo', 'log_artifacts': True, 'log_datasets': True, 'log_models': True, 'mode': 'online', 'name': 'full-pipeline-integrated', 'notes': '모든 기법이 통합된 최종 파이프라인', 'project': 'nlp-competition', 'tags': ['full_pipeline', 'production', 'all_techniques']}, '_wandb': {}}
2025-10-10 18:33:21,195 INFO    MainThread:273849 [wandb_init.py:init():880] starting backend
2025-10-10 18:33:23,008 INFO    MainThread:273849 [wandb_init.py:init():883] sending inform_init request
2025-10-10 18:33:23,010 INFO    MainThread:273849 [wandb_init.py:init():891] backend started and connected
2025-10-10 18:33:23,013 INFO    MainThread:273849 [wandb_run.py:_label_probe_notebook():1330] probe notebook
2025-10-10 18:33:23,014 INFO    MainThread:273849 [wandb_init.py:init():961] updated telemetry
2025-10-10 18:33:23,018 INFO    MainThread:273849 [wandb_init.py:init():985] communicating run to backend with 90.0 second timeout
2025-10-10 18:33:23,869 INFO    MainThread:273849 [wandb_init.py:init():1036] starting run threads in backend
2025-10-10 18:33:23,961 INFO    MainThread:273849 [wandb_run.py:_console_start():2509] atexit reg
2025-10-10 18:33:23,961 INFO    MainThread:273849 [wandb_run.py:_redirect():2357] redirect: wrap_raw
2025-10-10 18:33:23,962 INFO    MainThread:273849 [wandb_run.py:_redirect():2426] Wrapping output streams.
2025-10-10 18:33:23,962 INFO    MainThread:273849 [wandb_run.py:_redirect():2449] Redirects installed.
2025-10-10 18:33:23,964 INFO    MainThread:273849 [wandb_init.py:init():1076] run started, returning control to user process
2025-10-10 18:33:23,964 INFO    MainThread:273849 [wandb_init.py:_post_run_cell_hook():594] [no run ID] resuming backend
2025-10-10 18:33:23,975 INFO    MainThread:273849 [jupyter.py:save_ipynb():404] [no run ID] not saving jupyter notebook
2025-10-10 18:33:23,975 INFO    MainThread:273849 [wandb_init.py:_pre_run_cell_hook():583] [no run ID] pausing backend
2025-10-10 18:33:24,257 INFO    MainThread:273849 [wandb_init.py:_post_run_cell_hook():594] [no run ID] resuming backend
2025-10-10 18:33:24,285 INFO    MainThread:273849 [jupyter.py:save_ipynb():404] [no run ID] not saving jupyter notebook
2025-10-10 18:33:24,285 INFO    MainThread:273849 [wandb_init.py:_pre_run_cell_hook():583] [no run ID] pausing backend
2025-10-10 18:33:25,008 INFO    MainThread:273849 [wandb_init.py:_post_run_cell_hook():594] [no run ID] resuming backend
2025-10-10 18:33:25,067 INFO    MainThread:273849 [jupyter.py:save_ipynb():404] [no run ID] not saving jupyter notebook
2025-10-10 18:33:25,068 INFO    MainThread:273849 [wandb_init.py:_pre_run_cell_hook():583] [no run ID] pausing backend
2025-10-10 18:53:36,496 INFO    MainThread:273849 [wandb_init.py:_post_run_cell_hook():594] [no run ID] resuming backend
2025-10-10 18:53:36,513 INFO    MainThread:273849 [jupyter.py:save_ipynb():404] [no run ID] not saving jupyter notebook
2025-10-10 18:53:36,513 INFO    MainThread:273849 [wandb_init.py:_pre_run_cell_hook():583] [no run ID] pausing backend
2025-10-10 18:55:20,445 INFO    MainThread:273849 [wandb_init.py:_post_run_cell_hook():594] [no run ID] resuming backend
