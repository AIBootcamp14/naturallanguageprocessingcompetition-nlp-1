{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 K-Fold 교차 검증 - 5-Fold Cross Validation\n",
    "> PRD 계획에 따른 K-Fold 교차 검증으로 모델 안정성 평가\n",
    "\n",
    "**목표 성능**: ROUGE-F1 72-75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: /home/ieyeppo/AI_Lab/natural-language-processing-competition\n",
      "Current Dir: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent.parent.parent  # 3번만 parent 사용!\n",
    "\n",
    "# 다른 프로젝트 경로 제거하고 현재 프로젝트 경로만 추가\n",
    "sys.path = [p for p in sys.path if 'computer-vision-competition' not in p]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Current Dir: {notebook_dir}\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "# 커스텀 모듈 임포트\n",
    "from src.logging.notebook_logger import NotebookLogger\n",
    "from src.utils.gpu_optimization.team_gpu_check import check_gpu_tier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Splits: 5\n",
      "Model: upstage/SOLAR-10.7B-Instruct-v1.0\n",
      "Ensemble Method: weighted_average\n",
      "Save Each Fold: True\n"
     ]
    }
   ],
   "source": [
    "# 설정 파일 로드\n",
    "config_path = notebook_dir / 'configs' / 'config_kfold.yaml'\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"K-Fold Splits: {config['kfold']['n_splits']}\")\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Ensemble Method: {config['kfold']['ensemble_method']}\")\n",
    "print(f\"Save Each Fold: {config['kfold']['save_each_fold']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "K-Fold Cross Validation Experiment\n",
      "Timestamp: 20251010_090402\n",
      "Folds: 5\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 로그 디렉토리 생성\n",
    "# config의 로그 경로 사용\n",
    "def get_path(path_str):\n",
    "    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "# config에 log_dir이 정의되어 있으면 사용, 없으면 기본값\n",
    "if 'log_dir' in config['paths']:\n",
    "    log_dir = get_path(config['paths']['log_dir'])\n",
    "else:\n",
    "    # 기본값: notebook_dir/logs/kfold\n",
    "    log_dir = notebook_dir / 'logs' / 'kfold'\n",
    "\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 타임스탬프 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 로거 초기화\n",
    "log_file = log_dir / f'kfold_{config[\"kfold\"][\"n_splits\"]}fold_{timestamp}.log'\n",
    "logger = NotebookLogger(\n",
    "    log_path=str(log_file),\n",
    "    print_also=True\n",
    ")\n",
    "\n",
    "logger.write('='*50)\n",
    "logger.write('K-Fold Cross Validation Experiment')\n",
    "logger.write(f'Timestamp: {timestamp}')\n",
    "logger.write(f'Folds: {config[\"kfold\"][\"n_splits\"]}')\n",
    "logger.write('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold configured:\n",
      "  - Splits: 5\n",
      "  - Shuffle: True\n",
      "  - Random State: 42\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 설정\n",
    "kfold = KFold(\n",
    "    n_splits=config['kfold']['n_splits'],\n",
    "    shuffle=config['kfold']['shuffle'],\n",
    "    random_state=config['kfold']['random_state']\n",
    ")\n",
    "\n",
    "logger.write(f\"KFold configured:\")\n",
    "logger.write(f\"  - Splits: {config['kfold']['n_splits']}\")\n",
    "logger.write(f\"  - Shuffle: {config['kfold']['shuffle']}\")\n",
    "logger.write(f\"  - Random State: {config['kfold']['random_state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from config path:\n",
      "  - Train: /home/ieyeppo/AI_Lab/natural-language-processing-competition/notebooks/team/CHH/../../../data/raw/train.csv\n",
      "\n",
      "Data loaded: 12457 samples\n",
      "Fold 1: Train=9965, Val=2492\n",
      "Fold 1: Train=9965, Val=2492\n",
      "Fold 2: Train=9965, Val=2492\n",
      "Fold 2: Train=9965, Val=2492\n",
      "Fold 3: Train=9966, Val=2491\n",
      "Fold 3: Train=9966, Val=2491\n",
      "Fold 4: Train=9966, Val=2491\n",
      "Fold 4: Train=9966, Val=2491\n",
      "Fold 5: Train=9966, Val=2491\n",
      "Fold 5: Train=9966, Val=2491\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "# config 파일의 경로 사용\n",
    "def get_data_path(path_str):\n",
    "    \"\"\"config의 상대 경로를 절대 경로로 변환\"\"\"\n",
    "    path = Path(path_str)\n",
    "    if not path.is_absolute():\n",
    "        path = notebook_dir / path\n",
    "    return path\n",
    "\n",
    "# config에서 데이터 경로 가져오기\n",
    "train_path = get_data_path(config['paths']['train_file'])\n",
    "\n",
    "logger.write(f\"Loading data from config path:\")\n",
    "logger.write(f\"  - Train: {train_path}\")\n",
    "\n",
    "# 데이터 로드\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "logger.write(f\"\\nData loaded: {len(train_df)} samples\")\n",
    "\n",
    "# Fold별 데이터 분할 확인\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(train_df), 1):\n",
    "    logger.write(f\"Fold {fold_idx}: Train={len(train_idx)}, Val={len(val_idx)}\")\n",
    "    print(f\"Fold {fold_idx}: Train={len(train_idx)}, Val={len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# 데이터 품질 검증 시스템 (PRD 16_데이터_품질_검증_시스템.md)\nimport numpy as np\nfrom typing import Dict, List\n\nclass KFoldDataValidator:\n    \"\"\"K-Fold용 데이터 품질 검증\"\"\"\n    \n    def __init__(self):\n        self.validation_results = []\n        \n    def validate_fold_distribution(self, train_df: pd.DataFrame, kfold) -> Dict:\n        \"\"\"Fold 분포 검증\"\"\"\n        results = {}\n        \n        # 주제 분포 확인\n        if 'topic' in train_df.columns:\n            topic_counts = train_df['topic'].value_counts()\n            \n            # 각 fold의 주제 분포 확인\n            fold_topic_distributions = []\n            for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n                fold_train = train_df.iloc[train_idx]\n                fold_val = train_df.iloc[val_idx]\n                \n                train_topics = fold_train['topic'].value_counts(normalize=True)\n                val_topics = fold_val['topic'].value_counts(normalize=True)\n                \n                # 분포 차이 계산 (KL divergence 근사)\n                topic_diff = 0\n                for topic in topic_counts.index:\n                    train_prop = train_topics.get(topic, 0)\n                    val_prop = val_topics.get(topic, 0)\n                    if train_prop > 0 and val_prop > 0:\n                        topic_diff += abs(train_prop - val_prop)\n                \n                fold_topic_distributions.append({\n                    'fold': fold_idx + 1,\n                    'distribution_diff': topic_diff,\n                    'train_unique_topics': len(train_topics),\n                    'val_unique_topics': len(val_topics)\n                })\n            \n            results['topic_distributions'] = fold_topic_distributions\n        \n        # 텍스트 길이 분포 확인\n        dialogue_lengths = train_df['dialogue'].str.len()\n        \n        fold_length_stats = []\n        for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n            train_lengths = dialogue_lengths.iloc[train_idx]\n            val_lengths = dialogue_lengths.iloc[val_idx]\n            \n            fold_length_stats.append({\n                'fold': fold_idx + 1,\n                'train_mean_length': train_lengths.mean(),\n                'val_mean_length': val_lengths.mean(),\n                'length_diff': abs(train_lengths.mean() - val_lengths.mean())\n            })\n        \n        results['length_distributions'] = fold_length_stats\n        \n        # 데이터 누출 검사\n        for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n            train_set = set(train_idx)\n            val_set = set(val_idx)\n            \n            # 인덱스 중복 검사\n            overlap = train_set.intersection(val_set)\n            if overlap:\n                logger.write(f\"⚠️ WARNING: Data leakage detected in fold {fold_idx+1}: {len(overlap)} overlapping indices\")\n                results['data_leakage'] = True\n            else:\n                results['data_leakage'] = False\n        \n        self.validation_results = results\n        return results\n    \n    def recommend_stratification(self) -> List[str]:\n        \"\"\"층화 추천\"\"\"\n        recommendations = []\n        \n        if 'topic_distributions' in self.validation_results:\n            max_diff = max([f['distribution_diff'] for f in self.validation_results['topic_distributions']])\n            if max_diff > 0.2:\n                recommendations.append(\"Consider stratified K-Fold based on topic distribution\")\n        \n        if 'length_distributions' in self.validation_results:\n            max_length_diff = max([f['length_diff'] for f in self.validation_results['length_distributions']])\n            if max_length_diff > 500:\n                recommendations.append(\"Consider stratification based on text length\")\n        \n        if self.validation_results.get('data_leakage', False):\n            recommendations.append(\"CRITICAL: Fix data leakage issue immediately\")\n        \n        return recommendations\n\n# K-Fold 데이터 검증 실행\nkfold_validator = KFoldDataValidator()\nvalidation_results = kfold_validator.validate_fold_distribution(train_df, kfold)\n\nlogger.write(\"\\n=== K-Fold Data Validation ===\")\nif 'topic_distributions' in validation_results:\n    logger.write(\"\\nTopic Distribution Analysis:\")\n    for fold_stat in validation_results['topic_distributions'][:2]:  # 처음 2개 fold만 출력\n        logger.write(f\"  Fold {fold_stat['fold']}: Distribution diff={fold_stat['distribution_diff']:.3f}\")\n\nif 'length_distributions' in validation_results:\n    logger.write(\"\\nText Length Distribution:\")\n    for fold_stat in validation_results['length_distributions'][:2]:  # 처음 2개 fold만 출력\n        logger.write(f\"  Fold {fold_stat['fold']}: Mean length diff={fold_stat['length_diff']:.1f}\")\n\nrecommendations = kfold_validator.recommend_stratification()\nif recommendations:\n    logger.write(\"\\n📋 Stratification Recommendations:\")\n    for rec in recommendations:\n        logger.write(f\"  • {rec}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Solar API 교차 검증 시스템 (PRD 09_Solar_API_최적화.md, 10_교차_검증_시스템.md)\nimport requests\nimport json\nfrom typing import Optional, Dict\n\nclass KFoldSolarValidator:\n    \"\"\"K-Fold용 Solar API 검증\"\"\"\n    \n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.base_url = \"https://api.upstage.ai/v1/solar\"\n        self.headers = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        self.fold_comparisons = []\n        \n    def validate_fold_predictions(self, fold_idx: int, model_predictions: List[str], \n                                 test_dialogues: List[str], sample_size: int = 5) -> Dict:\n        \"\"\"Fold 예측 검증\"\"\"\n        comparisons = []\n        \n        # 랜덤 샘플 선택\n        sample_indices = np.random.choice(len(model_predictions), \n                                        min(sample_size, len(model_predictions)), \n                                        replace=False)\n        \n        for idx in sample_indices:\n            dialogue = test_dialogues[idx]\n            model_pred = model_predictions[idx]\n            \n            # Solar API 예측\n            api_pred = self.generate_with_solar(dialogue)\n            \n            if api_pred:\n                # 길이 비교\n                model_len = len(model_pred)\n                api_len = len(api_pred)\n                \n                comparisons.append({\n                    'model_length': model_len,\n                    'api_length': api_len,\n                    'model_summary': model_pred[:100],\n                    'api_summary': api_pred[:100]\n                })\n        \n        result = {\n            'fold': fold_idx,\n            'comparisons': comparisons,\n            'avg_model_length': np.mean([c['model_length'] for c in comparisons]),\n            'avg_api_length': np.mean([c['api_length'] for c in comparisons])\n        }\n        \n        self.fold_comparisons.append(result)\n        return result\n    \n    def generate_with_solar(self, dialogue: str, max_tokens: int = 150) -> Optional[str]:\n        \"\"\"Solar API로 요약 생성\"\"\"\n        try:\n            # 토큰 절약을 위한 텍스트 제한\n            if len(dialogue) > 2000:\n                dialogue = dialogue[:2000] + \"...\"\n            \n            prompt = f\"\"\"다음 대화를 3-5문장으로 간결하게 요약하세요:\n\n{dialogue}\n\n요약:\"\"\"\n            \n            payload = {\n                \"model\": \"solar-1-mini-chat\",\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": \"당신은 전문적인 대화 요약 AI입니다.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                \"max_tokens\": max_tokens,\n                \"temperature\": 0.3,\n                \"top_p\": 0.9\n            }\n            \n            response = requests.post(\n                f\"{self.base_url}/chat/completions\",\n                headers=self.headers,\n                json=payload,\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                result = response.json()\n                return result['choices'][0]['message']['content']\n            else:\n                logger.write(f\"Solar API error: {response.status_code}\")\n                return None\n                \n        except Exception as e:\n            logger.write(f\"Solar API exception: {e}\")\n            return None\n    \n    def get_fold_consensus(self) -> Dict:\n        \"\"\"Fold 간 일관성 분석\"\"\"\n        if not self.fold_comparisons:\n            return {}\n        \n        all_model_lengths = []\n        all_api_lengths = []\n        \n        for fold_comp in self.fold_comparisons:\n            all_model_lengths.append(fold_comp['avg_model_length'])\n            all_api_lengths.append(fold_comp['avg_api_length'])\n        \n        return {\n            'model_length_consistency': np.std(all_model_lengths),\n            'api_length_consistency': np.std(all_api_lengths),\n            'avg_model_vs_api_ratio': np.mean(all_model_lengths) / np.mean(all_api_lengths) if np.mean(all_api_lengths) > 0 else 0\n        }\n\n# 리스크 관리 시스템 (PRD 05_리스크_관리.md)\nclass KFoldRiskManager:\n    \"\"\"K-Fold 학습 리스크 관리\"\"\"\n    \n    def __init__(self):\n        self.fold_risks = []\n        self.critical_risks = []\n        \n    def assess_fold_risk(self, fold_idx: int, fold_result: Dict) -> Dict:\n        \"\"\"Fold별 리스크 평가\"\"\"\n        risks = []\n        \n        # 성능 편차 리스크\n        if 'best_rouge_l' in fold_result:\n            rouge_score = fold_result['best_rouge_l']\n            \n            if rouge_score < 0.3:\n                risks.append({\n                    'type': 'poor_performance',\n                    'severity': 'high',\n                    'fold': fold_idx,\n                    'metric': f'ROUGE-L: {rouge_score:.4f}',\n                    'mitigation': 'Check data quality, increase epochs, or adjust hyperparameters'\n                })\n            \n            # 이전 fold와 비교\n            if self.fold_risks:\n                prev_scores = [f.get('rouge_score', 0) for f in self.fold_risks]\n                avg_prev = np.mean(prev_scores)\n                if avg_prev > 0 and abs(rouge_score - avg_prev) > 0.1:\n                    risks.append({\n                        'type': 'inconsistent_performance',\n                        'severity': 'medium',\n                        'fold': fold_idx,\n                        'metric': f'Deviation from avg: {abs(rouge_score - avg_prev):.4f}',\n                        'mitigation': 'Review fold data distribution and training process'\n                    })\n        \n        # 학습 안정성 리스크\n        if 'train_loss' in fold_result and 'val_loss' in fold_result:\n            train_loss = fold_result['train_loss']\n            val_loss = fold_result['val_loss']\n            \n            if val_loss > train_loss * 2:\n                risks.append({\n                    'type': 'severe_overfitting',\n                    'severity': 'critical',\n                    'fold': fold_idx,\n                    'metric': f'Val/Train ratio: {val_loss/train_loss:.2f}',\n                    'mitigation': 'Apply regularization, reduce model complexity, or use early stopping'\n                })\n        \n        # 메모리 리스크\n        if torch.cuda.is_available():\n            memory_used = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()\n            if memory_used > 0.85:\n                risks.append({\n                    'type': 'memory_pressure',\n                    'severity': 'medium',\n                    'fold': fold_idx,\n                    'metric': f'Memory usage: {memory_used:.1%}',\n                    'mitigation': 'Reduce batch size or enable gradient accumulation'\n                })\n        \n        # 리스크 기록\n        fold_risk_summary = {\n            'fold': fold_idx,\n            'risks': risks,\n            'risk_count': len(risks),\n            'rouge_score': fold_result.get('best_rouge_l', 0)\n        }\n        \n        self.fold_risks.append(fold_risk_summary)\n        \n        # 심각한 리스크 추적\n        for risk in risks:\n            if risk['severity'] == 'critical':\n                self.critical_risks.append(risk)\n                logger.write(f\"⚠️ CRITICAL RISK in Fold {fold_idx}: {risk['type']} - {risk['metric']}\")\n        \n        return fold_risk_summary\n    \n    def get_overall_risk_assessment(self) -> Dict:\n        \"\"\"전체 리스크 평가\"\"\"\n        if not self.fold_risks:\n            return {'status': 'no_data'}\n        \n        total_risks = sum([f['risk_count'] for f in self.fold_risks])\n        avg_risk_per_fold = total_risks / len(self.fold_risks)\n        \n        # Fold 간 성능 편차\n        rouge_scores = [f['rouge_score'] for f in self.fold_risks if f['rouge_score'] > 0]\n        performance_variance = np.var(rouge_scores) if rouge_scores else 0\n        \n        assessment = {\n            'total_risks': total_risks,\n            'critical_risks': len(self.critical_risks),\n            'avg_risks_per_fold': avg_risk_per_fold,\n            'performance_variance': performance_variance,\n            'risk_level': 'low' if avg_risk_per_fold < 1 else 'medium' if avg_risk_per_fold < 2 else 'high'\n        }\n        \n        return assessment\n    \n    def suggest_improvements(self) -> List[str]:\n        \"\"\"개선 제안\"\"\"\n        suggestions = []\n        \n        assessment = self.get_overall_risk_assessment()\n        \n        if assessment.get('performance_variance', 0) > 0.01:\n            suggestions.append(\"High variance between folds - consider stratified sampling\")\n        \n        if assessment.get('critical_risks', 0) > 0:\n            suggestions.append(\"Critical risks detected - immediate attention required\")\n        \n        if assessment.get('risk_level') == 'high':\n            suggestions.append(\"Overall risk level is high - review training configuration\")\n        \n        # 리스크 타입별 제안\n        risk_types = {}\n        for fold_risk in self.fold_risks:\n            for risk in fold_risk['risks']:\n                risk_type = risk['type']\n                if risk_type not in risk_types:\n                    risk_types[risk_type] = 0\n                risk_types[risk_type] += 1\n        \n        if 'severe_overfitting' in risk_types:\n            suggestions.append(\"Overfitting detected in multiple folds - increase regularization\")\n        \n        if 'memory_pressure' in risk_types:\n            suggestions.append(\"Memory issues detected - optimize batch size or use gradient accumulation\")\n        \n        return suggestions\n\n# Solar API 검증 초기화 (config에서 키 확인)\nsolar_validator = None\nif 'solar_api' in config and 'api_key' in config['solar_api']:\n    solar_validator = KFoldSolarValidator(config['solar_api']['api_key'])\n    logger.write(\"Solar API validator initialized for K-Fold cross-validation\")\nelse:\n    logger.write(\"Solar API key not found - skipping API validation\")\n\n# 리스크 매니저 초기화\nrisk_manager = KFoldRiskManager()\nlogger.write(\"K-Fold risk management system initialized\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU: NVIDIA GeForce RTX 4090\n",
      "GPU Tier: LOW\n",
      "Will clear GPU cache between folds\n"
     ]
    }
   ],
   "source": [
    "# GPU 체크\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tier = check_gpu_tier()\n",
    "    logger.write(f\"\\nGPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.write(f\"GPU Tier: {gpu_tier}\")\n",
    "    \n",
    "    if config['gpu']['empty_cache_between_folds']:\n",
    "        logger.write(\"Will clear GPU cache between folds\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# 데이터셋 클래스 정의\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, BartForConditionalGeneration\n\nclass DialogueSummaryDataset(Dataset):\n    \"\"\"대화 요약 데이터셋\"\"\"\n    def __init__(self, dataframe, tokenizer, max_input_len=512, max_target_len=150, is_test=False):\n        self.df = dataframe.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_input_len = max_input_len\n        self.max_target_len = max_target_len\n        self.is_test = is_test\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        dialogue = row['dialogue']\n        \n        # 입력 토큰화\n        inputs = self.tokenizer(\n            dialogue,\n            max_length=self.max_input_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        if not self.is_test:\n            # 학습/검증 모드\n            summary = row['summary']\n            \n            # 타겟 토큰화\n            targets = self.tokenizer(\n                summary,\n                max_length=self.max_target_len,\n                padding='max_length',\n                truncation=True,\n                return_tensors='pt'\n            )\n            \n            # 라벨 생성 - 패딩 토큰을 -100으로 마스킹 (중요!)\n            labels = targets['input_ids'].squeeze()\n            labels[labels == self.tokenizer.pad_token_id] = -100  # 패딩 토큰 마스킹\n            \n            return {\n                'input_ids': inputs['input_ids'].squeeze(),\n                'attention_mask': inputs['attention_mask'].squeeze(),\n                'labels': labels\n            }\n        else:\n            # 테스트 모드\n            return {\n                'input_ids': inputs['input_ids'].squeeze(),\n                'attention_mask': inputs['attention_mask'].squeeze()\n            }\n\n# ROUGE 스코어 계산 함수\nfrom rouge import Rouge\n\ndef compute_rouge_scores(predictions, references):\n    \"\"\"ROUGE 점수 계산\"\"\"\n    rouge = Rouge()\n    \n    # 빈 문자열 처리\n    predictions = [p if p else \"요약 없음\" for p in predictions]\n    references = [r if r else \"요약 없음\" for r in references]\n    \n    try:\n        scores = rouge.get_scores(predictions, references, avg=True)\n        return {\n            'rouge-1': scores['rouge-1']['f'],\n            'rouge-2': scores['rouge-2']['f'],\n            'rouge-l': scores['rouge-l']['f']\n        }\n    except Exception as e:\n        logger.write(f\"ROUGE calculation error: {e}\")\n        return {\n            'rouge-1': 0.0,\n            'rouge-2': 0.0,\n            'rouge-l': 0.0\n        }\n\nlogger.write(\"Dataset class and ROUGE scorer defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# K-Fold 학습 함수 (PRD 전략 통합)\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm.auto import tqdm\nimport gc\n\ndef train_fold_with_validation(model, train_loader, val_loader, tokenizer, fold_idx, config, \n                              solar_validator=None, risk_manager=None):\n    \"\"\"향상된 Fold 학습 (Solar API 검증 및 리스크 모니터링 포함)\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    # learning_rate 변환\n    learning_rate = config['training']['learning_rate']\n    if isinstance(learning_rate, str):\n        learning_rate = float(learning_rate)\n    \n    # 옵티마이저 설정\n    optimizer = AdamW(\n        model.parameters(),\n        lr=learning_rate,\n        weight_decay=config['training']['weight_decay']\n    )\n    \n    num_epochs = config['training']['num_epochs']\n    num_training_steps = num_epochs * len(train_loader)\n    \n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=int(num_training_steps * config['training']['warmup_ratio']),\n        num_training_steps=num_training_steps\n    )\n    \n    best_rouge_l = 0\n    best_epoch = 0\n    fold_history = {'train_loss': [], 'val_loss': [], 'rouge_l': [], 'risks': []}\n    \n    for epoch in range(num_epochs):\n        # 학습\n        model.train()\n        total_loss = 0\n        \n        progress_bar = tqdm(train_loader, desc=f'Fold {fold_idx} Epoch {epoch+1}')\n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_loss += loss.item()\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            progress_bar.set_postfix({'loss': loss.item()})\n            \n            # 메모리 관리\n            if batch.get('__index', 0) % 50 == 0:\n                torch.cuda.empty_cache()\n        \n        avg_train_loss = total_loss / len(train_loader)\n        fold_history['train_loss'].append(avg_train_loss)\n        \n        # 검증\n        model.eval()\n        val_loss = 0\n        predictions = []\n        references = []\n        val_dialogues = []\n        \n        with torch.no_grad():\n            for batch in tqdm(val_loader, desc='Validating'):\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                \n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                val_loss += outputs.loss.item()\n                \n                # 예측 생성\n                generated_ids = model.generate(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    max_length=config['model']['max_target_length'],\n                    num_beams=config['evaluation']['num_beams'],\n                    early_stopping=True,\n                    no_repeat_ngram_size=config['evaluation'].get('no_repeat_ngram_size', 2),\n                    temperature=config['evaluation'].get('temperature', 1.0)\n                )\n                \n                preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n                refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n                \n                predictions.extend(preds)\n                references.extend(refs)\n                \n                # 대화 원문 저장 (Solar API 비교용)\n                dialogues = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n                val_dialogues.extend(dialogues)\n        \n        avg_val_loss = val_loss / len(val_loader)\n        fold_history['val_loss'].append(avg_val_loss)\n        \n        # ROUGE 계산\n        rouge_scores = compute_rouge_scores(predictions[:100], references[:100])  # 샘플만 평가\n        fold_history['rouge_l'].append(rouge_scores['rouge-l'])\n        \n        logger.write(f\"\\nFold {fold_idx} Epoch {epoch+1}:\")\n        logger.write(f\"  Train Loss: {avg_train_loss:.4f}\")\n        logger.write(f\"  Val Loss: {avg_val_loss:.4f}\")\n        logger.write(f\"  ROUGE-L: {rouge_scores['rouge-l']:.4f}\")\n        \n        # Solar API 검증 (2 에폭마다)\n        if solar_validator and epoch % 2 == 0 and len(predictions) > 0:\n            logger.write(f\"  🔄 Solar API validation...\")\n            solar_result = solar_validator.validate_fold_predictions(\n                fold_idx=fold_idx,\n                model_predictions=predictions[:10],\n                test_dialogues=val_dialogues[:10],\n                sample_size=3\n            )\n            \n            if solar_result and 'comparisons' in solar_result:\n                logger.write(f\"    Model avg length: {solar_result['avg_model_length']:.1f}\")\n                logger.write(f\"    API avg length: {solar_result['avg_api_length']:.1f}\")\n        \n        # 리스크 모니터링\n        if risk_manager:\n            fold_result = {\n                'best_rouge_l': rouge_scores['rouge-l'],\n                'train_loss': avg_train_loss,\n                'val_loss': avg_val_loss\n            }\n            \n            risk_assessment = risk_manager.assess_fold_risk(fold_idx, fold_result)\n            fold_history['risks'].append(risk_assessment)\n            \n            if risk_assessment['risk_count'] > 0:\n                logger.write(f\"  ⚠️ {risk_assessment['risk_count']} risks detected\")\n                \n                # 자동 완화 적용\n                for risk in risk_assessment['risks']:\n                    if risk['severity'] == 'critical':\n                        logger.write(f\"    Critical: {risk['type']}\")\n                        \n                        # 학습률 조정\n                        if risk['type'] == 'severe_overfitting':\n                            for param_group in optimizer.param_groups:\n                                param_group['lr'] *= 0.5\n                            logger.write(f\"    → Learning rate reduced\")\n        \n        # Best model 추적\n        if rouge_scores['rouge-l'] > best_rouge_l:\n            best_rouge_l = rouge_scores['rouge-l']\n            best_epoch = epoch\n            \n            # 모델 저장 (설정된 경우)\n            if config['kfold']['save_each_fold']:\n                output_dir = get_path(config['paths']['output_dir'])\n                output_dir.mkdir(parents=True, exist_ok=True)\n                model_path = output_dir / f'fold_{fold_idx}_best_model.pt'\n                \n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'rouge_scores': rouge_scores,\n                    'epoch': epoch,\n                    'fold_history': fold_history\n                }, model_path)\n                \n                logger.write(f\"  ✓ Saved best model for fold {fold_idx}\")\n        \n        # Early stopping\n        if config['training'].get('early_stopping_patience'):\n            if epoch - best_epoch >= config['training']['early_stopping_patience']:\n                logger.write(f\"  Early stopping triggered at epoch {epoch+1}\")\n                break\n    \n    return best_rouge_l, fold_history\n\nlogger.write(\"Enhanced train fold function defined with PRD strategies\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# WandB 초기화\nif config['wandb']['mode'] != 'disabled':\n    wandb.init(\n        project=config['wandb']['project'],\n        entity=config['wandb']['entity'],\n        name=config['wandb']['name'],\n        tags=config['wandb']['tags'],\n        config=config\n    )\n    logger.write(\"WandB initialized for K-Fold experiment\")\n\n# 모델 및 토크나이저 초기화 (한 번만)\nlogger.write(f\"\\nInitializing model: {config['model']['name']}\")\ntokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\nlogger.write(\"Tokenizer loaded\")\n\n# K-Fold 메인 학습 루프 (PRD 전략 통합)\nall_fold_results = []\nall_fold_histories = []\n\nlogger.write(\"\\n\" + \"=\"*50)\nlogger.write(\"Starting K-Fold Cross Validation with PRD Strategies\")\nlogger.write(\"=\"*50)\n\nfor fold_idx, (train_idx, val_idx) in enumerate(kfold.split(train_df), 1):\n    logger.write(f\"\\n{'='*30}\")\n    logger.write(f\"FOLD {fold_idx}/{config['kfold']['n_splits']}\")\n    logger.write(f\"{'='*30}\")\n    \n    # GPU 캐시 정리\n    if config['gpu']['empty_cache_between_folds'] and torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        gc.collect()\n        logger.write(\"GPU cache cleared\")\n    \n    # Fold 데이터 분할\n    fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n    fold_val_df = train_df.iloc[val_idx].reset_index(drop=True)\n    \n    logger.write(f\"Fold {fold_idx} data split: Train={len(fold_train_df)}, Val={len(fold_val_df)}\")\n    \n    # 데이터셋 생성\n    train_dataset = DialogueSummaryDataset(\n        fold_train_df, \n        tokenizer,\n        max_input_len=config['model']['max_input_length'],\n        max_target_len=config['model']['max_target_length']\n    )\n    \n    val_dataset = DialogueSummaryDataset(\n        fold_val_df,\n        tokenizer,\n        max_input_len=config['model']['max_input_length'],\n        max_target_len=config['model']['max_target_length']\n    )\n    \n    # DataLoader 생성\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['training']['batch_size'],\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['training']['batch_size'],\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # 모델 초기화 (각 Fold마다 새로운 모델)\n    model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n    logger.write(f\"Model initialized for fold {fold_idx}\")\n    \n    # Fold 학습 (향상된 버전 사용)\n    best_rouge_l, fold_history = train_fold_with_validation(\n        model, train_loader, val_loader, tokenizer, fold_idx, config,\n        solar_validator=solar_validator,  # Solar API 검증\n        risk_manager=risk_manager  # 리스크 관리\n    )\n    \n    # 결과 저장\n    fold_result = {\n        'fold': fold_idx,\n        'best_rouge_l': best_rouge_l,\n        'train_size': len(fold_train_df),\n        'val_size': len(fold_val_df),\n        'final_train_loss': fold_history['train_loss'][-1] if fold_history['train_loss'] else 0,\n        'final_val_loss': fold_history['val_loss'][-1] if fold_history['val_loss'] else 0,\n        'total_risks': sum([r['risk_count'] for r in fold_history.get('risks', [])])\n    }\n    all_fold_results.append(fold_result)\n    all_fold_histories.append(fold_history)\n    \n    logger.write(f\"\\nFold {fold_idx} completed:\")\n    logger.write(f\"  Best ROUGE-L: {best_rouge_l:.4f}\")\n    logger.write(f\"  Total risks encountered: {fold_result['total_risks']}\")\n    \n    # WandB 로깅\n    if config['wandb']['mode'] != 'disabled':\n        wandb.log({\n            f'fold_{fold_idx}_rouge_l': best_rouge_l,\n            f'fold_{fold_idx}_train_loss': fold_result['final_train_loss'],\n            f'fold_{fold_idx}_val_loss': fold_result['final_val_loss'],\n            f'fold_{fold_idx}_risks': fold_result['total_risks']\n        })\n    \n    # 메모리 정리\n    del model, train_dataset, val_dataset, train_loader, val_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# Solar API 일관성 분석\nif solar_validator:\n    consensus = solar_validator.get_fold_consensus()\n    if consensus:\n        logger.write(\"\\n=== Solar API Consensus Analysis ===\")\n        logger.write(f\"Model length consistency (std): {consensus.get('model_length_consistency', 0):.2f}\")\n        logger.write(f\"API length consistency (std): {consensus.get('api_length_consistency', 0):.2f}\")\n        logger.write(f\"Model vs API ratio: {consensus.get('avg_model_vs_api_ratio', 1):.2f}\")\n\n# 리스크 관리 최종 평가\nif risk_manager:\n    overall_risk = risk_manager.get_overall_risk_assessment()\n    logger.write(\"\\n=== Overall Risk Assessment ===\")\n    logger.write(f\"Total risks: {overall_risk.get('total_risks', 0)}\")\n    logger.write(f\"Critical risks: {overall_risk.get('critical_risks', 0)}\")\n    logger.write(f\"Risk level: {overall_risk.get('risk_level', 'unknown')}\")\n    \n    improvements = risk_manager.suggest_improvements()\n    if improvements:\n        logger.write(\"\\n📋 Improvement Suggestions:\")\n        for suggestion in improvements:\n            logger.write(f\"  • {suggestion}\")\n\nlogger.write(\"\\n\" + \"=\"*50)\nlogger.write(\"K-Fold Cross Validation with PRD Strategies Completed\")\nlogger.write(\"=\"*50)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# K-Fold 학습 함수\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm.auto import tqdm\nimport gc\n\ndef train_fold(model, train_loader, val_loader, tokenizer, fold_idx, config):\n    \"\"\"단일 Fold 학습\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    # learning_rate 변환\n    learning_rate = config['training']['learning_rate']\n    if isinstance(learning_rate, str):\n        learning_rate = float(learning_rate)\n    \n    # 옵티마이저 설정\n    optimizer = AdamW(\n        model.parameters(),\n        lr=learning_rate,\n        weight_decay=config['training']['weight_decay']\n    )\n    \n    num_epochs = config['training']['num_epochs']\n    num_training_steps = num_epochs * len(train_loader)\n    \n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=int(num_training_steps * config['training']['warmup_ratio']),\n        num_training_steps=num_training_steps\n    )\n    \n    best_rouge_l = 0\n    best_epoch = 0\n    fold_history = {'train_loss': [], 'val_loss': [], 'rouge_l': []}\n    \n    for epoch in range(num_epochs):\n        # 학습\n        model.train()\n        total_loss = 0\n        \n        progress_bar = tqdm(train_loader, desc=f'Fold {fold_idx} Epoch {epoch+1}')\n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_loss += loss.item()\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            progress_bar.set_postfix({'loss': loss.item()})\n        \n        avg_train_loss = total_loss / len(train_loader)\n        fold_history['train_loss'].append(avg_train_loss)\n        \n        # 검증\n        model.eval()\n        val_loss = 0\n        predictions = []\n        references = []\n        \n        with torch.no_grad():\n            for batch in tqdm(val_loader, desc='Validating'):\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                \n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                val_loss += outputs.loss.item()\n                \n                # 예측 생성\n                generated_ids = model.generate(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    max_length=config['model']['max_target_length'],\n                    num_beams=config['evaluation']['num_beams'],\n                    early_stopping=True\n                )\n                \n                preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n                refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n                \n                predictions.extend(preds)\n                references.extend(refs)\n        \n        avg_val_loss = val_loss / len(val_loader)\n        fold_history['val_loss'].append(avg_val_loss)\n        \n        # ROUGE 계산\n        rouge_scores = compute_rouge_scores(predictions[:100], references[:100])  # 샘플만 평가\n        fold_history['rouge_l'].append(rouge_scores['rouge-l'])\n        \n        logger.write(f\"Fold {fold_idx} Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, ROUGE-L={rouge_scores['rouge-l']:.4f}\")\n        \n        # Best model 추적\n        if rouge_scores['rouge-l'] > best_rouge_l:\n            best_rouge_l = rouge_scores['rouge-l']\n            best_epoch = epoch\n            \n            # 모델 저장 (설정된 경우)\n            if config['kfold']['save_each_fold']:\n                output_dir = get_path(config['paths']['output_dir'])\n                output_dir.mkdir(parents=True, exist_ok=True)\n                model_path = output_dir / f'fold_{fold_idx}_best_model.pt'\n                torch.save(model.state_dict(), model_path)\n                logger.write(f\"  Saved best model for fold {fold_idx}\")\n    \n    return best_rouge_l, fold_history\n\nlogger.write(\"Train fold function defined\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# WandB 초기화\nif config['wandb']['mode'] != 'disabled':\n    wandb.init(\n        project=config['wandb']['project'],\n        entity=config['wandb']['entity'],\n        name=config['wandb']['name'],\n        tags=config['wandb']['tags'],\n        config=config\n    )\n    logger.write(\"WandB initialized for K-Fold experiment\")\n\n# 모델 및 토크나이저 초기화 (한 번만)\nlogger.write(f\"\\nInitializing model: {config['model']['name']}\")\ntokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\nlogger.write(\"Tokenizer loaded\")\n\n# K-Fold 메인 학습 루프\nall_fold_results = []\nall_fold_histories = []\n\nlogger.write(\"\\n\" + \"=\"*50)\nlogger.write(\"Starting K-Fold Cross Validation\")\nlogger.write(\"=\"*50)\n\nfor fold_idx, (train_idx, val_idx) in enumerate(kfold.split(train_df), 1):\n    logger.write(f\"\\n{'='*30}\")\n    logger.write(f\"FOLD {fold_idx}/{config['kfold']['n_splits']}\")\n    logger.write(f\"{'='*30}\")\n    \n    # GPU 캐시 정리\n    if config['gpu']['empty_cache_between_folds'] and torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        gc.collect()\n        logger.write(\"GPU cache cleared\")\n    \n    # Fold 데이터 분할\n    fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n    fold_val_df = train_df.iloc[val_idx].reset_index(drop=True)\n    \n    logger.write(f\"Fold {fold_idx} data split: Train={len(fold_train_df)}, Val={len(fold_val_df)}\")\n    \n    # 데이터셋 생성\n    train_dataset = DialogueSummaryDataset(\n        fold_train_df, \n        tokenizer,\n        max_input_len=config['model']['max_input_length'],\n        max_target_len=config['model']['max_target_length']\n    )\n    \n    val_dataset = DialogueSummaryDataset(\n        fold_val_df,\n        tokenizer,\n        max_input_len=config['model']['max_input_length'],\n        max_target_len=config['model']['max_target_length']\n    )\n    \n    # DataLoader 생성\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['training']['batch_size'],\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['training']['batch_size'],\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # 모델 초기화 (각 Fold마다 새로운 모델)\n    model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n    logger.write(f\"Model initialized for fold {fold_idx}\")\n    \n    # Fold 학습\n    best_rouge_l, fold_history = train_fold(\n        model, train_loader, val_loader, tokenizer, fold_idx, config\n    )\n    \n    # 결과 저장\n    fold_result = {\n        'fold': fold_idx,\n        'best_rouge_l': best_rouge_l,\n        'train_size': len(fold_train_df),\n        'val_size': len(fold_val_df)\n    }\n    all_fold_results.append(fold_result)\n    all_fold_histories.append(fold_history)\n    \n    logger.write(f\"\\nFold {fold_idx} completed - Best ROUGE-L: {best_rouge_l:.4f}\")\n    \n    # WandB 로깅\n    if config['wandb']['mode'] != 'disabled':\n        wandb.log({\n            f'fold_{fold_idx}_rouge_l': best_rouge_l,\n            f'fold_{fold_idx}_train_loss': fold_history['train_loss'][-1],\n            f'fold_{fold_idx}_val_loss': fold_history['val_loss'][-1]\n        })\n    \n    # 메모리 정리\n    del model, train_dataset, val_dataset, train_loader, val_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n\nlogger.write(\"\\n\" + \"=\"*50)\nlogger.write(\"K-Fold Cross Validation Completed\")\nlogger.write(\"=\"*50)"
  },
  {
   "cell_type": "markdown",
   "source": "## K-Fold 결과 분석 및 앙상블",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# K-Fold 결과 분석\nlogger.write(\"\\n\" + \"=\"*50)\nlogger.write(\"K-FOLD RESULTS ANALYSIS\")\nlogger.write(\"=\"*50)\n\n# 결과 DataFrame 생성\nresults_df = pd.DataFrame(all_fold_results)\nlogger.write(\"\\nFold Results:\")\nlogger.write(results_df.to_string())\n\n# 통계 계산\nmean_rouge = results_df['best_rouge_l'].mean()\nstd_rouge = results_df['best_rouge_l'].std()\nmin_rouge = results_df['best_rouge_l'].min()\nmax_rouge = results_df['best_rouge_l'].max()\n\nlogger.write(f\"\\n{'='*30}\")\nlogger.write(\"ROUGE-L Statistics:\")\nlogger.write(f\"  Mean: {mean_rouge:.4f}\")\nlogger.write(f\"  Std:  {std_rouge:.4f}\")\nlogger.write(f\"  Min:  {min_rouge:.4f}\")\nlogger.write(f\"  Max:  {max_rouge:.4f}\")\nlogger.write(f\"  95% CI: [{mean_rouge - 1.96*std_rouge:.4f}, {mean_rouge + 1.96*std_rouge:.4f}]\")\nlogger.write(f\"{'='*30}\")\n\n# WandB 로깅\nif config['wandb']['mode'] != 'disabled':\n    wandb.log({\n        'kfold_mean_rouge_l': mean_rouge,\n        'kfold_std_rouge_l': std_rouge,\n        'kfold_min_rouge_l': min_rouge,\n        'kfold_max_rouge_l': max_rouge\n    })",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 시각화\nfrom src.utils.visualizations.training_viz import TrainingVisualizer\n\nviz = TrainingVisualizer()\n\n# 시각화 저장 경로\nviz_dir = get_path(config.get('paths', {}).get('visualization_dir', 'visualizations'))\nviz_dir.mkdir(parents=True, exist_ok=True)\n\n# K-Fold 결과 시각화\nif len(all_fold_results) > 0:\n    # Fold별 ROUGE-L 점수를 위한 데이터 준비\n    fold_rouge_scores = [{'rouge-l': r['best_rouge_l']} for r in all_fold_results]\n    \n    # K-Fold 결과 플롯\n    viz.plot_kfold_results(\n        fold_rouge_scores,\n        save_path=viz_dir / f'kfold_{config[\"kfold\"][\"n_splits\"]}fold_results.png'\n    )\n    \n    logger.write(f\"Visualization saved to {viz_dir}\")\n\n# 결과 저장 (JSON)\nimport json\n\nresults_summary = {\n    'config': config,\n    'fold_results': all_fold_results,\n    'statistics': {\n        'mean_rouge_l': float(mean_rouge),\n        'std_rouge_l': float(std_rouge),\n        'min_rouge_l': float(min_rouge),\n        'max_rouge_l': float(max_rouge)\n    },\n    'timestamp': timestamp\n}\n\nresults_path = log_dir / f'kfold_results_{timestamp}.json'\nwith open(results_path, 'w', encoding='utf-8') as f:\n    json.dump(results_summary, f, indent=4, ensure_ascii=False)\n\nlogger.write(f\"\\nResults saved to {results_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 앙상블 예측 생성 (설정된 경우)\nif config['kfold'].get('generate_ensemble_predictions', False):\n    logger.write(\"\\n\" + \"=\"*50)\n    logger.write(\"GENERATING ENSEMBLE PREDICTIONS\")\n    logger.write(\"=\"*50)\n    \n    # 테스트 데이터 로드\n    test_path = get_data_path(config['paths']['test_file'])\n    test_df = pd.read_csv(test_path)\n    logger.write(f\"Test data loaded: {len(test_df)} samples\")\n    \n    # 테스트 데이터셋\n    test_dataset = DialogueSummaryDataset(\n        test_df,\n        tokenizer,\n        max_input_len=config['model']['max_input_length'],\n        max_target_len=config['model']['max_target_length'],\n        is_test=True\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=config['inference']['batch_size'],\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # 각 Fold 모델로 예측 생성\n    all_fold_predictions = []\n    \n    output_dir = get_path(config['paths']['output_dir'])\n    \n    for fold_idx in range(1, config['kfold']['n_splits'] + 1):\n        model_path = output_dir / f'fold_{fold_idx}_best_model.pt'\n        \n        if model_path.exists():\n            logger.write(f\"\\nLoading fold {fold_idx} model...\")\n            \n            # 모델 로드\n            model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n            model.load_state_dict(torch.load(model_path))\n            model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n            model.eval()\n            \n            # 예측 생성\n            fold_predictions = []\n            \n            with torch.no_grad():\n                for batch in tqdm(test_loader, desc=f'Fold {fold_idx} predictions'):\n                    input_ids = batch['input_ids'].to(model.device)\n                    attention_mask = batch['attention_mask'].to(model.device)\n                    \n                    generated_ids = model.generate(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        max_length=config['inference']['max_length'],\n                        num_beams=config['inference']['num_beams'],\n                        early_stopping=config['inference']['early_stopping'],\n                        no_repeat_ngram_size=config['inference']['no_repeat_ngram_size']\n                    )\n                    \n                    preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n                    fold_predictions.extend(preds)\n            \n            all_fold_predictions.append(fold_predictions)\n            logger.write(f\"  Generated {len(fold_predictions)} predictions\")\n            \n            # 메모리 정리\n            del model\n            torch.cuda.empty_cache()\n            gc.collect()\n    \n    # 앙상블 (간단한 투표 방식)\n    if len(all_fold_predictions) > 0:\n        logger.write(f\"\\nEnsembling {len(all_fold_predictions)} fold predictions...\")\n        \n        ensemble_predictions = []\n        for i in range(len(test_df)):\n            # 각 fold의 예측 수집\n            fold_preds = [fold_pred[i] for fold_pred in all_fold_predictions]\n            \n            # 가장 빈번한 예측 선택 (간단한 투표)\n            # 실제로는 더 정교한 앙상블 방법 사용 가능\n            from collections import Counter\n            most_common = Counter(fold_preds).most_common(1)[0][0]\n            ensemble_predictions.append(most_common)\n        \n        # 제출 파일 생성\n        submission_df = pd.DataFrame({\n            'fname': test_df['fname'],\n            'summary': ensemble_predictions\n        })\n        \n        submission_dir = get_path(config['paths']['submission_dir'])\n        submission_dir.mkdir(parents=True, exist_ok=True)\n        \n        submission_path = submission_dir / f'kfold_ensemble_submission_{timestamp}.csv'\n        # index=True로 설정하여 인덱스를 포함시킴\n        submission_df.to_csv(submission_path, index=True, encoding='utf-8')  # index=False -> index=True로 변경\n        \n        logger.write(f\"\\nEnsemble submission saved to {submission_path}\")\n        logger.write(f\"Shape: {submission_df.shape}\")\n    else:\n        logger.write(\"\\nNo fold models found for ensemble prediction\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 앙상블 예측 생성 (설정된 경우)\nif config['kfold'].get('generate_ensemble_predictions', False):\n    logger.write(\"\\n\" + \"=\"*50)\n    logger.write(\"GENERATING ENSEMBLE PREDICTIONS\")\n    logger.write(\"=\"*50)\n    \n    # 테스트 데이터 로드\n    test_path = get_data_path(config['paths']['test_file'])\n    test_df = pd.read_csv(test_path)\n    logger.write(f\"Test data loaded: {len(test_df)} samples\")\n    \n    # 테스트 데이터셋\n    test_dataset = DialogueSummaryDataset(\n        test_df,\n        tokenizer,\n        max_input_len=config['model']['max_input_length'],\n        max_target_len=config['model']['max_target_length'],\n        is_test=True\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=config['inference']['batch_size'],\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # 각 Fold 모델로 예측 생성\n    all_fold_predictions = []\n    \n    output_dir = get_path(config['paths']['output_dir'])\n    \n    for fold_idx in range(1, config['kfold']['n_splits'] + 1):\n        model_path = output_dir / f'fold_{fold_idx}_best_model.pt'\n        \n        if model_path.exists():\n            logger.write(f\"\\nLoading fold {fold_idx} model...\")\n            \n            # 모델 로드\n            model = BartForConditionalGeneration.from_pretrained(config['model']['name'])\n            model.load_state_dict(torch.load(model_path))\n            model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n            model.eval()\n            \n            # 예측 생성\n            fold_predictions = []\n            \n            with torch.no_grad():\n                for batch in tqdm(test_loader, desc=f'Fold {fold_idx} predictions'):\n                    input_ids = batch['input_ids'].to(model.device)\n                    attention_mask = batch['attention_mask'].to(model.device)\n                    \n                    generated_ids = model.generate(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        max_length=config['inference']['max_length'],\n                        num_beams=config['inference']['num_beams'],\n                        early_stopping=config['inference']['early_stopping'],\n                        no_repeat_ngram_size=config['inference']['no_repeat_ngram_size']\n                    )\n                    \n                    preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n                    fold_predictions.extend(preds)\n            \n            all_fold_predictions.append(fold_predictions)\n            logger.write(f\"  Generated {len(fold_predictions)} predictions\")\n            \n            # 메모리 정리\n            del model\n            torch.cuda.empty_cache()\n            gc.collect()\n    \n    # 앙상블 (간단한 투표 방식)\n    if len(all_fold_predictions) > 0:\n        logger.write(f\"\\nEnsembling {len(all_fold_predictions)} fold predictions...\")\n        \n        ensemble_predictions = []\n        for i in range(len(test_df)):\n            # 각 fold의 예측 수집\n            fold_preds = [fold_pred[i] for fold_pred in all_fold_predictions]\n            \n            # 가장 빈번한 예측 선택 (간단한 투표)\n            # 실제로는 더 정교한 앙상블 방법 사용 가능\n            from collections import Counter\n            most_common = Counter(fold_preds).most_common(1)[0][0]\n            ensemble_predictions.append(most_common)\n        \n        # 제출 파일 생성\n        submission_df = pd.DataFrame({\n            'id': test_df['id'],\n            'summary': ensemble_predictions\n        })\n        \n        submission_dir = get_path(config['paths']['submission_dir'])\n        submission_dir.mkdir(parents=True, exist_ok=True)\n        \n        submission_path = submission_dir / f'kfold_ensemble_submission_{timestamp}.csv'\n        submission_df.to_csv(submission_path, index=False, encoding='utf-8')\n        \n        logger.write(f\"\\nEnsemble submission saved to {submission_path}\")\n        logger.write(f\"Shape: {submission_df.shape}\")\n    else:\n        logger.write(\"\\nNo fold models found for ensemble prediction\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 최종 요약\nlogger.write(\"\\n\" + \"=\"*50)\nlogger.write(\"K-FOLD CROSS VALIDATION SUMMARY\")\nlogger.write(\"=\"*50)\nlogger.write(f\"Model: {config['model']['name']}\")\nlogger.write(f\"Folds: {config['kfold']['n_splits']}\")\nlogger.write(f\"Mean ROUGE-L: {mean_rouge:.4f} (±{std_rouge:.4f})\")\nlogger.write(f\"Best Fold: {results_df.loc[results_df['best_rouge_l'].idxmax(), 'fold']}\")\nlogger.write(f\"Best Score: {max_rouge:.4f}\")\nlogger.write(f\"Worst Fold: {results_df.loc[results_df['best_rouge_l'].idxmin(), 'fold']}\")\nlogger.write(f\"Worst Score: {min_rouge:.4f}\")\n\nif config['kfold']['save_each_fold']:\n    logger.write(f\"\\nFold models saved to: {output_dir}\")\n\nlogger.write(f\"\\nLog file: {log_file}\")\nlogger.write(\"=\"*50)\n\n# WandB 종료\nif config['wandb']['mode'] != 'disabled':\n    wandb.summary['kfold_final_mean_rouge'] = mean_rouge\n    wandb.summary['kfold_final_std_rouge'] = std_rouge\n    wandb.finish()\n\nlogger.write(\"\\n✅ K-Fold Cross Validation completed successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}