# ============================================================================
# 다중 모델 앙상블 설정 파일
# ============================================================================
# 용도: 5개 다양한 모델을 활용한 앙상블 전략으로 성능 극대화
# 설명: 각 모델의 강점을 결합하여 단일 모델보다 높은 성능 달성
# 최종 수정: 2025-10-10
# ============================================================================

# ----------------------------------------------------------------------------
# 경로 설정 (Path Configuration)
# ----------------------------------------------------------------------------
paths:
  data_dir: "../../../data/raw"  # 원본 데이터 디렉토리 경로 (상대 경로)
  train_file: "../../../data/raw/train.csv"  # 학습 데이터 파일 경로
  dev_file: "../../../data/raw/dev.csv"  # 검증 데이터 파일 경로
  test_file: "../../../data/raw/test.csv"  # 테스트 데이터 파일 경로
  output_dir: "./models/multi_model"  # 다중 모델 저장 디렉토리 (모델별 하위 폴더)
  log_dir: "./logs/multi_model"  # 로그 파일 저장 디렉토리 (모델별 로그 포함)
  submission_dir: "./submissions/multi_model"  # 제출 파일 저장 디렉토리
  visualization_dir: "./logs/multi_model/visualizations"  # 시각화 파일 저장 디렉토리
  cache_dir: "./cache/multi_model"  # 캐시 데이터 저장 디렉토리

# ----------------------------------------------------------------------------
# 앙상블 모델 구성 (Ensemble Models Configuration)
# ----------------------------------------------------------------------------
ensemble_models:
  # ===== 모델 1: SOLAR (최고 성능) =====
  solar:
    name: "upstage/SOLAR-10.7B-Instruct-v1.0"  # 모델 이름 (Upstage SOLAR 10.7B)
    weight: 0.30  # 앙상블 가중치 (30%, 가장 높은 비중)
    enabled: true  # 모델 사용 여부 (true: 사용, false: 비활성화)
    use_lora: true  # LoRA 사용 여부 (대형 LLM은 LoRA 권장)

    # LoRA 설정
    lora_config:
      r: 16  # LoRA rank (저랭크 분해 차원)
      alpha: 32  # LoRA alpha (스케일링 파라미터, r의 2배)
      dropout: 0.1  # LoRA dropout 비율 (10% 드롭아웃)

    load_in_8bit: true  # 8비트 양자화 로딩 (메모리 절약)
    max_length: 1024  # 최대 시퀀스 길이 (토큰 단위)

  # ===== 모델 2: Polyglot-Ko =====
  polyglot:
    name: "EleutherAI/polyglot-ko-12.8b"  # 모델 이름 (Polyglot Korean 12.8B)
    weight: 0.25  # 앙상블 가중치 (25%, 두 번째로 높은 비중)
    enabled: true  # 모델 사용 여부
    use_lora: true  # LoRA 사용 여부

    # LoRA 설정
    lora_config:
      r: 8  # LoRA rank (SOLAR보다 작게 설정)
      alpha: 16  # LoRA alpha (r의 2배)
      dropout: 0.05  # LoRA dropout 비율 (5%, 낮은 드롭아웃)

    load_in_8bit: true  # 8비트 양자화 로딩
    max_length: 1024  # 최대 시퀀스 길이

  # ===== 모델 3: KULLM-v2 =====
  kullm:
    name: "nlpai-lab/kullm-v2"  # 모델 이름 (Korea University LLM v2)
    weight: 0.20  # 앙상블 가중치 (20%)
    enabled: true  # 모델 사용 여부
    use_lora: true  # LoRA 사용 여부

    # LoRA 설정
    lora_config:
      r: 8  # LoRA rank
      alpha: 16  # LoRA alpha
      dropout: 0.1  # LoRA dropout 비율 (10%)

    load_in_4bit: true  # 4비트 양자화 로딩 (8비트보다 더 공격적인 양자화)
    max_length: 768  # 최대 시퀀스 길이 (다른 모델보다 짧음)

  # ===== 모델 4: KoBART =====
  kobart:
    name: "digit82/kobart-summarization"  # 모델 이름 (한국어 BART)
    weight: 0.15  # 앙상블 가중치 (15%)
    enabled: true  # 모델 사용 여부
    use_lora: false  # LoRA 미사용 (BART는 Encoder-Decoder이므로 전체 파인튜닝)
    model_type: "seq2seq"  # 모델 타입 (seq2seq: Sequence-to-Sequence)
    max_length: 512  # 최대 시퀀스 길이 (BART는 상대적으로 짧음)

  # ===== 모델 5: KoAlpaca =====
  koalpaca:
    name: "beomi/KoAlpaca-Polyglot-12.8B"  # 모델 이름 (KoAlpaca)
    weight: 0.10  # 앙상블 가중치 (10%, 가장 낮은 비중)
    enabled: true  # 모델 사용 여부
    use_lora: true  # LoRA 사용 여부

    # LoRA 설정
    lora_config:
      r: 8  # LoRA rank
      alpha: 16  # LoRA alpha
      dropout: 0.1  # LoRA dropout 비율 (10%)

    load_in_8bit: true  # 8비트 양자화 로딩
    max_length: 768  # 최대 시퀀스 길이

# ----------------------------------------------------------------------------
# 앙상블 전략 (Ensemble Strategy)
# ----------------------------------------------------------------------------
ensemble_strategy:
  # ===== 기본 앙상블 방법 =====
  method: "weighted_average"  # 앙상블 방법 (weighted_average: 가중 평균, voting: 투표, stacking: 스태킹, blending: 블렌딩)

  # ===== Weighted Average 설정 =====
  weighted_average:
    normalize_weights: true  # 가중치 정규화 여부 (합이 1이 되도록)
    optimization_metric: "rouge_l"  # 가중치 최적화 시 사용할 메트릭 (ROUGE-L)

  # ===== Voting 설정 =====
  voting:
    type: "soft"  # 투표 타입 (soft: 확률 기반, hard: 다수결)
    threshold: 0.5  # 임계값 (0.5 = 50% 이상 동의 시 채택)

  # ===== Stacking 설정 =====
  stacking:
    meta_model: "ridge"  # 메타 모델 (ridge: Ridge 회귀, lgbm: LightGBM, neural_network: 신경망)
    cv_folds: 3  # 교차 검증 Fold 수 (3-Fold CV)
    use_probabilities: true  # 확률 사용 여부 (true: 확률 벡터 사용, false: 예측값만 사용)

  # ===== Blending 설정 =====
  blending:
    validation_ratio: 0.2  # 검증 데이터 비율 (20%를 블렌딩 학습에 사용)
    blend_features:  # 블렌딩에 사용할 특성 목록
      - "rouge_scores"  # ROUGE 점수
      - "confidence"  # 모델 신뢰도
      - "length_ratio"  # 길이 비율

# ----------------------------------------------------------------------------
# TTA (Test Time Augmentation) 설정
# ----------------------------------------------------------------------------
tta:
  enabled: true  # TTA 활성화 여부 (추론 시 다양한 변형 생성)
  num_augmentations: 3  # 증강 개수 (각 샘플당 3개의 변형 생성)

  # ===== 증강 기법 =====
  techniques:
    # 의역 (Paraphrase)
    paraphrase:
      enabled: true  # 의역 활성화 여부
      model: "lcw99/t5-base-korean-paraphrase"  # 사용할 의역 모델
      num_variants: 2  # 생성할 의역 변형 개수

    # 문장 재배열 (Reorder)
    reorder:
      enabled: true  # 재배열 활성화 여부
      preserve_meaning: true  # 의미 보존 여부 (중요한 문장 순서는 유지)
      max_permutations: 2  # 최대 순열 개수 (2개의 재배열 변형)

    # 동의어 치환 (Synonym)
    synonym:
      enabled: false  # 동의어 치환 비활성화 (한국어 동의어 사전 필요)
      similarity_threshold: 0.8  # 유사도 임계값 (0.8 이상만 치환)

  aggregation: "mean"  # 증강 결과 집계 방법 (mean: 평균, median: 중앙값, max: 최대값)

# ----------------------------------------------------------------------------
# 학습 설정 (Training Configuration)
# ----------------------------------------------------------------------------
training:
  seed: 42  # 랜덤 시드 (재현성 보장)
  num_epochs: 3  # 학습 에폭 수 (각 모델별)
  batch_size: 4  # GPU당 배치 크기 (대형 모델은 작은 배치 사용)
  gradient_accumulation_steps: 8  # 그래디언트 누적 스텝 (실제 배치 = 4 × 8 = 32)
  learning_rate: 2e-5  # 학습률 (2 × 10^-5)
  warmup_ratio: 0.1  # Warmup 비율 (전체 스텝의 10%)
  weight_decay: 0.01  # 가중치 감쇠 (L2 정규화)

  # ===== 병렬/순차 학습 설정 =====
  parallel_training: false  # 병렬 학습 여부 (true: 모든 모델 동시 학습, GPU 여러 개 필요)
  sequential_training: true  # 순차 학습 여부 (true: 모델을 하나씩 순차적으로 학습)

  # ===== 조기 종료 설정 =====
  early_stopping_patience: 2  # 조기 종료 인내 횟수 (2 epoch 동안 개선 없으면 중단)
  early_stopping_threshold: 0.001  # 조기 종료 임계값 (0.001 미만 개선은 무시)

  # ===== Mixed Precision 설정 =====
  fp16: true  # FP16 학습 활성화 (메모리 절약, 속도 향상)
  gradient_checkpointing: true  # 그래디언트 체크포인팅 (메모리 절약)

# ----------------------------------------------------------------------------
# 추론 설정 (Inference Configuration)
# ----------------------------------------------------------------------------
inference:
  batch_size: 8  # 추론 배치 크기 (학습보다 크게 설정 가능)

  # ===== 각 모델별 생성 설정 =====
  generation_config:
    max_new_tokens: 150  # 생성할 최대 토큰 수
    min_length: 20  # 생성 최소 길이 (너무 짧은 요약 방지)
    num_beams: 4  # Beam Search 빔 개수
    no_repeat_ngram_size: 3  # 반복 방지 n-gram 크기 (3-gram 반복 금지)
    temperature: 0.7  # 샘플링 온도 (0.7 = 약간 창의적)
    top_p: 0.9  # Nucleus 샘플링 (누적 확률 90% 이내)
    do_sample: true  # 샘플링 사용 여부 (true: 확률적 생성)

  # ===== 앙상블 추론 설정 =====
  ensemble_inference:
    run_parallel: true  # 병렬 추론 여부 (true: 모든 모델 동시 추론, 속도 향상)
    timeout: 60  # 모델당 최대 추론 시간 (60초, 초과 시 타임아웃)
    fallback_on_error: true  # 실패 시 대체 전략 (true: 실패한 모델 제외하고 계속)

# ----------------------------------------------------------------------------
# 평가 설정 (Evaluation Configuration)
# ----------------------------------------------------------------------------
evaluation:
  # ===== 평가 메트릭 =====
  metrics:  # 사용할 평가 메트릭 목록
    - "rouge"  # ROUGE 점수 (요약 품질 평가)
    - "bleu"  # BLEU 점수 (기계 번역 메트릭, 요약에도 사용)
    - "meteor"  # METEOR 점수 (의미 기반 평가)

  # ===== 평가 범위 =====
  evaluate_individual: true  # 개별 모델 평가 여부 (각 모델의 성능 측정)
  evaluate_ensemble: true  # 앙상블 평가 여부 (최종 앙상블 성능 측정)

  # ===== 모델 선택 기준 =====
  model_selection:
    metric: "rouge_l"  # 모델 선택 메트릭 (ROUGE-L 기준)
    select_top_k: 3  # 상위 K개 모델만 선택 (상위 3개 모델만 최종 앙상블에 사용)

# ----------------------------------------------------------------------------
# Solar API 비교 (Solar API Comparison)
# ----------------------------------------------------------------------------
solar_api_comparison:
  enabled: true  # Solar API 비교 활성화 여부
  api_key: "up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT"  # Solar API 인증 키
  model: "solar-1-mini-chat"  # 사용할 Solar 모델 (경량 모델)
  use_as_baseline: true  # 베이스라인으로 사용 여부 (다른 모델과 비교 기준)
  include_in_ensemble: false  # 앙상블에 포함 여부 (false: API는 비교만, 앙상블 미포함)

# ----------------------------------------------------------------------------
# Solar API 설정 (PRD 09, 10 - 교차 검증 시스템)
# ----------------------------------------------------------------------------
solar_api:
  api_key: "up_rMJWNzzBi6YsD47RhwXPWZrZ0JKsT"  # Solar API 인증 키
  enabled: true  # Solar API 사용 여부
  base_url: "https://api.upstage.ai/v1/solar"  # Solar API 기본 URL
  model: "solar-1-mini-chat"  # 사용할 Solar 모델
  max_tokens: 150  # 생성 최대 토큰 수
  temperature: 0.3  # 샘플링 온도 (0.3 = 매우 결정적)
  top_p: 0.9  # Nucleus 샘플링 임계값
  timeout: 30  # API 요청 타임아웃 (초 단위)

# ----------------------------------------------------------------------------
# WandB 설정 (Weights & Biases)
# ----------------------------------------------------------------------------
wandb:
  project: "nlp-competition"  # WandB 프로젝트 이름
  entity: "ieyeppo"  # WandB 엔티티 (사용자/팀 이름)
  name: "multi-model-ensemble"  # 실험 이름
  tags:  # 실험 태그 (검색 및 필터링용)
    - "ensemble"  # 앙상블 실험
    - "multi_model"  # 다중 모델
    - "tta"  # Test Time Augmentation
  notes: "5개 모델 앙상블 + TTA"  # 실험 설명
  mode: "online"  # 로깅 모드 (online: 실시간, offline: 로컬)

  # ===== 개별 모델 로깅 =====
  log_individual_models: true  # 각 모델별로 개별 로그 기록
  group: "ensemble_experiment"  # 실험 그룹 (같은 그룹의 실험을 함께 볼 수 있음)

# ----------------------------------------------------------------------------
# 로깅 설정 (Logging Configuration)
# ----------------------------------------------------------------------------
logging:
  level: "INFO"  # 로그 레벨 (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  format: "%(asctime)s - [%(model)s] - %(name)s - %(levelname)s - %(message)s"  # 로그 포맷 (모델 이름 포함)
  save_to_file: true  # 파일로 로그 저장 여부
  log_every_n_steps: 50  # N 스텝마다 로그 출력
  use_notebook_logger: true  # 노트북 전용 로거 사용 여부
  notebook_logger_path: "../../../src/logging/notebook_logger.py"  # 노트북 로거 경로

  # ===== 모델별 로그 분리 =====
  separate_model_logs: true  # 모델별로 개별 로그 파일 생성 (solar.log, polyglot.log, ...)

# ----------------------------------------------------------------------------
# GPU 설정 (GPU Configuration)
# ----------------------------------------------------------------------------
gpu:
  device: "cuda"  # 사용할 디바이스 (cuda: GPU, cpu: CPU)
  cuda_device: 0  # 사용할 CUDA 디바이스 번호 (0번 GPU)
  mixed_precision: true  # Mixed Precision 학습 활성화 (FP16)
  memory_fraction: 0.95  # GPU 메모리 사용 비율 (0.95 = 95%)

  # ===== 멀티 GPU 설정 (사용 가능한 경우) =====
  multi_gpu:
    enabled: false  # 멀티 GPU 사용 여부 (false: 단일 GPU 사용)
    device_ids: [0, 1]  # 사용할 GPU ID 목록 (0번, 1번 GPU)
    strategy: "dp"  # 병렬화 전략 (dp: DataParallel, ddp: DistributedDataParallel)

  # ===== 메모리 관리 =====
  empty_cache_between_models: true  # 모델 간 GPU 메모리 정리 (메모리 누수 방지)
  use_gpu_optimization: true  # GPU 최적화 기능 사용 여부
  gpu_check_path: "../../../src/utils/gpu_optimization/team_gpu_check.py"  # GPU 체크 스크립트 경로

# ----------------------------------------------------------------------------
# 실험 추적 (Experiment Tracking)
# ----------------------------------------------------------------------------
experiment:
  name: "ensemble_5models_tta"  # 실험 고유 이름
  description: "5개 모델 앙상블 + TTA 전략"  # 실험 설명
  version: "1.0.0"  # 실험 버전
  timestamp: true  # 타임스탬프 자동 추가 여부

  # ===== 결과 저장 =====
  save_individual_predictions: true  # 개별 모델 예측 결과 저장
  save_ensemble_predictions: true  # 앙상블 예측 결과 저장
  save_voting_details: true  # 투표 상세 정보 저장 (각 모델의 투표 내역)

# ----------------------------------------------------------------------------
# 분석 및 시각화 (Analysis & Visualization)
# ----------------------------------------------------------------------------
analysis:
  # ===== 분석 옵션 =====
  correlation_analysis: true  # 모델 간 상관관계 분석 (어떤 모델들이 비슷한 예측을 하는지)
  contribution_analysis: true  # 모델별 기여도 분석 (어떤 모델이 성능 향상에 가장 기여했는지)
  difficult_samples_analysis: true  # 어려운 샘플 분석 (모든 모델이 실패한 샘플 식별)

  # ===== 시각화 목록 =====
  visualizations:  # 생성할 시각화 목록
    - "model_performance_comparison"  # 모델별 성능 비교 그래프
    - "ensemble_weight_distribution"  # 앙상블 가중치 분포 그래프
    - "correlation_heatmap"  # 모델 간 상관관계 히트맵
    - "tta_effect_analysis"  # TTA 효과 분석 그래프
    - "error_analysis"  # 오류 분석 그래프

# ----------------------------------------------------------------------------
# Optuna 최적화 설정 (앙상블 가중치)
# ----------------------------------------------------------------------------
optuna:
  enabled: true  # Optuna 하이퍼파라미터 최적화 활성화
  n_trials: 50  # 시도 횟수 (50회 탐색)
  study_name: "ensemble_weight_optimization"  # 연구 이름
  storage: "sqlite:///optuna_ensemble.db"  # 결과 저장 데이터베이스 (SQLite)
  direction: "maximize"  # 최적화 방향 (maximize: 최대화, minimize: 최소화)
  metric: "rouge_l"  # 최적화 목표 메트릭 (ROUGE-L 최대화)

  # ===== 최적화할 파라미터 =====
  optimize:  # 최적화 대상 파라미터 목록
    - "model_weights"  # 모델별 앙상블 가중치
    - "generation_params"  # 생성 파라미터 (temperature, top_p 등)
    - "tta_num_augmentations"  # TTA 증강 개수
